{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using MLP model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import time\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3775, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaknesses are minor the feel and layout of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many of our disney movies do n 't play on this...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player has a problem with dual layer dvd 's su...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i know the saying is you get what you pay for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will never purchase apex again .</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>so far , the anti spam feature seems to be ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>i did not have any of the installation problem...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>their products have been great and have saved ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3775 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     weaknesses are minor the feel and layout of th...      0  train\n",
       "1     many of our disney movies do n 't play on this...      0  train\n",
       "2     player has a problem with dual layer dvd 's su...      0  train\n",
       "3     i know the saying is you get what you pay for ...      0  train\n",
       "4                      will never purchase apex again .      0  train\n",
       "...                                                 ...    ...    ...\n",
       "3770  so far , the anti spam feature seems to be ver...      1  train\n",
       "3771  i downloaded a trial version of computer assoc...      1  train\n",
       "3772  i did not have any of the installation problem...      1  train\n",
       "3773  their products have been great and have saved ...      1  train\n",
       "3774                                                         1  train\n",
       "\n",
       "[3775 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../0_data/CR/CR.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3775 entries, 0 to 3774\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  3775 non-null   object\n",
      " 1   label     3775 non-null   int32 \n",
      " 2   split     3775 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 73.9+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2407</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          1368   1368\n",
       "1          2407   2407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Number of Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The vocabulary size: 5334\n",
      "\n",
      "{'the': 1, 'and': 2, 'i': 3, 'it': 4, 'to': 5, 'a': 6, 'is': 7, 'of': 8, 'this': 9, 'with': 10, 'for': 11, 'you': 12, 'that': 13, 'in': 14, 'have': 15, 'but': 16, 'not': 17, 'on': 18, 'my': 19, \"'t\": 20, 'as': 21, \"'s\": 22, 'are': 23, 'very': 24, 'can': 25, 'was': 26, 'use': 27, 'camera': 28, 'player': 29, 'all': 30, 'has': 31, 'phone': 32, 'great': 33, 'one': 34, 'be': 35, 'so': 36, 'at': 37, 'if': 38, 'good': 39, 'easy': 40, 'quality': 41, 'or': 42, 'up': 43, 'from': 44, 'no': 45, 'like': 46, 'an': 47, 'than': 48, 'had': 49, 'just': 50, 'battery': 51, 'get': 52, 'about': 53, 'when': 54, 'software': 55, 'only': 56, 'your': 57, 'ipod': 58, 'would': 59, 'which': 60, 'well': 61, 'they': 62, 'also': 63, 'more': 64, 'sound': 65, 'there': 66, 'me': 67, 'n': 68, 'other': 69, 'do': 70, 'will': 71, 'out': 72, 'does': 73, 'any': 74, \"'ve\": 75, 'features': 76, 'its': 77, 'zen': 78, 'router': 79, 'even': 80, 'some': 81, 'really': 82, 'by': 83, 'better': 84, 'after': 85, 'work': 86, 'creative': 87, 'time': 88, 'price': 89, 'problems': 90, 'little': 91, 'much': 92, 'product': 93, '2': 94, 'pictures': 95, 'too': 96, 'best': 97, 'most': 98, 'problem': 99, 'been': 100, 'what': 101, 'am': 102, '1': 103, 'still': 104, 'small': 105, 'dvd': 106, 'because': 107, 'music': 108, \"'m\": 109, 'nice': 110, 'used': 111, 'screen': 112, 'did': 113, 'works': 114, 'excellent': 115, 'now': 116, 'first': 117, 'thing': 118, 'using': 119, '3': 120, 'play': 121, 'their': 122, 'we': 123, 'over': 124, 'diaper': 125, 'don': 126, 'while': 127, 'far': 128, 'love': 129, 'could': 130, 'buy': 131, 'many': 132, 'picture': 133, 'life': 134, 'find': 135, 'bit': 136, 'take': 137, 'micro': 138, 'size': 139, 'digital': 140, 'computer': 141, 'then': 142, '4': 143, 'files': 144, 'them': 145, 'hard': 146, 'need': 147, 'into': 148, 'songs': 149, 'got': 150, 'want': 151, 'mp3': 152, 'way': 153, 'without': 154, 'feature': 155, 'lot': 156, 'new': 157, 'two': 158, 'were': 159, 'cd': 160, 'support': 161, 'enough': 162, 'long': 163, 'off': 164, '5': 165, 'how': 166, 'easily': 167, 'people': 168, 'through': 169, 'few': 170, 'everything': 171, 'takes': 172, 'make': 173, 'pretty': 174, 'since': 175, 'seems': 176, 'overall': 177, 'comes': 178, 'case': 179, 'champ': 180, 'nokia': 181, 'read': 182, 'say': 183, 'think': 184, 'interface': 185, 'big': 186, 'before': 187, 'service': 188, 'button': 189, 'speed': 190, 'light': 191, 'norton': 192, 'never': 193, 'looking': 194, 'go': 195, 'quite': 196, 'down': 197, 'manual': 198, 'another': 199, 'getting': 200, 'recommend': 201, 'mode': 202, 'made': 203, 'fast': 204, 'zoom': 205, 'apex': 206, 'video': 207, 'times': 208, 'fine': 209, 'however': 210, 'canon': 211, 'design': 212, 'user': 213, 'right': 214, 'buttons': 215, 'found': 216, 'hours': 217, 'tried': 218, 'unit': 219, 'back': 220, 'less': 221, 'see': 222, 'though': 223, 'controls': 224, 'nomad': 225, 'ever': 226, 'etc': 227, 'bought': 228, 'same': 229, 'scroll': 230, 't': 231, 'device': 232, 'radio': 233, 'perfect': 234, 'happy': 235, 'every': 236, 'anything': 237, 'working': 238, 'looks': 239, 'fact': 240, 'system': 241, 'give': 242, 'fm': 243, 'control': 244, 'who': 245, 'look': 246, 'windows': 247, 'included': 248, 'pc': 249, 'doesn': 250, 'should': 251, 'something': 252, 'touch': 253, \"'\": 254, 'program': 255, 'simple': 256, 'cool': 257, 'bags': 258, 'players': 259, 'able': 260, \"'re\": 261, 'although': 262, 'those': 263, 'day': 264, 'audio': 265, 'lcd': 266, 'pocket': 267, 'having': 268, 'put': 269, 'awesome': 270, 'power': 271, 'money': 272, 'set': 273, 'g3': 274, 'once': 275, 'internet': 276, 'know': 277, 'keep': 278, 'worked': 279, 'start': 280, 'card': 281, 'high': 282, 'around': 283, 'purchase': 284, 'again': 285, 'customer': 286, 'always': 287, 'months': 288, 'being': 289, 'free': 290, 'makes': 291, 'usb': 292, 'drive': 293, 'wireless': 294, 'bluetooth': 295, 'such': 296, 'almost': 297, 'especially': 298, 'month': 299, 'come': 300, 'lens': 301, 'photos': 302, 'memory': 303, 'things': 304, 'transfer': 305, 'plus': 306, 'mobile': 307, 'actually': 308, 'bad': 309, 'clear': 310, 'number': 311, 'where': 312, 'both': 313, \"'d\": 314, 'headphones': 315, 'setup': 316, 'storage': 317, 'installation': 318, 'diapers': 319, 'phones': 320, 'pleased': 321, \"'ll\": 322, 'second': 323, 'yet': 324, 'flash': 325, 'version': 326, 'linksys': 327, 'weeks': 328, 'took': 329, 'days': 330, 'line': 331, 'color': 332, 'these': 333, 'install': 334, 'wheel': 335, 'full': 336, 'low': 337, 'old': 338, 'stars': 339, 'reviews': 340, '10': 341, 'quick': 342, 'slow': 343, 'going': 344, 'menu': 345, 'built': 346, 'auto': 347, 'products': 348, 'settings': 349, 'different': 350, 'purchased': 351, 'sure': 352, 'deal': 353, 'open': 354, 'cameras': 355, 'highly': 356, 'intuitive': 357, 'firmware': 358, 'apple': 359, 'volume': 360, 'security': 361, 'remote': 362, 'must': 363, 'plays': 364, 'amazon': 365, '6': 366, 'point': 367, 'here': 368, 'hand': 369, 'own': 370, 'options': 371, 'amazing': 372, 'display': 373, 'tech': 374, 'mine': 375, 'cheap': 376, 'extra': 377, 'either': 378, 'compact': 379, 'itunes': 380, 'voice': 381, 'pail': 382, 'years': 383, 'finally': 384, 'already': 385, 'feels': 386, 'bag': 387, 'xtra': 388, 'gb': 389, 'seen': 390, 'easier': 391, 'market': 392, 'setting': 393, 'dvds': 394, 'worth': 395, 'smell': 396, 'probably': 397, 'store': 398, 'access': 399, 'compared': 400, 'last': 401, 'machine': 402, 'turn': 403, 'shots': 404, 'image': 405, 'change': 406, 'ability': 407, 'jack': 408, 'large': 409, 'headphone': 410, 'reception': 411, 'allows': 412, 'feel': 413, 'file': 414, 'playing': 415, 'thought': 416, 'experience': 417, 'top': 418, 'extremely': 419, 'why': 420, 'may': 421, '2004': 422, 'came': 423, 'itself': 424, 'click': 425, 'difficult': 426, 'decent': 427, 'mediasource': 428, 'charge': 429, 'odor': 430, 'table': 431, 'box': 432, 'hold': 433, 'several': 434, 'real': 435, 'regular': 436, 'disc': 437, 'via': 438, 'least': 439, 'didn': 440, 'menus': 441, 'away': 442, 'taking': 443, 'photo': 444, 'games': 445, 'definitely': 446, 'download': 447, 'quickly': 448, 'ones': 449, 'else': 450, 'signal': 451, 'week': 452, 'help': 453, 'impressed': 454, 'focus': 455, 'nikon': 456, 'images': 457, 'sometimes': 458, 'function': 459, 'between': 460, 'taken': 461, 'range': 462, 'smaller': 463, 'song': 464, 'earbuds': 465, 'running': 466, 'hitachi': 467, '6600': 468, 'media': 469, 'close': 470, 'tiny': 471, 'larger': 472, 'connection': 473, 'seconds': 474, 'optical': 475, 'solid': 476, 'gives': 477, 'blue': 478, 'said': 479, 'ok': 480, 'kind': 481, 'cable': 482, 'option': 483, 'symantec': 484, 'our': 485, 'lots': 486, 'seem': 487, 'annoying': 488, 'white': 489, 'inside': 490, 'end': 491, 'e': 492, 'load': 493, 'sleek': 494, 'installed': 495, 'available': 496, 'owned': 497, 'adjustment': 498, 'expensive': 499, 'major': 500, 'needs': 501, '8': 502, 'car': 503, 'process': 504, 'simply': 505, 'year': 506, 'wma': 507, 'ease': 508, 'network': 509, 'cost': 510, 'perfectly': 511, 'mini': 512, 'space': 513, 'anyone': 514, 'speakerphone': 515, 'fits': 516, 'movies': 517, 'run': 518, 'given': 519, 'played': 520, 'others': 521, 'nothing': 522, 'trash': 523, 'front': 524, 'expect': 525, 'sony': 526, 'instead': 527, 'viewfinder': 528, 'cover': 529, 'gets': 530, 'rather': 531, 'lock': 532, 'loud': 533, 'isn': 534, 'wonderful': 535, 'pics': 536, 'side': 537, 'person': 538, 'useful': 539, 'absolutely': 540, 'capacity': 541, 'refills': 542, 'won': 543, 'holds': 544, 'cds': 545, 'gave': 546, 'unfortunately': 547, 'job': 548, 'went': 549, 'tell': 550, 'uses': 551, 'disappointed': 552, '12': 553, 'connect': 554, 'com': 555, 'somewhat': 556, 'wrong': 557, 'understand': 558, 'issue': 559, 'batteries': 560, 'huge': 561, 'during': 562, 'plastic': 563, 'shoot': 564, 'issues': 565, 'shutter': 566, 'weight': 567, 'next': 568, 'short': 569, '0': 570, 'playlists': 571, 'might': 572, 'navigate': 573, 'fit': 574, 'data': 575, 'comfortable': 576, 'genie': 577, 'home': 578, 'listen': 579, 'standard': 580, 'baby': 581, 'normal': 582, 'christmas': 583, 'room': 584, 'believe': 585, 'special': 586, 'trying': 587, 'reason': 588, 'within': 589, 'dont': 590, 'main': 591, 'bright': 592, 'designed': 593, 'online': 594, 'construction': 595, 'yes': 596, 'review': 597, 'due': 598, 'automatic': 599, 'clip': 600, 'navigation': 601, 'minutes': 602, 'based': 603, 'artist': 604, 'explorer': 605, 'eax': 606, 'live': 607, 'remove': 608, 'collection': 609, 'flip': 610, 'pad': 611, 'replaceable': 612, 'removable': 613, 'plenty': 614, 'stop': 615, 'pop': 616, 'wo': 617, 'calls': 618, 'ago': 619, 'noise': 620, 'sharp': 621, 'sync': 622, 'black': 623, 'favorite': 624, 'useless': 625, 'maybe': 626, 'seemed': 627, 'try': 628, 'adjust': 629, 'unlike': 630, 'flaw': 631, 'sd500': 632, 'xp': 633, 'id3': 634, 'album': 635, 'ear': 636, 'area': 637, 'company': 638, 'programs': 639, 'complaints': 640, 'piece': 641, 'smooth': 642, 'value': 643, 'colors': 644, 'hands': 645, 'speaker': 646, 'recorder': 647, 'firewall': 648, 'beautiful': 649, 'stand': 650, 'longer': 651, 'web': 652, 'course': 653, 'couple': 654, 'site': 655, 'completely': 656, 'otherwise': 657, 'dirty': 658, 'rate': 659, 'left': 660, 'myself': 661, 'automatically': 662, 'past': 663, 'heavy': 664, '7': 665, 'format': 666, 'buying': 667, 'carry': 668, 'except': 669, 'choice': 670, 'resolution': 671, '30': 672, 'let': 673, 'modes': 674, 'instructions': 675, 'drop': 676, 'liked': 677, 'mentioned': 678, 'superior': 679, 'connected': 680, 'despite': 681, 'giving': 682, 'convenient': 683, 'whole': 684, 'downloaded': 685, 'haven': 686, 'needed': 687, 'bits': 688, 'tool': 689, 'upgrade': 690, 'average': 691, '6610': 692, 'call': 693, 'tuner': 694, 'antivirus': 695, 'w': 696, 'fantastic': 697, 'pay': 698, 'non': 699, 'model': 700, '50': 701, 'half': 702, 'clean': 703, 'friends': 704, 'press': 705, 's': 706, 'kept': 707, 'update': 708, 'slightly': 709, 'external': 710, 'slr': 711, 'operate': 712, 'complaint': 713, 'raw': 714, 'wanted': 715, 'depth': 716, 'done': 717, 'bottom': 718, 'fairly': 719, 'macro': 720, 'balance': 721, 'accessories': 722, 'jukebox': 723, 'friendly': 724, 'portable': 725, '20': 726, 'stuck': 727, 'folder': 728, 'tags': 729, 'tracks': 730, 'satisfied': 731, '40': 732, 'level': 733, 'unless': 734, 'plug': 735, 'making': 736, 'adapter': 737, 'garbage': 738, 'above': 739, 'performance': 740, 'mac': 741, 'hardware': 742, 'wrt54g': 743, 'powerful': 744, 'functions': 745, 'nis': 746, 'offers': 747, 'r': 748, '2600': 749, 'period': 750, 'hot': 751, 'goes': 752, 'properly': 753, 'none': 754, 'disk': 755, 'received': 756, 'disappointment': 757, 'star': 758, 'website': 759, 'three': 760, 'perhaps': 761, 'previous': 762, 'looked': 763, 'quiet': 764, 'weak': 765, 'record': 766, 'per': 767, 'sensitive': 768, 'bar': 769, 'dropped': 770, 'switch': 771, 'genre': 772, 'durable': 773, 'sounds': 774, 'gotten': 775, 'order': 776, 'ripping': 777, 'serious': 778, 'handle': 779, 'stick': 780, 'single': 781, 'couldn': 782, 'priority': 783, 'opinion': 784, 'outlook': 785, 'important': 786, 'learn': 787, 'ringtones': 788, 'anywhere': 789, 'm12v': 790, 'mp3s': 791, 'started': 792, 'discs': 793, 'consider': 794, 'type': 795, 'recognize': 796, 'strong': 797, 'matter': 798, 'usually': 799, 'list': 800, 'email': 801, 'basically': 802, 'flimsy': 803, 'five': 804, 'cheaper': 805, 'multiple': 806, 'scan': 807, 'doing': 808, 'awkward': 809, 'turned': 810, 'trouble': 811, 'reading': 812, 'considering': 813, 'whether': 814, 'lack': 815, 'replace': 816, 'lower': 817, 'downside': 818, 'reviewers': 819, 'functionality': 820, 'often': 821, 'true': 822, 'exposure': 823, 'bigger': 824, 'key': 825, 'folders': 826, 'changing': 827, 'replacement': 828, 'os': 829, 'warranty': 830, 'under': 831, 'biggest': 832, 'until': 833, 'track': 834, 'mention': 835, 'napster': 836, 'models': 837, 'computers': 838, 'panel': 839, '40gb': 840, 'lasts': 841, 'means': 842, 'upon': 843, 'knob': 844, 'plunge': 845, 'guide': 846, 'package': 847, 'along': 848, 'possible': 849, 'night': 850, 'applications': 851, 'dialing': 852, 'relatively': 853, 'runs': 854, 'glad': 855, 'results': 856, 'outstanding': 857, 'stuff': 858, 'minor': 859, 'answer': 860, 'item': 861, 'opening': 862, 'information': 863, '90': 864, 'movie': 865, 'certain': 866, 'everyone': 867, 'tv': 868, 'moment': 869, 'called': 870, 'each': 871, 'poor': 872, 'hour': 873, 'hear': 874, 'example': 875, 'house': 876, 'manually': 877, 'allow': 878, 'dial': 879, 'bother': 880, 'sort': 881, 'clips': 882, 'advanced': 883, 'move': 884, 'place': 885, 'spare': 886, 'push': 887, 'cons': 888, 'forward': 889, 'break': 890, 'pro': 891, 'operating': 892, 'totally': 893, 'expected': 894, 'stylish': 895, 'window': 896, 'services': 897, 'belt': 898, 'devices': 899, 'near': 900, 'among': 901, 'recording': 902, 'mind': 903, 'laptop': 904, 'anyway': 905, 'care': 906, 'class': 907, 'leave': 908, 'positive': 909, 'recently': 910, 'soft': 911, 'clarity': 912, 'configuration': 913, 'wants': 914, 'supports': 915, 'impressive': 916, 'packed': 917, 'check': 918, 'keys': 919, 'megapixel': 920, 'exceptional': 921, 'costs': 922, 'fun': 923, 'incredible': 924, 'beat': 925, 's100': 926, 'kitchen': 927, '4300': 928, 'show': 929, '3x': 930, 'constantly': 931, 'busy': 932, 'today': 933, 'occasionally': 934, 'hassle': 935, 'higher': 936, 'junk': 937, 'sent': 938, 'negative': 939, 'ad': 940, 'sucks': 941, 'view': 942, 'error': 943, 'broken': 944, 'imagine': 945, 'addition': 946, 'wide': 947, 'elph': 948, 'terrible': 949, 'flat': 950, 'sturdy': 951, 'exactly': 952, 'part': 953, '15': 954, 'shot': 955, 'someone': 956, 'charger': 957, 'fully': 958, 'worst': 959, 'operation': 960, 'face': 961, 'hit': 962, 'installing': 963, 'clearly': 964, 'cut': 965, 'ready': 966, 'labs': 967, 'variable': 968, 'ac': 969, 'breeze': 970, 'replaced': 971, 'carrying': 972, 'third': 973, 'recharge': 974, 'personal': 975, 'older': 976, 'loved': 977, 'supplied': 978, 'learning': 979, 'listening': 980, 'sized': 981, 'effective': 982, 'following': 983, 'stay': 984, 'combination': 985, 'required': 986, 'he': 987, 'alot': 988, 'us': 989, 'necessary': 990, 'wouldn': 991, 'basic': 992, 'formats': 993, 'including': 994, 'send': 995, 'subscription': 996, 'transfers': 997, 'pda': 998, 'modem': 999, 'book': 1000, 'cell': 1001, 'backlight': 1002, 'reasonable': 1003, 'red': 1004, 'pros': 1005, '2003': 1006, 'super': 1007, 'amazed': 1008, 'scene': 1009, 'ive': 1010, 'decided': 1011, 'saying': 1012, 'contact': 1013, 'died': 1014, 'door': 1015, 'turns': 1016, 'spent': 1017, 'emails': 1018, 'neither': 1019, 'discovered': 1020, 'hate': 1021, 'entire': 1022, 'poorly': 1023, 'freezes': 1024, 'freeze': 1025, 'calling': 1026, 'incredibly': 1027, 'numerous': 1028, 'output': 1029, 'instant': 1030, 'miss': 1031, 'wait': 1032, 'feet': 1033, 'glitches': 1034, 'navigating': 1035, 'build': 1036, 'plate': 1037, 'silver': 1038, 'accurate': 1039, 'mostly': 1040, 'cap': 1041, 'cause': 1042, 'hope': 1043, 'produces': 1044, 'world': 1045, 'general': 1046, 'shooting': 1047, 'sites': 1048, 'dark': 1049, 'yourself': 1050, 'manage': 1051, 'firewire': 1052, 'generally': 1053, 'straight': 1054, 'frustrating': 1055, 'party': 1056, 'search': 1057, 'actual': 1058, 'figure': 1059, 'bass': 1060, 'complicated': 1061, 'listed': 1062, 'doubt': 1063, 'terms': 1064, 'equalizer': 1065, 'provide': 1066, 'rip': 1067, 'name': 1068, 'encountered': 1069, 'ways': 1070, 'notmad': 1071, 'durability': 1072, '100': 1073, '14': 1074, 'lid': 1075, 'below': 1076, 'collet': 1077, 'finish': 1078, 'son': 1079, 'electronic': 1080, 'documentation': 1081, 'together': 1082, 'nearly': 1083, 'stupid': 1084, 'touchpad': 1085, 'wasn': 1086, 'personally': 1087, 'gig': 1088, 'similar': 1089, 'transferring': 1090, 'include': 1091, 'organizer': 1092, 'charging': 1093, 'info': 1094, 'directly': 1095, 'talk': 1096, 'mmc': 1097, 'saw': 1098, 'tones': 1099, 'ring': 1100, 'scratched': 1101, 'keypad': 1102, 'infrared': 1103, 'ipods': 1104, 'metal': 1105, 'helpful': 1106, 'updates': 1107, 'flawlessly': 1108, 'nicely': 1109, 'oh': 1110, 'powershot': 1111, '11': 1112, 'toy': 1113, 'prints': 1114, 'technology': 1115, 'neat': 1116, 'beats': 1117, 'pod': 1118, 'equipment': 1119, 'speakers': 1120, 'mb': 1121, 'calendar': 1122, '4x': 1123, 'game': 1124, 'responsive': 1125, 'broke': 1126, 'return': 1127, '60': 1128, 'tend': 1129, 'professional': 1130, 'literally': 1131, 'family': 1132, 'knows': 1133, 'defective': 1134, '24': 1135, 'eventually': 1136, 'shows': 1137, 'lasted': 1138, '9': 1139, 'failed': 1140, 'waiting': 1141, 'worse': 1142, 'bucks': 1143, 'keeps': 1144, 'recent': 1145, 'address': 1146, 'jpeg': 1147, 'doesnt': 1148, 'correctly': 1149, 'finding': 1150, 'loading': 1151, 'gift': 1152, 'playback': 1153, 'scratch': 1154, 'save': 1155, 'scratches': 1156, 'reliable': 1157, 'brand': 1158, 'updated': 1159, 'visible': 1160, 'four': 1161, 'finger': 1162, 'situations': 1163, 'action': 1164, 'ugly': 1165, 'processing': 1166, 'focusing': 1167, 'body': 1168, 'strap': 1169, 'parts': 1170, 'twice': 1171, 'print': 1172, 'adjustments': 1173, 'awful': 1174, 'tons': 1175, 'eye': 1176, 'lithium': 1177, 'turning': 1178, 'impossible': 1179, 'holding': 1180, 'compatible': 1181, 'drivers': 1182, 'create': 1183, 'application': 1184, 'aren': 1185, 'fingers': 1186, 'ed': 1187, 'suck': 1188, 'users': 1189, 'overly': 1190, 'instruction': 1191, 'transfering': 1192, 'idea': 1193, 'shut': 1194, 'fly': 1195, 'become': 1196, 'cumbersome': 1197, 'asked': 1198, 'downloads': 1199, 'travel': 1200, 'band': 1201, 'mean': 1202, 'palm': 1203, 'albums': 1204, 'nx': 1205, 'requires': 1206, 'willing': 1207, 'hang': 1208, 'advertised': 1209, 'added': 1210, 'charged': 1211, 'locked': 1212, 'spend': 1213, 'wider': 1214, 'noticed': 1215, 'stinky': 1216, 'latest': 1217, 'killer': 1218, 'routers': 1219, 're': 1220, 'seriously': 1221, 'wizard': 1222, 'currently': 1223, 'browser': 1224, 'novice': 1225, '11b': 1226, 'onto': 1227, 'trip': 1228, 'charges': 1229, 'loaded': 1230, 'original': 1231, 'tunes': 1232, 'initially': 1233, 'alternative': 1234, 'buck': 1235, 'pick': 1236, 'his': 1237, '20gb': 1238, 'indoor': 1239, 'lighting': 1240, '35mm': 1241, 'priced': 1242, 'bang': 1243, 'boot': 1244, 'samsung': 1245, 'motorola': 1246, 'nokias': 1247, 'rebate': 1248, '70': 1249, 'text': 1250, 'heard': 1251, 'headset': 1252, 'proprietary': 1253, 'suite': 1254, 'uninstall': 1255, 'spam': 1256, 'dell': 1257, 'provided': 1258, 'anti': 1259, 'affordable': 1260, 'stored': 1261, 'attractive': 1262, 'photography': 1263, '4mp': 1264, 'truly': 1265, 'detail': 1266, 'add': 1267, 'terrific': 1268, 'superb': 1269, 'comfortably': 1270, 'worry': 1271, 'prefer': 1272, 'everywhere': 1273, 'ratio': 1274, 'bonus': 1275, 'odors': 1276, 'stereo': 1277, 'layout': 1278, 'complete': 1279, 'technical': 1280, 'tells': 1281, 'freezing': 1282, 'telephone': 1283, 'beginning': 1284, 'crap': 1285, 'spin': 1286, '1st': 1287, 'message': 1288, '25': 1289, 'frequently': 1290, 'difference': 1291, 'starts': 1292, 'leaving': 1293, 'questions': 1294, 'naturally': 1295, 'mail': 1296, 'www': 1297, 'present': 1298, 'proven': 1299, 'hell': 1300, 'forget': 1301, 'immediately': 1302, 'motor': 1303, 'absolute': 1304, 'progressive': 1305, 'hooked': 1306, 'produced': 1307, 'distance': 1308, 'rw': 1309, 'vcd': 1310, 'backlit': 1311, 'bulky': 1312, 'b': 1313, 'loose': 1314, 'damage': 1315, 'disappointing': 1316, 'sold': 1317, 'knew': 1318, 'casing': 1319, 'capture': 1320, 'flashes': 1321, 'horrible': 1322, 'rarely': 1323, 'appearance': 1324, 'limited': 1325, 'autofocus': 1326, 'share': 1327, 'research': 1328, 'manipulate': 1329, 'bring': 1330, 'hardly': 1331, 'luck': 1332, 'max': 1333, 'fix': 1334, 'photoshop': 1335, 'stock': 1336, 'select': 1337, 'pops': 1338, 'creating': 1339, 'mp': 1340, 'result': 1341, 'titles': 1342, 'inferior': 1343, 'uncomfortable': 1344, 'various': 1345, 'desk': 1346, 'transferred': 1347, 'selection': 1348, 'protection': 1349, 'appears': 1350, 'bundled': 1351, 'definately': 1352, 'library': 1353, 'enjoy': 1354, 'sense': 1355, 'eq': 1356, 'confusing': 1357, 'harder': 1358, 'concern': 1359, 'missing': 1360, 'complain': 1361, 'playlist': 1362, 'numbers': 1363, 'integrated': 1364, 'paid': 1365, 'plan': 1366, 'protective': 1367, 'tag': 1368, 'flaws': 1369, 'ripped': 1370, 'experienced': 1371, 'tough': 1372, 'amount': 1373, 'road': 1374, 'zero': 1375, 'popping': 1376, 'curve': 1377, 'notice': 1378, 'extended': 1379, 'besides': 1380, 'forth': 1381, 'mess': 1382, 'outside': 1383, 'particularly': 1384, 'empty': 1385, 'thumb': 1386, 'improved': 1387, 'helps': 1388, 'edge': 1389, 'practically': 1390, 'barely': 1391, 'height': 1392, 'reach': 1393, 'wood': 1394, 'wrench': 1395, 'plunging': 1396, 'hp': 1397, 'purchasing': 1398, 'held': 1399, 'cables': 1400, 'adequate': 1401, 'corporate': 1402, 'linux': 1403, 'likely': 1404, 'worthless': 1405, 'net': 1406, 'word': 1407, 'bugs': 1408, 'speeds': 1409, 'offered': 1410, 'carrier': 1411, 'iriver': 1412, 'usage': 1413, 'style': 1414, 'delete': 1415, 'refund': 1416, 'pair': 1417, 'points': 1418, 'stations': 1419, 'normally': 1420, 'apart': 1421, '200': 1422, 'mega': 1423, 'previously': 1424, 'microphone': 1425, 'slower': 1426, 'editing': 1427, 'terribly': 1428, 't610': 1429, 'against': 1430, 'u': 1431, 'contacts': 1432, 'gprs': 1433, 'midi': 1434, 'coverage': 1435, 'presets': 1436, 'lasting': 1437, 'arm': 1438, 'microsoft': 1439, 'components': 1440, 'virus': 1441, 'variety': 1442, 'log': 1443, 'shipping': 1444, 'form': 1445, 'broadband': 1446, 'slim': 1447, 'panasonic': 1448, 'ups': 1449, 'details': 1450, 'faster': 1451, 'aperture': 1452, 'versatile': 1453, 'laid': 1454, 'enjoyed': 1455, 'ii': 1456, 'date': 1457, 'her': 1458, 'upgraded': 1459, 'advantage': 1460, 'shuffle': 1461, 'handy': 1462, 'rocks': 1463, 'compatibility': 1464, 'lets': 1465, 'source': 1466, 'alarm': 1467, 'toddler': 1468, 'fell': 1469, 'strength': 1470, 'cute': 1471, 'array': 1472, 'java': 1473, 'handsfree': 1474, 'polyphonic': 1475, 'names': 1476, 'behind': 1477, 'middle': 1478, 'okay': 1479, 'pause': 1480, 'placed': 1481, 'displayed': 1482, 'viewing': 1483, 'total': 1484, 'yesterday': 1485, 'ten': 1486, 'occasional': 1487, 'forever': 1488, 'stopped': 1489, 'signals': 1490, 'coming': 1491, 'obviously': 1492, 'respond': 1493, 'later': 1494, 'nor': 1495, 'ask': 1496, 'pressing': 1497, 'department': 1498, 'catch': 1499, 'extras': 1500, 'moving': 1501, 'tries': 1502, 'successfully': 1503, 'hook': 1504, 'soon': 1505, 'repeatedly': 1506, 'closed': 1507, 'significant': 1508, 'ringing': 1509, 'friend': 1510, 'drawback': 1511, 'printed': 1512, 'potential': 1513, 'limitations': 1514, 'lag': 1515, 'blurry': 1516, 'consistently': 1517, 'heavier': 1518, 'metering': 1519, 'fragile': 1520, 'corner': 1521, 'distortion': 1522, 'places': 1523, 'cracked': 1524, 'shake': 1525, 'sensitivity': 1526, 'agree': 1527, 'robust': 1528, 'head': 1529, 'inconvenient': 1530, 'silent': 1531, 'subject': 1532, 'steady': 1533, 'grip': 1534, 'functional': 1535, '98': 1536, 'backup': 1537, 'kodak': 1538, 'wife': 1539, 'levels': 1540, 'pdf': 1541, 'readable': 1542, 'cards': 1543, 'reset': 1544, 'par': 1545, 'zennx': 1546, '3rd': 1547, 'earphones': 1548, 'greatest': 1549, 'accessing': 1550, 'tad': 1551, 'con': 1552, 'title': 1553, 'reboot': 1554, 'painless': 1555, 'jog': 1556, 'easiest': 1557, 'future': 1558, 'pain': 1559, 'lit': 1560, 'crashes': 1561, 'kbps': 1562, 'yeah': 1563, 'mediocre': 1564, 'tagging': 1565, 'organized': 1566, 'books': 1567, 'database': 1568, 'covers': 1569, 'starting': 1570, 'musicmatch': 1571, '400': 1572, 'copy': 1573, 'bunch': 1574, 'sounding': 1575, 'covered': 1576, 'tightly': 1577, 'dollars': 1578, 'attach': 1579, 'state': 1580, 'created': 1581, 'business': 1582, 'archos': 1583, 'reasonably': 1584, 'morning': 1585, 'wipes': 1586, 'bundle': 1587, 'fill': 1588, 'wrap': 1589, 'pull': 1590, 'gone': 1591, 'raised': 1592, 'freehand': 1593, 'mounted': 1594, 'benefit': 1595, 'improvement': 1596, 'mechanism': 1597, 'housing': 1598, 'reasons': 1599, 'sliding': 1600, 'helped': 1601, 'jump': 1602, 'double': 1603, 'current': 1604, 'equipped': 1605, 'losing': 1606, 'desktop': 1607, 'buggy': 1608, 'configure': 1609, 'suggest': 1610, 'mins': 1611, 'drops': 1612, 'prices': 1613, 'boy': 1614, 'pass': 1615, 'negatives': 1616, 'hasn': 1617, 'audible': 1618, 'port': 1619, 'karma': 1620, 'spectacular': 1621, '00': 1622, 'reliability': 1623, 'wav': 1624, 'thats': 1625, 'worried': 1626, 'advice': 1627, 'location': 1628, 'selected': 1629, 'buds': 1630, 'step': 1631, 'rechargable': 1632, 'correct': 1633, 'cellphone': 1634, 'areas': 1635, 'loss': 1636, 'gadgets': 1637, '800': 1638, 'regret': 1639, 'server': 1640, 'fond': 1641, 'messaging': 1642, '99': 1643, 'rings': 1644, 'activated': 1645, 'sending': 1646, 'id': 1647, 'versions': 1648, 'default': 1649, '18': 1650, 'popular': 1651, 'moveable': 1652, 'gym': 1653, '300': 1654, 'thus': 1655, '16': 1656, 'systemworks': 1657, 'registry': 1658, 'enormous': 1659, 'edition': 1660, 'aside': 1661, 'solutions': 1662, '95': 1663, 'nortron': 1664, 'ram': 1665, 'modern': 1666, 'happier': 1667, 'investment': 1668, 'videos': 1669, 'surprised': 1670, 'factor': 1671, 'owner': 1672, 'mixed': 1673, 'notch': 1674, 'recommended': 1675, 'lense': 1676, 'flexibility': 1677, 'photographer': 1678, 'highest': 1679, 'ideal': 1680, 'reputation': 1681, 'film': 1682, 'decision': 1683, 'dream': 1684, 'shape': 1685, 'edges': 1686, 'sharper': 1687, 'delivers': 1688, 'camcorder': 1689, 'competition': 1690, 'operates': 1691, 'rich': 1692, 'timer': 1693, 'boasts': 1694, 'crystal': 1695, '500': 1696, 'wherever': 1697, 'compression': 1698, 'across': 1699, 'unbelievably': 1700, 'saver': 1701, 'degree': 1702, 'pack': 1703, 'keeping': 1704, 'performs': 1705, 'guy': 1706, 'complained': 1707, 'drag': 1708, 'unbeatable': 1709, '38': 1710, 'wise': 1711, 'ton': 1712, 'follow': 1713, 'clock': 1714, 'dispose': 1715, 'cloth': 1716, 'require': 1717, 'handed': 1718, 'win': 1719, 'stable': 1720, 'provides': 1721, 'connectivity': 1722, 'charm': 1723, 'rechargeable': 1724, 'admit': 1725, 'countries': 1726, 'symbian': 1727, '2x': 1728, 'dual': 1729, 'season': 1730, 'skipping': 1731, 'shortly': 1732, 'kids': 1733, 'blowing': 1734, 'rep': 1735, '80': 1736, 'telling': 1737, 'particular': 1738, 'happened': 1739, 'universal': 1740, 'released': 1741, 'sale': 1742, 'tips': 1743, 'promised': 1744, 'pieces': 1745, 'six': 1746, 'die': 1747, 'watching': 1748, 'rated': 1749, '26': 1750, 'answered': 1751, '27': 1752, 'reads': 1753, 'gripe': 1754, 'meant': 1755, 'component': 1756, 'responding': 1757, 'occasions': 1758, 'quit': 1759, 'connections': 1760, 'p': 1761, 'confused': 1762, '45': 1763, '2nd': 1764, 'chapter': 1765, 'thinking': 1766, 'post': 1767, 'parents': 1768, 'nicer': 1769, 'inexpensive': 1770, 'damaged': 1771, 'base': 1772, 'consumer': 1773, 'angle': 1774, 'darn': 1775, 'partially': 1776, 'surely': 1777, 'accidently': 1778, 'achieve': 1779, 'cf': 1780, '512': 1781, 'please': 1782, 'barrel': 1783, 'finder': 1784, 'round': 1785, 'pockets': 1786, 'subjects': 1787, 'stunning': 1788, 's330': 1789, 'pricey': 1790, 'sd': 1791, 'purple': 1792, 'icons': 1793, 'nature': 1794, 'cnet': 1795, 'meg': 1796, '256': 1797, 'station': 1798, 'length': 1799, 'zooms': 1800, 'unable': 1801, 'situation': 1802, 'delay': 1803, 'yield': 1804, 'accurately': 1805, '640x480': 1806, 'dynamic': 1807, 'casio': 1808, 'watch': 1809, 'sticks': 1810, 'sub': 1811, 'beef': 1812, 'structure': 1813, 'stores': 1814, 'man': 1815, 'concerned': 1816, 'directory': 1817, 'genres': 1818, 'driver': 1819, 'belkin': 1820, 'skip': 1821, 'obvious': 1822, 'ridiculous': 1823, 'material': 1824, 'odd': 1825, 'screwed': 1826, 'crashed': 1827, 'sit': 1828, 'rates': 1829, 'organize': 1830, 'receiver': 1831, 'delicate': 1832, 'common': 1833, 'rapidly': 1834, 'custom': 1835, 'bookmarks': 1836, 'purpose': 1837, 'identical': 1838, 'fails': 1839, 'traveling': 1840, 'slip': 1841, 'virtually': 1842, 'guess': 1843, 'static': 1844, 'documents': 1845, 'launched': 1846, 'words': 1847, 'additional': 1848, 'noticeable': 1849, '250': 1850, 'prone': 1851, 'albeit': 1852, 'companies': 1853, 'audigy': 1854, 'equally': 1855, 'dropping': 1856, 'marketing': 1857, 'kinda': 1858, 'acceptable': 1859, 'elsewhere': 1860, 'contained': 1861, 'uninstalled': 1862, 'reviewer': 1863, 'continues': 1864, 'sturdier': 1865, 'feedback': 1866, '75': 1867, 'shutting': 1868, 'raise': 1869, 'ended': 1870, 'fail': 1871, 'convinced': 1872, 'daughter': 1873, 'everyday': 1874, 'stink': 1875, 'deeper': 1876, 'medium': 1877, 'effort': 1878, 'poop': 1879, 'she': 1880, 'cleaned': 1881, 'lysol': 1882, 'anymore': 1883, 'saving': 1884, 'intended': 1885, 'art': 1886, 'porter': 1887, 'ms': 1888, 'springs': 1889, 'shop': 1890, 'ears': 1891, 'brought': 1892, 'sloppy': 1893, 'hi': 1894, 'includes': 1895, 'configuring': 1896, 'systems': 1897, 'wep': 1898, 'encryption': 1899, 'wpa': 1900, 'office': 1901, 'environment': 1902, 'stream': 1903, 'local': 1904, 'indeed': 1905, 'wirelessly': 1906, 'write': 1907, 'dlink': 1908, 'link': 1909, 'pages': 1910, 'carefully': 1911, 'alone': 1912, 'cord': 1913, 'separately': 1914, 'minimum': 1915, 'accessory': 1916, 'daily': 1917, 'slight': 1918, 'promise': 1919, 'told': 1920, 'audiophile': 1921, 'standards': 1922, 'continuously': 1923, 'shorter': 1924, 'supposed': 1925, 'antenna': 1926, 'connecting': 1927, 'rio': 1928, 'reboots': 1929, 'stretch': 1930, 'primarily': 1931, 'target': 1932, 'nyc': 1933, 'vertical': 1934, 'gen': 1935, 'es': 1936, 'adjustable': 1937, 'whatever': 1938, 'plugging': 1939, 'outlet': 1940, 'unusable': 1941, 'slightest': 1942, 'park': 1943, 'slowly': 1944, 'affect': 1945, 'unlimited': 1946, 'avoid': 1947, 'lacking': 1948, 'focused': 1949, 'daylight': 1950, 'knowing': 1951, 'newer': 1952, 'primary': 1953, 'vga': 1954, 'apps': 1955, 'joystick': 1956, 'ergonomics': 1957, 'states': 1958, 'grow': 1959, 'dozen': 1960, 'directions': 1961, 'crazy': 1962, 'driving': 1963, 'ericsson': 1964, 'earpiece': 1965, 'smoothly': 1966, 'ex': 1967, 'pixel': 1968, 'syncing': 1969, 'isync': 1970, 'meaning': 1971, 'rebates': 1972, 'usual': 1973, 'rating': 1974, 'disappoint': 1975, 'convert': 1976, 'sprint': 1977, 'items': 1978, 'assumed': 1979, 'zones': 1980, 'demands': 1981, 'vibration': 1982, 'messages': 1983, 'visibility': 1984, 'connector': 1985, 'appear': 1986, 'currency': 1987, 'thumbs': 1988, 'offer': 1989, 'writing': 1990, 'wap': 1991, 'news': 1992, 'remember': 1993, 'chrome': 1994, 'surface': 1995, 'rare': 1996, 'survived': 1997, 'individual': 1998, 'installs': 1999, 'position': 2000, 'headaches': 2001, 'liveupdate': 2002, 'whenever': 2003, 'highs': 2004, 'vs': 2005, 'waited': 2006, 'speak': 2007, 'proof': 2008, 'patience': 2009, 'release': 2010, 'im': 2011, 'hung': 2012, 'av': 2013, 'sources': 2014, 'conclusion': 2015, 'written': 2016, 'unbelievable': 2017, 'antispam': 2018, 'preferences': 2019, 'dead': 2020, 'mainly': 2021, 'rs': 2022, 'latter': 2023, 'him': 2024, 'visual': 2025, 'profile': 2026, 'smart': 2027, 'expectations': 2028, 'known': 2029, 'pioneer': 2030, 'quietly': 2031, 'hd': 2032, 'capabilities': 2033, 'paying': 2034, 'pic': 2035, 'dollar': 2036, 'category': 2037, 'throw': 2038, 'continue': 2039, 'lightweight': 2040, 'g2': 2041, 'choices': 2042, 'digicams': 2043, 'amateur': 2044, 'bargain': 2045, 'megapixels': 2046, 'outdoor': 2047, 'chose': 2048, 'fortunately': 2049, 'met': 2050, 'contrary': 2051, 'produce': 2052, 'surpasses': 2053, 'fabulous': 2054, 'snow': 2055, 'enables': 2056, 'plugged': 2057, 'powered': 2058, 'razor': 2059, 'self': 2060, 'jacket': 2061, 'pants': 2062, 'iso': 2063, 'surprisingly': 2064, 'suprisingly': 2065, 'decently': 2066, 'seamless': 2067, 'colours': 2068, 'eyes': 2069, 'natural': 2070, 'center': 2071, 'res': 2072, 'beginner': 2073, 'wonderfully': 2074, 'panorama': 2075, 'unequivocally': 2076, 'ultra': 2077, 'rugged': 2078, 'waterproof': 2079, 'tft': 2080, 'researched': 2081, 'leather': 2082, 'pouch': 2083, 'plusses': 2084, 'satisfactory': 2085, 'didnt': 2086, 'cinch': 2087, 'sweet': 2088, 'gigs': 2089, 'account': 2090, 'customization': 2091, 'cake': 2092, 'early': 2093, 'replacable': 2094, 'zx': 2095, 'green': 2096, 'wave': 2097, 'wish': 2098, 'slick': 2099, '160': 2100, '000': 2101, 'specs': 2102, 'wake': 2103, 'recharges': 2104, 'choose': 2105, 'scented': 2106, 'saved': 2107, 'tall': 2108, 'south': 2109, 'beast': 2110, 'fence': 2111, 'deep': 2112, 'g': 2113, 'ion': 2114, 'cooler': 2115, 'fortunate': 2116, 'hype': 2117, 'hip': 2118, 'shirt': 2119, 'winner': 2120, '5g': 2121, 'retail': 2122, 'phenomenal': 2123, 'optional': 2124, 'qualities': 2125, 'coolpix': 2126, 'delight': 2127, '512mb': 2128, 'converter': 2129, 'europe': 2130, 'mms': 2131, 'ringtone': 2132, 'wallpapers': 2133, 'receives': 2134, 'gsm': 2135, 'graphics': 2136, 'cycle': 2137, 'sorry': 2138, 'disney': 2139, 'alias': 2140, 'overloaded': 2141, 'began': 2142, 'checking': 2143, 'machines': 2144, 'dept': 2145, 'disposable': 2146, 'air': 2147, 'fan': 2148, 'remotes': 2149, 'conveniently': 2150, 'onscreen': 2151, 'displays': 2152, 'frustration': 2153, 'embarassing': 2154, 'rental': 2155, 'refuses': 2156, 'appeared': 2157, 'toll': 2158, 'recognizes': 2159, 'scenes': 2160, 'internal': 2161, 'board': 2162, 'everybody': 2163, 'ad2600': 2164, 'crappy': 2165, 'enter': 2166, 'bleeding': 2167, 'ch': 2168, 'heck': 2169, 'age': 2170, 'mailing': 2171, 'attempted': 2172, 'claim': 2173, 'reply': 2174, 'response': 2175, 'froze': 2176, 'says': 2177, '866': 2178, 'inc': 2179, 'rented': 2180, 'incident': 2181, 'refused': 2182, 'vivid': 2183, '17': 2184, 'monitor': 2185, 'rca': 2186, 'disks': 2187, 'recognized': 2188, 'shock': 2189, 'faulty': 2190, 'supply': 2191, 'caused': 2192, 'wile': 2193, '28': 2194, 'displaying': 2195, 'dad': 2196, 'inserted': 2197, 'feeling': 2198, 'counter': 2199, 'resulted': 2200, '34': 2201, 'region': 2202, 'closely': 2203, 'spaced': 2204, 'deliver': 2205, 'difficulty': 2206, 'jpegs': 2207, 'diopter': 2208, 'aps': 2209, 'views': 2210, 'blocked': 2211, 'lever': 2212, 'task': 2213, 'dust': 2214, 'grain': 2215, 'locks': 2216, '32': 2217, 'mbyte': 2218, '130': 2219, 'opposed': 2220, 'obstruct': 2221, 'pressed': 2222, 'captures': 2223, 'detract': 2224, '32mb': 2225, 'compactflash': 2226, 'purposes': 2227, 'lost': 2228, 'engineered': 2229, 'minimize': 2230, 'ot': 2231, 'steel': 2232, 'heft': 2233, 'neck': 2234, 'streaks': 2235, '57': 2236, 'showing': 2237, 'conditions': 2238, 'compromises': 2239, 'rebel': 2240, 'stiff': 2241, 'nearest': 2242, 'span': 2243, 'resulting': 2244, 'noisy': 2245, 'matters': 2246, 'overcome': 2247, 'challenge': 2248, 'snapping': 2249, 'realized': 2250, 'stops': 2251, 'originally': 2252, 'soho': 2253, 'forced': 2254, 'export': 2255, 'redeye': 2256, 'fooled': 2257, 'dense': 2258, 'calculator': 2259, 'tricky': 2260, 'themselves': 2261, 'sorts': 2262, 'hangs': 2263, 'flawed': 2264, 'scrolling': 2265, 'match': 2266, 'aesthetic': 2267, 'chinese': 2268, 'pressure': 2269, 'searched': 2270, 'renaming': 2271, 'enclosed': 2272, 'transmitter': 2273, 'locations': 2274, 'success': 2275, 'frustrated': 2276, 'adequately': 2277, 'weighs': 2278, 'ft': 2279, 'hides': 2280, 'division': 2281, 'managed': 2282, 'wouldnt': 2283, 'c': 2284, 'misfortune': 2285, 'f': 2286, 'cash': 2287, 'inconveniences': 2288, 'lacks': 2289, 'encode': 2290, '192': 2291, 'rubber': 2292, 'corners': 2293, 'walkman': 2294, 'necessarily': 2295, 'explain': 2296, 'configured': 2297, 'insert': 2298, 'boost': 2299, 'ounces': 2300, 'isnt': 2301, 'reservations': 2302, 'lists': 2303, 'alphabetical': 2304, 'individually': 2305, 'burner': 2306, 'sexy': 2307, 'creation': 2308, 'eliminated': 2309, 'vastly': 2310, 'clunky': 2311, 'aac': 2312, 'allowing': 2313, 'earlier': 2314, 'receivers': 2315, 'random': 2316, 'pulling': 2317, 'field': 2318, 'wary': 2319, 'readers': 2320, 'catalog': 2321, 'introduce': 2322, 'opened': 2323, 'copied': 2324, 'notebook': 2325, 'indicated': 2326, 'poping': 2327, 'latch': 2328, 'felt': 2329, 'gap': 2330, 'accept': 2331, 'pointed': 2332, 'winxp': 2333, 'organization': 2334, 'unavailable': 2335, 'placement': 2336, 'jukeboxes': 2337, 'consistent': 2338, 'universally': 2339, 'reported': 2340, 'replaces': 2341, 'fixed': 2342, 'regard': 2343, 'disposal': 2344, 'odorless': 2345, 'newborn': 2346, 'refill': 2347, 'messy': 2348, 'hole': 2349, 'costly': 2350, 'lift': 2351, 'plunger': 2352, 'suppose': 2353, 'prepared': 2354, 'tendency': 2355, 'caught': 2356, 'er': 2357, 'registered': 2358, 'leaves': 2359, 'serves': 2360, 'efficient': 2361, 'passes': 2362, 'wash': 2363, 'ours': 2364, 'smelled': 2365, 'floor': 2366, 'tight': 2367, 'fingertips': 2368, 'seal': 2369, 'piston': 2370, 'eliminate': 2371, 'diameter': 2372, 'makita': 2373, 'ain': 2374, 'bells': 2375, 'whistles': 2376, 'crank': 2377, 'distinction': 2378, 'precise': 2379, 'handheld': 2380, 'spindle': 2381, 'chuck': 2382, 'sleeve': 2383, 'noted': 2384, 'attention': 2385, 'seldom': 2386, 'cleaning': 2387, 'critical': 2388, 'activate': 2389, 'muscle': 2390, 'comparable': 2391, 'effect': 2392, 'assist': 2393, 'comment': 2394, 'careful': 2395, 'luckily': 2396, 'begins': 2397, 'disconnecting': 2398, 'input': 2399, 'existing': 2400, 'wired': 2401, 'apparently': 2402, 'briefly': 2403, 'proper': 2404, 'performed': 2405, 'inability': 2406, 'satellite': 2407, 'knowledge': 2408, 'spoke': 2409, 'improves': 2410, 'geek': 2411, 'interruptions': 2412, '802': 2413, 'vague': 2414, 'clumsy': 2415, 'transport': 2416, 'txt': 2417, 'lowest': 2418, 'bare': 2419, 'gross': 2420, 'profiteering': 2421, 'container': 2422, 'constructed': 2423, 'hidden': 2424, 'sable': 2425, 'import': 2426, 'evident': 2427, 'master': 2428, 'leads': 2429, 'dealing': 2430, '1500': 2431, '700': 2432, 'maximum': 2433, 'occasion': 2434, 'snag': 2435, 'bus': 2436, 'ports': 2437, 'hoops': 2438, 'jumped': 2439, 'history': 2440, 'staying': 2441, 'generation': 2442, 'woth': 2443, 'sennheisers': 2444, 'planning': 2445, 'storing': 2446, 'joke': 2447, 'drawbacks': 2448, 'consulting': 2449, 'determined': 2450, 'repair': 2451, 'buyer': 2452, 'puts': 2453, 'booted': 2454, 'burning': 2455, 'seamlessly': 2456, 'wmp': 2457, 'restart': 2458, 'putting': 2459, 'trigger': 2460, 'crash': 2461, 'touchy': 2462, 'heed': 2463, 'hyped': 2464, 'respectable': 2465, 'awe': 2466, 'buzzing': 2467, 'alive': 2468, 'elemenatary': 2469, 'tinker': 2470, 'challenging': 2471, 'yahoo': 2472, 'hazy': 2473, 'photographs': 2474, 'glow': 2475, 'instantly': 2476, 'havent': 2477, 'contrast': 2478, '8mb': 2479, 'lenses': 2480, 'anyhow': 2481, 'processor': 2482, 'excessive': 2483, 'thru': 2484, 'dig': 2485, 'gaming': 2486, 'layered': 2487, 'styling': 2488, 'expandability': 2489, 'transmission': 2490, 'dependability': 2491, 'vast': 2492, 'pdas': 2493, 'acknowledge': 2494, 'technician': 2495, 'technicians': 2496, 'globe': 2497, 'utterly': 2498, 'secondly': 2499, 'crammed': 2500, 'customizable': 2501, 'glance': 2502, 'purse': 2503, 'sides': 2504, 'seemingly': 2505, 'trial': 2506, 'technologies': 2507, 'slot': 2508, 'drawn': 2509, 't720i': 2510, 'solve': 2511, 'recorders': 2512, 'picky': 2513, 'awfully': 2514, 'sufficient': 2515, 'status': 2516, 'approved': 2517, 'delivered': 2518, 'provider': 2519, 'boards': 2520, 'august': 2521, 'plans': 2522, 'portability': 2523, '13': 2524, 'crisp': 2525, 'hearing': 2526, 'reps': 2527, 'pitched': 2528, 'bored': 2529, 'wow': 2530, 'swap': 2531, 'cant': 2532, 'relation': 2533, 'ringer': 2534, 'mm': 2535, 'app': 2536, 'regarding': 2537, 'traditional': 2538, 'zone': 2539, 'manufactured': 2540, 'deleted': 2541, 'talking': 2542, 'h10': 2543, 'liking': 2544, '4th': 2545, 'note': 2546, 'brick': 2547, 'minute': 2548, 'blame': 2549, 'formatted': 2550, 'formatting': 2551, 'changed': 2552, 'lose': 2553, 'falls': 2554, 'inevitable': 2555, 'nuisance': 2556, 'nitrus': 2557, 'whereas': 2558, 'steve': 2559, 'jobs': 2560, 'ruined': 2561, 'realize': 2562, 'cousin': 2563, 'shiny': 2564, 'asking': 2565, 'breaks': 2566, 'prior': 2567, 'scandisk': 2568, 'hr': 2569, 'protects': 2570, 'locking': 2571, 'mastered': 2572, 'appropriate': 2573, 'beyond': 2574, 'updating': 2575, 'importantly': 2576, 'warning': 2577, 'removal': 2578, 'october': 2579, 'assistance': 2580, 'symantect': 2581, 'brings': 2582, 'question': 2583, 'obtain': 2584, 'customers': 2585, 'pathetic': 2586, 'extreme': 2587, 'parental': 2588, '35': 2589, 'exe': 2590, 'virtual': 2591, 'remain': 2592, 'remotely': 2593, 'startup': 2594, 'tab': 2595, 'automated': 2596, '04': 2597, 'blocking': 2598, 'ate': 2599, 'disable': 2600, 'fault': 2601, 'public': 2602, 'handling': 2603, 'uni': 2604, 'registery': 2605, 'fee': 2606, 'vaio': 2607, '150': 2608, '56k': 2609, '2ghz': 2610, 'pentium': 2611, '256mb': 2612, 'suspect': 2613, 'mental': 2614, 'challenges': 2615, 'slows': 2616, 'became': 2617, 'alerts': 2618, 'swear': 2619, 'nicest': 2620, 'svcds': 2621, 'outputs': 2622, 'literature': 2623, 'pitch': 2624, 'mirror': 2625, 'multi': 2626, 'performer': 2627, 'december': 2628, 'slide': 2629, 'accident': 2630, 'mpeg1': 2631, 'mpeg2': 2632, 'american': 2633, 'mpeg': 2634, 'allowed': 2635, 'tested': 2636, 'offering': 2637, '1200': 2638, 'checked': 2639, 'finest': 2640, 'switched': 2641, 'unmatched': 2642, 'myriad': 2643, 'loves': 2644, 'whine': 2645, 'mountain': 2646, 'adds': 2647, 'group': 2648, 'flexible': 2649, 'series': 2650, 'expert': 2651, 'describe': 2652, 'hundreds': 2653, 'spot': 2654, 'semi': 2655, 'fringing': 2656, 'anybody': 2657, 'shoe': 2658, 'ct': 2659, 'dedicated': 2660, 'tweaking': 2661, 'realistic': 2662, 'limits': 2663, 'hobbiest': 2664, 'downloading': 2665, 'tremendous': 2666, 'viewer': 2667, 'clicking': 2668, 'correction': 2669, 'factory': 2670, 'offsets': 2671, 'stamp': 2672, 'lighter': 2673, 'penny': 2674, 'steep': 2675, 'stitch': 2676, 'foremost': 2677, 'budget': 2678, 'protect': 2679, 'learned': 2680, 'idiot': 2681, 'insanely': 2682, 'attachment': 2683, 'optics': 2684, '5000': 2685, 'combines': 2686, 'digic': 2687, 'snap': 2688, 'tops': 2689, 'truely': 2690, 'hundred': 2691, 'paper': 2692, 'pixels': 2693, 'crop': 2694, 'powerup': 2695, 'revised': 2696, 'panoramic': 2697, 'chip': 2698, 'rounded': 2699, 'jeans': 2700, 'suit': 2701, 'ultracompact': 2702, 'hefty': 2703, 'preset': 2704, 'detailed': 2705, 'ps': 2706, 'competitors': 2707, 'fewer': 2708, 'leaps': 2709, 'bounds': 2710, 'amazingly': 2711, 'fear': 2712, 'covering': 2713, 'consideration': 2714, 'further': 2715, 'strengths': 2716, 'printer': 2717, 'snapshots': 2718, 'excelent': 2719, 'captured': 2720, 'gorgeous': 2721, 'colored': 2722, 'smallest': 2723, 'taste': 2724, 'credit': 2725, 'wallet': 2726, 'background': 2727, 'amatuer': 2728, 'interesting': 2729, 'photostitch': 2730, '360': 2731, 'rendering': 2732, 'honestly': 2733, '2000': 2734, 'coolest': 2735, 'interested': 2736, 'convenience': 2737, 'fuss': 2738, 'practice': 2739, 'indicate': 2740, 'led': 2741, 'sunlight': 2742, 'combine': 2743, 'capability': 2744, 'appreciate': 2745, 'predecessor': 2746, 'requirements': 2747, 'changeable': 2748, 'loads': 2749, 'overpriced': 2750, 'blows': 2751, 'aspects': 2752, 'comparison': 2753, 'alter': 2754, 'winamp': 2755, 'pie': 2756, 'handles': 2757, 'counting': 2758, '30gb': 2759, 'orchestra': 2760, 'jazz': 2761, 'returning': 2762, 'factors': 2763, 'picked': 2764, 'records': 2765, 'blast': 2766, 'exceeded': 2767, 'uploading': 2768, 'stn': 2769, 'recharger': 2770, 'imo': 2771, 'repeat': 2772, 'content': 2773, 'advantages': 2774, 'deals': 2775, 'tank': 2776, '900': 2777, 'train': 2778, 'meets': 2779, 'minimal': 2780, 'touched': 2781, 'sennheiser': 2782, 'ui': 2783, 'weather': 2784, 'organizing': 2785, 'gracenotes': 2786, '1gb': 2787, 'releases': 2788, 'sleep': 2789, 'keen': 2790, 'modify': 2791, 'li': 2792, 'comparing': 2793, 'classical': 2794, 'skips': 2795, 'compare': 2796, 'generated': 2797, 'vanilla': 2798, 'nose': 2799, 'cram': 2800, 'wasting': 2801, 'ordinary': 2802, 'economical': 2803, 'brands': 2804, 'purchases': 2805, 'absolutly': 2806, 'tie': 2807, 'positively': 2808, 'stated': 2809, 'upstairs': 2810, 'downstairs': 2811, 'walking': 2812, 'attribute': 2813, 'march': 2814, 'certainly': 2815, 'containing': 2816, 'roll': 2817, 'safer': 2818, 'woodworking': 2819, 'cuts': 2820, 'maple': 2821, 'industry': 2822, '3hp': 2823, 'accessible': 2824, 'routing': 2825, 'preclude': 2826, 'regrets': 2827, 'ergonomic': 2828, 'rest': 2829, 'workhorse': 2830, 'stability': 2831, 'regularly': 2832, 'hog': 2833, 'bog': 2834, 'md': 2835, 'frankly': 2836, 'bet': 2837, '54': 2838, 'mbps': 2839, 'floors': 2840, 'senses': 2841, 'fourth': 2842, 'rough': 2843, 'backyard': 2844, 'wifi': 2845, 'utility': 2846, 'th': 2847, 'clients': 2848, 'falling': 2849, 'backward': 2850, 'introduced': 2851, 'booster': 2852, 'acts': 2853, 'wet11': 2854, 'logs': 2855, 'netgear': 2856, 'happily': 2857, 'kick': 2858, 'ass': 2859, 'neon': 2860, 'wmas': 2861, 'calender': 2862, 'stern': 2863, 'water': 2864, 'integrate': 2865, 'packaging': 2866, 'wall': 2867, 'appealing': 2868, 'earbud': 2869, 'blessing': 2870, 'treble': 2871, 'sleeker': 2872, 'subscribe': 2873, 'seperately': 2874, 'dj': 2875, 'sets': 2876, 'snazzy': 2877, 'shell': 2878, 'brain': 2879, 'glows': 2880, '5gb': 2881, 'npr': 2882, 'pim': 2883, 'exception': 2884, 'blend': 2885, 'tasks': 2886, 'beatiful': 2887, 'flawless': 2888, 'icing': 2889, 'savvy': 2890, 'gonna': 2891, 'rock': 2892, 'country': 2893, \"'zen\": 2894, 'messing': 2895, 'possibilities': 2896, 'sunset': 2897, 'endless': 2898, 'wanting': 2899, 'rooms': 2900, 'brilliant': 2901, 'indistinguishable': 2902, 'pix': 2903, 'established': 2904, 'dependable': 2905, 'map': 2906, 'exciting': 2907, 'handset': 2908, 'tone': 2909, 'mhz': 2910, 'zealand': 2911, 'australia': 2912, '6620': 2913, 'supporting': 2914, 'sim': 2915, 'gallery': 2916, 'interfaces': 2917, 'thousands': 2918, 'ir': 2919, 'osx': 2920, 'quicker': 2921, 'drove': 2922, 'kentucky': 2923, 'integration': 2924, 'assign': 2925, 'international': 2926, 'joy': 2927, 'eazy': 2928, '35mb': 2929, 'sonyericsson': 2930, 'multifunction': 2931, 'detroit': 2932, 'csr': 2933, 'downloadable': 2934, 'treat': 2935, 'africa': 2936, 'anytime': 2937, 'lying': 2938, 'bed': 2939, 'browsing': 2940, 'thank': 2941, 'macs': 2942, 'dock': 2943, 'navigable': 2944, 'adaptor': 2945, 'trendy': 2946, 'composer': 2947, 'doctor': 2948, '2002': 2949, 'weaknesses': 2950, 'ignorant': 2951, '1x': 2952, 'layer': 2953, 'stage': 2954, 'excuse': 2955, 'willingness': 2956, 'ruining': 2957, 'missed': 2958, 'circulation': 2959, 'electronics': 2960, 'canned': 2961, 'commonly': 2962, 'magnification': 2963, 'quarter': 2964, 'interferes': 2965, 'considerable': 2966, 'gear': 2967, 'aggravation': 2968, 'lonely': 2969, 'overworked': 2970, 'bough': 2971, 'nonexistent': 2972, 'presents': 2973, 'members': 2974, 'recognizing': 2975, 'stopping': 2976, 'flor': 2977, 'episodes': 2978, 'ps2': 2979, 'craps': 2980, 'claiming': 2981, 'inclined': 2982, 'engineer': 2983, 'embarrassed': 2984, 'engineering': 2985, 'profession': 2986, 'sends': 2987, 'discontinuous': 2988, 'saturated': 2989, 'crafted': 2990, 'screw': 2991, 'underside': 2992, 'anchor': 2993, 'hooking': 2994, 'turnaround': 2995, 'story': 2996, 'disappeared': 2997, 'responded': 2998, 'describing': 2999, 'cu': 3000, 'st': 3001, 'chucked': 3002, 'belongs': 3003, 'predict': 3004, 'gifts': 3005, 'kicks': 3006, 'moments': 3007, 'replying': 3008, 'units': 3009, 'washed': 3010, 'perceptible': 3011, 'ice': 3012, 'undeliverable': 3013, 'tvs': 3014, 'multitude': 3015, 'methods': 3016, 'mails': 3017, 'requesting': 3018, 'ra': 3019, '31': 3020, 'customerservice': 3021, 'apexdigital': 3022, 'valid': 3023, '4apexgo': 3024, 'girlfriend': 3025, 'pirates': 3026, 'caribbean': 3027, 'isolated': 3028, 'viewable': 3029, 'lip': 3030, 'lips': 3031, 'dialog': 3032, 'composite': 3033, 'v': 3034, 'operator': 3035, 'optic': 3036, 'devastated': 3037, 'january': 3038, '27th': 3039, 'crapped': 3040, 'completion': 3041, 'eject': 3042, 'brothers': 3043, 'disdain': 3044, '1600': 3045, '1220': 3046, 'act': 3047, 'aligned': 3048, 'ah': 3049, 'memo': 3050, 'frames': 3051, 'frame': 3052, 'yells': 3053, 'somethings': 3054, 'standing': 3055, 'somewhere': 3056, 'codes': 3057, 'identifying': 3058, 'pps': 3059, 'concludes': 3060, 'granted': 3061, 'mom': 3062, 'lame': 3063, 'whom': 3064, 'afflicted': 3065, 'exhibited': 3066, 'shelling': 3067, 'vcr': 3068, 'combo': 3069, 'blazing': 3070, 'creepiness': 3071, 'quirks': 3072, 'tray': 3073, 'perv': 3074, 'faded': 3075, 'reports': 3076, 'homework': 3077, 'false': 3078, 'dix': 3079, 'rips': 3080, 'rec': 3081, 'eyesight': 3082, 'minolta': 3083, 'vectors': 3084, 'contracted': 3085, 'ergonomically': 3086, 'bordered': 3087, 'skying': 3088, 'snug': 3089, 'obstructs': 3090, 'len': 3091, 'au': 3092, 'ti': 3093, 'gt': 3094, 'zooming': 3095, 'shaky': 3096, 'mechanically': 3097, 'uneasy': 3098, 'girl': 3099, 'basketball': 3100, 'wan': 3101, 'combined': 3102, 'unsatisfactory': 3103, 'relative': 3104, 'harsh': 3105, 'spots': 3106, 'processed': 3107, 'affecting': 3108, 'fantasy': 3109, 'uncritical': 3110, 'legitimate': 3111, 'criticism': 3112, 'unresponsiveness': 3113, 'precious': 3114, 'indefinite': 3115, 'unbearably': 3116, 'capturing': 3117, 'tiff': 3118, 'pitiful': 3119, 'handbags': 3120, 'switches': 3121, 'illuminated': 3122, 'harm': 3123, 'cam': 3124, 'ea': 3125, 'parallax': 3126, 'phenomenon': 3127, 'lamest': 3128, 'bothered': 3129, 'blown': 3130, 'highlights': 3131, 'depressed': 3132, 'stainless': 3133, 'nits': 3134, 'boxy': 3135, 'wrist': 3136, 'spite': 3137, 'fluid': 3138, 'jackson': 3139, 'pollock': 3140, 'blotches': 3141, 'knock': 3142, 'underpowered': 3143, 'blobs': 3144, 'figured': 3145, 'contend': 3146, 'disadvantages': 3147, 'candid': 3148, 'warm': 3149, 'possession': 3150, 'clicked': 3151, 'happens': 3152, 'vacation': 3153, 'gas': 3154, 'uncommon': 3155, 'override': 3156, 'glasses': 3157, 'depress': 3158, 'fuzzy': 3159, 'unusually': 3160, 'intermediate': 3161, 'suggested': 3162, 'meaningless': 3163, 'maine': 3164, 'selectable': 3165, 'represent': 3166, '160x120': 3167, 'november': 3168, 'cannon': 3169, 'adobe': 3170, 'document': 3171, 'struggled': 3172, 'skin': 3173, 'reduction': 3174, 'clouds': 3175, 'dc260': 3176, 'granny': 3177, 'overused': 3178, 'prompting': 3179, 'depressing': 3180, 'selecting': 3181, 'infuriating': 3182, 'mechanics': 3183, 'deficiencies': 3184, 'living': 3185, 'clutter': 3186, 'shortcut': 3187, 'annoy': 3188, 'separated': 3189, 'longevity': 3190, 'lump': 3191, 'duplicate': 3192, 'quirky': 3193, 'receive': 3194, 'illogical': 3195, 'wildly': 3196, 'resting': 3197, 'strange': 3198, 'noises': 3199, 'defects': 3200, 'accepted': 3201, 'intend': 3202, 'patches': 3203, 'rename': 3204, 'blunt': 3205, 'outs': 3206, 'prime': 3207, 'warrant': 3208, 'survive': 3209, 'travesty': 3210, 'd': 3211, 'mp4s': 3212, 'monstrosity': 3213, 'cage': 3214, 'spending': 3215, 'aesthetics': 3216, 'irrigation': 3217, 'environmental': 3218, 'embedded': 3219, 'estimate': 3220, 'stands': 3221, 'packing': 3222, 'beforehand': 3223, 'cavity': 3224, 'enhancement': 3225, 'weighty': 3226, 'biggie': 3227, 'forgot': 3228, 'bookmark': 3229, 'defeats': 3230, 'justify': 3231, 'consuming': 3232, 'interacts': 3233, 'ignore': 3234, 'snapped': 3235, 'eh': 3236, 'docking': 3237, 'unproven': 3238, 'obscures': 3239, 'accentuates': 3240, 'diminished': 3241, 'hits': 3242, 'inordinate': 3243, 'utilized': 3244, 'dds': 3245, 'populate': 3246, 'ho': 3247, 'hum': 3248, 'secure': 3249, 'reachable': 3250, 'buyers': 3251, 'resolves': 3252, 'burn': 3253, '278': 3254, '128bps': 3255, 'kudos': 3256, 'sizing': 3257, 'documented': 3258, 'tragic': 3259, 'recharging': 3260, 'goofy': 3261, 'returned': 3262, 'flywheel': 3263, 'uneven': 3264, 'engage': 3265, 'cheesiest': 3266, 'shoddy': 3267, 'rebooted': 3268, 'reloaded': 3269, 'amazement': 3270, 'attempts': 3271, 'clue': 3272, 'gut': 3273, 'lesson': 3274, 'fried': 3275, 'recharged': 3276, '20usd': 3277, 'reaping': 3278, 'damned': 3279, 'patient': 3280, 'detecting': 3281, 'dragging': 3282, 'incorrect': 3283, 'oversight': 3284, 'occludes': 3285, 'relies': 3286, 'invest': 3287, 'treated': 3288, 'annoyed': 3289, 'carried': 3290, 'briefcase': 3291, 'zapped': 3292, 'withstand': 3293, 'rigor': 3294, 'traveler': 3295, 'sorted': 3296, 'unfilled': 3297, 'potentially': 3298, 'unknown': 3299, 'interference': 3300, 'toggle': 3301, 'resistant': 3302, 'operators': 3303, 'lockups': 3304, 'suffers': 3305, 'detracts': 3306, 'applies': 3307, 'finicky': 3308, 'plain': 3309, 'inbuilt': 3310, 'manufacturing': 3311, 'creates': 3312, 'abuse': 3313, 'fizzled': 3314, 'intel': 3315, 'p4': 3316, 'percent': 3317, 'sis': 3318, 'likings': 3319, 'stinks': 3320, '280': 3321, 'lousy': 3322, 'blaster': 3323, 'dumb': 3324, 'thinks': 3325, 'corrupt': 3326, 'oddities': 3327, 'typically': 3328, 'posted': 3329, 'defectively': 3330, 'observed': 3331, 'undone': 3332, 'failure': 3333, 'occur': 3334, 'expire': 3335, 'smelling': 3336, 'filled': 3337, 'emoting': 3338, 'module': 3339, 'dumps': 3340, 'brink': 3341, 'un': 3342, 'soiled': 3343, 'unloading': 3344, 'wad': 3345, 'pinched': 3346, 'inspection': 3347, 'food': 3348, 'contain': 3349, 'wished': 3350, 'eating': 3351, 'solids': 3352, 'escaping': 3353, 'freshener': 3354, 'trap': 3355, 'loader': 3356, 'resorted': 3357, 'dumping': 3358, 'wet': 3359, 'flipped': 3360, 'realizing': 3361, 'extract': 3362, 'jammed': 3363, 'faint': 3364, 'babies': 3365, 'diets': 3366, 'changes': 3367, 'aka': 3368, 'foods': 3369, 'oder': 3370, 'odorous': 3371, 'snagged': 3372, 'causing': 3373, 'backed': 3374, 'compartment': 3375, 'shove': 3376, 'chipped': 3377, 'nail': 3378, 'hurt': 3379, 'force': 3380, 'grove': 3381, 'decor': 3382, 'whiff': 3383, 'smells': 3384, 'deodorizer': 3385, 'lowering': 3386, 'inch': 3387, 'viper': 3388, 'bulkier': 3389, 'cutting': 3390, 'pun': 3391, 'tilt': 3392, 'heaviest': 3393, 'tightening': 3394, 'slipping': 3395, 'sufficiently': 3396, 'ground': 3397, 'rp': 3398, 'spring': 3399, 'hammer': 3400, 'sawdust': 3401, 'builds': 3402, 'channel': 3403, 'slop': 3404, 'columns': 3405, 'engaged': 3406, 'weren': 3407, 'handful': 3408, 'template': 3409, 'raising': 3410, 'removed': 3411, 'tubes': 3412, 'bend': 3413, 'shafts': 3414, 'sticking': 3415, 'repeal': 3416, 'stationary': 3417, 'oftentimes': 3418, 'loosened': 3419, 'sceptically': 3420, 'deference': 3421, 'makers': 3422, 'recessed': 3423, 'screwdriver': 3424, 'dowel': 3425, 'rod': 3426, 'raiser': 3427, 'racier': 3428, 'warmed': 3429, 'lubricated': 3430, 'safety': 3431, 'hazard': 3432, 'tossed': 3433, 'depths': 3434, 'cup': 3435, 'unplug': 3436, 'sinister': 3437, 'attaching': 3438, 'pre': 3439, 'proudly': 3440, 'securest': 3441, 'tm': 3442, 'cisco': 3443, 'crucial': 3444, 'reconsider': 3445, 'ego': 3446, 'airport': 3447, 'notoriously': 3448, 'nowhere': 3449, 'miserable': 3450, 'enabled': 3451, 'moved': 3452, 'costlier': 3453, 'disco': 3454, 'readily': 3455, 'networking': 3456, 'method': 3457, 'enterprise': 3458, 'essentially': 3459, 'expectation': 3460, 'achilles': 3461, 'heel': 3462, 'sells': 3463, 'cease': 3464, 'resolve': 3465, 'knocked': 3466, 'wasted': 3467, 'tune': 3468, 'neil': 3469, 'young': 3470, 'cr': 3471, 'hookup': 3472, 'hired': 3473, 'consult': 3474, 'intermittent': 3475, 'desktops': 3476, 'instinct': 3477, 'messes': 3478, 'di52': 3479, 'p2p': 3480, 'spirit': 3481, 'incompetent': 3482, 'tito': 3483, '11g': 3484, 'existant': 3485, 'logging': 3486, 'cheapest': 3487, 'familiar': 3488, 'walls': 3489, 'block': 3490, 'scant': 3491, 'outset': 3492, 'attempting': 3493, 'inquire': 3494, 'academic': 3495, 'maze': 3496, 'killed': 3497, 'bothersome': 3498, 'allegedly': 3499, 'hassles': 3500, 'foreign': 3501, 'reduced': 3502, 'outrageous': 3503, 'weekend': 3504, 'lug': 3505, 'trashed': 3506, 'maker': 3507, 'barest': 3508, 'nickles': 3509, 'dimes': 3510, 'extraordinarily': 3511, 'inflated': 3512, 'polyester': 3513, 'string': 3514, 'marbles': 3515, 'dish': 3516, 'wrote': 3517, 'gouging': 3518, 'royally': 3519, 'conceivable': 3520, 'pres': 3521, 'fixing': 3522, 'hrs': 3523, 'pauses': 3524, 'synchronize': 3525, 'irritating': 3526, 'unstructured': 3527, 'dumped': 3528, 'cluttered': 3529, 'excludes': 3530, 'enjoyment': 3531, 'fixes': 3532, 'goner': 3533, 'volumes': 3534, 'cranking': 3535, 'mark': 3536, 'compromised': 3537, 'awhile': 3538, 'nightmare': 3539, 'toss': 3540, 'meet': 3541, 'claimed': 3542, 'optimistic': 3543, 'touching': 3544, 'impaired': 3545, 'desired': 3546, 'syn': 3547, 'recurring': 3548, 'appointments': 3549, 'wont': 3550, 'lightly': 3551, 'desensitized': 3552, 'rise': 3553, 'catching': 3554, 'cz': 3555, 'securely': 3556, 'motherboard': 3557, 'rear': 3558, 'sexier': 3559, 'supported': 3560, 'gog': 3561, 'efficiently': 3562, 'purge': 3563, 'aspect': 3564, 'building': 3565, 'bat': 3566, \"'shutting\": 3567, 'functioning': 3568, 'mentioning': 3569, \"'first\": 3570, 'packaged': 3571, 'thieves': 3572, 'controlled': 3573, 'strip': 3574, 'trick': 3575, 'wonder': 3576, 'metro': 3577, 'bug': 3578, 'reproducible': 3579, 'patched': 3580, 'recourse': 3581, 'se': 3582, 'concept': 3583, 'beware': 3584, 'nit': 3585, 'thread': 3586, 'fuzzes': 3587, 'oversensitive': 3588, 'intending': 3589, 'shorted': 3590, 'avail': 3591, 'suggestions': 3592, 'frozen': 3593, 'restarting': 3594, 'asks': 3595, 'unholy': 3596, 'verdict': 3597, 'fair': 3598, 'decrease': 3599, 'shuts': 3600, 'overheating': 3601, 'residential': 3602, 'mad': 3603, 'brush': 3604, 'causes': 3605, 'moves': 3606, 'beta': 3607, 'proved': 3608, 'strongest': 3609, 'tower': 3610, 'weaker': 3611, 'suggests': 3612, 'grouchy': 3613, 'promises': 3614, 'inspiring': 3615, 'cycles': 3616, 'wards': 3617, 'rattling': 3618, 'humming': 3619, 'sarene': 3620, 'marching': 3621, 'commies': 3622, 'plagued': 3623, 'ridiculously': 3624, 'engineers': 3625, 'circuit': 3626, 'encoding': 3627, 'drm': 3628, 'encoded': 3629, 'repaired': 3630, 'outfoxing': 3631, 'shakes': 3632, 'distorts': 3633, 'servicing': 3634, 'diagnose': 3635, 'inoperable': 3636, 'dull': 3637, 'photograph': 3638, 'becoming': 3639, 'impatient': 3640, 'rack': 3641, 'brightly': 3642, 'shade': 3643, 'orange': 3644, '8ft': 3645, 'direct': 3646, '19mm': 3647, 'wc': 3648, '68': 3649, 'obscured': 3650, '48': 3651, 'steeply': 3652, 'demerits': 3653, 'variants': 3654, 'involved': 3655, 'whiz': 3656, 'entered': 3657, 'magnifying': 3658, 'glass': 3659, 'segregated': 3660, 'fancy': 3661, 'siemens': 3662, 's56': 3663, 'beautifully': 3664, 'frigging': 3665, 'sometime': 3666, 'tended': 3667, 'lead': 3668, 'bmw': 3669, 'unintuitive': 3670, 'booklet': 3671, 'accustomed': 3672, '200k': 3673, 'quad': 3674, 'editor': 3675, 'employ': 3676, \"'braille\": 3677, 'attn': 3678, 'stylized': 3679, 'developed': 3680, 'greedy': 3681, 'addle': 3682, 'majority': 3683, 'truth': 3684, 'nuance': 3685, 'refuse': 3686, 'scripts': 3687, 'chiding': 3688, 'english': 3689, 'ultimately': 3690, 'deserved': 3691, 'scaled': 3692, 'lego': 3693, 'command': 3694, '3x4cm': 3695, 'fonts': 3696, 'convoluted': 3697, 'suitable': 3698, 'tossing': 3699, 'unsafe': 3700, 'shift': 3701, 'highway': 3702, 'sacrifices': 3703, 'mic': 3704, 'surroundings': 3705, 'prigs': 3706, 'coloured': 3707, 'theory': 3708, 'proves': 3709, 'cells': 3710, 'functionalists': 3711, 'advocate': 3712, '7610': 3713, 'desperate': 3714, 'squeezing': 3715, 'experimental': 3716, 'blunders': 3717, 'simpler': 3718, 'airline': 3719, 'prerecorded': 3720, 'signing': 3721, 'contract': 3722, 'catchy': 3723, 'upfront': 3724, 'qualify': 3725, 'ab': 3726, 'verizon': 3727, 'troubles': 3728, 'exaggerating': 3729, 'rebooting': 3730, 'secs': 3731, 'recordings': 3732, 'ugh': 3733, 'dosn': 3734, 'commented': 3735, 'rightfully': 3736, 'nick': 3737, 'soap': 3738, 'stubby': 3739, 'hitting': 3740, 'adjacent': 3741, 'react': 3742, 'lest': 3743, 'forms': 3744, 'rely': 3745, 'usu': 3746, 'discharges': 3747, 'exp': 3748, 'erasing': 3749, 'letters': 3750, 'namely': 3751, 'scouring': 3752, 'arbitrary': 3753, 'pervasive': 3754, 'unhappy': 3755, 'traded': 3756, 'torture': 3757, 'delighted': 3758, 'arrived': 3759, 'heaven': 3760, 'accepts': 3761, 'unpredictable': 3762, 'dangerous': 3763, 'uncreative': 3764, 'laos': 3765, 'angele': 3766, 'horrendous': 3767, 'mo': 3768, 'countless': 3769, 'heavily': 3770, 'logged': 3771, 'subtle': 3772, 'minus': 3773, 'impossibly': 3774, 'answers': 3775, 'glitch': 3776, 'sticky': 3777, 'tho': 3778, 'kits': 3779, 'funky': 3780, 'rectangular': 3781, 'keypads': 3782, 'weird': 3783, 'memorized': 3784, 'vibrate': 3785, 'caller': 3786, 'individualized': 3787, 'accidentally': 3788, 'tracking': 3789, 'converts': 3790, 'types': 3791, 'metrics': 3792, 'constant': 3793, 'distorted': 3794, 'unique': 3795, 'mils': 3796, 'estate': 3797, 'broker': 3798, 'entertaining': 3799, 'disturbing': 3800, 'arrangement': 3801, 'unconventional': 3802, 'shapes': 3803, 'reiterate': 3804, 'sporadic': 3805, 'unpleasant': 3806, 'packs': 3807, 'outweighs': 3808, 'shortcoming': 3809, 'manufacturer': 3810, 'enable': 3811, 'recalled': 3812, 'tacky': 3813, 'gel': 3814, 'x5': 3815, 'tuners': 3816, 'dislikes': 3817, 'statement': 3818, 'fees': 3819, 'caveat': 3820, 'preserved': 3821, 'compete': 3822, 'tors': 3823, 'slots': 3824, 'draining': 3825, 'nope': 3826, 'casual': 3827, 'listeners': 3828, 'titanium': 3829, 'superficially': 3830, 'solder': 3831, 'jockey': 3832, 'plentiful': 3833, 'gained': 3834, 'ogle': 3835, \"'ipod\": 3836, 'eight': 3837, 'roughly': 3838, '105': 3839, 'abusing': 3840, 'reformatted': 3841, 'backing': 3842, 'picks': 3843, 'fingerprints': 3844, 'cosmetic': 3845, 'standpoint': 3846, 'holy': 3847, 'cow': 3848, 'island': 3849, 'resembled': 3850, 'observation': 3851, 'marginal': 3852, 'apples': 3853, 'incompatibility': 3854, 'throwing': 3855, 'river': 3856, 'twisted': 3857, 'unrepeatable': 3858, 'conspiracy': 3859, 'freak': 3860, 'manufacture': 3861, '299': 3862, 'minimalist': 3863, 'flag': 3864, 'riddled': 3865, 'miracle': 3866, 'thirty': 3867, 'viable': 3868, 'screws': 3869, 'navy': 3870, 'disgraceful': 3871, 'shutdown': 3872, 'slap': 3873, 'downhill': 3874, 'slid': 3875, 'fallen': 3876, 'cliff': 3877, 'loyal': 3878, 'dissatisfied': 3879, 'hence': 3880, 'intertwined': 3881, 'implementations': 3882, 'edited': 3883, 'royal': 3884, 'reviewed': 3885, 'notably': 3886, 'definitions': 3887, 'innumerable': 3888, 'comings': 3889, 'annoyance': 3890, 'remnant': 3891, 'fragments': 3892, 'proceeding': 3893, 'demand': 3894, 'fifth': 3895, 'reinstall': 3896, 'shelf': 3897, 'earned': 3898, 'lows': 3899, 'representative': 3900, 'mailed': 3901, 'unresponsive': 3902, 'boilerplate': 3903, 'paragraphs': 3904, 'insulting': 3905, 'equal': 3906, 'frustrates': 3907, 'utter': 3908, 'dud': 3909, 'buys': 3910, 'syman': 3911, 'tic': 3912, '55': 3913, 'meaningful': 3914, 'tedious': 3915, 'activation': 3916, 'cleanly': 3917, 'hangups': 3918, 'continual': 3919, 'shutdowns': 3920, 'cc': 3921, 'foll': 3922, 'wed': 3923, 'slowdowns': 3924, 'preloaded': 3925, 'steelworks': 3926, 'errors': 3927, 'persons': 3928, 'leaning': 3929, 'towards': 3930, 'profit': 3931, 'visit': 3932, \"'home\": 3933, 'assistant': 3934, 'resellers': 3935, 'booting': 3936, 'cookies': 3937, 'unauthorized': 3938, 'supervisor': 3939, 'renewal': 3940, 'disabled': 3941, 'decide': 3942, 'involve': 3943, 'muzak': 3944, 'discuss': 3945, 'defect': 3946, 'usp': 3947, 'staff': 3948, 'refundable': 3949, 'purely': 3950, 'ship': 3951, 'indignant': 3952, 'combative': 3953, 'mccaffee': 3954, 'sickly': 3955, 'abandoned': 3956, 'deserve': 3957, 'stalled': 3958, 'trace': 3959, 'disappoints': 3960, 'refresh': 3961, 'apology': 3962, 'hibernating': 3963, 'disabling': 3964, 'paring': 3965, 'sample': 3966, 'damn': 3967, 'reformat': 3968, 'greer': 3969, 'warn': 3970, 'pent4': 3971, 'resources': 3972, 'scanning': 3973, 'halt': 3974, 'behave': 3975, 'twenty': 3976, 'permissions': 3977, 'lacked': 3978, 'administrator': 3979, 'physically': 3980, 'discovering': 3981, 'rewind': 3982, 'alternate': 3983, 'cads': 3984, 'cods': 3985, 'valuable': 3986, 'coax': 3987, 'scanned': 3988, 'corrected': 3989, 'father': 3990, 'tom': 3991, 'jones': 3992, 'concert': 3993, 'viewed': 3994, 'jogs': 3995, 'cmdr': 3996, 'cadre': 3997, 'uk': 3998, 'giff': 3999, 'vision': 4000, 'regional': 4001, 'stack': 4002, 'vb': 4003, 'ripper': 4004, 'af': 4005, 'converting': 4006, 'letterbox': 4007, 'drawer': 4008, 'anticipate': 4009, 'simplest': 4010, 'manufacturers': 4011, 'toshiba': 4012, 'br': 4013, 'mirrors': 4014, 'feed': 4015, 'surprise': 4016, 'cheep': 4017, 'burned': 4018, 'jv': 4019, '1100s': 4020, 'lemon': 4021, 'condition': 4022, 'evolve': 4023, 'theater': 4024, 'cautious': 4025, 'recommendation': 4026, 'picking': 4027, 'retraction': 4028, 'om': 4029, 'capable': 4030, 'substandard': 4031, 'troubleshooting': 4032, 'hesitant': 4033, 'receiving': 4034, 'hdtv': 4035, 'overlook': 4036, 'sister': 4037, 'college': 4038, 'shopped': 4039, '39': 4040, 'tax': 4041, 'unplayable': 4042, 'philips': 4043, 'impress': 4044, 'dots': 4045, 'dd5': 4046, 'claims': 4047, 'fiddling': 4048, 'relax': 4049, 'brag': 4050, 'fraction': 4051, 'noiseless': 4052, 'silverfish': 4053, 'yours': 4054, 'instance': 4055, 'vacationing': 4056, 'elderly': 4057, 'fired': 4058, 'constituents': 4059, 'enlarging': 4060, 'x': 4061, 'vi': 4062, 'filters': 4063, 'overview': 4064, 'flagship': 4065, 'brilliance': 4066, 'previews': 4067, 'automation': 4068, 'conveniences': 4069, 'programming': 4070, 'latitude': 4071, 'pulls': 4072, 'rotates': 4073, 'direction': 4074, '14x': 4075, 'upload': 4076, 'imaginable': 4077, 'newbies': 4078, 'unreservedly': 4079, 'calorimetry': 4080, 'knockoff': 4081, 'buffs': 4082, 'july': 4083, 'fire': 4084, 'sparklers': 4085, 'focal': 4086, 'selects': 4087, 'fumble': 4088, 'substance': 4089, 'thrilled': 4090, 'joe': 4091, 'sharpness': 4092, 'imaging': 4093, 'eat': 4094, 'rice': 4095, 'objects': 4096, 'marvel': 4097, 'obtainable': 4098, 'f8': 4099, 'reveals': 4100, 'stunned': 4101, 'conjunction': 4102, 'quote': 4103, 'k': 4104, 'reeves': 4105, 'astounding': 4106, 'supplier': 4107, 'topnotch': 4108, 'cocking': 4109, 'halfway': 4110, 'amaze': 4111, 'selectively': 4112, 'squarer': 4113, 'shaking': 4114, 'stone': 4115, 'glinting': 4116, 'sun': 4117, 'shining': 4118, 'glaze': 4119, 'contours': 4120, 'inspired': 4121, 'altered': 4122, 'buildings': 4123, 'considered': 4124, 'tonal': 4125, '5mp': 4126, 'swivel': 4127, 'overlooked': 4128, 'fiance': 4129, 'approval': 4130, 'buns': 4131, 'aries': 4132, 'iguassu': 4133, 'worrying': 4134, 'reflects': 4135, 'magnesium': 4136, 'lines': 4137, '600': 4138, 'configurable': 4139, 'duration': 4140, 'hinged': 4141, 'positions': 4142, 'logically': 4143, 'medical': 4144, 'closest': 4145, 'diagram': 4146, 'boat': 4147, 'wind': 4148, 'science': 4149, 'understood': 4150, 'strictly': 4151, 'closer': 4152, 'postage': 4153, 'sophisticated': 4154, 'powerhouse': 4155, 'arguably': 4156, 'algorithms': 4157, 'shortcomings': 4158, 'exterior': 4159, 'elegantly': 4160, 'limitless': 4161, 'rivals': 4162, 'g6': 4163, 'varying': 4164, 'conduct': 4165, 'rigorous': 4166, 'test': 4167, 'firmly': 4168, 'powers': 4169, 'ultimate': 4170, 'tack': 4171, 'hearts': 4172, 'desire': 4173, '640': 4174, '30fps': 4175, 'mono': 4176, 'distortions': 4177, 'statements': 4178, 'focuses': 4179, 'bulletproof': 4180, 'a60': 4181, 'btw': 4182, 'merge': 4183, \"'l\": 4184, 'upright': 4185, 'horizontal': 4186, 's70': 4187, 'compromise': 4188, 'manuals': 4189, 'object': 4190, 'blurring': 4191, 'preliminary': 4192, 'testing': 4193, 'simone': 4194, 'advise': 4195, 'moreover': 4196, 'personalize': 4197, 'definable': 4198, 'removes': 4199, 'macros': 4200, 'iso100': 4201, 'artefact': 4202, 'hairs': 4203, 'peoples': 4204, 'whizzing': 4205, 'viedo': 4206, 'indicator': 4207, 'p200': 4208, 'paint': 4209, 'warnings': 4210, 'ponce': 4211, 'ur': 4212, 'pimples': 4213, 's30': 4214, 'school': 4215, 'funny': 4216, 'happen': 4217, 'researching': 4218, 'marketplace': 4219, 'fantastically': 4220, 'fyi': 4221, 'turkey': 4222, 'vividly': 4223, 'ceramic': 4224, 'tiles': 4225, 'darkened': 4226, 'mosques': 4227, '2mp': 4228, 'overkill': 4229, 'blow': 4230, 'compensation': 4231, 'increments': 4232, 'brighten': 4233, 'syncro': 4234, 'infinity': 4235, 'ss': 4236, 'elp2': 4237, 's300': 4238, '33': 4239, '1024x768': 4240, 'dc240': 4241, 'painting': 4242, 'uniformly': 4243, 'seeming': 4244, 'visually': 4245, 'distinctive': 4246, 'knits': 4247, 'panoramas': 4248, 'standout': 4249, 'aptly': 4250, 'named': 4251, 'diminutive': 4252, 'students': 4253, 'families': 4254, 'businesses': 4255, 'pound': 4256, 'minded': 4257, 'jewel': 4258, 'usability': 4259, 'cigarettes': 4260, 'scotch': 4261, 'central': 4262, 'retake': 4263, 'flubbed': 4264, 'lo': 4265, 'behold': 4266, 'slides': 4267, 'confusion': 4268, 'hiking': 4269, 'skiing': 4270, 'boating': 4271, 'expansion': 4272, 'kayaking': 4273, 'retracts': 4274, 'shiest': 4275, 's20': 4276, 'ebay': 4277, 'hopping': 4278, 'bandwagon': 4279, 'household': 4280, 'inventory': 4281, 'believer': 4282, 'shoots': 4283, 'convergence': 4284, 'indefinitely': 4285, 'affordability': 4286, 'navigational': 4287, 'categorizes': 4288, 'widely': 4289, 'surprising': 4290, 'peripheral': 4291, 'infinitely': 4292, 'advertises': 4293, 'hat': 4294, 'cored': 4295, 'cases': 4296, 'environments': 4297, 'owners': 4298, 'dim': 4299, 'blind': 4300, 'stare': 4301, 'limit': 4302, 'deciding': 4303, 'appliance': 4304, '60gb': 4305, 'pales': 4306, 'born': 4307, 'according': 4308, 'candy': 4309, 'visuals': 4310, 'lil': 4311, 'mixing': 4312, 'sorting': 4313, 'intense': 4314, 'administrative': 4315, '19gb': 4316, 'fussy': 4317, 'emailed': 4318, 'timely': 4319, 'responses': 4320, 'holiday': 4321, 'plane': 4322, 'rides': 4323, 'symphony': 4324, 'seated': 4325, 'uncomplicated': 4326, 'superfluous': 4327, 'differing': 4328, 'sounded': 4329, 'saves': 4330, 'lugging': 4331, 'filing': 4332, 'fortune': 4333, 'defaults': 4334, 'stains': 4335, 'reality': 4336, 'socks': 4337, 'spills': 4338, 'beer': 4339, 'greater': 4340, 'accessibility': 4341, 'sensibilities': 4342, 'madness': 4343, 'zens': 4344, 'leading': 4345, 'dd': 4346, 'structured': 4347, 'defined': 4348, 'wears': 4349, 'versus': 4350, 'illuminates': 4351, 'detectable': 4352, 'decibels': 4353, 'lastly': 4354, 'uploaded': 4355, 'int': 4356, 'rested': 4357, 'reproduced': 4358, 'faithfully': 4359, '320kbs': 4360, '2k': 4361, 'uploads': 4362, 'messed': 4363, 'specifically': 4364, 'downfall': 4365, 'slowing': 4366, 'speeding': 4367, 'auditorium': 4368, 'drains': 4369, 'aid': 4370, 'selections': 4371, 'cozmo': 4372, \"n't\": 4373, 'expecting': 4374, 'shuttle': 4375, 'serve': 4376, 'cassette': 4377, 'hopefully': 4378, 'vendor': 4379, 'snugly': 4380, 'mastering': 4381, 'em': 4382, 'unwrapped': 4383, '65': 4384, 'compensate': 4385, 'extraneous': 4386, 'criteria': 4387, 'shame': 4388, 'ships': 4389, 'commutes': 4390, 'achieved': 4391, 'objective': 4392, 'stoppage': 4393, 'hesitation': 4394, 'progress': 4395, 'm3u': 4396, 'recreate': 4397, 'hooray': 4398, '160kbps': 4399, 'stacks': 4400, 'tapes': 4401, 'exceedingly': 4402, 'staggering': 4403, 'opted': 4404, 'vice': 4405, 'verse': 4406, '98db': 4407, 'unspecified': 4408, '497': 4409, 'srs': 4410, '202': 4411, 'sec': 4412, 'chic': 4413, 'outdoors': 4414, 'fahrenheit': 4415, 'continued': 4416, 'linked': 4417, 'cb': 4418, 'listings': 4419, 'hz': 4420, '52x': 4421, 'synchronization': 4422, 'specified': 4423, 'noting': 4424, 'deficient': 4425, 'achievement': 4426, '5717': 4427, '491': 4428, 'immaterial': 4429, 'timers': 4430, 'waking': 4431, 'attached': 4432, 'secret': 4433, 'mood': 4434, 'enhancements': 4435, 'stays': 4436, 'impression': 4437, 'depends': 4438, 'crack': 4439, 'variations': 4440, 'tabbed': 4441, 'interruption': 4442, 'afford': 4443, 'ably': 4444, 'ahead': 4445, 'chair': 4446, 'adjusted': 4447, 'preference': 4448, 'possibly': 4449, 'herself': 4450, 'rivers': 4451, 'bones': 4452, 'addict': 4453, 'decade': 4454, 'regards': 4455, 'flashy': 4456, 'normalization': 4457, 'xmas': 4458, 'routinely': 4459, 'excel': 4460, 'monster': 4461, 'solidly': 4462, 'risk': 4463, 'cramp': 4464, 'circles': 4465, 'endlessly': 4466, 'nudge': 4467, 'ensuring': 4468, 'bevy': 4469, 'preview': 4470, 'cried': 4471, 'havoc': 4472, 'hissing': 4473, 'plopping': 4474, 'grand': 4475, 'bull': 4476, 'contains': 4477, 'spec': 4478, 'ail': 4479, 'gallon': 4480, 'grocery': 4481, 'laying': 4482, 'savings': 4483, 'becomes': 4484, 'toys': 4485, 'difficulties': 4486, 'moms': 4487, 'unload': 4488, 'replacements': 4489, 'ventured': 4490, 'land': 4491, 'accompanying': 4492, 'prospect': 4493, 'manageable': 4494, 'emptying': 4495, 'shower': 4496, 'spray': 4497, 'inquisitive': 4498, 'child': 4499, 'escape': 4500, 'nursery': 4501, 'smelly': 4502, 'reinforced': 4503, 'vital': 4504, 'def': 4505, 'finite': 4506, 'emanating': 4507, 'ties': 4508, 'bulk': 4509, 'sealing': 4510, 'suckered': 4511, 'bedroom': 4512, 'pails': 4513, 'waste': 4514, 'letting': 4515, 'regardless': 4516, 'deodorizers': 4517, 'facing': 4518, 'mindless': 4519, 'cocoon': 4520, 'dump': 4521, 'hanging': 4522, 'largest': 4523, 'sits': 4524, 'bathroom': 4525, 'damp': 4526, 'humid': 4527, 'kinds': 4528, 'rife': 4529, 'folded': 4530, 'exploring': 4531, '2005': 4532, 'till': 4533, 'bargains': 4534, 'paraphernalia': 4535, 'lifesaver': 4536, \"'diaper\": 4537, \"'potent\": 4538, 'disappear': 4539, 'leg': 4540, 'hunch': 4541, 'curious': 4542, 'tip': 4543, 'assemble': 4544, 'nook': 4545, 'portion': 4546, 'pocketbook': 4547, 'formula': 4548, 'breastfed': 4549, 'invented': 4550, 'pr': 4551, 'duct': 4552, 'registering': 4553, 'infants': 4554, 'toddlers': 4555, 'shield': 4556, 'operated': 4557, 'demo': 4558, 'opinions': 4559, 'effortlessly': 4560, 'freud': 4561, 'malaya': 4562, 'usa': 4563, 'churn': 4564, 'threw': 4565, 'clydesdale': 4566, 'workhorses': 4567, 'nimble': 4568, 'leigh': 4569, 'dovetail': 4570, 'jig': 4571, 'accuracy': 4572, 'elated': 4573, 'sprayed': 4574, 'lubricant': 4575, 'precisely': 4576, 'removing': 4577, 'shaft': 4578, 'incentive': 4579, 'code': 4580, 'seeker': 4581, 'delivery': 4582, '135': 4583, 'cordless': 4584, 'drill': 4585, 'laminate': 4586, 'trimmer': 4587, 'coupon': 4588, 'resist': 4589, 'arena': 4590, 'quoted': 4591, 'm12': 4592, 'woo': 4593, 'drat': 4594, 'circumstances': 4595, 'torque': 4596, 'gold': 4597, 'purchasers': 4598, 'knobs': 4599, 'gizmo': 4600, 'contributes': 4601, 'driven': 4602, 'beauties': 4603, 'talked': 4604, 'cabinet': 4605, 'col': 4606, 'exceeds': 4607, 'craft': 4608, 'invested': 4609, 'reliant': 4610, 'merits': 4611, 'masada': 4612, 'predictable': 4613, 'permanently': 4614, '2in': 4615, 'prevent': 4616, 'blowout': 4617, 'smoother': 4618, 'pushed': 4619, 'workload': 4620, 'blinking': 4621, 'plywood': 4622, 'butter': 4623, 'count': 4624, 'dew': 4625, 'alts': 4626, 'bosch': 4627, 'grab': 4628, 'dado': 4629, 'limitation': 4630, 'steal': 4631, 'buddy': 4632, 'offload': 4633, 'systematic': 4634, 'china': 4635, 'junkie': 4636, '36': 4637, 'loo': 4638, 'kin': 4639, 'elf': 4640, 'refrigerator': 4641, 'pertaining': 4642, '54mps': 4643, '54mbps': 4644, 'megabyte': 4645, 'kilobyte': 4646, 'kilobytes': 4647, 'flies': 4648, 'roommates': 4649, 'configures': 4650, 'newbie': 4651, 'fasten': 4652, 'bolt': 4653, 'instructs': 4654, 'steps': 4655, 'misleading': 4656, 'redirected': 4657, 'india': 4658, 'mbs': 4659, 'befcmu10': 4660, 'stacked': 4661, 'townhouse': 4662, 'encrypt': 4663, 'hogging': 4664, 'stealing': 4665, 'bandwidth': 4666, 'writers': 4667, 'lick': 4668, 'aunt': 4669, '801': 4670, 'paragraph': 4671, 'anted': 4672, 'headache': 4673, 'broad': 4674, 'menisci': 4675, 'lucien': 4676, 'silicon': 4677, 'cpu': 4678, 'explaining': 4679, 'knowledgeable': 4680, 'backs': 4681, 'pipeline': 4682, '54g': 4683, 'strainers': 4684, 'op': 4685, 'concentrate': 4686, 'teddy': 4687, 'ha': 4688, 'drooped': 4689, 'purchaser': 4690, '03': 4691, 'multipurpose': 4692, 'ital': 4693, 'dhaka': 4694, 'brother': 4695, 'magic': 4696, 'yin': 4697, 'splurge': 4698, 'ether': 4699, 'nest': 4700, 'bridge': 4701, 'comp': 4702, 'antennae': 4703, 'collisions': 4704, 'packets': 4705, 'vip': 4706, 'whatsoever': 4707, 'paramecia': 4708, 'pose': 4709, 'http': 4710, 'suavest': 4711, 'forum6': 4712, 'html': 4713, 'followed': 4714, 'tweak': 4715, 'streamline': 4716, 'upgrading': 4717, 'gain': 4718, 'unattainable': 4719, 'spitting': 4720, 'favor': 4721, 'farthest': 4722, '18m': 4723, '10m': 4724, 'ethernet': 4725, 'hga7t': 4726, 'solution': 4727, 'walled': 4728, 'crisper': 4729, 'butt': 4730, 'freedom': 4731, 'kiss': 4732, 'confronted': 4733, 'microfiber': 4734, 'glowing': 4735, 'remarkably': 4736, 'contrasting': 4737, 'ambiance': 4738, 'prop': 4739, 'textured': 4740, 'sdon': 4741, 'thoughtful': 4742, 'carbon': 4743, 'louder': 4744, 'outright': 4745, 'recorded': 4746, 'modifying': 4747, 'postal': 4748, 'exchanges': 4749, 'inaccurate': 4750, 'howard': 4751, 'memos': 4752, 'ripples': 4753, 'coating': 4754, 'makeshift': 4755, 'sorta': 4756, 'positives': 4757, 'fiddle': 4758, 'separate': 4759, 'wmp10': 4760, 'syncs': 4761, 'rocked': 4762, 'bose': 4763, 'comfort': 4764, 'presented': 4765, 'cardboard': 4766, 'distinct': 4767, 'appeal': 4768, 'geeks': 4769, 'coolness': 4770, 'defiantly': 4771, 'shines': 4772, 'excited': 4773, 'staring': 4774, 'dc': 4775, '128': 4776, 'lives': 4777, 'ak': 4778, 'studio': 4779, '240': 4780, 'touchpaper': 4781, 'supposedly': 4782, 'serviceable': 4783, 'notes': 4784, 'juice': 4785, 'aw': 4786, 'jeez': 4787, 'trouser': 4788, 'freebies': 4789, 'cradle': 4790, 'detachable': 4791, '3800': 4792, 'thankfully': 4793, 'privilege': 4794, 'owning': 4795, 'subsequently': 4796, 'assured': 4797, 'informed': 4798, 'exclusively': 4799, 'flinch': 4800, 'needing': 4801, 'mouth': 4802, 'caters': 4803, 'youngsters': 4804, 'walks': 4805, 'ostentatious': 4806, 'thanks': 4807, 'partial': 4808, 'zs': 4809, 'seizing': 4810, 'begin': 4811, 'determinant': 4812, 'quantity': 4813, '180': 4814, 'remedied': 4815, 'upgrades': 4816, 'alright': 4817, 'rive': 4818, 'intimidated': 4819, 'operational': 4820, 'edit': 4821, 'e828lp': 4822, 'mx': 4823, 'avoiding': 4824, 'theft': 4825, 'subways': 4826, 'whichever': 4827, 'shocked': 4828, 'towers': 4829, 'sassier': 4830, 'flair': 4831, 'trimming': 4832, 'speaking': 4833, 'knocks': 4834, 'curved': 4835, 'cough': 4836, '4g': 4837, 'adore': 4838, 'preferred': 4839, 'ie': 4840, 'downs': 4841, 'related': 4842, 'untouched': 4843, 'considerably': 4844, 'invasive': 4845, 'wheels': 4846, 'pads': 4847, 'surfaces': 4848, 'timing': 4849, 'branding': 4850, 'lightning': 4851, 'chalked': 4852, 'goodies': 4853, 'halloween': 4854, 'cart': 4855, 'encountering': 4856, 'principally': 4857, 'possibility': 4858, 'certainty': 4859, 'gremlins': 4860, 'kicking': 4861, 'pods': 4862, 'char': 4863, 'shire': 4864, 'decades': 4865, 'customize': 4866, 'birthday': 4867, 'smokes': 4868, 'transported': 4869, 'wade': 4870, 'folks': 4871, 'pretend': 4872, 'inactive': 4873, 'tuning': 4874, 'treadmill': 4875, 'concerts': 4876, 'simulcast': 4877, '1g': 4878, 'architecture': 4879, 'publicly': 4880, 'trade': 4881, 'muvo2': 4882, 'tomorrow': 4883, 'accomplish': 4884, 'plugs': 4885, 'aux': 4886, 'offense': 4887, 'sink': 4888, 'fragility': 4889, 'ball': 4890, 'metaphor': 4891, 'hoping': 4892, 'solves': 4893, 'unarguably': 4894, 'gigabytes': 4895, 'nails': 4896, 'faltered': 4897, 'policy': 4898, 'anyways': 4899, 'fashionable': 4900, 'lovers': 4901, 'sonic': 4902, 'humble': 4903, 'retrieved': 4904, 'labeled': 4905, 'categorized': 4906, 'ks': 4907, 'relaxation': 4908, 'hop': 4909, 'korean': 4910, 'japanese': 4911, 'afro': 4912, 'cuban': 4913, 'salsa': 4914, 'blues': 4915, 'halo': 4916, 'surrounds': 4917, '4gbs': 4918, 'removeable': 4919, 'worship': 4920, 'mighty': 4921, '1993': 4922, 'temporarily': 4923, 'batter': 4924, 'reminders': 4925, 'meetings': 4926, \"'creative\": 4927, 'batch': 4928, 'converted': 4929, 'undecided': 4930, 'temper': 4931, 'enthusiastic': 4932, 'coat': 4933, 'annie': 4934, 'levitt': 4935, 'abilities': 4936, 'filling': 4937, 'blanks': 4938, 'dummy': 4939, 'correspond': 4940, 'seek': 4941, 'enthusiastically': 4942, 'immense': 4943, '1000s': 4944, 'minutest': 4945, 'optimized': 4946, 'situational': 4947, 'portrait': 4948, 'landscape': 4949, 'beach': 4950, 'win98': 4951, 'experimented': 4952, 'ordering': 4953, 'mortar': 4954, 'retailers': 4955, '8x10': 4956, 'sign': 4957, 'evening': 4958, 'alkaline': 4959, 'emergency': 4960, 'yo': 4961, 'offensive': 4962, '12x': 4963, 'grainy': 4964, 'zoomed': 4965, 'perspective': 4966, 'camper': 4967, 'gaining': 4968, 'carries': 4969, 'prove': 4970, 'ample': 4971, 'marriage': 4972, 'willa': 4973, 'bu': 4974, 'aids': 4975, 'maneuver': 4976, 'trust': 4977, 'moderate': 4978, '3m': 4979, '4m': 4980, 'combos': 4981, 'children': 4982, 'memories': 4983, 'fanatic': 4984, 'summary': 4985, 'heartedly': 4986, 'remainder': 4987, 'lengthy': 4988, 'extensive': 4989, 'journey': 4990, 'gravitated': 4991, 'gem': 4992, 'sheer': 4993, 'telephoto': 4994, 'proverbial': 4995, 'legendary': 4996, 'raul': 4997, 'thingy': 4998, 'ooh': 4999, 'beginners': 5000, 'photographers': 5001, 'continuous': 5002, 'rapid': 5003, 'succession': 5004, 'enthusiast': 5005, 'grandmother': 5006, '4500': 5007, 'expand': 5008, 'extenders': 5009, 'closeup': 5010, 'beauty': 5011, '3660': 5012, 'avaunt': 5013, 'quest': 5014, 'maps': 5015, 'addresses': 5016, 'dismay': 5017, 'groundbreaking': 5018, 'mankind': 5019, 'owing': 5020, 'fingered': 5021, 'conviction': 5022, 'recollection': 5023, 'wanna': 5024, 'airplane': 5025, 'brightness': 5026, 'extraordinary': 5027, '65536': 5028, '16bit': 5029, 'ensures': 5030, 'animations': 5031, 'incredibility': 5032, 'incoming': 5033, 'outgoing': 5034, 'calendars': 5035, 'oval': 5036, '65000': 5037, 'community': 5038, 'score': 5039, 'newest': 5040, 'versatility': 5041, 'turnoff': 5042, 'flimsier': 5043, 'fans': 5044, 'amenities': 5045, 'chubby': 5046, 'hips': 5047, 'squeak': 5048, 'boundless': 5049, 'houses': 5050, 'texts': 5051, 'o': 5052, 'wires': 5053, \"'world\": 5054, 'singular': 5055, '800mhz': 5056, 'refer': 5057, '850': 5058, 'excluding': 5059, '900mhz': 5060, 'stellar': 5061, 'quickness': 5062, '65k': 5063, 'films': 5064, 'crying': 5065, 'erickson': 5066, 'competitive': 5067, 'deserves': 5068, 'accomplishes': 5069, 'lofty': 5070, '3330': 5071, 'robustness': 5072, 'feb': 5073, 'washes': 5074, 'dishes': 5075, 'complement': 5076, 'streaming': 5077, '3gpp': 5078, 'multimedia': 5079, 'enhanced': 5080, 'extension': 5081, 'rundown': 5082, 'evolution': 5083, 'revolution': 5084, 'themes': 5085, 'cream': 5086, 'niftiest': 5087, 'hitch': 5088, 'blackberry': 5089, 'imho': 5090, 'upside': 5091, 'abra': 5092, 'darned': 5093, 'platform': 5094, 'iq': 5095, 'screens': 5096, '4x6': 5097, 'dali': 5098, 'overboard': 5099, 'synced': 5100, 'reached': 5101, 'city': 5102, 'eastern': 5103, 'mountains': 5104, 'bars': 5105, 'drain': 5106, 'pac': 5107, 'mafia': 5108, 'wars': 5109, '3210': 5110, 'phillips': 5111, 'gage': 5112, 'traffic411': 5113, 'la': 5114, 'traffic': 5115, '405': 5116, 'chunk': 5117, 'tablet': 5118, 'von': 5119, 'laptops': 5120, 'ipa': 5121, '4155': 5122, 'pop3': 5123, 'smtp': 5124, 'smut': 5125, 'ob': 5126, 'kde': 5127, 'conqueror': 5128, 'groups': 5129, 'dislike': 5130, 'complications': 5131, 'gr': 5132, 'southwest': 5133, 'pavement': 5134, 'agents': 5135, 'prompt': 5136, 'polite': 5137, 'reservation': 5138, '660': 5139, 'fare': 5140, 'ins': 5141, 'events': 5142, 'ringers': 5143, 'simian': 5144, 'hunt': 5145, 'colorful': 5146, 'usefully': 5147, 'displaced': 5148, 'upcoming': 5149, '610': 5150, '6mb': 5151, 'n6600': 5152, 'loudspeaker': 5153, 'conference': 5154, 'milestones': 5155, 'cellular': 5156, 'secretary': 5157, 'gaps': 5158, 'controller': 5159, 'shareware': 5160, 'extend': 5161, 'teri': 5162, 'exists': 5163, 'primitive': 5164, 'suburbs': 5165, 'northern': 5166, 'cincinnati': 5167, 'stretches': 5168, 'route': 5169, 'freeway': 5170, 'entering': 5171, 'brief': 5172, 'synopsis': 5173, 'manager': 5174, 'fairness': 5175, 'solely': 5176, 'apparent': 5177, 'indestructibility': 5178, 'poly': 5179, 'graphic': 5180, 'atones': 5181, 'nifty': 5182, 'brisk': 5183, 'lunch': 5184, '3650': 5185, 'disturbance': 5186, 'chance': 5187, 'typical': 5188, 'bulging': 5189, 'surreal': 5190, 'beneficial': 5191, 'doubles': 5192, 'stopwatch': 5193, 'surfing': 5194, 'critter': 5195, 'concealed': 5196, 'street': 5197, 'cellphones': 5198, 'talks': 5199, 'pillow': 5200, 'enjoying': 5201, 'guessing': 5202, 'chicago': 5203, 'jame': 5204, '8290': 5205, 'comfy': 5206, 'specific': 5207, 'seller': 5208, 'apartment': 5209, 'surpassed': 5210, 'oz': 5211, 'polymer': 5212, 'additionally': 5213, 'chess': 5214, 'chat': 5215, 'sharing': 5216, 'niceties': 5217, 'settled': 5218, 'teamed': 5219, 'aim': 5220, 'quieter': 5221, 'talkers': 5222, 'classic': 5223, 'disappears': 5224, 'excels': 5225, 'god': 5226, 'shine': 5227, 'commands': 5228, 'flips': 5229, 'shoulder': 5230, 'solved': 5231, 'sports': 5232, 'snooze': 5233, 'peice': 5234, 'satisfactorily': 5235, 'resolved': 5236, 'shouldn': 5237, 'offerings': 5238, 'improving': 5239, 'twelve': 5240, 'exchange': 5241, 'transition': 5242, 'instantaneous': 5243, 'usb2': 5244, 'firewire400': 5245, 'clicks': 5246, 'exist': 5247, 'ant': 5248, 'relationship': 5249, 'depending': 5250, 'expertise': 5251, 'comments': 5252, 'overrated': 5253, 'beater': 5254, 'tempted': 5255, 'fathomed': 5256, '1000': 5257, 'numbingly': 5258, 'sought': 5259, 'acoustic': 5260, 'reducer': 5261, 'dance': 5262, 'broadcast': 5263, 'broadcaster': 5264, 'fulfilled': 5265, 'midas': 5266, 'incorrectly': 5267, 'prompts': 5268, 'realistically': 5269, 'endurance': 5270, 'associated': 5271, 'lover': 5272, 'indicators': 5273, 'detect': 5274, 'voila': 5275, 'amp': 5276, 'lifer': 5277, 'superiority': 5278, 'magnificent': 5279, 'initial': 5280, 'section': 5281, 'trivia': 5282, 'tests': 5283, 'skill': 5284, 'shoulders': 5285, 'gleaming': 5286, 'sue': 5287, 'dammit': 5288, 'organizes': 5289, 'helpline': 5290, 'convent': 5291, \"'mini\": 5292, 'budge': 5293, 'mass': 5294, 'commercialism': 5295, 'lou': 5296, 'andy': 5297, 'mcgee': 5298, 'wares': 5299, 'slowed': 5300, \"'98\": 5301, 'semantic': 5302, 'efficiency': 5303, 'exaggerated': 5304, 'checkup': 5305, '133': 5306, 'backtracking': 5307, 'utilities': 5308, 'likewise': 5309, 'intrusions': 5310, 'intrusion': 5311, 'blocker': 5312, 'bonuses': 5313, 'effortless': 5314, 'lan': 5315, 'venerable': 5316, 'skate': 5317, 'renewing': 5318, 'banner': 5319, 'ads': 5320, 'netscape': 5321, 'acrobat': 5322, 'reader': 5323, 'crashing': 5324, 'pencilings': 5325, 'maccabees': 5326, 'featured': 5327, 'pi': 5328, '1ghz': 5329, 'rd': 5330, '80gb': 5331, 'associates': 5332, 'highlighted': 5333, 'bacon': 5334}\n"
     ]
    }
   ],
   "source": [
    "# Build the raw vocobulary for first inspection\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_raw = tokenizer.word_index\n",
    "print('\\nThe vocabulary size: {}\\n'.format(len(vocab_raw)))\n",
    "print(vocab_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `clean_doc` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "    \n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) >= 1]\n",
    "    # Stem the token\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Vocabulary\n",
    "\n",
    "A part of preparing text for text classification involves defining and tailoring the vocabulary of words supported by the model. **We can do this by loading all of the documents in the dataset and building a set of words.**\n",
    "\n",
    "The larger the vocabulary, the more sparse the representation of each word or document. So, we may decide to support all of these words, or perhaps discard some. The final chosen vocabulary can then be saved to a file for later use, such as filtering words in new documents in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `Counter` class and create an instance called `vocab` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter()\n",
    "\n",
    "def add_doc_to_vocab(docs, vocab):\n",
    "    '''\n",
    "    input:\n",
    "        docs: a list of sentences (docs)\n",
    "        vocab: a vocabulary dictionary\n",
    "    output:\n",
    "        return an updated vocabulary\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        tokens = clean_doc(doc)\n",
    "        vocab.update(tokens)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'weak': 12,\n",
       "         'minor': 9,\n",
       "         'feel': 48,\n",
       "         'layout': 5,\n",
       "         'remot': 30,\n",
       "         'control': 84,\n",
       "         'n': 144,\n",
       "         'show': 16,\n",
       "         'complet': 19,\n",
       "         'file': 89,\n",
       "         'name': 13,\n",
       "         'mp3': 73,\n",
       "         'realli': 119,\n",
       "         'long': 56,\n",
       "         'must': 26,\n",
       "         'cycl': 3,\n",
       "         'everi': 40,\n",
       "         'zoom': 51,\n",
       "         'set': 87,\n",
       "         '2x': 3,\n",
       "         '3x': 8,\n",
       "         '4x': 6,\n",
       "         '1': 93,\n",
       "         'etc': 42,\n",
       "         'get': 243,\n",
       "         'back': 46,\n",
       "         'normal': 21,\n",
       "         'size': 76,\n",
       "         'sorri': 2,\n",
       "         'ignor': 2,\n",
       "         'way': 68,\n",
       "         '1x': 1,\n",
       "         'quickli': 20,\n",
       "         'mani': 70,\n",
       "         'disney': 2,\n",
       "         'movi': 26,\n",
       "         'play': 142,\n",
       "         'dvd': 113,\n",
       "         'player': 331,\n",
       "         'problem': 202,\n",
       "         'dual': 3,\n",
       "         'layer': 3,\n",
       "         'alia': 2,\n",
       "         'season': 3,\n",
       "         '2': 102,\n",
       "         'know': 43,\n",
       "         'say': 60,\n",
       "         'pay': 15,\n",
       "         'stage': 1,\n",
       "         'game': 29,\n",
       "         'better': 111,\n",
       "         'qualiti': 218,\n",
       "         'excus': 1,\n",
       "         'never': 49,\n",
       "         'purchas': 69,\n",
       "         'apex': 46,\n",
       "         'custom': 42,\n",
       "         'servic': 61,\n",
       "         'technic': 5,\n",
       "         'support': 69,\n",
       "         'overload': 2,\n",
       "         'non': 12,\n",
       "         'respons': 9,\n",
       "         'tell': 24,\n",
       "         'product': 130,\n",
       "         'willing': 1,\n",
       "         'stand': 15,\n",
       "         'behind': 4,\n",
       "         'would': 160,\n",
       "         'stop': 21,\n",
       "         'middl': 4,\n",
       "         'even': 124,\n",
       "         'read': 64,\n",
       "         'new': 59,\n",
       "         'cd': 74,\n",
       "         'almost': 32,\n",
       "         'alway': 33,\n",
       "         'began': 2,\n",
       "         'skip': 8,\n",
       "         'thought': 23,\n",
       "         'start': 53,\n",
       "         'check': 13,\n",
       "         'disc': 31,\n",
       "         'find': 75,\n",
       "         '2600': 11,\n",
       "         'actual': 38,\n",
       "         'ruin': 3,\n",
       "         'media': 19,\n",
       "         'worth': 23,\n",
       "         'price': 116,\n",
       "         'recommend': 52,\n",
       "         'answer': 13,\n",
       "         'phone': 312,\n",
       "         'contact': 12,\n",
       "         'bad': 31,\n",
       "         'everyth': 53,\n",
       "         '3': 80,\n",
       "         'die': 10,\n",
       "         'shortli': 3,\n",
       "         'nice': 96,\n",
       "         'machin': 25,\n",
       "         'consid': 21,\n",
       "         'pretti': 52,\n",
       "         'low': 29,\n",
       "         'item': 12,\n",
       "         'broke': 6,\n",
       "         'two': 59,\n",
       "         'week': 49,\n",
       "         'gave': 16,\n",
       "         'kid': 3,\n",
       "         'christma': 15,\n",
       "         'door': 7,\n",
       "         'close': 25,\n",
       "         'tri': 77,\n",
       "         'return': 9,\n",
       "         'miss': 13,\n",
       "         'amazon': 26,\n",
       "         'period': 11,\n",
       "         'took': 29,\n",
       "         'month': 65,\n",
       "         'dept': 2,\n",
       "         'unfortun': 16,\n",
       "         'turn': 46,\n",
       "         'dispos': 8,\n",
       "         'type': 11,\n",
       "         'sinc': 52,\n",
       "         'first': 86,\n",
       "         'day': 65,\n",
       "         'final': 24,\n",
       "         'less': 43,\n",
       "         '60': 6,\n",
       "         'recogn': 15,\n",
       "         'anyth': 40,\n",
       "         'pop': 24,\n",
       "         'tend': 7,\n",
       "         'run': 47,\n",
       "         'quit': 51,\n",
       "         'hot': 11,\n",
       "         'given': 17,\n",
       "         'lot': 78,\n",
       "         'room': 17,\n",
       "         'air': 2,\n",
       "         'circul': 1,\n",
       "         'also': 150,\n",
       "         'seem': 85,\n",
       "         'strong': 10,\n",
       "         'electron': 8,\n",
       "         'smell': 27,\n",
       "         'time': 155,\n",
       "         'thing': 115,\n",
       "         'experi': 23,\n",
       "         'freez': 19,\n",
       "         'abl': 37,\n",
       "         'clear': 31,\n",
       "         'open': 38,\n",
       "         'blow': 6,\n",
       "         'can': 1,\n",
       "         'okay': 4,\n",
       "         'fan': 3,\n",
       "         'tini': 19,\n",
       "         'button': 95,\n",
       "         'especi': 32,\n",
       "         'like': 214,\n",
       "         'commonli': 1,\n",
       "         'use': 515,\n",
       "         'paus': 5,\n",
       "         'larger': 19,\n",
       "         'conveni': 18,\n",
       "         'place': 17,\n",
       "         'display': 33,\n",
       "         'inform': 10,\n",
       "         'screen': 88,\n",
       "         'mode': 60,\n",
       "         'goe': 11,\n",
       "         'magnif': 1,\n",
       "         'one': 297,\n",
       "         'quarter': 1,\n",
       "         'top': 24,\n",
       "         'interfer': 2,\n",
       "         'view': 15,\n",
       "         'spent': 7,\n",
       "         'consider': 4,\n",
       "         'profession': 6,\n",
       "         'video': 50,\n",
       "         'gear': 1,\n",
       "         'onscreen': 2,\n",
       "         'annoy': 21,\n",
       "         '90': 9,\n",
       "         'pictur': 171,\n",
       "         'matter': 12,\n",
       "         'see': 43,\n",
       "         'total': 13,\n",
       "         '6': 26,\n",
       "         'frustrat': 12,\n",
       "         'aggrav': 1,\n",
       "         'job': 18,\n",
       "         'hold': 44,\n",
       "         'email': 18,\n",
       "         'telephon': 5,\n",
       "         'number': 36,\n",
       "         'constantli': 8,\n",
       "         'busi': 13,\n",
       "         'believ': 16,\n",
       "         'lone': 1,\n",
       "         'rep': 5,\n",
       "         'probabl': 23,\n",
       "         'extrem': 24,\n",
       "         'overwork': 1,\n",
       "         'wo': 14,\n",
       "         'yesterday': 4,\n",
       "         'today': 8,\n",
       "         '80': 3,\n",
       "         'store': 34,\n",
       "         'bough': 1,\n",
       "         'ten': 4,\n",
       "         'tech': 25,\n",
       "         'liter': 6,\n",
       "         'nonexist': 1,\n",
       "         'bought': 42,\n",
       "         'model': 22,\n",
       "         'present': 7,\n",
       "         'neither': 7,\n",
       "         'work': 269,\n",
       "         'embarass': 2,\n",
       "         'call': 43,\n",
       "         'famili': 7,\n",
       "         'member': 1,\n",
       "         'ago': 14,\n",
       "         'longer': 13,\n",
       "         'properli': 11,\n",
       "         'usual': 13,\n",
       "         'occasion': 12,\n",
       "         'particular': 3,\n",
       "         'point': 33,\n",
       "         'access': 30,\n",
       "         'certain': 9,\n",
       "         'special': 15,\n",
       "         'featur': 196,\n",
       "         'rental': 2,\n",
       "         'happen': 5,\n",
       "         'sever': 21,\n",
       "         'differ': 33,\n",
       "         'keep': 44,\n",
       "         'someth': 39,\n",
       "         'discov': 8,\n",
       "         'flor': 1,\n",
       "         'got': 63,\n",
       "         'touch': 41,\n",
       "         'web': 13,\n",
       "         'far': 73,\n",
       "         'refus': 5,\n",
       "         'episod': 1,\n",
       "         'other': 17,\n",
       "         'ps2': 1,\n",
       "         'could': 72,\n",
       "         'went': 16,\n",
       "         'sound': 166,\n",
       "         'hate': 7,\n",
       "         'love': 83,\n",
       "         'everyon': 9,\n",
       "         'crap': 7,\n",
       "         'univers': 5,\n",
       "         'claim': 5,\n",
       "         'none': 11,\n",
       "         'cours': 13,\n",
       "         'coupl': 13,\n",
       "         'appear': 15,\n",
       "         'defect': 9,\n",
       "         'list': 20,\n",
       "         'toll': 2,\n",
       "         'free': 33,\n",
       "         'real': 21,\n",
       "         'hassl': 9,\n",
       "         'regular': 21,\n",
       "         'line': 30,\n",
       "         'inclin': 1,\n",
       "         'unit': 45,\n",
       "         'forev': 4,\n",
       "         'begin': 8,\n",
       "         'higher': 8,\n",
       "         'scene': 10,\n",
       "         'engin': 5,\n",
       "         'embarrass': 1,\n",
       "         'profess': 1,\n",
       "         'releas': 8,\n",
       "         'sale': 3,\n",
       "         'send': 13,\n",
       "         'discontinu': 1,\n",
       "         'signal': 24,\n",
       "         'tv': 10,\n",
       "         'moment': 10,\n",
       "         'white': 18,\n",
       "         'nois': 15,\n",
       "         'make': 98,\n",
       "         'color': 46,\n",
       "         'look': 139,\n",
       "         'satur': 1,\n",
       "         'entir': 7,\n",
       "         'poorli': 7,\n",
       "         'craft': 2,\n",
       "         'sharp': 15,\n",
       "         'screw': 5,\n",
       "         'tip': 4,\n",
       "         'undersid': 1,\n",
       "         'come': 89,\n",
       "         'insid': 18,\n",
       "         'obvious': 4,\n",
       "         'anchor': 1,\n",
       "         'intern': 4,\n",
       "         'board': 4,\n",
       "         'hook': 10,\n",
       "         'found': 45,\n",
       "         '50': 12,\n",
       "         'put': 39,\n",
       "         'spin': 5,\n",
       "         'alreadi': 24,\n",
       "         'disappoint': 36,\n",
       "         'respond': 8,\n",
       "         'promis': 7,\n",
       "         'turnaround': 1,\n",
       "         '24': 6,\n",
       "         'hour': 54,\n",
       "         'piec': 17,\n",
       "         'junk': 8,\n",
       "         'later': 4,\n",
       "         'eventu': 6,\n",
       "         'stori': 1,\n",
       "         'everybodi': 2,\n",
       "         'els': 20,\n",
       "         'noth': 17,\n",
       "         'fine': 46,\n",
       "         '1st': 5,\n",
       "         'half': 12,\n",
       "         'disappear': 3,\n",
       "         'still': 93,\n",
       "         'describ': 3,\n",
       "         'basic': 18,\n",
       "         'cu': 1,\n",
       "         'st': 1,\n",
       "         'help': 36,\n",
       "         'mine': 25,\n",
       "         'old': 28,\n",
       "         'chuck': 3,\n",
       "         'trash': 18,\n",
       "         'belong': 1,\n",
       "         '4': 66,\n",
       "         'last': 44,\n",
       "         'six': 3,\n",
       "         'sent': 8,\n",
       "         'ad2600': 2,\n",
       "         'messag': 12,\n",
       "         'though': 43,\n",
       "         'bit': 81,\n",
       "         'flimsi': 10,\n",
       "         'predict': 2,\n",
       "         'gift': 7,\n",
       "         'second': 49,\n",
       "         'digit': 67,\n",
       "         'site': 20,\n",
       "         '25': 5,\n",
       "         'watch': 6,\n",
       "         'kick': 4,\n",
       "         'rate': 22,\n",
       "         'five': 10,\n",
       "         'star': 39,\n",
       "         'poor': 9,\n",
       "         'manual': 58,\n",
       "         '12': 16,\n",
       "         '26': 3,\n",
       "         '9': 6,\n",
       "         'fail': 12,\n",
       "         'neg': 12,\n",
       "         'review': 57,\n",
       "         'ask': 13,\n",
       "         'repli': 3,\n",
       "         'wait': 16,\n",
       "         '27': 3,\n",
       "         '10': 28,\n",
       "         'otherwis': 13,\n",
       "         'clean': 17,\n",
       "         'friend': 16,\n",
       "         'gripe': 3,\n",
       "         'incred': 17,\n",
       "         'crappi': 2,\n",
       "         'wors': 6,\n",
       "         'cheaper': 10,\n",
       "         'press': 18,\n",
       "         'hard': 65,\n",
       "         'frequent': 5,\n",
       "         'end': 21,\n",
       "         'enter': 4,\n",
       "         'meant': 3,\n",
       "         'scroll': 44,\n",
       "         'reason': 31,\n",
       "         'wash': 4,\n",
       "         'bleed': 2,\n",
       "         'compar': 29,\n",
       "         'compon': 8,\n",
       "         'connect': 58,\n",
       "         'much': 104,\n",
       "         'percept': 1,\n",
       "         'cheap': 25,\n",
       "         'ch': 2,\n",
       "         'easi': 217,\n",
       "         'sure': 30,\n",
       "         'buck': 12,\n",
       "         'heck': 2,\n",
       "         'dirti': 13,\n",
       "         'ice': 3,\n",
       "         'age': 2,\n",
       "         'e': 18,\n",
       "         'mail': 9,\n",
       "         'undeliver': 1,\n",
       "         'leav': 16,\n",
       "         'question': 7,\n",
       "         'attempt': 4,\n",
       "         'multitud': 1,\n",
       "         'method': 2,\n",
       "         'ad': 15,\n",
       "         'numer': 7,\n",
       "         'recent': 15,\n",
       "         'yet': 30,\n",
       "         'without': 61,\n",
       "         'depart': 4,\n",
       "         'request': 1,\n",
       "         'ra': 1,\n",
       "         'disk': 13,\n",
       "         'natur': 11,\n",
       "         '31': 1,\n",
       "         'froze': 2,\n",
       "         'load': 32,\n",
       "         'via': 21,\n",
       "         'customerservic': 1,\n",
       "         'apexdigit': 1,\n",
       "         'com': 16,\n",
       "         'address': 7,\n",
       "         'valid': 1,\n",
       "         '866': 2,\n",
       "         '4apexgo': 1,\n",
       "         'suck': 14,\n",
       "         'hear': 11,\n",
       "         'www': 5,\n",
       "         'inc': 2,\n",
       "         'receiv': 21,\n",
       "         'kept': 12,\n",
       "         'rent': 2,\n",
       "         'great': 280,\n",
       "         'girlfriend': 1,\n",
       "         'somewhat': 16,\n",
       "         'fact': 40,\n",
       "         'exampl': 9,\n",
       "         'pirat': 1,\n",
       "         'caribbean': 1,\n",
       "         'extra': 29,\n",
       "         'isol': 1,\n",
       "         'incid': 2,\n",
       "         'proven': 5,\n",
       "         'wrong': 16,\n",
       "         'well': 156,\n",
       "         'output': 9,\n",
       "         'catch': 5,\n",
       "         'occas': 5,\n",
       "         'littl': 106,\n",
       "         'understand': 16,\n",
       "         'jpeg': 8,\n",
       "         'viewabl': 1,\n",
       "         'vivid': 2,\n",
       "         '17': 2,\n",
       "         'monitor': 2,\n",
       "         'awesom': 35,\n",
       "         'lip': 2,\n",
       "         'sync': 19,\n",
       "         'issu': 32,\n",
       "         'move': 15,\n",
       "         'dialog': 1,\n",
       "         'black': 14,\n",
       "         'composit': 1,\n",
       "         'v': 1,\n",
       "         'p': 3,\n",
       "         'confus': 9,\n",
       "         'doesnt': 6,\n",
       "         'may': 22,\n",
       "         'oper': 37,\n",
       "         'error': 9,\n",
       "         'hell': 5,\n",
       "         'forget': 5,\n",
       "         'sleek': 18,\n",
       "         'within': 15,\n",
       "         '45': 3,\n",
       "         'rca': 2,\n",
       "         'optic': 22,\n",
       "         'instal': 89,\n",
       "         'devast': 1,\n",
       "         'least': 21,\n",
       "         'updat': 27,\n",
       "         'januari': 1,\n",
       "         '27th': 1,\n",
       "         '2004': 22,\n",
       "         'dont': 15,\n",
       "         'buy': 86,\n",
       "         'immedi': 5,\n",
       "         'favorit': 14,\n",
       "         'multipl': 10,\n",
       "         'avail': 19,\n",
       "         'success': 7,\n",
       "         'broken': 8,\n",
       "         'motor': 5,\n",
       "         'eject': 1,\n",
       "         'brother': 2,\n",
       "         'hous': 14,\n",
       "         'either': 25,\n",
       "         'imagin': 9,\n",
       "         'shock': 3,\n",
       "         'absolut': 22,\n",
       "         'instant': 7,\n",
       "         'disdain': 1,\n",
       "         'made': 47,\n",
       "         '2nd': 3,\n",
       "         'faulti': 2,\n",
       "         'power': 51,\n",
       "         'suppli': 10,\n",
       "         'caus': 11,\n",
       "         '1600': 1,\n",
       "         'correctli': 6,\n",
       "         '1220': 1,\n",
       "         'act': 3,\n",
       "         'front': 17,\n",
       "         'align': 1,\n",
       "         'life': 70,\n",
       "         'slightli': 12,\n",
       "         'ah': 1,\n",
       "         'wile': 2,\n",
       "         'memo': 2,\n",
       "         'chapter': 3,\n",
       "         '28': 2,\n",
       "         'frame': 2,\n",
       "         'good': 228,\n",
       "         'own': 19,\n",
       "         'expect': 31,\n",
       "         'anoth': 48,\n",
       "         'progress': 6,\n",
       "         'scan': 12,\n",
       "         'soon': 4,\n",
       "         'yell': 1,\n",
       "         'dad': 2,\n",
       "         'quick': 29,\n",
       "         'left': 13,\n",
       "         'think': 55,\n",
       "         '5': 55,\n",
       "         'post': 4,\n",
       "         'somewher': 1,\n",
       "         'code': 2,\n",
       "         'useless': 14,\n",
       "         'websit': 11,\n",
       "         'slow': 32,\n",
       "         'identifi': 1,\n",
       "         'insert': 4,\n",
       "         'mayb': 14,\n",
       "         'produc': 15,\n",
       "         'audio': 36,\n",
       "         'deal': 31,\n",
       "         'pp': 1,\n",
       "         'music': 90,\n",
       "         'take': 142,\n",
       "         'conclud': 1,\n",
       "         'grant': 1,\n",
       "         'mom': 2,\n",
       "         'enough': 57,\n",
       "         'allow': 36,\n",
       "         'menu': 49,\n",
       "         'lame': 1,\n",
       "         'awkward': 10,\n",
       "         'addit': 12,\n",
       "         'feet': 7,\n",
       "         'away': 21,\n",
       "         'although': 37,\n",
       "         'batteri': 200,\n",
       "         'came': 22,\n",
       "         'huge': 16,\n",
       "         'parent': 5,\n",
       "         'three': 11,\n",
       "         'afflict': 1,\n",
       "         'glitch': 8,\n",
       "         'repeatedli': 4,\n",
       "         'playback': 6,\n",
       "         'counter': 2,\n",
       "         'go': 77,\n",
       "         'exhibit': 1,\n",
       "         'speed': 56,\n",
       "         'scratch': 19,\n",
       "         'save': 14,\n",
       "         'money': 35,\n",
       "         'result': 19,\n",
       "         'shell': 3,\n",
       "         'nicer': 3,\n",
       "         'vcr': 1,\n",
       "         'combo': 2,\n",
       "         'blaze': 1,\n",
       "         'creepi': 1,\n",
       "         'impress': 31,\n",
       "         'inexpens': 3,\n",
       "         'quirk': 1,\n",
       "         'tray': 1,\n",
       "         'perv': 1,\n",
       "         'automat': 28,\n",
       "         'extern': 12,\n",
       "         'small': 93,\n",
       "         'fade': 1,\n",
       "         'signific': 4,\n",
       "         'distanc': 5,\n",
       "         '34': 2,\n",
       "         'navig': 41,\n",
       "         'past': 13,\n",
       "         'built': 28,\n",
       "         'region': 3,\n",
       "         'damag': 8,\n",
       "         'ring': 15,\n",
       "         'build': 10,\n",
       "         'base': 18,\n",
       "         'plate': 7,\n",
       "         'soni': 17,\n",
       "         'overal': 52,\n",
       "         'plastic': 16,\n",
       "         'space': 20,\n",
       "         'howev': 46,\n",
       "         'deliv': 8,\n",
       "         'difficulti': 3,\n",
       "         'troubl': 11,\n",
       "         'consum': 4,\n",
       "         'report': 3,\n",
       "         'reliabl': 10,\n",
       "         'brand': 9,\n",
       "         'homework': 1,\n",
       "         'fals': 1,\n",
       "         'silver': 7,\n",
       "         'instead': 17,\n",
       "         'window': 48,\n",
       "         'dix': 1,\n",
       "         'rip': 24,\n",
       "         'whether': 10,\n",
       "         'rec': 1,\n",
       "         'rw': 5,\n",
       "         'vcd': 5,\n",
       "         'main': 16,\n",
       "         'dial': 19,\n",
       "         'backlit': 5,\n",
       "         'len': 33,\n",
       "         'visibl': 9,\n",
       "         'viewfind': 17,\n",
       "         'wide': 9,\n",
       "         'angl': 3,\n",
       "         'lcd': 36,\n",
       "         'bother': 10,\n",
       "         'four': 6,\n",
       "         'darn': 4,\n",
       "         'diopter': 2,\n",
       "         'adjust': 42,\n",
       "         'accur': 10,\n",
       "         'focu': 20,\n",
       "         'eyesight': 1,\n",
       "         'bulki': 5,\n",
       "         'minolta': 1,\n",
       "         'vector': 1,\n",
       "         'ap': 2,\n",
       "         'slr': 12,\n",
       "         'heavi': 13,\n",
       "         'solid': 20,\n",
       "         'contract': 2,\n",
       "         'mostli': 7,\n",
       "         'unlik': 14,\n",
       "         'canon': 46,\n",
       "         'elph': 8,\n",
       "         'ergonom': 6,\n",
       "         'shoot': 24,\n",
       "         'border': 1,\n",
       "         'ski': 2,\n",
       "         'camera': 328,\n",
       "         'cap': 7,\n",
       "         'snug': 1,\n",
       "         'easili': 54,\n",
       "         'partial': 4,\n",
       "         'obstruct': 3,\n",
       "         'drawback': 6,\n",
       "         'block': 5,\n",
       "         'b': 5,\n",
       "         'cover': 27,\n",
       "         'loos': 5,\n",
       "         'accid': 5,\n",
       "         'finger': 13,\n",
       "         'print': 17,\n",
       "         'au': 1,\n",
       "         'ti': 1,\n",
       "         'gt': 1,\n",
       "         'potenti': 5,\n",
       "         'lever': 2,\n",
       "         'shaki': 1,\n",
       "         'hope': 9,\n",
       "         'mechan': 6,\n",
       "         'uneasi': 1,\n",
       "         'lack': 16,\n",
       "         'shot': 31,\n",
       "         'sold': 5,\n",
       "         'expens': 18,\n",
       "         'girl': 1,\n",
       "         'basketbal': 1,\n",
       "         'wan': 1,\n",
       "         'task': 4,\n",
       "         'light': 56,\n",
       "         'situat': 10,\n",
       "         'combin': 13,\n",
       "         'sort': 13,\n",
       "         'action': 6,\n",
       "         'dust': 2,\n",
       "         'grain': 2,\n",
       "         'terribl': 13,\n",
       "         'flash': 35,\n",
       "         'photo': 53,\n",
       "         'limit': 13,\n",
       "         'knew': 5,\n",
       "         'lag': 4,\n",
       "         'lock': 27,\n",
       "         'bright': 16,\n",
       "         'unsatisfactori': 1,\n",
       "         'rel': 11,\n",
       "         'achiev': 5,\n",
       "         'nikon': 20,\n",
       "         'g3': 35,\n",
       "         'harsh': 1,\n",
       "         'flat': 8,\n",
       "         'imag': 44,\n",
       "         'ugli': 6,\n",
       "         'spot': 3,\n",
       "         'complaint': 26,\n",
       "         'softwar': 172,\n",
       "         'process': 25,\n",
       "         'raw': 12,\n",
       "         'replac': 49,\n",
       "         '32': 2,\n",
       "         'mbyte': 2,\n",
       "         'cf': 3,\n",
       "         '512': 3,\n",
       "         'give': 72,\n",
       "         '130': 2,\n",
       "         'oppos': 2,\n",
       "         '7': 13,\n",
       "         'affect': 4,\n",
       "         'fantasi': 1,\n",
       "         'world': 8,\n",
       "         'design': 61,\n",
       "         'pleas': 34,\n",
       "         'uncrit': 1,\n",
       "         'legitim': 1,\n",
       "         'critic': 3,\n",
       "         'onlin': 15,\n",
       "         'focus': 10,\n",
       "         'shutter': 16,\n",
       "         'blurri': 4,\n",
       "         'perhap': 11,\n",
       "         'unrespons': 2,\n",
       "         'preciou': 1,\n",
       "         'sometim': 21,\n",
       "         'indefinit': 2,\n",
       "         'consist': 6,\n",
       "         'unbear': 1,\n",
       "         'captur': 10,\n",
       "         'devic': 50,\n",
       "         'want': 86,\n",
       "         'includ': 57,\n",
       "         'bodi': 6,\n",
       "         'construct': 17,\n",
       "         'case': 58,\n",
       "         'heavier': 4,\n",
       "         'sturdi': 8,\n",
       "         'flaw': 21,\n",
       "         'detract': 3,\n",
       "         'barrel': 3,\n",
       "         'finder': 3,\n",
       "         'hand': 45,\n",
       "         'tiff': 1,\n",
       "         'format': 25,\n",
       "         'meter': 4,\n",
       "         'piti': 1,\n",
       "         '32mb': 2,\n",
       "         'compactflash': 2,\n",
       "         'card': 38,\n",
       "         'purpos': 5,\n",
       "         'memori': 33,\n",
       "         'fragil': 5,\n",
       "         'bag': 62,\n",
       "         'carri': 23,\n",
       "         'round': 5,\n",
       "         'handbag': 1,\n",
       "         'pocket': 39,\n",
       "         'function': 47,\n",
       "         'switch': 14,\n",
       "         'illumin': 2,\n",
       "         'subject': 7,\n",
       "         'depth': 13,\n",
       "         'lost': 2,\n",
       "         'strap': 6,\n",
       "         'horribl': 5,\n",
       "         'part': 14,\n",
       "         'need': 97,\n",
       "         'ye': 15,\n",
       "         'corner': 6,\n",
       "         'distort': 7,\n",
       "         'harm': 1,\n",
       "         'done': 12,\n",
       "         'cam': 1,\n",
       "         'ea': 1,\n",
       "         'exactli': 8,\n",
       "         'minim': 4,\n",
       "         'parallax': 1,\n",
       "         'phenomenon': 1,\n",
       "         'lamest': 1,\n",
       "         'ot': 2,\n",
       "         'previou': 11,\n",
       "         'lower': 11,\n",
       "         'rather': 17,\n",
       "         'stun': 4,\n",
       "         'rare': 8,\n",
       "         'major': 19,\n",
       "         'bottom': 12,\n",
       "         '15': 8,\n",
       "         'blown': 1,\n",
       "         'highlight': 2,\n",
       "         's330': 3,\n",
       "         'depress': 3,\n",
       "         'gener': 18,\n",
       "         'stainless': 1,\n",
       "         'steel': 2,\n",
       "         'heft': 2,\n",
       "         'nit': 2,\n",
       "         'fairli': 12,\n",
       "         'boxi': 1,\n",
       "         'wrist': 1,\n",
       "         'neck': 2,\n",
       "         'spite': 1,\n",
       "         'pricey': 3,\n",
       "         'crack': 5,\n",
       "         'sd': 3,\n",
       "         'fluid': 1,\n",
       "         'jackson': 1,\n",
       "         'pollock': 1,\n",
       "         'blue': 20,\n",
       "         'purpl': 3,\n",
       "         'blotch': 1,\n",
       "         'streak': 2,\n",
       "         'knock': 3,\n",
       "         'underpow': 1,\n",
       "         'blob': 1,\n",
       "         'figur': 8,\n",
       "         '57': 2,\n",
       "         'except': 24,\n",
       "         'icon': 3,\n",
       "         'due': 15,\n",
       "         'weight': 16,\n",
       "         'shake': 6,\n",
       "         'contend': 1,\n",
       "         'disadvantag': 1,\n",
       "         'autofocu': 5,\n",
       "         'candid': 1,\n",
       "         'compact': 25,\n",
       "         'someon': 8,\n",
       "         'clip': 24,\n",
       "         'warm': 2,\n",
       "         'loud': 17,\n",
       "         'downsid': 10,\n",
       "         'condit': 3,\n",
       "         'sd500': 14,\n",
       "         'possess': 1,\n",
       "         'twice': 6,\n",
       "         'sensit': 15,\n",
       "         'compromis': 4,\n",
       "         'rebel': 2,\n",
       "         'agre': 4,\n",
       "         'advanc': 9,\n",
       "         'robust': 5,\n",
       "         'head': 4,\n",
       "         'share': 6,\n",
       "         'click': 26,\n",
       "         'stiff': 2,\n",
       "         'aw': 9,\n",
       "         'ton': 10,\n",
       "         'research': 9,\n",
       "         'cnet': 3,\n",
       "         'manipul': 5,\n",
       "         'dark': 7,\n",
       "         '8': 18,\n",
       "         'meg': 3,\n",
       "         'next': 16,\n",
       "         '256': 3,\n",
       "         'eye': 9,\n",
       "         'taken': 20,\n",
       "         'lithium': 6,\n",
       "         'highli': 27,\n",
       "         'inconveni': 6,\n",
       "         'vacat': 2,\n",
       "         'nearest': 2,\n",
       "         'ga': 1,\n",
       "         'station': 8,\n",
       "         'span': 2,\n",
       "         'short': 17,\n",
       "         'uncommon': 1,\n",
       "         'bring': 7,\n",
       "         'charger': 8,\n",
       "         'spare': 9,\n",
       "         'length': 3,\n",
       "         'silent': 4,\n",
       "         'hardli': 5,\n",
       "         'unabl': 3,\n",
       "         'quiet': 11,\n",
       "         'noisi': 2,\n",
       "         'macro': 13,\n",
       "         'auto': 28,\n",
       "         'overrid': 1,\n",
       "         'overcom': 2,\n",
       "         'choic': 16,\n",
       "         'difficult': 22,\n",
       "         'manag': 11,\n",
       "         'imposs': 7,\n",
       "         'glass': 2,\n",
       "         'steadi': 4,\n",
       "         'challeng': 6,\n",
       "         'grip': 4,\n",
       "         'delay': 3,\n",
       "         'fulli': 8,\n",
       "         'yield': 3,\n",
       "         'fuzzi': 1,\n",
       "         'unusu': 1,\n",
       "         'system': 43,\n",
       "         'intermedi': 1,\n",
       "         'resolut': 13,\n",
       "         'suggest': 7,\n",
       "         'meaningless': 1,\n",
       "         'snap': 5,\n",
       "         'car': 18,\n",
       "         'realiz': 5,\n",
       "         'select': 19,\n",
       "         'luck': 5,\n",
       "         'repres': 2,\n",
       "         'record': 40,\n",
       "         'max': 5,\n",
       "         '30': 13,\n",
       "         '160x120': 1,\n",
       "         'per': 11,\n",
       "         '640x480': 3,\n",
       "         'origin': 8,\n",
       "         '98': 5,\n",
       "         'wonder': 21,\n",
       "         'comput': 77,\n",
       "         'novemb': 1,\n",
       "         'xp': 14,\n",
       "         'usb': 33,\n",
       "         'soho': 2,\n",
       "         'compat': 11,\n",
       "         'driver': 9,\n",
       "         'cannon': 1,\n",
       "         'backup': 4,\n",
       "         'adob': 1,\n",
       "         'let': 19,\n",
       "         'forc': 3,\n",
       "         'creat': 16,\n",
       "         'document': 12,\n",
       "         'export': 2,\n",
       "         'applic': 16,\n",
       "         'intuit': 27,\n",
       "         'often': 10,\n",
       "         'struggl': 1,\n",
       "         'said': 19,\n",
       "         'peopl': 55,\n",
       "         'skin': 1,\n",
       "         'pic': 20,\n",
       "         'true': 10,\n",
       "         'exposur': 10,\n",
       "         'redey': 2,\n",
       "         'reduct': 1,\n",
       "         'balanc': 12,\n",
       "         'fool': 2,\n",
       "         'dens': 2,\n",
       "         'cloud': 1,\n",
       "         'dynam': 3,\n",
       "         'rang': 20,\n",
       "         'kodak': 4,\n",
       "         'dc260': 1,\n",
       "         'ed': 6,\n",
       "         'casio': 3,\n",
       "         'worst': 8,\n",
       "         'calcul': 2,\n",
       "         'ok': 19,\n",
       "         'wife': 4,\n",
       "         'granni': 1,\n",
       "         'side': 19,\n",
       "         'fix': 9,\n",
       "         'photoshop': 5,\n",
       "         '0': 16,\n",
       "         'level': 16,\n",
       "         'person': 34,\n",
       "         'accessori': 15,\n",
       "         'headphon': 54,\n",
       "         ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "add_doc_to_vocab(sentences, vocab)\n",
    "print(len(vocab))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('weak', 12), ('minor', 9), ('feel', 48), ('layout', 5), ('remot', 30), ('control', 84), ('n', 144), ('show', 16), ('complet', 19), ('file', 89), ('name', 13), ('mp3', 73), ('realli', 119), ('long', 56), ('must', 26), ('cycl', 3), ('everi', 40), ('zoom', 51), ('set', 87), ('2x', 3), ('3x', 8), ('4x', 6), ('1', 93), ('etc', 42), ('get', 243), ('back', 46), ('normal', 21), ('size', 76), ('sorri', 2), ('ignor', 2), ('way', 68), ('1x', 1), ('quickli', 20), ('mani', 70), ('disney', 2), ('movi', 26), ('play', 142), ('dvd', 113), ('player', 331), ('problem', 202), ('dual', 3), ('layer', 3), ('alia', 2), ('season', 3), ('2', 102), ('know', 43), ('say', 60), ('pay', 15), ('stage', 1), ('game', 29), ('better', 111), ('qualiti', 218), ('excus', 1), ('never', 49), ('purchas', 69), ('apex', 46), ('custom', 42), ('servic', 61), ('technic', 5), ('support', 69), ('overload', 2), ('non', 12), ('respons', 9), ('tell', 24), ('product', 130), ('willing', 1), ('stand', 15), ('behind', 4), ('would', 160), ('stop', 21), ('middl', 4), ('even', 124), ('read', 64), ('new', 59), ('cd', 74), ('almost', 32), ('alway', 33), ('began', 2), ('skip', 8), ('thought', 23), ('start', 53), ('check', 13), ('disc', 31), ('find', 75), ('2600', 11), ('actual', 38), ('ruin', 3), ('media', 19), ('worth', 23), ('price', 116), ('recommend', 52), ('answer', 13), ('phone', 312), ('contact', 12), ('bad', 31), ('everyth', 53), ('3', 80), ('die', 10), ('shortli', 3), ('nice', 96), ('machin', 25), ('consid', 21), ('pretti', 52), ('low', 29), ('item', 12), ('broke', 6), ('two', 59), ('week', 49), ('gave', 16), ('kid', 3), ('christma', 15), ('door', 7), ('close', 25), ('tri', 77), ('return', 9), ('miss', 13), ('amazon', 26), ('period', 11), ('took', 29), ('month', 65), ('dept', 2), ('unfortun', 16), ('turn', 46), ('dispos', 8), ('type', 11), ('sinc', 52), ('first', 86), ('day', 65), ('final', 24), ('less', 43), ('60', 6), ('recogn', 15), ('anyth', 40), ('pop', 24), ('tend', 7), ('run', 47), ('quit', 51), ('hot', 11), ('given', 17), ('lot', 78), ('room', 17), ('air', 2), ('circul', 1), ('also', 150), ('seem', 85), ('strong', 10), ('electron', 8), ('smell', 27), ('time', 155), ('thing', 115), ('experi', 23), ('freez', 19), ('abl', 37), ('clear', 31), ('open', 38), ('blow', 6), ('can', 1), ('okay', 4), ('fan', 3), ('tini', 19), ('button', 95), ('especi', 32), ('like', 214), ('commonli', 1), ('use', 515), ('paus', 5), ('larger', 19), ('conveni', 18), ('place', 17), ('display', 33), ('inform', 10), ('screen', 88), ('mode', 60), ('goe', 11), ('magnif', 1), ('one', 297), ('quarter', 1), ('top', 24), ('interfer', 2), ('view', 15), ('spent', 7), ('consider', 4), ('profession', 6), ('video', 50), ('gear', 1), ('onscreen', 2), ('annoy', 21), ('90', 9), ('pictur', 171), ('matter', 12), ('see', 43), ('total', 13), ('6', 26), ('frustrat', 12), ('aggrav', 1), ('job', 18), ('hold', 44), ('email', 18), ('telephon', 5), ('number', 36), ('constantli', 8), ('busi', 13), ('believ', 16), ('lone', 1), ('rep', 5), ('probabl', 23), ('extrem', 24), ('overwork', 1), ('wo', 14), ('yesterday', 4), ('today', 8), ('80', 3), ('store', 34), ('bough', 1), ('ten', 4), ('tech', 25), ('liter', 6), ('nonexist', 1), ('bought', 42), ('model', 22), ('present', 7), ('neither', 7), ('work', 269), ('embarass', 2), ('call', 43), ('famili', 7), ('member', 1), ('ago', 14), ('longer', 13), ('properli', 11), ('usual', 13), ('occasion', 12), ('particular', 3), ('point', 33), ('access', 30), ('certain', 9), ('special', 15), ('featur', 196), ('rental', 2), ('happen', 5), ('sever', 21), ('differ', 33), ('keep', 44), ('someth', 39), ('discov', 8), ('flor', 1), ('got', 63), ('touch', 41), ('web', 13), ('far', 73), ('refus', 5), ('episod', 1), ('other', 17), ('ps2', 1), ('could', 72), ('went', 16), ('sound', 166), ('hate', 7), ('love', 83), ('everyon', 9), ('crap', 7), ('univers', 5), ('claim', 5), ('none', 11), ('cours', 13), ('coupl', 13), ('appear', 15), ('defect', 9), ('list', 20), ('toll', 2), ('free', 33), ('real', 21), ('hassl', 9), ('regular', 21), ('line', 30), ('inclin', 1), ('unit', 45), ('forev', 4), ('begin', 8), ('higher', 8), ('scene', 10), ('engin', 5), ('embarrass', 1), ('profess', 1), ('releas', 8), ('sale', 3), ('send', 13), ('discontinu', 1), ('signal', 24), ('tv', 10), ('moment', 10), ('white', 18), ('nois', 15), ('make', 98), ('color', 46), ('look', 139), ('satur', 1), ('entir', 7), ('poorli', 7), ('craft', 2), ('sharp', 15), ('screw', 5), ('tip', 4), ('undersid', 1), ('come', 89), ('insid', 18), ('obvious', 4), ('anchor', 1), ('intern', 4), ('board', 4), ('hook', 10), ('found', 45), ('50', 12), ('put', 39), ('spin', 5), ('alreadi', 24), ('disappoint', 36), ('respond', 8), ('promis', 7), ('turnaround', 1), ('24', 6), ('hour', 54), ('piec', 17), ('junk', 8), ('later', 4), ('eventu', 6), ('stori', 1), ('everybodi', 2), ('els', 20), ('noth', 17), ('fine', 46), ('1st', 5), ('half', 12), ('disappear', 3), ('still', 93), ('describ', 3), ('basic', 18), ('cu', 1), ('st', 1), ('help', 36), ('mine', 25), ('old', 28), ('chuck', 3), ('trash', 18), ('belong', 1), ('4', 66), ('last', 44), ('six', 3), ('sent', 8), ('ad2600', 2), ('messag', 12), ('though', 43), ('bit', 81), ('flimsi', 10), ('predict', 2), ('gift', 7), ('second', 49), ('digit', 67), ('site', 20), ('25', 5), ('watch', 6), ('kick', 4), ('rate', 22), ('five', 10), ('star', 39), ('poor', 9), ('manual', 58), ('12', 16), ('26', 3), ('9', 6), ('fail', 12), ('neg', 12), ('review', 57), ('ask', 13), ('repli', 3), ('wait', 16), ('27', 3), ('10', 28), ('otherwis', 13), ('clean', 17), ('friend', 16), ('gripe', 3), ('incred', 17), ('crappi', 2), ('wors', 6), ('cheaper', 10), ('press', 18), ('hard', 65), ('frequent', 5), ('end', 21), ('enter', 4), ('meant', 3), ('scroll', 44), ('reason', 31), ('wash', 4), ('bleed', 2), ('compar', 29), ('compon', 8), ('connect', 58), ('much', 104), ('percept', 1), ('cheap', 25), ('ch', 2), ('easi', 217), ('sure', 30), ('buck', 12), ('heck', 2), ('dirti', 13), ('ice', 3), ('age', 2), ('e', 18), ('mail', 9), ('undeliver', 1), ('leav', 16), ('question', 7), ('attempt', 4), ('multitud', 1), ('method', 2), ('ad', 15), ('numer', 7), ('recent', 15), ('yet', 30), ('without', 61), ('depart', 4), ('request', 1), ('ra', 1), ('disk', 13), ('natur', 11), ('31', 1), ('froze', 2), ('load', 32), ('via', 21), ('customerservic', 1), ('apexdigit', 1), ('com', 16), ('address', 7), ('valid', 1), ('866', 2), ('4apexgo', 1), ('suck', 14), ('hear', 11), ('www', 5), ('inc', 2), ('receiv', 21), ('kept', 12), ('rent', 2), ('great', 280), ('girlfriend', 1), ('somewhat', 16), ('fact', 40), ('exampl', 9), ('pirat', 1), ('caribbean', 1), ('extra', 29), ('isol', 1), ('incid', 2), ('proven', 5), ('wrong', 16), ('well', 156), ('output', 9), ('catch', 5), ('occas', 5), ('littl', 106), ('understand', 16), ('jpeg', 8), ('viewabl', 1), ('vivid', 2), ('17', 2), ('monitor', 2), ('awesom', 35), ('lip', 2), ('sync', 19), ('issu', 32), ('move', 15), ('dialog', 1), ('black', 14), ('composit', 1), ('v', 1), ('p', 3), ('confus', 9), ('doesnt', 6), ('may', 22), ('oper', 37), ('error', 9), ('hell', 5), ('forget', 5), ('sleek', 18), ('within', 15), ('45', 3), ('rca', 2), ('optic', 22), ('instal', 89), ('devast', 1), ('least', 21), ('updat', 27), ('januari', 1), ('27th', 1), ('2004', 22), ('dont', 15), ('buy', 86), ('immedi', 5), ('favorit', 14), ('multipl', 10), ('avail', 19), ('success', 7), ('broken', 8), ('motor', 5), ('eject', 1), ('brother', 2), ('hous', 14), ('either', 25), ('imagin', 9), ('shock', 3), ('absolut', 22), ('instant', 7), ('disdain', 1), ('made', 47), ('2nd', 3), ('faulti', 2), ('power', 51), ('suppli', 10), ('caus', 11), ('1600', 1), ('correctli', 6), ('1220', 1), ('act', 3), ('front', 17), ('align', 1), ('life', 70), ('slightli', 12), ('ah', 1), ('wile', 2), ('memo', 2), ('chapter', 3), ('28', 2), ('frame', 2), ('good', 228), ('own', 19), ('expect', 31), ('anoth', 48), ('progress', 6), ('scan', 12), ('soon', 4), ('yell', 1), ('dad', 2), ('quick', 29), ('left', 13), ('think', 55), ('5', 55), ('post', 4), ('somewher', 1), ('code', 2), ('useless', 14), ('websit', 11), ('slow', 32), ('identifi', 1), ('insert', 4), ('mayb', 14), ('produc', 15), ('audio', 36), ('deal', 31), ('pp', 1), ('music', 90), ('take', 142), ('conclud', 1), ('grant', 1), ('mom', 2), ('enough', 57), ('allow', 36), ('menu', 49), ('lame', 1), ('awkward', 10), ('addit', 12), ('feet', 7), ('away', 21), ('although', 37), ('batteri', 200), ('came', 22), ('huge', 16), ('parent', 5), ('three', 11), ('afflict', 1), ('glitch', 8), ('repeatedli', 4), ('playback', 6), ('counter', 2), ('go', 77), ('exhibit', 1), ('speed', 56), ('scratch', 19), ('save', 14), ('money', 35), ('result', 19), ('shell', 3), ('nicer', 3), ('vcr', 1), ('combo', 2), ('blaze', 1), ('creepi', 1), ('impress', 31), ('inexpens', 3), ('quirk', 1), ('tray', 1), ('perv', 1), ('automat', 28), ('extern', 12), ('small', 93), ('fade', 1), ('signific', 4), ('distanc', 5), ('34', 2), ('navig', 41), ('past', 13), ('built', 28), ('region', 3), ('damag', 8), ('ring', 15), ('build', 10), ('base', 18), ('plate', 7), ('soni', 17), ('overal', 52), ('plastic', 16), ('space', 20), ('howev', 46), ('deliv', 8), ('difficulti', 3), ('troubl', 11), ('consum', 4), ('report', 3), ('reliabl', 10), ('brand', 9), ('homework', 1), ('fals', 1), ('silver', 7), ('instead', 17), ('window', 48), ('dix', 1), ('rip', 24), ('whether', 10), ('rec', 1), ('rw', 5), ('vcd', 5), ('main', 16), ('dial', 19), ('backlit', 5), ('len', 33), ('visibl', 9), ('viewfind', 17), ('wide', 9), ('angl', 3), ('lcd', 36), ('bother', 10), ('four', 6), ('darn', 4), ('diopter', 2), ('adjust', 42), ('accur', 10), ('focu', 20), ('eyesight', 1), ('bulki', 5), ('minolta', 1), ('vector', 1), ('ap', 2), ('slr', 12), ('heavi', 13), ('solid', 20), ('contract', 2), ('mostli', 7), ('unlik', 14), ('canon', 46), ('elph', 8), ('ergonom', 6), ('shoot', 24), ('border', 1), ('ski', 2), ('camera', 328), ('cap', 7), ('snug', 1), ('easili', 54), ('partial', 4), ('obstruct', 3), ('drawback', 6), ('block', 5), ('b', 5), ('cover', 27), ('loos', 5), ('accid', 5), ('finger', 13), ('print', 17), ('au', 1), ('ti', 1), ('gt', 1), ('potenti', 5), ('lever', 2), ('shaki', 1), ('hope', 9), ('mechan', 6), ('uneasi', 1), ('lack', 16), ('shot', 31), ('sold', 5), ('expens', 18), ('girl', 1), ('basketbal', 1), ('wan', 1), ('task', 4), ('light', 56), ('situat', 10), ('combin', 13), ('sort', 13), ('action', 6), ('dust', 2), ('grain', 2), ('terribl', 13), ('flash', 35), ('photo', 53), ('limit', 13), ('knew', 5), ('lag', 4), ('lock', 27), ('bright', 16), ('unsatisfactori', 1), ('rel', 11), ('achiev', 5), ('nikon', 20), ('g3', 35), ('harsh', 1), ('flat', 8), ('imag', 44), ('ugli', 6), ('spot', 3), ('complaint', 26), ('softwar', 172), ('process', 25), ('raw', 12), ('replac', 49), ('32', 2), ('mbyte', 2), ('cf', 3), ('512', 3), ('give', 72), ('130', 2), ('oppos', 2), ('7', 13), ('affect', 4), ('fantasi', 1), ('world', 8), ('design', 61), ('pleas', 34), ('uncrit', 1), ('legitim', 1), ('critic', 3), ('onlin', 15), ('focus', 10), ('shutter', 16), ('blurri', 4), ('perhap', 11), ('unrespons', 2), ('preciou', 1), ('sometim', 21), ('indefinit', 2), ('consist', 6), ('unbear', 1), ('captur', 10), ('devic', 50), ('want', 86), ('includ', 57), ('bodi', 6), ('construct', 17), ('case', 58), ('heavier', 4), ('sturdi', 8), ('flaw', 21), ('detract', 3), ('barrel', 3), ('finder', 3), ('hand', 45), ('tiff', 1), ('format', 25), ('meter', 4), ('piti', 1), ('32mb', 2), ('compactflash', 2), ('card', 38), ('purpos', 5), ('memori', 33), ('fragil', 5), ('bag', 62), ('carri', 23), ('round', 5), ('handbag', 1), ('pocket', 39), ('function', 47), ('switch', 14), ('illumin', 2), ('subject', 7), ('depth', 13), ('lost', 2), ('strap', 6), ('horribl', 5), ('part', 14), ('need', 97), ('ye', 15), ('corner', 6), ('distort', 7), ('harm', 1), ('done', 12), ('cam', 1), ('ea', 1), ('exactli', 8), ('minim', 4), ('parallax', 1), ('phenomenon', 1), ('lamest', 1), ('ot', 2), ('previou', 11), ('lower', 11), ('rather', 17), ('stun', 4), ('rare', 8), ('major', 19), ('bottom', 12), ('15', 8), ('blown', 1), ('highlight', 2), ('s330', 3), ('depress', 3), ('gener', 18), ('stainless', 1), ('steel', 2), ('heft', 2), ('nit', 2), ('fairli', 12), ('boxi', 1), ('wrist', 1), ('neck', 2), ('spite', 1), ('pricey', 3), ('crack', 5), ('sd', 3), ('fluid', 1), ('jackson', 1), ('pollock', 1), ('blue', 20), ('purpl', 3), ('blotch', 1), ('streak', 2), ('knock', 3), ('underpow', 1), ('blob', 1), ('figur', 8), ('57', 2), ('except', 24), ('icon', 3), ('due', 15), ('weight', 16), ('shake', 6), ('contend', 1), ('disadvantag', 1), ('autofocu', 5), ('candid', 1), ('compact', 25), ('someon', 8), ('clip', 24), ('warm', 2), ('loud', 17), ('downsid', 10), ('condit', 3), ('sd500', 14), ('possess', 1), ('twice', 6), ('sensit', 15), ('compromis', 4), ('rebel', 2), ('agre', 4), ('advanc', 9), ('robust', 5), ('head', 4), ('share', 6), ('click', 26), ('stiff', 2), ('aw', 9), ('ton', 10), ('research', 9), ('cnet', 3), ('manipul', 5), ('dark', 7), ('8', 18), ('meg', 3), ('next', 16), ('256', 3), ('eye', 9), ('taken', 20), ('lithium', 6), ('highli', 27), ('inconveni', 6), ('vacat', 2), ('nearest', 2), ('ga', 1), ('station', 8), ('span', 2), ('short', 17), ('uncommon', 1), ('bring', 7), ('charger', 8), ('spare', 9), ('length', 3), ('silent', 4), ('hardli', 5), ('unabl', 3), ('quiet', 11), ('noisi', 2), ('macro', 13), ('auto', 28), ('overrid', 1), ('overcom', 2), ('choic', 16), ('difficult', 22), ('manag', 11), ('imposs', 7), ('glass', 2), ('steadi', 4), ('challeng', 6), ('grip', 4), ('delay', 3), ('fulli', 8), ('yield', 3), ('fuzzi', 1), ('unusu', 1), ('system', 43), ('intermedi', 1), ('resolut', 13), ('suggest', 7), ('meaningless', 1), ('snap', 5), ('car', 18), ('realiz', 5), ('select', 19), ('luck', 5), ('repres', 2), ('record', 40), ('max', 5), ('30', 13), ('160x120', 1), ('per', 11), ('640x480', 3), ('origin', 8), ('98', 5), ('wonder', 21), ('comput', 77), ('novemb', 1), ('xp', 14), ('usb', 33), ('soho', 2), ('compat', 11), ('driver', 9), ('cannon', 1), ('backup', 4), ('adob', 1), ('let', 19), ('forc', 3), ('creat', 16), ('document', 12), ('export', 2), ('applic', 16), ('intuit', 27), ('often', 10), ('struggl', 1), ('said', 19), ('peopl', 55), ('skin', 1), ('pic', 20), ('true', 10), ('exposur', 10), ('redey', 2), ('reduct', 1), ('balanc', 12), ('fool', 2), ('dens', 2), ('cloud', 1), ('dynam', 3), ('rang', 20), ('kodak', 4), ('dc260', 1), ('ed', 6), ('casio', 3), ('worst', 8), ('calcul', 2), ('ok', 19), ('wife', 4), ('granni', 1), ('side', 19), ('fix', 9), ('photoshop', 5), ('0', 16), ('level', 16), ('person', 34), ('accessori', 15), ('headphon', 54), ('stock', 5), ('tricki', 2), ('pdf', 4), ('instruct', 20), ('bigger', 10), ('smaller', 20), ('readabl', 4), ('overus', 1), ('firewir', 7), ('user', 52), ('push', 10), ('wheel', 30), ('straight', 7), ('stick', 15), ('playlist', 21), ('nomad', 43), ('jukebox', 14), ('zen', 132), ('xtra', 24), ('gb', 24), ('interfac', 53), ('friendli', 12), ('face', 9), ('minut', 17), ('hang', 9), ('transfer', 58), ('prompt', 3), ('reset', 4), ('overli', 6), ('bar', 12), ('setup', 31), ('infuri', 1), ('sub', 3), ('par', 4), ('portabl', 14), ('mp', 5), ('beef', 3), ('defici', 2), ('zennx', 4), ('3rd', 4), ('parti', 7), ('earphon', 4), ('20', 12), ('program', 53), ('live', 17), ('song', 84), ('idea', 6), ('clutter', 2), ('stuck', 12), ('ipod', 171), ('match', 2), ('greatest', 4), ('search', 9), ('fast', 47), ('key', 19), ('shortcut', 1), ('con', 13), ('tad', 4), ('aesthet', 3), ('folder', 22), ('structur', 4), ('big', 51), ('titl', 9), ('separ', 5), ('pc', 39), ('chang', 36), ('might', 16), ('man', 3), ('chines', 2), ('concern', 8), ('longev', 1), ('forward', 9), ('pressur', 2), ('id3', 14), ('tag', 21), ('track', 23), ('lump', 1), ('directori', 3), ('artist', 15), ('album', 20), ('renam', 3), ('duplic', 1), ('explor', 16), ('shut', 11), ('genr', 14), ('reboot', 9), ('hit', 10), ('painless', 4), ('jog', 5), ('quirki', 1), ('break', 11), ('pro', 17), ('enclos', 2), ('belkin', 3), ('fm', 40), ('transmitt', 2), ('radio', 41), ('inferior', 5), ('simpl', 38), ('fli', 7), ('uncomfort', 5), ('locat', 6), ('variou', 5), ('illog', 1), ('creativ', 109), ('wildli', 1), ('rest', 4), ('desk', 5), ('strang', 1), ('obviou', 3), ('accept', 7), ('clearli', 8), ('intend', 5), ('patch', 2), ('easiest', 4), ('becom', 8), ('ridicul', 4), ('blunt', 1), ('cumbersom', 6), ('ever', 43), ('protect', 14), ('abil', 24), ('cut', 11), ('out', 1), ('materi', 3), ('adequ', 7), ('satisfi', 12), ('odd', 3), ('simpli', 18), ('firmwar', 27), ('os', 10), ('readi', 8), ('prime', 1), ('futur', 4), ('40', 12), ('year', 43), ('warranti', 10), ('warrant', 1), ('weigh', 2), ('best', 99), ('drop', 31), ('ft', 2), ('hide', 2), ('itun', 25), ('pain', 4), ('high', 37), ('divis', 2), ('bundl', 9), ('defin', 7), ('wouldnt', 2), ('surviv', 4), ('lit', 4), ('c', 2), ('travesti', 1), ('misfortun', 2), ('crash', 10), ('librari', 5), ('mp4', 1), ('monstros', 1), ('fit', 34), ('cage', 1), ('f', 2), ('spend', 7), ('kind', 20), ('cash', 2), ('lab', 8), ('download', 44), ('irrig', 1), ('stylish', 9), ('right', 47), ('sit', 4), ('environment', 1), ('encod', 4), ('192', 2), ('kbp', 4), ('variabl', 8), ('yeah', 4), ('earbud', 22), ('cool', 39), ('drive', 36), ('embed', 1), ('organ', 19), ('rubber', 2), ('delic', 3), ('durabl', 18), ('jack', 23), ('decent', 25), ('estim', 1), ('walkman', 2), ('necessarili', 2), ('enjoy', 12), ('biggest', 10), ('common', 3), ('rapidli', 3), ('ac', 8), ('unless', 12), ('pack', 15), ('travel', 10), ('beforehand', 1), ('explain', 3), ('configur', 20), ('sens', 7), ('ear', 17), ('caviti', 1), ('eax', 15), ('enhanc', 3), ('eq', 5), ('band', 6), ('bass', 7), ('boost', 2), ('plug', 19), ('mean', 19), ('breez', 8), ('weighti', 1), ('ounc', 2), ('biggi', 1), ('forgot', 1), ('isnt', 2), ('mediocr', 4), ('bookmark', 4), ('excel', 90), ('area', 18), ('defeat', 1), ('harder', 5), ('gotten', 11), ('justifi', 1), ('reserv', 3), ('interact', 1), ('alphabet', 2), ('order', 12), ('complic', 8), ('individu', 6), ('burner', 2), ('complain', 9), ('sexi', 2), ('mention', 24), ('remov', 36), ('eh', 1), ('doubt', 7), ('dock', 3), ('creation', 2), ('book', 12), ('elimin', 4), ('palm', 6), ('unproven', 1), ('vastli', 2), ('integr', 9), ('clunki', 2), ('wma', 20), ('term', 7), ('superior', 14), ('aac', 2), ('appl', 28), ('paid', 5), ('napster', 10), ('plan', 9), ('obscur', 2), ('earlier', 2), ('equal', 11), ('accentu', 1), ('diminish', 1), ('provid', 19), ('volum', 28), ('ident', 3), ('inordin', 1), ('random', 2), ('despit', 13), ('larg', 23), ('databas', 4), ('util', 4), ('mediasourc', 22), ('pull', 7), ('data', 16), ('dd', 2), ('popul', 1), ('field', 2), ('comfort', 23), ('ho', 1), ('hum', 2), ('belt', 9), ('secur', 29), ('slip', 4), ('reachabl', 1), ('buyer', 3), ('wari', 2), ('reader', 3), ('third', 8), ('compani', 17), ('resolv', 3), ('virtual', 5), ('catalog', 2), ('burn', 4), ('musicmatch', 4), ('278', 1), ('400', 4), ('128bp', 1), ('guess', 4), ('kudo', 1), ('experienc', 5), ('introduc', 4), ('static', 3), ('seriou', 11), ('launch', 3), ('copi', 6), ('word', 8), ('storag', 31), ('capac', 17), ('collect', 15), ('version', 34), ('nx', 6), ('requir', 20), ('adapt', 12), ('recharg', 23), ('charg', 41), ('cabl', 24), ('tragic', 1), ('notebook', 2), ('goofi', 1), ('indic', 6), ('whole', 13), ('bunch', 4), ('tough', 5), ('pope', 2), ('near', 9), ('latch', 2), ('felt', 2), ('flywheel', 1), ('tightli', 4), ('uneven', 1), ('amount', 5), ('engag', 2), ('cheesiest', 1), ('seen', 24), ('panel', 10), ('notic', 14), ('gap', 3), ('will', 6), ('shoddi', 1), ('250', 3), ('dollar', 7), ('attach', 8), ('state', 9), ('reload', 1), ('among', 9), ('encount', 8), ('amaz', 36), ('prone', 3), ('clue', 1), ('gut', 1), ('40gb', 10), ('albeit', 3), ('lesson', 1), ('audigi', 3), ('fri', 1), ('20usd', 1), ('reap', 1), ('damn', 2), ('patient', 1), ('winxp', 2), ('detect', 3), ('drag', 5), ('older', 8), ('incorrect', 1), ('voic', 25), ('oversight', 1), ('market', 27), ('occlud', 1), ('reli', 2), ('kinda', 3), ('invest', 6), ('treat', 3), ('definit', 22), ('mind', 10), ('notmad', 7), ('road', 5), ('zero', 5), ('briefcas', 1), ('zap', 1), ('elsewher', 3), ('withstand', 1), ('rigor', 2), ('option', 48), ('contain', 9), ('unavail', 2), ('unfil', 1), ('unknown', 1), ('uninstal', 9), ('100', 7), ('toggl', 1), ('placement', 2), ('continu', 12), ('14', 7), ('sturdier', 3), ('archo', 4), ('resist', 2), ('advertis', 7), ('lockup', 1), ('feedback', 3), ('suffer', 1), ('appli', 1), ('finicki', 1), ('learn', 21), ('curv', 6), ('75', 3), ('plain', 1), ('inbuilt', 1), ('manufactur', 6), ('abus', 2), ('fizzl', 1), ('laptop', 10), ('intel', 1), ('p4', 1), ('percent', 1), ('si', 1), ('anyway', 10), ('stink', 4), ('extend', 7), ('rais', 8), ('regard', 5), ('besid', 5), ('perfect', 41), ('280', 1), ('care', 14), ('lousi', 1), ('blaster', 1), ('dumb', 1), ('corrupt', 1), ('odditi', 1), ('typic', 2), ('convinc', 3), ('observ', 2), ('undon', 1), ('failur', 1), ('occur', 1), ('expir', 1), ('listen', 25), ('morn', 4), ('class', 9), ('diaper', 108), ('wipe', 4), ('handl', 15), ('forth', 5), ('odorless', 2), ('daughter', 3), ('odor', 29), ('newborn', 2), ('fill', 6), ('emot', 1), ('pail', 26), ('everyday', 3), ('geni', 16), ('refil', 19), ('messi', 2), ('mess', 9), ('modul', 1), ('dump', 4), ('outsid', 5), ('deeper', 3), ('wider', 6), ('garbag', 12), ('hole', 2), ('medium', 3), ('brink', 1), ('un', 1), ('soil', 1), ('unload', 2), ('champ', 52), ('costli', 2), ('stinki', 6), ('full', 29), ('flip', 17), ('particularli', 5), ('lift', 2), ('lid', 7), ('wad', 1), ('empti', 6), ('pinch', 1), ('thumb', 8), ('effort', 3), ('plunger', 2), ('upon', 10), ('inspect', 1), ('suppos', 5), ('improv', 12), ('food', 2), ('poop', 3), ('wish', 4), ('eat', 2), ('escap', 2), ('freshen', 1), ('prepar', 2), ('trap', 1), ('loader', 1), ('tendenc', 2), ('resort', 1), ('wet', 1), ('caught', 2), ('er', 2), ('extract', 1), ('regist', 3), ('jam', 1), ('faint', 1), ('serv', 3), ('effici', 4), ('effect', 10), ('pass', 6), ('follow', 13), ('babi', 17), ('diet', 1), ('aka', 1), ('lysol', 3), ('oder', 1), ('edg', 9), ('snag', 3), ('floor', 4), ('stay', 11), ('around', 34), ('wrap', 4), ('compart', 1), ('shove', 1), ('tight', 2), ('chip', 3), ('nail', 2), ('hurt', 1), ('fingertip', 2), ('seal', 3), ('piston', 2), ('anymor', 3), ('grove', 1), ('decor', 1), ('whiff', 1), ('gone', 4), ('deodor', 2), ('knob', 11), ('router', 131), ('practic', 7), ('collet', 7), ('inch', 1), ('viper', 1), ('bare', 7), ('bulkier', 1), ('freehand', 4), ('mount', 4), ('tabl', 22), ('singl', 11), ('easier', 24), ('diamet', 2), ('hitachi', 20), ('makita', 2), ('pun', 1), ('art', 3), ('latest', 6), ('bell', 2), ('whistl', 2), ('tilt', 1), ('crank', 3), ('height', 5), ('heaviest', 1), ('porter', 3), ('distinct', 4), ('precis', 3), ('handheld', 2), ('plung', 15), ('reach', 6), ('spindl', 2), ('sleev', 2), ('tighten', 1), ('suffici', 3), ('ground', 1), ('smooth', 14), ('benefit', 4), ('rp', 1), ('ms', 3), ('finish', 7), ('perform', 20), ('wood', 5), ('spring', 4), ('hammer', 1), ('note', 6), ('tool', 13), ('sawdust', 1), ('channel', 1), ('attent', 2), ('killer', 6), ('slop', 1), ('column', 1), ('shop', 4), ('templat', 1), ('guid', 10), ('tube', 1), ('seldom', 2), ('bend', 1), ('wrench', 5), ('brought', 3), ('shaft', 2), ('repeal', 1), ('stationari', 1), ('oftentim', 1), ('activ', 7), ('muscl', 2), ('loosen', 1), ('sceptic', 1), ('defer', 1), ('maker', 2), ('hp', 5), ('sloppi', 3), ('recess', 1), ('screwdriv', 1), ('dowel', 1), ('rod', 1), ('son', 7), ('assist', 5), ('posit', 16), ('comment', 4), ('micro', 68), ('raiser', 1), ('slide', 7), ('racier', 1), ('serious', 6), ('held', 5), ('lubric', 2), ('safeti', 1), ('hazard', 1), ('luckili', 2), ('soft', 9), ('toss', 3), ('jump', 6), ('doubl', 5), ('hi', 3), ('cup', 1), ('unplug', 1), ('wizard', 6), ('sinist', 1), ('disconnect', 2), ('input', 2), ('current', 10), ('pre', 2), ('exist', 5), ('clariti', 9), ('wire', 3), ('wireless', 33), ('equip', 11), ('box', 22), ('proudli', 1), ('securest', 1), ('tm', 1), ('appar', 3), ('linksi', 30), ('cisco', 1), ('eas', 18), ('crucial', 1), ('briefli', 2), ('reconsid', 1), ('ego', 1), ('airport', 1), ('notori', 1), ('mac', 14), ('nowher', 1), ('proper', 2), ('miser', 1), ('enabl', 5), ('wep', 3), ('encrypt', 4), ('wpa', 3), ('costlier', 1), ('home', 17), ('disco', 1), ('readili', 1), ('network', 19), ('enterpris', 1), ('hardwar', 12), ('offic', 3), ('corpor', 5), ('environ', 4), ('linux', 5), ('essenti', 1), ('packag', 13), ('worthless', 5), ('achil', 1), ('heel', 1), ('inabl', 2), ('stream', 4), ('local', 3), ('net', 5), ('inde', 3), ('wrt54g', 12), ('sell', 1), ('ceas', 1), ('internet', 35), ('browser', 6), ('wast', 4), ('alot', 8), ('tune', 8), ('neil', 1), ('young', 1), ('cr', 1), ('satellit', 2), ('hookup', 1), ('hire', 1), ('knowledg', 3), ('spoke', 2), ('consult', 3), ('intermitt', 1), ('lose', 6), ('wirelessli', 3), ('desktop', 5), ('togeth', 7), ('write', 6), ('instinct', 1), ('geek', 3), ('along', 10), ('buggi', 4), ('bug', 6), ('novic', 6), ('dlink', 3), ('di52', 1), ('min', 4), ('p2p', 1), ('spirit', 1), ('incompet', 1), ('interrupt', 3), ('tito', 1), ('802', 2), ('11b', 6), ('11g', 1), ('nearli', 7), ('log', 9), ('cheapest', 1), ('vagu', 2), ('familiar', 1), ('wall', 4), ('link', 4), ('offer', 23), ('scant', 1), ('page', 3), ('outset', 1), ('clumsi', 2), ('pad', 16), ('inquir', 1), ('prioriti', 11), ('academ', 1), ('us', 8), ('maze', 1), ('stupid', 7), ('kill', 1), ('bothersom', 1), ('allegedli', 1), ('transport', 3), ('onto', 6), ('foreign', 1), ('txt', 2), ('reduc', 2), ('lowest', 2), ('possibl', 14), ('alon', 3), ('cord', 3), ('outrag', 1), ('cost', 27), ('weekend', 1), ('lug', 2), ('trip', 6), ('opinion', 12), ('barest', 1), ('minimum', 3), ('gross', 2), ('profit', 3), ('nickl', 1), ('dime', 1), ('extraordinarili', 1), ('inflat', 1), ('polyest', 1), ('string', 1), ('boy', 4), ('marbl', 1), ('carrier', 5), ('dish', 2), ('iriv', 5), ('wrote', 1), ('hidden', 2), ('goug', 1), ('royal', 2), ('conceiv', 1), ('necessari', 8), ('daili', 3), ('usag', 5), ('touchpad', 7), ('sabl', 2), ('hr', 3), ('synchron', 2), ('irrit', 1), ('unstructur', 1), ('style', 7), ('exclud', 2), ('import', 13), ('slight', 3), ('goner', 1), ('evid', 2), ('master', 5), ('mark', 1), ('lead', 4), ('awhil', 1), ('nightmar', 1), ('1500', 2), ('700', 2), ('told', 3), ('meet', 4), ('audiophil', 3), ('standard', 19), ('optimist', 1), ('shorter', 3), ('impair', 1), ('desir', 2), ('outlook', 11), ('syn', 1), ('recur', 1), ('appoint', 1), ('wont', 1), ('lightli', 1), ('maximum', 2), ('desensit', 1), ('audibl', 4), ('rise', 1), ('antenna', 4), ('cz', 1), ('initi', 7), ('port', 6), ('bu', 3), ('motherboard', 1), ('rear', 1), ('perfectli', 18), ('mini', 19), ('sexier', 1), ('rio', 3), ('karma', 4), ('valu', 14), ('gig', 10), ('gog', 1), ('delet', 7), ('refund', 6), ('hoop', 2), ('purg', 1), ('plu', 32), ('stretch', 4), ('aspect', 3), ('recept', 23), ('primarili', 3), ('histori', 2), ('bat', 1), ('altern', 7), ('woth', 2), ('pair', 5), ('sennheis', 4), ('similar', 7), ('target', 3), ('thiev', 1), ('nyc', 3), ('vertic', 3), ('strip', 1), ('trick', 1), ('joke', 2), ('spectacular', 4), ('pick', 10), ('metro', 1), ('00', 4), ('reproduc', 2), ('determin', 3), ('recours', 1), ('repair', 3), ('se', 1), ('concept', 1), ('gen', 3), ('bewar', 1), ('es', 3), ('wav', 4), ('thread', 1), ('fuzz', 1), ('apart', 6), ('oversensit', 1), ('boot', 9), ('night', 10), ('200', 5), ('seamlessli', 2), ('wmp', 2), ('restart', 3), ('frozen', 1), ('that', 4), ('trigger', 2), ('unholi', 1), ('worri', 11), ('verdict', 1), ('fair', 2), ('whatev', 3), ('touchi', 2), ('decreas', 1), ('upgrad', 20), ('heed', 2), ('advic', 4), ('outlet', 3), ('info', 7), ('overh', 1), ('residenti', 1), ('unus', 3), ('mad', 2), ('slightest', 3), ('brush', 1), ('beta', 1), ('prove', 3), ('mega', 5), ('strongest', 1), ('park', 3), ('tower', 2), ('weaker', 1), ('grouchi', 1), ('hype', 5), ('respect', 2), ('awe', 2), ('inspir', 2), ('bud', 4), ('previous', 5), ('ward', 1), ('rattl', 1), ('buzz', 2), ('saren', 1), ('aliv', 2), ('march', 3), ('step', 5), ('commi', 1), ('microphon', 5), ('plagu', 1), ('elemenatari', 2), ('circuit', 1), ('anyon', 18), ('20gb', 6), ('subscript', 8), ('tinker', 2), ('slowli', 3), ('slower', 5), ('drm', 1), ('yahoo', 2), ('unlimit', 3), ('directli', 7), ('outfox', 1), ('indoor', 6), ('avoid', 4), ('diagnos', 1), ('inoper', 1), ('dull', 1), ('hazi', 2), ('photograph', 8), ('impati', 1), ('glow', 5), ('rack', 1), ('brightli', 1), ('shade', 1), ('orang', 1), ('instantli', 2), ('havent', 2), ('daylight', 3), ('averag', 13), ('8ft', 1), ('contrast', 3), ('edit', 11), ('35mm', 6), ('8mb', 2), ('direct', 5), ('lens', 6), ('19mm', 1), ('wc', 1), ('68', 1), ('48', 1), ('talk', 11), ('newer', 3), ('nokia', 58), ('steepli', 1), ('anyhow', 2), ('demerit', 1), ('processor', 2), ('6610', 13), ('variant', 1), ('excess', 2), ('involv', 2), ('whiz', 1), ('bang', 6), ('primari', 3), ('bluetooth', 33), ('pda', 10), ('correct', 7), ('magnifi', 1), ('segreg', 1), ('fanci', 1), ('siemen', 1), ('s56', 1), ('beauti', 17), ('frig', 1), ('vga', 3), ('cellphon', 5), ('app', 5), ('thru', 2), ('samsung', 6), ('motorola', 6), ('joystick', 3), ('dig', 2), ('bmw', 1), ('unintuit', 1), ('booklet', 1), ('accustom', 1), ('200k', 1), ('megapixel', 12), ('quad', 1), ('editor', 1), ('employ', 1), ('braill', 1), ('attn', 1), ('styliz', 1), ('6600', 20), ('develop', 1), ('greedi', 1), ('addl', 1), ('expand', 3), ('transmiss', 2), ('depend', 6), ('grow', 3), ('dozen', 3), ('mobil', 32), ('modem', 8), ('vast', 2), ('truth', 1), ('nuanc', 1), ('acknowledg', 2), ('technician', 4), ('globe', 2), ('script', 1), ('chide', 1), ('english', 1), ('ultim', 2), ('loss', 4), ('utterli', 2), ('deserv', 3), ('scale', 1), ('lego', 1), ('secondli', 2), ('command', 2), ('cram', 4), ('3x4cm', 1), ('font', 1), ('convolut', 1), ('customiz', 2), ('suitabl', 1), ('crazi', 3), ('glanc', 2), ('purs', 2), ('unsaf', 1), ('shift', 1), ('highway', 1), ('ericsson', 3), ('t610', 5), ('earpiec', 3), ('speaker', 21), ('sacrific', 1), ('cell', 9), ('mic', 1), ('surround', 2), ('prig', 1), ('u', 5), ('smoothli', 3), ('colour', 4), ('theori', 1), ('ex', 3), ('functionalist', 1), ('gadget', 4), ('advoc', 1), ('7610', 1), ('seemingli', 2), ('desper', 1), ('trial', 2), ('squeez', 1), ('experiment', 1), ('technolog', 9), ('blunder', 1), ('mmc', 7), ('slot', 3), ('simpler', 1), ('800', 4), ('airlin', 1), ('prerecord', 1), ('pixel', 5), ('regret', 6), ('sign', 2), ('drawn', 2), ('catchi', 1), ('rebat', 9), ('upfront', 1), ('qualifi', 1), ('ab', 1), ('t720i', 2), ('verizon', 1), ('saw', 7), ('exagger', 2), ('isync', 3), ('solv', 4), ('sec', 2), ('server', 4), ('ugh', 1), ('picki', 2), ('70', 6), ('dosn', 1), ('nick', 1), ('soap', 1), ('stubbi', 1), ('adjac', 1), ('react', 1), ('lest', 1), ('form', 6), ('statu', 2), ('approv', 3), ('usu', 1), ('discharg', 1), ('exp', 1), ('fond', 4), ('text', 7), ('eras', 1), ('letter', 1), ('scour', 1), ('arbitrari', 1), ('pervas', 1), ('unhappi', 1), ('gpr', 5), ('trade', 2), ('midi', 5), ('tortur', 1), ('delight', 4), ('august', 2), ('convert', 9), ('arriv', 1), ('sprint', 3), ('heaven', 1), ('13', 2), ('unpredict', 1), ('crisp', 2), ('backlight', 8), ('danger', 1), ('uncr', 1), ('assum', 3), ('lao', 1), ('angel', 1), ('horrend', 1), ('zone', 5), ('99', 4), ('mo', 1), ('countless', 1), ('heard', 6), ('heavili', 1), ('demand', 4), ('pitch', 4), ('subtl', 1), ('tone', 9), ('vibrat', 4), ('bore', 2), ('wow', 2), ('minu', 1), ('speakerphon', 18), ('swap', 2), ('cant', 2), ('sticki', 1), ('tho', 1), ('kit', 1), ('connector', 3), ('funki', 1), ('relat', 3), ('rectangular', 1), ('keypad', 8), ('weird', 1), ('memor', 1), ('ringer', 3), ('mm', 5), ('headset', 6), ('caller', 1), ('id', 4), ('rington', 14), ('proprietari', 6), ('accident', 1), ('metric', 1), ('currenc', 3), ('suit', 8), ('infrar', 7), ('constant', 1), ('uniqu', 1), ('default', 5), ('mil', 1), ('estat', 1), ('broker', 1), ('entertain', 1), ('disturb', 2), ('tradit', 2), ('arrang', 1), ('unconvent', 1), ('shape', 5), ('reiter', 1), ('coverag', 5), ('sporad', 1), ('unpleas', 1), ('outweigh', 1), ('shortcom', 2), ('wap', 3), ('h10', 2), ('preset', 7), ('news', 3), ('recal', 1), ('18', 4), ('metal', 7), ('tacki', 1), ('gel', 1), ('tuner', 14), ('x5', 1), ('dislik', 2), ('rememb', 3), ('statement', 2), ('fee', 3), ('chrome', 3), ('surfac', 4), ('caveat', 1), ('preserv', 1), ('compet', 1), ('tor', 1), ('popular', 4), ('drain', 3), ('arm', 5), ('nope', 1), ('moveabl', 4), ('4th', 2), ('gym', 4), ('casual', 1), ('titanium', 1), ('superfici', 1), ('solder', 1), ('jockey', 1), ('plenti', 16), ('gain', 3), ('ogl', 1), ('300', 4), ('eight', 1), ('brick', 2), ('roughli', 1), ('105', 1), ('blame', 2), ('reformat', 2), ('fingerprint', 1), ('cosmet', 1), ('standpoint', 1), ('holi', 1), ('cow', 1), ('fall', 4), ('inevit', 2), ('island', 1), ('resembl', 1), ('microsoft', 5), ('nuisanc', 2), ('margin', 1), ('incompat', 1), ('nitru', 2), ('wherea', 2), ('throw', 4), ('river', 2), ('steve', 2), ('twist', 1), ('unrepeat', 1), ('conspiraci', 1), ('freak', 1), ('299', 1), ('minimalist', 1), ('red', 8), ('flag', 1), ('cousin', 2), ('riddl', 1), ('shini', 2), ('miracl', 1), ('thu', 4), ('thirti', 1), ('viabl', 1), ('ni', 12), ('navi', 1), ('prior', 2), ('norton', 50), ('disgrac', 1), ('glad', 10), ('scandisk', 2), ('shutdown', 2), ('slap', 1), ('downhil', 1), ('slid', 1), ('fallen', 1), ('cliff', 1), ('loyal', 1), ('symantec', 19), ('firewal', 14), ('dissatisfi', 1), ('henc', 1), ('intertwin', 1), ('headach', 4), ('implement', 1), ('appropri', 2), ('beyond', 2), ('liveupd', 3), ('16', 4), ('whenev', 3), ('notabl', 1), ('importantli', 2), ('viru', 5), ('innumer', 1), ('remnant', 1), ('systemwork', 4), ('warn', 4), ('fragment', 1), ('registri', 4), ('proceed', 1), ('octob', 2), ('fifth', 1), ('reinstal', 1), ('symantect', 2), ('shelf', 1), ('enorm', 4), ('earn', 1), ('vs', 3), ('speak', 4), ('obtain', 3), ('boilerpl', 1), ('paragraph', 2), ('insult', 1), ('proof', 3), ('pathet', 2), ('patienc', 3), ('utter', 1), ('dud', 1), ('antiviru', 13), ('im', 3), ('syman', 1), ('tic', 1), ('35', 2), ('55', 1), ('hung', 3), ('2003', 8), ('meaning', 1), ('asid', 4), ('tediou', 1), ('cleanli', 1), ('hangup', 1), ('cc', 1), ('exe', 2), ('foll', 1), ('wed', 1), ('slowdown', 1), ('preload', 1), ('av', 3), ('steelwork', 1), ('remain', 2), ('solut', 5), ('lean', 1), ('toward', 1), ('startup', 2), ('visit', 1), ('tab', 3), ('autom', 3), ('spam', 6), ('resel', 1), ('varieti', 5), ('sourc', 8), ('conclus', 3), ('04', 2), ('cooki', 1), ('unauthor', 1), ('written', 3), ('supervisor', 1), ('unbeliev', 7), ('ate', 2), ('renew', 2), ('disabl', 4), ('antispam', 3), ('fault', 2), ('decid', 10), ('public', 2), ('prefer', 11), ('dead', 3), ('muzak', 1), ('discuss', 1), ('95', 4), ('usp', 1), ('staff', 1), ('pure', 1), ('ship', 7), ('indign', 1), ('comb', 1), ('mccaffe', 1), ('sickli', 1), ('abandon', 1), ('nortron', 4), ('uni', 2), ('stall', 1), ('registeri', 2), ('trace', 1), ('refresh', 1), ('apolog', 1), ('vaio', 2), ('150', 2), ('hibern', 1), ('56k', 2), ('dell', 6), ('2ghz', 2), ('pentium', 2), ('256mb', 2), ('broadband', 5), ('pare', 1), ('anti', 6), ('suspect', 2), ('sampl', 1), ('mental', 2), ('mainli', 3), ('greer', 1), ('pent4', 1), ('ram', 4), ('resourc', 1), ('modern', 4), ('halt', 1), ('becam', 2), ('behav', 1), ('alert', 2), ('twenti', 1), ('permiss', 1), ('administr', 2), ('swear', 2), ('physic', 1), ('happier', 4), ('nicest', 2), ('rewind', 1), ('cad', 1), ('svcd', 2), ('cod', 1), ('rs', 3), ('valuabl', 1), ('coax', 1), ('latter', 3), ('literatur', 2), ('mirror', 3), ('afford', 8), ('multi', 2), ('slim', 5), ('father', 1), ('tom', 1), ('jone', 1), ('concert', 2), ('decemb', 2), ('visual', 5), ('anywher', 11), ('mpeg1', 2), ('r', 12), ('mpeg2', 2), ('cmdr', 1), ('cadr', 1), ('uk', 1), ('giff', 1), ('vision', 1), ('american', 2), ('mpeg', 2), ('profil', 3), ('surpris', 6), ('stack', 3), ('vb', 1), ('smart', 3), ('ripper', 1), ('af', 1), ('letterbox', 1), ('drawer', 1), ('anticip', 1), ('simplest', 1), ('flawlessli', 7), ('test', 5), ('factor', 6), ('known', 3), ('toshiba', 1), ('pioneer', 3), ('panason', 5), ('quietli', 3), ('br', 1), ('1200', 2), ('hd', 3), ('feed', 1), ('cheep', 1), ('finest', 2), ('jv', 1), ('1100', 1), ('lemon', 1), ('happi', 41), ('capabl', 6), ('evolv', 1), ('theater', 1), ('unmatch', 2), ('attract', 6), ('cautiou', 1), ('retract', 2), ('om', 1), ('owner', 5), ('substandard', 1), ('troubleshoot', 1), ('hesit', 2), ('hdtv', 1), ('categori', 3), ('overlook', 2), ('myriad', 2), ('sister', 1), ('colleg', 1), ('39', 1), ('tax', 1), ('unplay', 1), ('philip', 1), ('mix', 5), ('whine', 2), ('notch', 4), ('dot', 1), ('dd5', 1), ('fiddl', 2), ('relax', 2), ('brag', 1), ('mountain', 3), ('fraction', 1), ('noiseless', 1), ('lightweight', 3), ('oh', 7), ('silverfish', 1), ('add', 8), ('instanc', 1), ('up', 5), ('w', 13), ('powershot', 7), ('elderli', 1), ('group', 3), ('fire', 2), ('constitu', 1), ('g2', 3), ('enlarg', 1), ('x', 1), ('11', 7), ('vi', 1), ('super', 8), ('flexibl', 6), ('filter', 1), ('toy', 8), ('overview', 1), ('flagship', 1), ('seri', 2), ('brillianc', 1), ('expert', 2), ('detail', 13), ('digicam', 3), ('preview', 2), ('hundr', 4), ('photographi', 6), ('fun', 9), ('latitud', 1), ('4mp', 6), ('semi', 2), ('amateur', 3), ('rotat', 1), ('14x', 1), ('highest', 4), ('fring', 2), ('upload', 5), ('fantast', 14), ('bargain', 4), ('newbi', 2), ('anybodi', 2), ('faster', 5), ('unreservedli', 1), ('calorimetri', 1), ('knockoff', 1), ('buff', 1), ('juli', 1), ('sparkler', 1), ('apertur', 5), ('focal', 1), ('ideal', 4), ('fumbl', 1), ('substanc', 1), ('thrill', 1), ('joe', 1), ('rice', 1), ('outdoor', 4), ('object', 3), ('marvel', 1), ('versatil', 6), ('chose', 3), ('reput', 4), ('f8', 1), ('fortun', 7), ('shoe', 2), ('met', 3), ('ct', 2), ('contrari', 3), ('ive', 8), ('dedic', 2), ('reveal', 1), ('truli', 6), ('tweak', 3), ('realist', 3), ('film', 5), ('conjunct', 1), ('decis', 4), ('hobbiest', 2), ('quot', 2), ('k', 1), ('reev', 1), ('astound', 1), ('supplier', 1), ('topnotch', 1), ('cock', 1), ('halfway', 1), ('dream', 4), ('tremend', 2), ('viewer', 2), ('squarer', 1), ('stone', 1), ('glint', 1), ('sun', 1), ('shine', 3), ('glaze', 1), ('contour', 1), ('factori', 2), ('alter', 3), ('sharper', 4), ('offset', 2), ('tonal', 1), ('5mp', 1), ('swivel', 1), ('fianc', 1), ('stamp', 2), ('lighter', 2), ('camcord', 4), ('bun', 1), ('ari', 1), ('iguassu', 1), ('penni', 2), ('reflect', 1), ('magnesium', 1), ('steep', 2), ('competit', 5), ('stitch', 2), ('foremost', 2), ('600', 1), ('budget', 2), ('durat', 1), ('hing', 1), ('surpass', 4), ('laid', 5), ('idiot', 2), ('logic', 1), ('medic', 1), ('terrif', 6), ('closest', 1), ('diagram', 1), ('insan', 2), ('fabul', 3), ('snow', 3), ('boat', 2), ('wind', 1), ('scienc', 1), ('understood', 1), ('strictli', 1), ('closer', 1), ('postag', 1), ('sophist', 1), ('powerhous', 1), ('arguabl', 1), ('algorithm', 1), ('5000', 2), ('exterior', 1), ('elegantli', 1), ('digic', 2), ('ii', 5), ('limitless', 1), ('rival', 1), ('g6', 1), ('trueli', 2), ('superb', 6), ('outstand', 10), ('vari', 1), ('conduct', 1), ('firmli', 1), ('rich', 4), ('paper', 2), ('tack', 1), ('crop', 2), ('heart', 1), ('powerup', 2), ('640', 1), ('30fp', 1), ('mono', 1), ('revis', 2), ('razor', 3), ('bulletproof', 1), ('a60', 1), ('btw', 1), ('merg', 1), ('panoram', 2), ('l', 1), ('date', 5), ('self', 3), ('timer', 5), ('upright', 1), ('horizont', 1), ('beat', 16), ('s70', 1), ('jean', 2), ('jacket', 3), ('pant', 3), ('iso', 3), ('surprisingli', 3), ('ultracompact', 2), ('boast', 4), ('blur', 1), ('preliminari', 1), ('simon', 1), ('suprisingli', 3), ('crystal', 4), ('advis', 1), ('hefti', 2), ('500', 4), ('moreov', 1), ('wherev', 4), ('seamless', 3), ('ps', 2), ('competitor', 2), ('iso100', 1), ('artefact', 1), ('hair', 1), ('whizz', 1), ('compress', 4), ('viedo', 1), ('p200', 1), ('fewer', 2), ('center', 3), ('paint', 2), ('neat', 7), ('leap', 2), ('bound', 2), ('re', 3), ('ponc', 1), ('ur', 1), ('pimpl', 1), ('s30', 1), ('school', 1), ('funni', 1), ('amazingli', 2), ('fear', 2), ('across', 4), ('beginn', 4), ('marketplac', 1), ('s100', 9), ('advantag', 7), ('strength', 7), ('printer', 2), ('snapshot', 2), ('fyi', 1), ('turkey', 1), ('gorgeou', 2), ('vividli', 1), ('ceram', 1), ('tile', 1), ('darken', 1), ('mosqu', 1), ('smallest', 2), ('2mp', 1), ('overkil', 1), ('compens', 2), ('increment', 1), ('brighten', 1), ('tast', 2), ('syncro', 1), ('infin', 1), ('ss', 1), ('elp2', 1), ('credit', 2), ('wallet', 2), ('background', 2), ('panorama', 4), ('s300', 1), ('33', 1), ('1024x768', 1), ('unequivoc', 3), ('saver', 4), ('amatu', 2), ('dc240', 1), ('everywher', 6), ('interest', 4), ('photostitch', 2), ('360', 2), ('degre', 4), ('uniformli', 1), ('render', 2), ('knit', 1), ('standout', 1), ('aptli', 1), ('diminut', 1), ('student', 1), ('ultra', 3), ('pound', 1), ('jewel', 1), ('honestli', 2), ('usabl', 1), ('2000', 2), ('coolest', 2), ('cigarett', 1), ('scotch', 1), ('central', 1), ('retak', 1), ('flub', 1), ('lo', 1), ('behold', 1), ('rug', 3), ('hike', 1), ('expans', 1), ('waterproof', 3), ('kayak', 1), ('fuss', 2), ('led', 2), ('sunlight', 2), ('shiest', 1), ('tft', 3), ('s20', 1), ('ebay', 1), ('hop', 2), ('bandwagon', 1), ('household', 1), ('inventori', 1), ('converg', 1), ('guy', 4), ('appreci', 2), ('predecessor', 2), ('categor', 2), ('peripher', 1), ('infinit', 1), ('hat', 1), ('pod', 8), ('core', 1), ('leather', 3), ('pouch', 3), ('pluss', 3), ('changeabl', 2), ('overpr', 2), ('dim', 1), ('blind', 1), ('stare', 2), ('shuffl', 5), ('satisfactori', 3), ('applianc', 1), ('60gb', 1), ('pale', 1), ('comparison', 2), ('didnt', 3), ('born', 1), ('accord', 1), ('candi', 1), ('lil', 1), ('winamp', 2), ('cinch', 3), ('sweet', 3), ('pie', 2), ('intens', 1), ('account', 3), ('count', 3), ('30gb', 2), ('19gb', 1), ('fussi', 1), ('stuff', 10), ('unbeat', 4), ('cake', 3), ('handi', 5), ('holiday', 1), ('plane', 1), ('ride', 1), ('symphoni', 1), ('orchestra', 2), ('seat', 1), ('jazz', 2), ('uncompl', 1), ('superflu', 1), ('rock', 8), ('earli', 3), ('stain', 1), ('38', 4), ('realiti', 1), ('sock', 1), ('spill', 1), ('beer', 1), ('greater', 1), ('sensibl', 1), ('blast', 2), ('exceed', 2), ('wise', 4), ('wear', 1), ('versu', 1), ('zx', 3), ('green', 3), ('ratio', 6), ('wave', 3), ('stn', 2), ('decibel', 1), ('lastli', 1), ('int', 1), ('faith', 1), ('320kb', 1), ('2k', 1), ('imo', 2), ('specif', 2), ('downfal', 1), ('auditorium', 1), ('aid', 2), ('repeat', 2), ('cozmo', 1), ('nt', 1), ('shuttl', 1), ('content', 2), ('cassett', 1), ('vendor', 1), ('snugli', 1), ('tank', 2), ('em', 1), ('slick', 3), ('unwrap', 1), ('160', 3), ('65', 1), ('mb', 8), ('900', 2), ('000', 3), ('extran', 1), ('train', 2), ('criteria', 1), ('spec', 4), ('shame', 1), ('commut', 1), ('stoppag', 1), ('m3u', 1), ('recreat', 1), ('hooray', 1), ('160kbp', 1), ('tape', 1), ('exceedingli', 1), ('stagger', 1), ('opt', 1), ('vice', 1), ('vers', 1), ('98db', 1), ('unspecifi', 1), ('497', 1), ('sr', 1), ('202', 1), ('ui', 2), ('chic', 1), ('fahrenheit', 1), ('weather', 2), ('cb', 1), ('gracenot', 2), ('hz', 1), ('1gb', 2), ('52x', 1), ('wake', 4), ('specifi', 1), ('5717', 1), ('491', 1), ('immateri', 1), ('sleep', 2), ('keen', 2), ('secret', 1), ('mood', 1), ('modifi', 3), ('li', 2), ('variat', 1), ('choos', 3), ('classic', 3), ('alarm', 5), ('clock', 4), ('abli', 1), ('ahead', 1), ('chair', 1), ('bone', 1), ('addict', 1), ('decad', 2), ('flashi', 1), ('xma', 1), ('routin', 1), ('monster', 1), ('solidli', 1), ('risk', 1), ('cramp', 1), ('circl', 1), ('endlessli', 1), ('nudg', 1), ('ensur', 2), ('bonu', 6), ('bevi', 1), ('cri', 2), ('havoc', 1), ('hiss', 1), ('plop', 1), ('grand', 1), ('bull', 1), ('ail', 1), ('gallon', 1), ('vanilla', 2), ('scent', 3), ('groceri', 1), ('lay', 1), ('toddler', 6), ('nose', 2), ('ordinari', 2), ('cloth', 4), ('ventur', 1), ('land', 1), ('accompani', 1), ('econom', 2), ('prospect', 1), ('shower', 1), ('kitchen', 9), ('spray', 2), ('inquisit', 1), ('child', 1), ('nurseri', 1), ('tall', 3), ('smelli', 1), ('absolutli', 2), ('reinforc', 1), ('vital', 1), ('def', 1), ('finit', 1), ('eman', 1), ('tie', 3), ('bulk', 1), ('sucker', 1), ('bedroom', 1), ('regardless', 1), ('win', 4), ('mindless', 1), ('cocoon', 1), ('largest', 1), ('upstair', 2), ('downstair', 2), ('bathroom', 1), ('damp', 1), ('humid', 1), ('south', 3), ('rife', 1), ('fold', 1), ('walk', 3), ('attribut', 2), ('2005', 1), ('till', 1), ('paraphernalia', 1), ('lifesav', 1), ('potent', 1), ('certainli', 2), ('leg', 1), ('hunch', 1), ('stabl', 4), ('curiou', 1), ('assembl', 1), ('nook', 1), ('portion', 1), ('pocketbook', 1), ('formula', 1), ('breastf', 1), ('invent', 1), ('fell', 5), ('pr', 1), ('duct', 1), ('roll', 2), ('infant', 1), ('shield', 1), ('safer', 2), ('woodwork', 2), ('demo', 1), ('m12v', 11), ('effortlessli', 1), ('mapl', 2), ('freud', 1), ('malaya', 1), ('usa', 1), ('beast', 3), ('churn', 1), ('threw', 1), ('clydesdal', 1), ('industri', 2), ('3hp', 2), ('workhors', 3), ('nimbl', 1), ('leigh', 1), ('dovetail', 1), ('jig', 1), ('accuraci', 1), ('elat', 1), ('fenc', 3), ('rout', 3), ('preclud', 2), ('incent', 1), ('seeker', 1), ('deliveri', 1), ('135', 1), ('cordless', 1), ('drill', 1), ('lamin', 1), ('trimmer', 1), ('coupon', 1), ('arena', 1), ('m12', 1), ('woo', 1), ('drat', 1), ('circumst', 1), ('torqu', 1), ('gold', 1), ('gizmo', 1), ('contribut', 1), ('stabil', 2), ('driven', 1), ('cabinet', 1), ('regularli', 2), ('col', 1), ('exce', 1), ('hog', 3), ('reliant', 1), ('merit', 1), ('masada', 1), ('perman', 1), ('2in', 1), ('prevent', 1), ('blowout', 1), ('smoother', 1), ('bog', 2), ('workload', 1), ('blink', 1), ('md', 2), ('plywood', 1), ('butter', 1), ('dew', 1), ('alt', 1), ('bosch', 1), ('grab', 1), ('deep', 3), ('dado', 1), ('frankli', 2), ('steal', 2), ('buddi', 1), ('offload', 1), ('systemat', 1), ('bet', 2), ('china', 1), ('junki', 1), ('54', 2), ('mbp', 2), ('36', 1), ('loo', 1), ('kin', 1), ('elf', 1), ('refriger', 1), ('pertain', 1), ('54mp', 1), ('54mbp', 1), ('megabyt', 1), ('kilobyt', 2), ('roommat', 1), ('fasten', 1), ('bolt', 1), ('mislead', 1), ('redirect', 1), ('india', 1), ('fourth', 2), ('rough', 2), ('backyard', 2), ('befcmu10', 1), ('townhous', 1), ('bandwidth', 1), ('writer', 1), ('lick', 1), ('aunt', 1), ('801', 1), ('ant', 2), ('broad', 1), ('wifi', 2), ('menisci', 1), ('lucien', 1), ('silicon', 1), ('cpu', 1), ('th', 2), ('pipelin', 1), ('client', 2), ('54g', 1), ('strainer', 1), ('backward', 2), ('g', 3), ('booster', 2), ('op', 1), ('ion', 3), ('concentr', 1), ('teddi', 1), ('ha', 1), ('droop', 1), ('03', 1), ('multipurpos', 1), ('ital', 1), ('dhaka', 1), ('magic', 1), ('yin', 1), ('wet11', 2), ('splurg', 1), ('ether', 1), ('nest', 1), ('bridg', 1), ('comp', 1), ('cooler', 3), ('collis', 1), ('packet', 1), ('vip', 1), ('whatsoev', 1), ('netgear', 2), ('paramecia', 1), ('charm', 4), ('pose', 1), ('http', 1), ('suavest', 1), ('forum6', 1), ('html', 1), ('streamlin', 1), ('happili', 2), ('unattain', 1), ('spit', 1), ('favor', 1), ('farthest', 1), ('18m', 1), ('10m', 1), ('ethernet', 1), ('hga7t', 1), ('crisper', 1), ('butt', 1), ('freedom', 1), ('kiss', 1), ('ass', 2), ('confront', 1), ('cute', 5), ('microfib', 1), ('remark', 1), ('neon', 2), ('ambianc', 1), ('prop', 1), ('textur', 1), ('sdon', 1), ('carbon', 1), ('louder', 1), ('outright', 1), ('calend', 2), ('postal', 1), ('exchang', 2), ('inaccur', 1), ('howard', 1), ('stern', 2), ('water', 2), ('rippl', 1), ('coat', 2), ('makeshift', 1), ('sorta', 1), ('array', 5), ('wmp10', 1), ('calendar', 8), ('bose', 1), ('appeal', 3), ('cardboard', 1), ('defiantli', 1), ('excit', 3), ('stereo', 6), ('dc', 1), ('128', 1), ('ak', 1), ('studio', 1), ('240', 1), ('touchpap', 1), ('supposedli', 1), ('bless', 2), ('juic', 1), ('trebl', 2), ('jeez', 1), ('trouser', 1), ('freebi', 1), ('cradl', 1), ('detach', 1), ('3800', 1), ('thank', 4), ('privileg', 1), ('subsequ', 1), ('assur', 1), ('exclus', 1), ('flinch', 1), ('mouth', 1), ('cater', 1), ('hip', 4), ('youngster', 1), ('shirt', 3), ('ostentati', 1), ('zs', 1), ('winner', 3), ('seiz', 1), ('quantiti', 1), ('180', 1), ('remedi', 1), ('alright', 1), ('rive', 1), ('admit', 4), ('intimid', 1), ('e828lp', 1), ('mx', 1), ('theft', 1), ('subway', 1), ('whichev', 1), ('sleeker', 2), ('sassier', 1), ('flair', 1), ('trim', 1), ('subscrib', 2), ('cough', 1), ('4g', 1), ('5g', 3), ('seper', 2), ('ador', 1), ('ie', 1), ('down', 1), ('untouch', 1), ('invas', 1), ('dj', 2), ('retail', 4), ('lightn', 1), ('chalk', 1), ('goodi', 1), ('halloween', 1), ('cart', 1), ('princip', 1), ('certainti', 1), ('gremlin', 1), ('char', 1), ('shire', 1), ('birthday', 1), ('snazzi', 2), ('smoke', 1), ('wade', 1), ('folk', 1), ('pretend', 1), ('brain', 2), ('inact', 1), ('5gb', 2), ('treadmil', 1), ('simulcast', 1), ('npr', 2), ('pim', 2), ('1g', 1), ('architectur', 1), ('publicli', 1), ('muvo2', 1), ('tomorrow', 1), ('blend', 2), ('accomplish', 2), ('aux', 1), ('offens', 2), ('sink', 1), ('ball', 1), ('metaphor', 1), ('phenomen', 3), ('unargu', 1), ('beati', 2), ('gigabyt', 1), ('falter', 1), ('flawless', 2), ('savvi', 2), ('polici', 1), ('gonna', 2), ('fashion', 1), ('lover', 2), ('sonic', 1), ('humbl', 1), ('retriev', 1), ('label', 1), ('ks', 1), ('korean', 1), ('japanes', 1), ('afro', 1), ('cuban', 1), ('salsa', 1), ('countri', 6), ('halo', 1), ('4gb', 1), ('worship', 1), ('mighti', 1), ('1993', 1), ('temporarili', 1), ('batter', 1), ('remind', 1), ('batch', 1), ('undecid', 1), ('temper', 1), ('enthusiast', 3), ('anni', 1), ('levitt', 1), ('blank', 1), ('dummi', 1), ('correspond', 1), ('seek', 1), ('immens', 1), ('1000', 2), ('4300', 9), ('minutest', 1), ('optim', 1), ('portrait', 1), ('landscap', 1), ('beach', 1), ('sunset', 2), ('endless', 2), ('win98', 1), ('mortar', 1), ('8x10', 1), ('alkalin', 1), ('emerg', 1), ('coolpix', 3), ('yo', 1), ('12x', 1), ('graini', 1), ('perspect', 1), ('camper', 1), ('ampl', 1), ('marriag', 1), ('willa', 1), ('maneuv', 1), ('trust', 1), ('moder', 1), ('3m', 1), ('4m', 1), ('children', 1), ('fanat', 1), ('brilliant', 2), ('summari', 1), ('heartedli', 1), ('indistinguish', 2), ('remaind', 1), ('lengthi', 1), ('extens', 2), ('journey', 1), ('gravit', 1), ('gem', 1), ('sheer', 1), ('telephoto', 1), ('proverbi', 1), ('legendari', 1), ('raul', 1), ('thingi', 1), ('ooh', 1), ('pix', 2), ('rapid', 1), ('grandmoth', 1), ('establish', 2), ('4500', 1), ('closeup', 1), ('3660', 1), ('avaunt', 1), ('map', 3), ('quest', 1), ('dismay', 1), ('groundbreak', 1), ('mankind', 1), ('owe', 1), ('convict', 1), ('java', 5), ('recollect', 1), ('wanna', 1), ('airplan', 1), ('extraordinari', 1), ('65536', 1), ('16bit', 1), ('anim', 1), ('incom', 1), ('outgo', 1), ('handsfre', 5), ('512mb', 3), ('oval', 1), ('65000', 1), ('commun', 1), ('score', 1), ('newest', 1), ('handset', 2), ('turnoff', 1), ('flimsier', 1), ('amen', 1), ('chubbi', 1), ('squeak', 1), ('boundless', 1), ('mhz', 2), ('zealand', 2), ('australia', 2), ('6620', 2), ('singular', 1), ('800mhz', 1), ('refer', 1), ('850', 1), ('900mhz', 1), ('stellar', 1), ('symbian', 4), ('65k', 1), ('erickson', 1), ('lofti', 1), ('3330', 1), ('feb', 1), ('sim', 2), ('europ', 3), ('complement', 1), ('3gpp', 1), ('multimedia', 1), ('galleri', 2), ('rundown', 1), ('evolut', 1), ('revolut', 1), ('theme', 1), ('wallpap', 3), ('polyphon', 5), ('cream', 1), ('niftiest', 1), ('hitch', 1), ('blackberri', 1), ('imho', 1), ('upsid', 1), ('abra', 1), ('thousand', 2), ('platform', 1), ('ir', 2), ('iq', 1), ('4x6', 1), ('dali', 1), ('overboard', 1), ('osx', 2), ('quicker', 2), ('drove', 2), ('citi', 1), ('eastern', 1), ('kentucki', 2), ('pac', 1), ('mafia', 1), ('war', 1), ('3210', 1), ('phillip', 1), ('gage', 1), ('traffic411', 1), ('la', 1), ('traffic', 1), ('405', 1), ('chunk', 1), ('tablet', 1), ('von', 1), ('ipa', 1), ('4155', 1), ('pop3', 1), ('smtp', 1), ('smut', 1), ('ob', 1), ('kde', 1), ('conqueror', 1), ('assign', 2), ('gr', 1), ('southwest', 1), ('pavement', 1), ('agent', 1), ('polit', 1), ('660', 1), ('fare', 1), ('in', 1), ('event', 1), ('simian', 1), ('hunt', 1), ('joy', 2), ('eazi', 2), ('35mb', 2), ('displac', 1), ('upcom', 1), ('sonyericsson', 2), ('multifunct', 2), ('610', 1), ('6mb', 1), ('n6600', 1), ('loudspeak', 1), ('confer', 1), ('mileston', 1), ('cellular', 1), ('secretari', 1), ('sharewar', 1), ('teri', 1), ('gsm', 3), ('primit', 1), ('detroit', 2), ('suburb', 1), ('northern', 1), ('cincinnati', 1), ('freeway', 1), ('brief', 1), ('synopsi', 1), ('csr', 2), ('sole', 1), ('indestruct', 1), ('poli', 1), ('graphic', 4), ('aton', 1), ('nifti', 1), ('brisk', 1), ('lunch', 1), ('3650', 1), ('africa', 2), ('chanc', 1), ('bulg', 1), ('surreal', 1), ('benefici', 1), ('stopwatch', 1), ('surf', 1), ('critter', 1), ('conceal', 1), ('street', 1), ('anytim', 2), ('lie', 2), ('bed', 2), ('pillow', 1), ('chicago', 1), ('jame', 1), ('8290', 1), ('comfi', 1), ('seller', 1), ('brows', 2), ('oz', 1), ('polym', 1), ('chess', 1), ('chat', 1), ('niceti', 1), ('settl', 1), ('team', 1), ('aim', 1), ('quieter', 1), ('talker', 1), ('god', 1), ('shoulder', 2), ('sport', 1), ('snooz', 1), ('peic', 1), ('satisfactorili', 1), ('twelv', 1), ('transit', 1), ('instantan', 1), ('usb2', 1), ('firewire400', 1), ('relationship', 1), ('expertis', 1), ('overr', 1), ('beater', 1), ('tempt', 1), ('fathom', 1), ('numbingli', 1), ('sought', 1), ('acoust', 1), ('danc', 1), ('broadcast', 2), ('adaptor', 2), ('fulfil', 1), ('mida', 1), ('incorrectli', 1), ('endur', 1), ('associ', 2), ('voila', 1), ('amp', 1), ('lifer', 1), ('magnific', 1), ('trendi', 2), ('compos', 2), ('section', 1), ('trivia', 1), ('skill', 1), ('gleam', 1), ('sue', 1), ('dammit', 1), ('helplin', 1), ('convent', 1), ('budg', 1), ('mass', 1), ('commerci', 1), ('lou', 1), ('andi', 1), ('mcgee', 1), ('ware', 1), ('semant', 1), ('doctor', 2), ('checkup', 1), ('133', 1), ('backtrack', 1), ('likewis', 1), ('intrus', 2), ('blocker', 1), ('bonus', 1), ('2002', 2), ('effortless', 1), ('lan', 1), ('vener', 1), ('skate', 1), ('banner', 1), ('netscap', 1), ('acrobat', 1), ('pencil', 1), ('maccabe', 1), ('pi', 1), ('1ghz', 1), ('rd', 1), ('80gb', 1), ('bacon', 1)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################\n",
    "# # Define the vocabulary #\n",
    "# #########################\n",
    "\n",
    "# from collections import Counter\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords = stopwords.words('english')\n",
    "# stemmer = PorterStemmer()\n",
    "    \n",
    "# def clean_doc(doc):\n",
    "#     # split into tokens by white space\n",
    "#     tokens = doc.split()\n",
    "#     # prepare regex for char filtering\n",
    "#     re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "#     # remove punctuation from each word\n",
    "#     tokens = [re_punc.sub('', w) for w in tokens]\n",
    "#     # filter out stop words\n",
    "#     tokens = [w for w in tokens if not w in stopwords]\n",
    "#     # filter out short tokens\n",
    "#     tokens = [word for word in tokens if len(word) >= 1]\n",
    "#     # Stem the token\n",
    "#     tokens = [stemmer.stem(token) for token in tokens]\n",
    "#     return tokens\n",
    "\n",
    "# def add_doc_to_vocab(docs, vocab):\n",
    "#     '''\n",
    "#     input:\n",
    "#         docs: a list of sentences (docs)\n",
    "#         vocab: a vocabulary dictionary\n",
    "#     output:\n",
    "#         return an updated vocabulary\n",
    "#     '''\n",
    "#     for doc in docs:\n",
    "#         tokens = clean_doc(doc)\n",
    "#         vocab.update(tokens)\n",
    "#     return vocab\n",
    "        \n",
    "\n",
    "# # prepare cross validation with 10 splits and shuffle = True\n",
    "# kfold = KFold(10, True)\n",
    "\n",
    "# # Separate the sentences and the labels\n",
    "# sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# acc_list = []\n",
    "\n",
    "# # kfold.split() will return set indices for each split\n",
    "# for train, test in kfold.split(sentences):\n",
    "#     # Instantiate a vocab object\n",
    "#     vocab = Counter()\n",
    "    \n",
    "#     train_x, test_x = [], []\n",
    "#     train_y, test_y = [], []\n",
    "    \n",
    "#     for i in train:\n",
    "#         train_x.append(sentences[i])\n",
    "#         train_y.append(labels[i])\n",
    "    \n",
    "#     for i in test:\n",
    "#         test_x.append(sentences[i])\n",
    "#         test_y.append(labels[i])\n",
    "    \n",
    "#     vocab = add_doc_to_vocab(train_x, vocab)\n",
    "#     print(len(train_x), len(test_x))\n",
    "#     print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<dir>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words Representation\n",
    "<hr>\n",
    "\n",
    "Once we define our vocab obtained from the training data, we need to **convert each review into a representation that we can feed to a Multilayer Perceptron Model.**\n",
    "\n",
    "As a reminder, here are the summary what we will do:\n",
    "- extract features from the text so the text input can be used with ML algorithms like neural networks\n",
    "- we do by converting the text into a vector representation. The larger the vocab, the longer the representation.\n",
    "- we will score the words in a document inside the vector. These scores are placed in the corresponding location in the vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_line(doc):\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [token for token in tokens if token in vocab]\n",
    "    line = ' '.join([token for token in tokens])\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_docs(docs):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        line = doc_to_line(doc)\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"weaknesses are minor the feel and layout of the remote control are only so so . it does n 't show the complete file names of mp3s with really long names . you must cycle through every zoom setting ( 2x , 3x , 4x , 1 2x , etc . ) before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly .\", \"many of our disney movies do n 't play on this dvd player .\", \"player has a problem with dual layer dvd 's such as alias season 1 and season 2 .\", 'i know the saying is you get what you pay for but at this stage of game dvd players must have better quality than this there is no excuse .', 'will never purchase apex again .']\n",
      "\n",
      "['weak minor feel layout remot control n show complet file name mp3 realli long name must cycl everi zoom set 2x 3x 4x 1 2x etc get back normal size sorri ignor way get back 1x quickli', 'mani disney movi n play dvd player', 'player problem dual layer dvd alia season 1 season 2', 'know say get pay stage game dvd player must better qualiti excus', 'never purchas apex']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])\n",
    "clean_sentences = clean_docs(sentences[:5])\n",
    "print()\n",
    "print( clean_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Vectors\n",
    "\n",
    "We will use the **Keras API** to **convert sentences to encoded document vectors**. Although the `Tokenizer` class from TF Keras provides cleaning and vocab definition, it's better we do this ourselves so that we know exactly we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(sentence):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process determines a consistent way to **convert the vocabulary to a fixed-length vector**, which is the total number of words in the vocabulary `vocab`. \n",
    "\n",
    "Next, documents can then be encoded using the Tokenizer by calling `texts_to_matrix()`. \n",
    "\n",
    "The function takes both a list of documents to encode and an encoding mode, which is the method used to score words in the document. Here we specify **freq** to score words based on their frequency in the document. \n",
    "\n",
    "This can be used to encode the loaded training and test data, for example:\n",
    "\n",
    "`Xtrain = tokenizer.texts_to_matrix(train_docs, mode='freq')`\n",
    "\n",
    "`Xtest = tokenizer.texts_to_matrix(test_docs, mode='freq')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #########################\n",
    "# # Define the vocabulary #\n",
    "# #########################\n",
    "\n",
    "# from collections import Counter\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords = stopwords.words('english')\n",
    "# stemmer = PorterStemmer()\n",
    "    \n",
    "# def clean_doc(doc):\n",
    "#     # split into tokens by white space\n",
    "#     tokens = doc.split()\n",
    "#     # prepare regex for char filtering\n",
    "#     re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "#     # remove punctuation from each word\n",
    "#     tokens = [re_punc.sub('', w) for w in tokens]\n",
    "#     # filter out stop words\n",
    "#     tokens = [w for w in tokens if not w in stopwords]\n",
    "#     # filter out short tokens\n",
    "#     tokens = [word for word in tokens if len(word) >= 1]\n",
    "#     # Stem the token\n",
    "#     tokens = [stemmer.stem(token) for token in tokens]\n",
    "#     return tokens\n",
    "\n",
    "# def add_doc_to_vocab(docs, vocab):\n",
    "#     '''\n",
    "#     input:\n",
    "#         docs: a list of sentences (docs)\n",
    "#         vocab: a vocabulary dictionary\n",
    "#     output:\n",
    "#         return an updated vocabulary\n",
    "#     '''\n",
    "#     for doc in docs:\n",
    "#         tokens = clean_doc(doc)\n",
    "#         vocab.update(tokens)\n",
    "#     return vocab\n",
    "        \n",
    "# def doc_to_line(doc, vocab):\n",
    "#     tokens = clean_doc(doc)\n",
    "#     # filter by vocab\n",
    "#     tokens = [token for token in tokens if token in vocab]\n",
    "#     line = ' '.join(tokens)\n",
    "#     return line\n",
    "\n",
    "# def clean_docs(docs, vocab):\n",
    "#     lines = []\n",
    "#     for doc in docs:\n",
    "#         line = doc_to_line(doc, vocab)\n",
    "#         lines.append(line)\n",
    "#     return lines\n",
    "\n",
    "# def create_tokenizer(sentences):\n",
    "#     tokenizer = Tokenizer()\n",
    "#     tokenizer.fit_on_texts(sentences)\n",
    "#     return tokenizer\n",
    "\n",
    "# # prepare cross validation with 10 splits and shuffle = True\n",
    "# kfold = KFold(10, True)\n",
    "\n",
    "# # Separate the sentences and the labels\n",
    "# sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# acc_list = []\n",
    "\n",
    "# # kfold.split() will return set indices for each split\n",
    "# for train, test in kfold.split(sentences):\n",
    "#     # Instantiate a vocab object\n",
    "#     vocab = Counter()\n",
    "    \n",
    "#     train_x, test_x = [], []\n",
    "#     train_y, test_y = [], []\n",
    "    \n",
    "#     for i in train:\n",
    "#         train_x.append(sentences[i])\n",
    "#         train_y.append(labels[i])\n",
    "    \n",
    "#     for i in test:\n",
    "#         test_x.append(sentences[i])\n",
    "#         test_y.append(labels[i])\n",
    "    \n",
    "#     # Turn the labels into a numpy array\n",
    "#     train_y = np.array(train_y)\n",
    "#     test_y = np.array(test_y)\n",
    "    \n",
    "#     # Define a vocabulary for each fold\n",
    "#     vocab = add_doc_to_vocab(train_x, vocab)\n",
    "#     print('The number of vocab: ', len(vocab))\n",
    "    \n",
    "#     # Clean the sentences\n",
    "#     train_x = clean_docs(train_x, vocab)\n",
    "#     test_x = clean_docs(test_x, vocab)\n",
    "    \n",
    "#     # Define the tokenizer\n",
    "#     tokenizer = create_tokenizer(train_x)\n",
    "    \n",
    "#     # encode data using freq mode\n",
    "#     Xtrain = tokenizer.texts_to_matrix(train_x, mode='freq')\n",
    "#     Xtest = tokenizer.texts_to_matrix(test_x, mode='freq')\n",
    "   \n",
    "\n",
    "# print(Xtrain.shape)\n",
    "# print(train_x[0])\n",
    "# print(Xtrain[0])\n",
    "# print(Xtest.shape)\n",
    "# print(test_x[0])\n",
    "# print(Xtest[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing the Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model 3\n",
    "\n",
    "Now, we will build Multilayer Perceptron (MLP) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "As you might have expected, the models are simply feedforward network with fully connected layers called `Dense` in the `Keras` library.\n",
    "\n",
    "Now, we will define our MLP neural network with very little trial and error so cannot be considered tuned for this problem. The configuration is as follows:\n",
    "- First hidden layer with 100 neurons and Relu activation function\n",
    "- Second hidden layer with 50 neurons and Relu activation function\n",
    "- Dropout Layer for each fully connected layer with p = 0.5\n",
    "- Output layer with Sigmoid activation function\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_3(train_x, train_y, batch_size = 50, epochs = 10, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 - 5s - loss: 0.6551 - accuracy: 0.6370 - val_loss: 0.6320 - val_accuracy: 0.6243\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.5948 - accuracy: 0.6409 - val_loss: 0.5521 - val_accuracy: 0.6508\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.4926 - accuracy: 0.7607 - val_loss: 0.4699 - val_accuracy: 0.8122\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3931 - accuracy: 0.8434 - val_loss: 0.4432 - val_accuracy: 0.8148\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3150 - accuracy: 0.8764 - val_loss: 0.4637 - val_accuracy: 0.8148\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2588 - accuracy: 0.9073 - val_loss: 0.4750 - val_accuracy: 0.8069\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2181 - accuracy: 0.9264 - val_loss: 0.4903 - val_accuracy: 0.7989\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1713 - accuracy: 0.9455 - val_loss: 0.5068 - val_accuracy: 0.7937\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1408 - accuracy: 0.9535 - val_loss: 0.5408 - val_accuracy: 0.7989\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6577 - accuracy: 0.6344 - val_loss: 0.6143 - val_accuracy: 0.6640\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6006 - accuracy: 0.6350 - val_loss: 0.5449 - val_accuracy: 0.6640\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5034 - accuracy: 0.7359 - val_loss: 0.4801 - val_accuracy: 0.7857\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.4048 - accuracy: 0.8475 - val_loss: 0.4529 - val_accuracy: 0.7857\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3209 - accuracy: 0.8852 - val_loss: 0.4617 - val_accuracy: 0.7963\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2672 - accuracy: 0.9087 - val_loss: 0.4805 - val_accuracy: 0.7884\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2277 - accuracy: 0.9246 - val_loss: 0.5042 - val_accuracy: 0.7910\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1916 - accuracy: 0.9402 - val_loss: 0.5302 - val_accuracy: 0.7857\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1588 - accuracy: 0.9541 - val_loss: 0.5641 - val_accuracy: 0.7963\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.1331 - accuracy: 0.9594 - val_loss: 0.5978 - val_accuracy: 0.7884\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6658 - accuracy: 0.6294 - val_loss: 0.6514 - val_accuracy: 0.6164\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6148 - accuracy: 0.6400 - val_loss: 0.5935 - val_accuracy: 0.6164\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5103 - accuracy: 0.7271 - val_loss: 0.5075 - val_accuracy: 0.7619\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3931 - accuracy: 0.8508 - val_loss: 0.5023 - val_accuracy: 0.7804\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3153 - accuracy: 0.8805 - val_loss: 0.5098 - val_accuracy: 0.7804\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2564 - accuracy: 0.9052 - val_loss: 0.5401 - val_accuracy: 0.7672\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2108 - accuracy: 0.9255 - val_loss: 0.5954 - val_accuracy: 0.7751\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1698 - accuracy: 0.9394 - val_loss: 0.6469 - val_accuracy: 0.7804\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1359 - accuracy: 0.9541 - val_loss: 0.7151 - val_accuracy: 0.7725\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 78.04232835769653\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6638 - accuracy: 0.6335 - val_loss: 0.6317 - val_accuracy: 0.6429\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6095 - accuracy: 0.6370 - val_loss: 0.5664 - val_accuracy: 0.6429\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5148 - accuracy: 0.7295 - val_loss: 0.4735 - val_accuracy: 0.7698\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3962 - accuracy: 0.8410 - val_loss: 0.4303 - val_accuracy: 0.7989\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3218 - accuracy: 0.8775 - val_loss: 0.4420 - val_accuracy: 0.7910\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2620 - accuracy: 0.9005 - val_loss: 0.4686 - val_accuracy: 0.7884\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2150 - accuracy: 0.9258 - val_loss: 0.4922 - val_accuracy: 0.7831\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1761 - accuracy: 0.9408 - val_loss: 0.5307 - val_accuracy: 0.7831\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1457 - accuracy: 0.9529 - val_loss: 0.5860 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6611 - accuracy: 0.6291 - val_loss: 0.6225 - val_accuracy: 0.6587\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6019 - accuracy: 0.6353 - val_loss: 0.5631 - val_accuracy: 0.6614\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5060 - accuracy: 0.7362 - val_loss: 0.4911 - val_accuracy: 0.7540\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.4037 - accuracy: 0.8360 - val_loss: 0.4588 - val_accuracy: 0.7937\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3181 - accuracy: 0.8837 - val_loss: 0.4598 - val_accuracy: 0.7989\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2639 - accuracy: 0.9020 - val_loss: 0.4737 - val_accuracy: 0.7831\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2102 - accuracy: 0.9246 - val_loss: 0.5054 - val_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1819 - accuracy: 0.9405 - val_loss: 0.5307 - val_accuracy: 0.7857\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1474 - accuracy: 0.9508 - val_loss: 0.5700 - val_accuracy: 0.7672\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.1265 - accuracy: 0.9597 - val_loss: 0.6006 - val_accuracy: 0.7884\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6658 - accuracy: 0.6280 - val_loss: 0.6312 - val_accuracy: 0.6499\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6181 - accuracy: 0.6366 - val_loss: 0.5827 - val_accuracy: 0.6499\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5142 - accuracy: 0.7469 - val_loss: 0.4937 - val_accuracy: 0.7798\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3976 - accuracy: 0.8411 - val_loss: 0.4721 - val_accuracy: 0.8011\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3171 - accuracy: 0.8808 - val_loss: 0.4780 - val_accuracy: 0.7878\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2634 - accuracy: 0.9041 - val_loss: 0.4942 - val_accuracy: 0.7958\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2206 - accuracy: 0.9229 - val_loss: 0.5279 - val_accuracy: 0.8064\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1892 - accuracy: 0.9364 - val_loss: 0.5506 - val_accuracy: 0.7825\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1564 - accuracy: 0.9511 - val_loss: 0.5677 - val_accuracy: 0.8090\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.1271 - accuracy: 0.9623 - val_loss: 0.6068 - val_accuracy: 0.8037\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.1095 - accuracy: 0.9647 - val_loss: 0.6304 - val_accuracy: 0.8011\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0878 - accuracy: 0.9768 - val_loss: 0.6774 - val_accuracy: 0.8037\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0828 - accuracy: 0.9768 - val_loss: 0.6963 - val_accuracy: 0.7984\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0614 - accuracy: 0.9859 - val_loss: 0.7520 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6518 - accuracy: 0.6368 - val_loss: 0.6245 - val_accuracy: 0.6419\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.5854 - accuracy: 0.6418 - val_loss: 0.5391 - val_accuracy: 0.6817\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.4776 - accuracy: 0.7766 - val_loss: 0.4601 - val_accuracy: 0.7772\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3759 - accuracy: 0.8564 - val_loss: 0.4514 - val_accuracy: 0.7798\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3142 - accuracy: 0.8817 - val_loss: 0.4316 - val_accuracy: 0.7878\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2536 - accuracy: 0.9070 - val_loss: 0.4632 - val_accuracy: 0.7719\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2135 - accuracy: 0.9261 - val_loss: 0.4806 - val_accuracy: 0.7719\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1802 - accuracy: 0.9432 - val_loss: 0.5107 - val_accuracy: 0.7719\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1508 - accuracy: 0.9482 - val_loss: 0.5657 - val_accuracy: 0.7692\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.1233 - accuracy: 0.9635 - val_loss: 0.6053 - val_accuracy: 0.7692\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 78.77984046936035\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6617 - accuracy: 0.6315 - val_loss: 0.6195 - val_accuracy: 0.6605\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6073 - accuracy: 0.6351 - val_loss: 0.5472 - val_accuracy: 0.6605\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5016 - accuracy: 0.7504 - val_loss: 0.4458 - val_accuracy: 0.7851\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3908 - accuracy: 0.8490 - val_loss: 0.4150 - val_accuracy: 0.8064\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3129 - accuracy: 0.8826 - val_loss: 0.4213 - val_accuracy: 0.8037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2553 - accuracy: 0.9070 - val_loss: 0.4281 - val_accuracy: 0.8064\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2157 - accuracy: 0.9244 - val_loss: 0.4648 - val_accuracy: 0.8011\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1807 - accuracy: 0.9408 - val_loss: 0.4835 - val_accuracy: 0.7958\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1531 - accuracy: 0.9520 - val_loss: 0.5190 - val_accuracy: 0.8037\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6619 - accuracy: 0.6330 - val_loss: 0.6416 - val_accuracy: 0.6340\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6101 - accuracy: 0.6380 - val_loss: 0.5986 - val_accuracy: 0.6340\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5116 - accuracy: 0.7125 - val_loss: 0.5451 - val_accuracy: 0.7188\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3980 - accuracy: 0.8446 - val_loss: 0.5419 - val_accuracy: 0.7401\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3129 - accuracy: 0.8829 - val_loss: 0.5631 - val_accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2598 - accuracy: 0.8988 - val_loss: 0.5933 - val_accuracy: 0.7454\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2094 - accuracy: 0.9267 - val_loss: 0.6476 - val_accuracy: 0.7268\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1781 - accuracy: 0.9406 - val_loss: 0.6848 - val_accuracy: 0.7241\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1468 - accuracy: 0.9526 - val_loss: 0.7369 - val_accuracy: 0.7268\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.1245 - accuracy: 0.9626 - val_loss: 0.7804 - val_accuracy: 0.7215\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.1008 - accuracy: 0.9712 - val_loss: 0.8405 - val_accuracy: 0.7241\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 74.53581094741821\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6590 - accuracy: 0.6410 - val_loss: 0.6681 - val_accuracy: 0.5836\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6044 - accuracy: 0.6439 - val_loss: 0.6073 - val_accuracy: 0.5836\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.4999 - accuracy: 0.7490 - val_loss: 0.5066 - val_accuracy: 0.7613\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.3914 - accuracy: 0.8325 - val_loss: 0.4801 - val_accuracy: 0.7772\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.3136 - accuracy: 0.8793 - val_loss: 0.4982 - val_accuracy: 0.7719\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.2527 - accuracy: 0.9064 - val_loss: 0.5374 - val_accuracy: 0.7586\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.2138 - accuracy: 0.9267 - val_loss: 0.5831 - val_accuracy: 0.7613\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.1746 - accuracy: 0.9423 - val_loss: 0.6321 - val_accuracy: 0.7560\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.1473 - accuracy: 0.9526 - val_loss: 0.6584 - val_accuracy: 0.7347\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 77.71883010864258\n",
      "\n",
      "The test ccuracy for each training:\n",
      "[0.81481481 0.7962963  0.78042328 0.79894179 0.79894179 0.80901855\n",
      " 0.7877984  0.80636603 0.74535811 0.7771883 ]\n",
      "The mean of the test accuracy:  0.7915147364139556\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Define the vocabulary #\n",
    "#########################\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "    \n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # filter out stop words\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) >= 1]\n",
    "    # Stem the token\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def add_doc_to_vocab(docs, vocab):\n",
    "    '''\n",
    "    input:\n",
    "        docs: a list of sentences (docs)\n",
    "        vocab: a vocabulary dictionary\n",
    "    output:\n",
    "        return an updated vocabulary\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        tokens = clean_doc(doc)\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "        \n",
    "def doc_to_line(doc, vocab):\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [token for token in tokens if token in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    return line\n",
    "\n",
    "def clean_docs(docs, vocab):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        line = doc_to_line(doc, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "def create_tokenizer(sentences):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    return tokenizer\n",
    "\n",
    "def train_mlp_3(train_x, train_y, test_x, test_y, batch_size = 50, epochs = 20, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose, callbacks = [callbacks], validation_data=(test_x, test_y))\n",
    "    return model\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "for train, test in kfold.split(sentences):\n",
    "    # Instantiate a vocab object\n",
    "    vocab = Counter()\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "    \n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "    \n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "    \n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Define a vocabulary for each fold\n",
    "    vocab = add_doc_to_vocab(train_x, vocab)\n",
    "    # print('The number of vocab: ', len(vocab))\n",
    "    \n",
    "    # Clean the sentences\n",
    "    train_x = clean_docs(train_x, vocab)\n",
    "    test_x = clean_docs(test_x, vocab)\n",
    "    \n",
    "    # Define the tokenizer\n",
    "    tokenizer = create_tokenizer(train_x)\n",
    "    \n",
    "    # encode data using freq mode\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_x, mode='freq')\n",
    "    Xtest = tokenizer.texts_to_matrix(test_x, mode='freq')\n",
    "       \n",
    "    # train the model\n",
    "    model = train_mlp_3(Xtrain, train_y, Xtest, test_y)\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "\n",
    "acc_list = np.array(acc_list)\n",
    "print()\n",
    "print('The test ccuracy for each training:\\n{}'.format(acc_list))\n",
    "print('The mean of the test accuracy: ', acc_list.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 100)               356400    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 361,501\n",
      "Trainable params: 361,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Word Scoring Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use `text_to_matrix()` function, we are given 4 different methods for scoring words:\n",
    "- `binary`: words are marked as 1 (present) or 0 (absent)\n",
    "- `count`: words are counted based on their occurrence (integer)\n",
    "- `tfidf`: words are scored  based on their frequency of occurrence in their own document, but also are being penalized if they are common across  all documents\n",
    "- `freq`: wrods are scored based on their frequency of occurrence in their own document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare bag-of-words encoding of docs\n",
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode test data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    return Xtrain, Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode:  binary\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 77.24867463111877\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 77.45358347892761\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 82.49337077140808\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "The test ccuracy for each training:\n",
      "[0.77248675 0.81481481 0.7962963  0.76719576 0.80687833 0.81167108\n",
      " 0.77453583 0.79045093 0.82493371 0.78249335]\n",
      "The mean of the test accuracy:  0.7941756844520569\n",
      "\n",
      "mode:  count\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 83.33333134651184\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 77.18833088874817\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 76.1273205280304\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "The test ccuracy for each training:\n",
      "[0.80952382 0.80423278 0.7962963  0.80158728 0.83333331 0.79045093\n",
      " 0.77188331 0.76127321 0.78514588 0.79840851]\n",
      "The mean of the test accuracy:  0.7952135324478149\n",
      "\n",
      "mode:  tfidf\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 83.59788656234741\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 77.18833088874817\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 75.86206793785095\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "The test ccuracy for each training:\n",
      "[0.81216931 0.83597887 0.79894179 0.78835976 0.80158728 0.81167108\n",
      " 0.77188331 0.78249335 0.75862068 0.79840851]\n",
      "The mean of the test accuracy:  0.7960113942623138\n",
      "\n",
      "mode:  freq\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.77984046936035\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 78.77984046936035\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.37135004997253\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "The test ccuracy for each training:\n",
      "[0.80687833 0.81481481 0.7962963  0.78835976 0.80158728 0.7877984\n",
      " 0.78249335 0.7877984  0.8037135  0.79575598]\n",
      "The mean of the test accuracy:  0.7965496122837067\n",
      "\n",
      "     binary     count     tfidf      freq\n",
      "0  0.772487  0.809524  0.812169  0.806878\n",
      "1  0.814815  0.804233  0.835979  0.814815\n",
      "2  0.796296  0.796296  0.798942  0.796296\n",
      "3  0.767196  0.801587  0.788360  0.788360\n",
      "4  0.806878  0.833333  0.801587  0.801587\n",
      "5  0.811671  0.790451  0.811671  0.787798\n",
      "6  0.774536  0.771883  0.771883  0.782493\n",
      "7  0.790451  0.761273  0.782493  0.787798\n",
      "8  0.824934  0.785146  0.758621  0.803714\n",
      "9  0.782493  0.798409  0.798409  0.795756\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Define the vocabulary #\n",
    "#########################\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "    \n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # filter out stop words\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) >= 1]\n",
    "    # Stem the token\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def add_doc_to_vocab(docs, vocab):\n",
    "    '''\n",
    "    input:\n",
    "        docs: a list of sentences (docs)\n",
    "        vocab: a vocabulary dictionary\n",
    "    output:\n",
    "        return an updated vocabulary\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        tokens = clean_doc(doc)\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "        \n",
    "def doc_to_line(doc, vocab):\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [token for token in tokens if token in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    return line\n",
    "\n",
    "def clean_docs(docs, vocab):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        line = doc_to_line(doc, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "# prepare bag-of-words encoding of docs\n",
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode test data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    return Xtrain, Xtest\n",
    "\n",
    "def train_mlp_3(train_x, train_y,  test_x, test_y, batch_size = 50, epochs = 20, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose, callbacks = [callbacks], validation_data=(test_x, test_y))\n",
    "    return model\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Run Experiment of 4 different modes\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for mode in modes:\n",
    "    print('mode: ', mode)\n",
    "    acc_list = []\n",
    "    \n",
    "    # kfold.split() will return set indices for each split\n",
    "    for train, test in kfold.split(sentences):\n",
    "        # Instantiate a vocab object\n",
    "        vocab = Counter()\n",
    "\n",
    "        train_x, test_x = [], []\n",
    "        train_y, test_y = [], []\n",
    "\n",
    "        for i in train:\n",
    "            train_x.append(sentences[i])\n",
    "            train_y.append(labels[i])\n",
    "\n",
    "        for i in test:\n",
    "            test_x.append(sentences[i])\n",
    "            test_y.append(labels[i])\n",
    "\n",
    "        # Turn the labels into a numpy array\n",
    "        train_y = np.array(train_y)\n",
    "        test_y = np.array(test_y)\n",
    "\n",
    "        # Define a vocabulary for each fold\n",
    "        vocab = add_doc_to_vocab(train_x, vocab)\n",
    "        # print('The number of vocab: ', len(vocab))\n",
    "\n",
    "        # Clean the sentences\n",
    "        train_x = clean_docs(train_x, vocab)\n",
    "        test_x = clean_docs(test_x, vocab)\n",
    "\n",
    "        # encode data using freq mode\n",
    "        Xtrain, Xtest = prepare_data(train_x, test_x, mode)\n",
    "\n",
    "        # train the model\n",
    "        model = train_mlp_3(Xtrain, train_y, Xtest, test_y, verbose=0)\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "        print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "        acc_list.append(acc)\n",
    "    \n",
    "    results[mode] = acc_list\n",
    "    acc_list = np.array(acc_list)\n",
    "    print('The test ccuracy for each training:\\n{}'.format(acc_list))\n",
    "    print('The mean of the test accuracy: ', acc_list.mean())\n",
    "    print()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "results.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary</th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772487</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.812169</td>\n",
       "      <td>0.806878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.835979</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.788360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.806878</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.801587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.811671</td>\n",
       "      <td>0.790451</td>\n",
       "      <td>0.811671</td>\n",
       "      <td>0.787798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.774536</td>\n",
       "      <td>0.771883</td>\n",
       "      <td>0.771883</td>\n",
       "      <td>0.782493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.790451</td>\n",
       "      <td>0.761273</td>\n",
       "      <td>0.782493</td>\n",
       "      <td>0.787798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.824934</td>\n",
       "      <td>0.785146</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.803714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.782493</td>\n",
       "      <td>0.798409</td>\n",
       "      <td>0.798409</td>\n",
       "      <td>0.795756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     binary     count     tfidf      freq\n",
       "0  0.772487  0.809524  0.812169  0.806878\n",
       "1  0.814815  0.804233  0.835979  0.814815\n",
       "2  0.796296  0.796296  0.798942  0.796296\n",
       "3  0.767196  0.801587  0.788360  0.788360\n",
       "4  0.806878  0.833333  0.801587  0.801587\n",
       "5  0.811671  0.790451  0.811671  0.787798\n",
       "6  0.774536  0.771883  0.771883  0.782493\n",
       "7  0.790451  0.761273  0.782493  0.787798\n",
       "8  0.824934  0.785146  0.758621  0.803714\n",
       "9  0.782493  0.798409  0.798409  0.795756"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary</th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.794176</td>\n",
       "      <td>0.795214</td>\n",
       "      <td>0.796011</td>\n",
       "      <td>0.796550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019940</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>0.022037</td>\n",
       "      <td>0.010195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.761273</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.782493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.776525</td>\n",
       "      <td>0.786472</td>\n",
       "      <td>0.783960</td>\n",
       "      <td>0.787939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.793374</td>\n",
       "      <td>0.797352</td>\n",
       "      <td>0.798675</td>\n",
       "      <td>0.796026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.810473</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.809150</td>\n",
       "      <td>0.803182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.824934</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.835979</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          binary      count      tfidf       freq\n",
       "count  10.000000  10.000000  10.000000  10.000000\n",
       "mean    0.794176   0.795214   0.796011   0.796550\n",
       "std     0.019940   0.020032   0.022037   0.010195\n",
       "min     0.767196   0.761273   0.758621   0.782493\n",
       "25%     0.776525   0.786472   0.783960   0.787939\n",
       "50%     0.793374   0.797352   0.798675   0.796026\n",
       "75%     0.810473   0.803571   0.809150   0.803182\n",
       "max     0.824934   0.833333   0.835979   0.814815"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = results\n",
    "report = report.to_excel('BoW_MLP_CR_3.xlsx', sheet_name='model_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing the Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model 2\n",
    "\n",
    "Now, we will build Multilayer Perceptron (MLP) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "As you might have expected, the models are simply feedforward network with fully connected layers called `Dense` in the `Keras` library.\n",
    "\n",
    "Now, we will define our MLP neural network with very little trial and error so cannot be considered tuned for this problem. The configuration is as follows:\n",
    "- First hidden layer with 100 neurons and Relu activation function\n",
    "- Dropout layer with p = 0.5\n",
    "- Output layer with Sigmoid activation function\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_2(train_x, train_y, batch_size = 50, epochs = 10, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6617 - accuracy: 0.6353 - val_loss: 0.6567 - val_accuracy: 0.5979\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6186 - accuracy: 0.6420 - val_loss: 0.6254 - val_accuracy: 0.5979\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5682 - accuracy: 0.6685 - val_loss: 0.5757 - val_accuracy: 0.6772\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5021 - accuracy: 0.7736 - val_loss: 0.5255 - val_accuracy: 0.7116\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4406 - accuracy: 0.8360 - val_loss: 0.4976 - val_accuracy: 0.7116\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3920 - accuracy: 0.8605 - val_loss: 0.4834 - val_accuracy: 0.7169\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3551 - accuracy: 0.8714 - val_loss: 0.4701 - val_accuracy: 0.7619\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3254 - accuracy: 0.8840 - val_loss: 0.4709 - val_accuracy: 0.7434\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3011 - accuracy: 0.8940 - val_loss: 0.4748 - val_accuracy: 0.7381\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2754 - accuracy: 0.9037 - val_loss: 0.4690 - val_accuracy: 0.7593\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2579 - accuracy: 0.9132 - val_loss: 0.4681 - val_accuracy: 0.7619\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2412 - accuracy: 0.9226 - val_loss: 0.4777 - val_accuracy: 0.7593\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 76.1904776096344\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6656 - accuracy: 0.6314 - val_loss: 0.6350 - val_accuracy: 0.6561\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6210 - accuracy: 0.6361 - val_loss: 0.6059 - val_accuracy: 0.6561\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5661 - accuracy: 0.6856 - val_loss: 0.5715 - val_accuracy: 0.7116\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5003 - accuracy: 0.7945 - val_loss: 0.5369 - val_accuracy: 0.7302\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4401 - accuracy: 0.8272 - val_loss: 0.5169 - val_accuracy: 0.7566\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3915 - accuracy: 0.8572 - val_loss: 0.5106 - val_accuracy: 0.7566\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3542 - accuracy: 0.8728 - val_loss: 0.5075 - val_accuracy: 0.7619\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3192 - accuracy: 0.8861 - val_loss: 0.5095 - val_accuracy: 0.7619\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.2921 - accuracy: 0.8993 - val_loss: 0.5121 - val_accuracy: 0.7487\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2707 - accuracy: 0.9087 - val_loss: 0.5185 - val_accuracy: 0.7460\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2531 - accuracy: 0.9149 - val_loss: 0.5250 - val_accuracy: 0.7672\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2343 - accuracy: 0.9226 - val_loss: 0.5297 - val_accuracy: 0.7619\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2191 - accuracy: 0.9329 - val_loss: 0.5382 - val_accuracy: 0.7566\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2041 - accuracy: 0.9329 - val_loss: 0.5464 - val_accuracy: 0.7593\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.1922 - accuracy: 0.9408 - val_loss: 0.5541 - val_accuracy: 0.7646\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.1785 - accuracy: 0.9435 - val_loss: 0.5616 - val_accuracy: 0.7619\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6640 - accuracy: 0.6341 - val_loss: 0.6388 - val_accuracy: 0.6376\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6187 - accuracy: 0.6376 - val_loss: 0.6088 - val_accuracy: 0.6402\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5645 - accuracy: 0.6853 - val_loss: 0.5664 - val_accuracy: 0.7169\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.4995 - accuracy: 0.7772 - val_loss: 0.5310 - val_accuracy: 0.7725\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4396 - accuracy: 0.8349 - val_loss: 0.5082 - val_accuracy: 0.7937\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3933 - accuracy: 0.8590 - val_loss: 0.4972 - val_accuracy: 0.7751\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3501 - accuracy: 0.8772 - val_loss: 0.4960 - val_accuracy: 0.7857\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3240 - accuracy: 0.8790 - val_loss: 0.4958 - val_accuracy: 0.7910\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.2958 - accuracy: 0.8923 - val_loss: 0.4992 - val_accuracy: 0.7963\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2736 - accuracy: 0.9058 - val_loss: 0.5043 - val_accuracy: 0.7937\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2542 - accuracy: 0.9164 - val_loss: 0.5107 - val_accuracy: 0.7910\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2398 - accuracy: 0.9126 - val_loss: 0.5210 - val_accuracy: 0.7937\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2194 - accuracy: 0.9273 - val_loss: 0.5327 - val_accuracy: 0.7963\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2074 - accuracy: 0.9285 - val_loss: 0.5413 - val_accuracy: 0.7963\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6614 - accuracy: 0.6414 - val_loss: 0.6549 - val_accuracy: 0.6005\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6184 - accuracy: 0.6417 - val_loss: 0.6225 - val_accuracy: 0.6005\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5692 - accuracy: 0.6780 - val_loss: 0.5661 - val_accuracy: 0.6640\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5050 - accuracy: 0.7730 - val_loss: 0.5126 - val_accuracy: 0.7513\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4458 - accuracy: 0.8237 - val_loss: 0.4725 - val_accuracy: 0.7937\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3974 - accuracy: 0.8566 - val_loss: 0.4479 - val_accuracy: 0.8016\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3605 - accuracy: 0.8722 - val_loss: 0.4335 - val_accuracy: 0.8069\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3288 - accuracy: 0.8817 - val_loss: 0.4235 - val_accuracy: 0.8122\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3032 - accuracy: 0.8937 - val_loss: 0.4164 - val_accuracy: 0.8148\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2788 - accuracy: 0.9090 - val_loss: 0.4149 - val_accuracy: 0.8069\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2631 - accuracy: 0.9093 - val_loss: 0.4157 - val_accuracy: 0.8069\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2444 - accuracy: 0.9214 - val_loss: 0.4147 - val_accuracy: 0.8069\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2282 - accuracy: 0.9296 - val_loss: 0.4197 - val_accuracy: 0.8069\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2108 - accuracy: 0.9370 - val_loss: 0.4216 - val_accuracy: 0.8069\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6653 - accuracy: 0.6288 - val_loss: 0.6400 - val_accuracy: 0.6429\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6231 - accuracy: 0.6370 - val_loss: 0.6093 - val_accuracy: 0.6429\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5740 - accuracy: 0.6685 - val_loss: 0.5633 - val_accuracy: 0.6878\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5070 - accuracy: 0.7869 - val_loss: 0.5198 - val_accuracy: 0.7381\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4462 - accuracy: 0.8257 - val_loss: 0.4895 - val_accuracy: 0.7884\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3957 - accuracy: 0.8581 - val_loss: 0.4709 - val_accuracy: 0.8016\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3577 - accuracy: 0.8678 - val_loss: 0.4627 - val_accuracy: 0.7963\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3286 - accuracy: 0.8846 - val_loss: 0.4612 - val_accuracy: 0.7937\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.2964 - accuracy: 0.9002 - val_loss: 0.4621 - val_accuracy: 0.7963\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2750 - accuracy: 0.9061 - val_loss: 0.4665 - val_accuracy: 0.7937\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2536 - accuracy: 0.9158 - val_loss: 0.4731 - val_accuracy: 0.7804\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6657 - accuracy: 0.6251 - val_loss: 0.6084 - val_accuracy: 0.7003\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6252 - accuracy: 0.6313 - val_loss: 0.5735 - val_accuracy: 0.7056\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5737 - accuracy: 0.6833 - val_loss: 0.5171 - val_accuracy: 0.7241\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5061 - accuracy: 0.7843 - val_loss: 0.4730 - val_accuracy: 0.8196\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4444 - accuracy: 0.8273 - val_loss: 0.4351 - val_accuracy: 0.8170\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3987 - accuracy: 0.8452 - val_loss: 0.4191 - val_accuracy: 0.8170\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3574 - accuracy: 0.8729 - val_loss: 0.4016 - val_accuracy: 0.8223\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3234 - accuracy: 0.8876 - val_loss: 0.4006 - val_accuracy: 0.8170\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.2991 - accuracy: 0.8967 - val_loss: 0.3976 - val_accuracy: 0.8196\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2786 - accuracy: 0.9073 - val_loss: 0.3988 - val_accuracy: 0.8196\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2537 - accuracy: 0.9144 - val_loss: 0.4038 - val_accuracy: 0.7958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2381 - accuracy: 0.9223 - val_loss: 0.4101 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6617 - accuracy: 0.6371 - val_loss: 0.6418 - val_accuracy: 0.6260\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6172 - accuracy: 0.6389 - val_loss: 0.6117 - val_accuracy: 0.6260\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5661 - accuracy: 0.6672 - val_loss: 0.5656 - val_accuracy: 0.7029\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5035 - accuracy: 0.7696 - val_loss: 0.5252 - val_accuracy: 0.7613\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4419 - accuracy: 0.8323 - val_loss: 0.4985 - val_accuracy: 0.7613\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3944 - accuracy: 0.8540 - val_loss: 0.4818 - val_accuracy: 0.7692\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3571 - accuracy: 0.8661 - val_loss: 0.4733 - val_accuracy: 0.7692\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3247 - accuracy: 0.8846 - val_loss: 0.4708 - val_accuracy: 0.7639\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3010 - accuracy: 0.8943 - val_loss: 0.4689 - val_accuracy: 0.7533\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2742 - accuracy: 0.9044 - val_loss: 0.4699 - val_accuracy: 0.7533\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2580 - accuracy: 0.9114 - val_loss: 0.4731 - val_accuracy: 0.7533\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 76.92307829856873\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6654 - accuracy: 0.6230 - val_loss: 0.6274 - val_accuracy: 0.6658\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6245 - accuracy: 0.6345 - val_loss: 0.5928 - val_accuracy: 0.6684\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5759 - accuracy: 0.6686 - val_loss: 0.5484 - val_accuracy: 0.7294\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5044 - accuracy: 0.7908 - val_loss: 0.5027 - val_accuracy: 0.7692\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4403 - accuracy: 0.8314 - val_loss: 0.4786 - val_accuracy: 0.7851\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3923 - accuracy: 0.8561 - val_loss: 0.4712 - val_accuracy: 0.8090\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3548 - accuracy: 0.8729 - val_loss: 0.4698 - val_accuracy: 0.7905\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3231 - accuracy: 0.8811 - val_loss: 0.4647 - val_accuracy: 0.7851\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.2954 - accuracy: 0.8982 - val_loss: 0.4725 - val_accuracy: 0.7931\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2756 - accuracy: 0.9046 - val_loss: 0.4724 - val_accuracy: 0.7825\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2532 - accuracy: 0.9117 - val_loss: 0.4831 - val_accuracy: 0.7798\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6592 - accuracy: 0.6342 - val_loss: 0.6463 - val_accuracy: 0.6154\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6157 - accuracy: 0.6401 - val_loss: 0.6129 - val_accuracy: 0.6180\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5621 - accuracy: 0.6813 - val_loss: 0.5614 - val_accuracy: 0.6950\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.4958 - accuracy: 0.7796 - val_loss: 0.5171 - val_accuracy: 0.7639\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4410 - accuracy: 0.8358 - val_loss: 0.4876 - val_accuracy: 0.7719\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3911 - accuracy: 0.8602 - val_loss: 0.4676 - val_accuracy: 0.7798\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3586 - accuracy: 0.8737 - val_loss: 0.4598 - val_accuracy: 0.7798\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3272 - accuracy: 0.8832 - val_loss: 0.4563 - val_accuracy: 0.7825\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.2993 - accuracy: 0.8973 - val_loss: 0.4521 - val_accuracy: 0.7798\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2797 - accuracy: 0.9049 - val_loss: 0.4544 - val_accuracy: 0.7851\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2570 - accuracy: 0.9161 - val_loss: 0.4546 - val_accuracy: 0.7719\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2386 - accuracy: 0.9238 - val_loss: 0.4584 - val_accuracy: 0.7798\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2232 - accuracy: 0.9270 - val_loss: 0.4633 - val_accuracy: 0.7798\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2089 - accuracy: 0.9344 - val_loss: 0.4708 - val_accuracy: 0.7666\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.1987 - accuracy: 0.9367 - val_loss: 0.4809 - val_accuracy: 0.7798\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6670 - accuracy: 0.6292 - val_loss: 0.6444 - val_accuracy: 0.6340\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6234 - accuracy: 0.6380 - val_loss: 0.6144 - val_accuracy: 0.6340\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5759 - accuracy: 0.6704 - val_loss: 0.5680 - val_accuracy: 0.7188\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5076 - accuracy: 0.7831 - val_loss: 0.5234 - val_accuracy: 0.7613\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4462 - accuracy: 0.8352 - val_loss: 0.4922 - val_accuracy: 0.7745\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.3992 - accuracy: 0.8490 - val_loss: 0.4720 - val_accuracy: 0.7639\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.3595 - accuracy: 0.8696 - val_loss: 0.4608 - val_accuracy: 0.7878\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3279 - accuracy: 0.8799 - val_loss: 0.4551 - val_accuracy: 0.7931\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3020 - accuracy: 0.8985 - val_loss: 0.4495 - val_accuracy: 0.7905\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.2809 - accuracy: 0.8999 - val_loss: 0.4495 - val_accuracy: 0.8011\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.2597 - accuracy: 0.9097 - val_loss: 0.4493 - val_accuracy: 0.7931\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2422 - accuracy: 0.9185 - val_loss: 0.4528 - val_accuracy: 0.7984\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2244 - accuracy: 0.9247 - val_loss: 0.4586 - val_accuracy: 0.7905\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2114 - accuracy: 0.9303 - val_loss: 0.4624 - val_accuracy: 0.7958\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.1976 - accuracy: 0.9423 - val_loss: 0.4678 - val_accuracy: 0.7984\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "\n",
      "The test ccuracy for each training:\n",
      "[0.76190478 0.76719576 0.7962963  0.81481481 0.80158728 0.82228118\n",
      " 0.76923078 0.80901855 0.78514588 0.80106103]\n",
      "The mean of the test accuracy:  0.7928536355495452\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Define the vocabulary #\n",
    "#########################\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "    \n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # filter out stop words\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) >= 1]\n",
    "    # Stem the token\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def add_doc_to_vocab(docs, vocab):\n",
    "    '''\n",
    "    input:\n",
    "        docs: a list of sentences (docs)\n",
    "        vocab: a vocabulary dictionary\n",
    "    output:\n",
    "        return an updated vocabulary\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        tokens = clean_doc(doc)\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "        \n",
    "def doc_to_line(doc, vocab):\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [token for token in tokens if token in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    return line\n",
    "\n",
    "def clean_docs(docs, vocab):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        line = doc_to_line(doc, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "def create_tokenizer(sentences):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    return tokenizer\n",
    "\n",
    "def train_mlp_2(train_x, train_y, test_x, test_y, batch_size = 50, epochs = 20, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose, callbacks = [callbacks], validation_data=(test_x, test_y))\n",
    "    return model\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "for train, test in kfold.split(sentences):\n",
    "    # Instantiate a vocab object\n",
    "    vocab = Counter()\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "    \n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "    \n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "    \n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Define a vocabulary for each fold\n",
    "    vocab = add_doc_to_vocab(train_x, vocab)\n",
    "    # print('The number of vocab: ', len(vocab))\n",
    "    \n",
    "    # Clean the sentences\n",
    "    train_x = clean_docs(train_x, vocab)\n",
    "    test_x = clean_docs(test_x, vocab)\n",
    "    \n",
    "    # Define the tokenizer\n",
    "    tokenizer = create_tokenizer(train_x)\n",
    "    \n",
    "    # encode data using freq mode\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_x, mode='freq')\n",
    "    Xtest = tokenizer.texts_to_matrix(test_x, mode='freq')\n",
    "       \n",
    "    # train the model\n",
    "    model = train_mlp_2(Xtrain, train_y, Xtest, test_y)\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "\n",
    "acc_list = np.array(acc_list)\n",
    "print()\n",
    "print('The test ccuracy for each training:\\n{}'.format(acc_list))\n",
    "print('The mean of the test accuracy: ', acc_list.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Word Scoring Methods\n",
    "\n",
    "When we use `text_to_matrix()` function, we are given 4 different methods for scoring words:\n",
    "- `binary`: words are marked as 1 (present) or 0 (absent)\n",
    "- `count`: words are counted based on their occurrence (integer)\n",
    "- `tfidf`: words are scored  based on their frequency of occurrence in their own document, but also are being penalized if they are common across  all documents\n",
    "- `freq`: wrods are scored based on their frequency of occurrence in their own document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode:  binary\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 75.66137313842773\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 76.65782570838928\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 74.80106353759766\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.37135004997253\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "The test ccuracy for each training:\n",
      "[0.7962963  0.79894179 0.80952382 0.75661373 0.79894179 0.76657826\n",
      " 0.80636603 0.74801064 0.8037135  0.80901855]\n",
      "The mean of the test accuracy:  0.789400440454483\n",
      "\n",
      "mode:  count\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 82.49337077140808\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 77.18833088874817\n",
      "The test ccuracy for each training:\n",
      "[0.81481481 0.76719576 0.79365081 0.7962963  0.80687833 0.77984083\n",
      " 0.79840851 0.79840851 0.82493371 0.77188331]\n",
      "The mean of the test accuracy:  0.7952310860157012\n",
      "\n",
      "mode:  tfidf\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.7460298538208\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.8624358177185\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 82.0105791091919\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 75.86206793785095\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 76.92307829856873\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "The test ccuracy for each training:\n",
      "[0.76719576 0.80687833 0.8174603  0.83862436 0.82010579 0.81697613\n",
      " 0.77984083 0.75862068 0.76923078 0.78249335]\n",
      "The mean of the test accuracy:  0.7957426309585571\n",
      "\n",
      "mode:  freq\n",
      "Test Accuracy: 77.77777910232544\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 78.04232835769653\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 76.1904776096344\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 80.37135004997253\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "The test ccuracy for each training:\n",
      "[0.77777779 0.79100531 0.78042328 0.76190478 0.78306878 0.79310346\n",
      " 0.8037135  0.8143236  0.79840851 0.80636603]\n",
      "The mean of the test accuracy:  0.7910095036029816\n",
      "\n",
      "     binary     count     tfidf      freq\n",
      "0  0.796296  0.814815  0.767196  0.777778\n",
      "1  0.798942  0.767196  0.806878  0.791005\n",
      "2  0.809524  0.793651  0.817460  0.780423\n",
      "3  0.756614  0.796296  0.838624  0.761905\n",
      "4  0.798942  0.806878  0.820106  0.783069\n",
      "5  0.766578  0.779841  0.816976  0.793103\n",
      "6  0.806366  0.798409  0.779841  0.803714\n",
      "7  0.748011  0.798409  0.758621  0.814324\n",
      "8  0.803714  0.824934  0.769231  0.798409\n",
      "9  0.809019  0.771883  0.782493  0.806366\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Define the vocabulary #\n",
    "#########################\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "    \n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # filter out stop words\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) >= 1]\n",
    "    # Stem the token\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def add_doc_to_vocab(docs, vocab):\n",
    "    '''\n",
    "    input:\n",
    "        docs: a list of sentences (docs)\n",
    "        vocab: a vocabulary dictionary\n",
    "    output:\n",
    "        return an updated vocabulary\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        tokens = clean_doc(doc)\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "        \n",
    "def doc_to_line(doc, vocab):\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [token for token in tokens if token in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    return line\n",
    "\n",
    "def clean_docs(docs, vocab):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        line = doc_to_line(doc, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "# prepare bag-of-words encoding of docs\n",
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode test data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    return Xtrain, Xtest\n",
    "\n",
    "def train_mlp_2(train_x, train_y, test_x, test_y, batch_size = 50, epochs = 20, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose, callbacks = [callbacks], validation_data=(test_x, test_y))\n",
    "    return model\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Run Experiment of 4 different modes\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for mode in modes:\n",
    "    print('mode: ', mode)\n",
    "    acc_list = []\n",
    "    \n",
    "    # kfold.split() will return set indices for each split\n",
    "    for train, test in kfold.split(sentences):\n",
    "        # Instantiate a vocab object\n",
    "        vocab = Counter()\n",
    "\n",
    "        train_x, test_x = [], []\n",
    "        train_y, test_y = [], []\n",
    "\n",
    "        for i in train:\n",
    "            train_x.append(sentences[i])\n",
    "            train_y.append(labels[i])\n",
    "\n",
    "        for i in test:\n",
    "            test_x.append(sentences[i])\n",
    "            test_y.append(labels[i])\n",
    "\n",
    "        # Turn the labels into a numpy array\n",
    "        train_y = np.array(train_y)\n",
    "        test_y = np.array(test_y)\n",
    "\n",
    "        # Define a vocabulary for each fold\n",
    "        vocab = add_doc_to_vocab(train_x, vocab)\n",
    "        # print('The number of vocab: ', len(vocab))\n",
    "\n",
    "        # Clean the sentences\n",
    "        train_x = clean_docs(train_x, vocab)\n",
    "        test_x = clean_docs(test_x, vocab)\n",
    "\n",
    "        # encode data using freq mode\n",
    "        Xtrain, Xtest = prepare_data(train_x, test_x, mode)\n",
    "\n",
    "        # train the model\n",
    "        model = train_mlp_2(Xtrain, train_y, Xtest, test_y, verbose=0)\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "        print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "        acc_list.append(acc)\n",
    "    \n",
    "    results[mode] = acc_list\n",
    "    acc_list = np.array(acc_list)\n",
    "    print('The test ccuracy for each training:\\n{}'.format(acc_list))\n",
    "    print('The mean of the test accuracy: ', acc_list.mean())\n",
    "    print()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary</th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.806878</td>\n",
       "      <td>0.791005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.780423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.756614</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.838624</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.806878</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.783069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.766578</td>\n",
       "      <td>0.779841</td>\n",
       "      <td>0.816976</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.806366</td>\n",
       "      <td>0.798409</td>\n",
       "      <td>0.779841</td>\n",
       "      <td>0.803714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.748011</td>\n",
       "      <td>0.798409</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.814324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.803714</td>\n",
       "      <td>0.824934</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.798409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.809019</td>\n",
       "      <td>0.771883</td>\n",
       "      <td>0.782493</td>\n",
       "      <td>0.806366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     binary     count     tfidf      freq\n",
       "0  0.796296  0.814815  0.767196  0.777778\n",
       "1  0.798942  0.767196  0.806878  0.791005\n",
       "2  0.809524  0.793651  0.817460  0.780423\n",
       "3  0.756614  0.796296  0.838624  0.761905\n",
       "4  0.798942  0.806878  0.820106  0.783069\n",
       "5  0.766578  0.779841  0.816976  0.793103\n",
       "6  0.806366  0.798409  0.779841  0.803714\n",
       "7  0.748011  0.798409  0.758621  0.814324\n",
       "8  0.803714  0.824934  0.769231  0.798409\n",
       "9  0.809019  0.771883  0.782493  0.806366"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary</th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.789400</td>\n",
       "      <td>0.795231</td>\n",
       "      <td>0.795743</td>\n",
       "      <td>0.791010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023145</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.748011</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.774008</td>\n",
       "      <td>0.783293</td>\n",
       "      <td>0.771883</td>\n",
       "      <td>0.781085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.797352</td>\n",
       "      <td>0.794686</td>\n",
       "      <td>0.792054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.805703</td>\n",
       "      <td>0.804761</td>\n",
       "      <td>0.817339</td>\n",
       "      <td>0.802387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.824934</td>\n",
       "      <td>0.838624</td>\n",
       "      <td>0.814324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          binary      count      tfidf       freq\n",
       "count  10.000000  10.000000  10.000000  10.000000\n",
       "mean    0.789400   0.795231   0.795743   0.791010\n",
       "std     0.023145   0.018237   0.027494   0.015625\n",
       "min     0.748011   0.767196   0.758621   0.761905\n",
       "25%     0.774008   0.783293   0.771883   0.781085\n",
       "50%     0.798942   0.797352   0.794686   0.792054\n",
       "75%     0.805703   0.804761   0.817339   0.802387\n",
       "max     0.809524   0.824934   0.838624   0.814324"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = results\n",
    "report = report.to_excel('BoW_MLP_CR_2.xlsx', sheet_name='model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing the Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model 1\n",
    "\n",
    "Now, we will build Multilayer Perceptron (MLP) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "As you might have expected, the models are simply feedforward network with fully connected layers called `Dense` in the `Keras` library.\n",
    "\n",
    "Now, we will define our MLP neural network with very little trial and error so cannot be considered tuned for this problem. The configuration is as follows:\n",
    "- First hidden layer with 50 neurons and Relu activation function\n",
    "- Dropout layer with p = 0.5\n",
    "- Output layer with Sigmoid activation function\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_1(train_x, train_y, batch_size = 50, epochs = 10, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 - 5s - loss: 0.6704 - accuracy: 0.6279 - val_loss: 0.6419 - val_accuracy: 0.6561\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6340 - accuracy: 0.6356 - val_loss: 0.6178 - val_accuracy: 0.6561\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.6013 - accuracy: 0.6438 - val_loss: 0.5888 - val_accuracy: 0.6772\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5503 - accuracy: 0.7077 - val_loss: 0.5595 - val_accuracy: 0.7407\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.5028 - accuracy: 0.7907 - val_loss: 0.5278 - val_accuracy: 0.7328\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4547 - accuracy: 0.8207 - val_loss: 0.5082 - val_accuracy: 0.7725\n",
      "Epoch 7/20\n",
      "68/68 - 2s - loss: 0.4147 - accuracy: 0.8463 - val_loss: 0.4934 - val_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3888 - accuracy: 0.8631 - val_loss: 0.4849 - val_accuracy: 0.7725\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3567 - accuracy: 0.8764 - val_loss: 0.4751 - val_accuracy: 0.7751\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3374 - accuracy: 0.8861 - val_loss: 0.4714 - val_accuracy: 0.7751\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3177 - accuracy: 0.8923 - val_loss: 0.4714 - val_accuracy: 0.7646\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2967 - accuracy: 0.8996 - val_loss: 0.4717 - val_accuracy: 0.7646\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 77.77777910232544\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6684 - accuracy: 0.6326 - val_loss: 0.6423 - val_accuracy: 0.6508\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6330 - accuracy: 0.6361 - val_loss: 0.6167 - val_accuracy: 0.6508\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5956 - accuracy: 0.6509 - val_loss: 0.5874 - val_accuracy: 0.6720\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5509 - accuracy: 0.7230 - val_loss: 0.5524 - val_accuracy: 0.7090\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4994 - accuracy: 0.7866 - val_loss: 0.5227 - val_accuracy: 0.7487\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4532 - accuracy: 0.8296 - val_loss: 0.5024 - val_accuracy: 0.7725\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4176 - accuracy: 0.8466 - val_loss: 0.4863 - val_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3865 - accuracy: 0.8546 - val_loss: 0.4763 - val_accuracy: 0.7804\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3612 - accuracy: 0.8661 - val_loss: 0.4709 - val_accuracy: 0.7831\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3390 - accuracy: 0.8808 - val_loss: 0.4695 - val_accuracy: 0.7884\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3190 - accuracy: 0.8867 - val_loss: 0.4666 - val_accuracy: 0.7804\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.3024 - accuracy: 0.8902 - val_loss: 0.4656 - val_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2843 - accuracy: 0.9082 - val_loss: 0.4663 - val_accuracy: 0.7831\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2704 - accuracy: 0.9055 - val_loss: 0.4680 - val_accuracy: 0.7831\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.2553 - accuracy: 0.9238 - val_loss: 0.4725 - val_accuracy: 0.7751\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Epoch 1/20\n",
      "68/68 - 4s - loss: 0.6711 - accuracy: 0.6317 - val_loss: 0.6624 - val_accuracy: 0.6032\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6348 - accuracy: 0.6414 - val_loss: 0.6441 - val_accuracy: 0.6032\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.6026 - accuracy: 0.6482 - val_loss: 0.6111 - val_accuracy: 0.6111\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5591 - accuracy: 0.7109 - val_loss: 0.5765 - val_accuracy: 0.6746\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.5090 - accuracy: 0.7839 - val_loss: 0.5435 - val_accuracy: 0.7407\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4613 - accuracy: 0.8260 - val_loss: 0.5201 - val_accuracy: 0.7513\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4270 - accuracy: 0.8396 - val_loss: 0.5005 - val_accuracy: 0.7804\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3980 - accuracy: 0.8555 - val_loss: 0.4887 - val_accuracy: 0.7831\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3674 - accuracy: 0.8672 - val_loss: 0.4842 - val_accuracy: 0.7857\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3416 - accuracy: 0.8725 - val_loss: 0.4797 - val_accuracy: 0.7937\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3220 - accuracy: 0.8834 - val_loss: 0.4768 - val_accuracy: 0.7857\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.3017 - accuracy: 0.8964 - val_loss: 0.4784 - val_accuracy: 0.7831\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2889 - accuracy: 0.9023 - val_loss: 0.4756 - val_accuracy: 0.7778\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2705 - accuracy: 0.9096 - val_loss: 0.4755 - val_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.2578 - accuracy: 0.9164 - val_loss: 0.4780 - val_accuracy: 0.7778\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Epoch 1/20\n",
      "68/68 - 6s - loss: 0.6666 - accuracy: 0.6326 - val_loss: 0.6426 - val_accuracy: 0.6402\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6297 - accuracy: 0.6373 - val_loss: 0.6168 - val_accuracy: 0.6402\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5962 - accuracy: 0.6441 - val_loss: 0.5838 - val_accuracy: 0.6693\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5502 - accuracy: 0.7077 - val_loss: 0.5475 - val_accuracy: 0.7487\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.5026 - accuracy: 0.7836 - val_loss: 0.5164 - val_accuracy: 0.7725\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4573 - accuracy: 0.8207 - val_loss: 0.4918 - val_accuracy: 0.7725\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4212 - accuracy: 0.8463 - val_loss: 0.4771 - val_accuracy: 0.7963\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3880 - accuracy: 0.8619 - val_loss: 0.4680 - val_accuracy: 0.7963\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3595 - accuracy: 0.8669 - val_loss: 0.4630 - val_accuracy: 0.7910\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3359 - accuracy: 0.8843 - val_loss: 0.4610 - val_accuracy: 0.7910\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3151 - accuracy: 0.8873 - val_loss: 0.4641 - val_accuracy: 0.7804\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.3014 - accuracy: 0.8940 - val_loss: 0.4626 - val_accuracy: 0.7963\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6706 - accuracy: 0.6303 - val_loss: 0.6548 - val_accuracy: 0.6190\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6360 - accuracy: 0.6397 - val_loss: 0.6319 - val_accuracy: 0.6190\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.6060 - accuracy: 0.6435 - val_loss: 0.5964 - val_accuracy: 0.6296\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5605 - accuracy: 0.7047 - val_loss: 0.5506 - val_accuracy: 0.7090\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.5092 - accuracy: 0.7833 - val_loss: 0.5092 - val_accuracy: 0.7857\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4646 - accuracy: 0.8172 - val_loss: 0.4812 - val_accuracy: 0.7937\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4249 - accuracy: 0.8413 - val_loss: 0.4588 - val_accuracy: 0.8148\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3926 - accuracy: 0.8560 - val_loss: 0.4440 - val_accuracy: 0.8069\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3673 - accuracy: 0.8702 - val_loss: 0.4382 - val_accuracy: 0.8122\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3399 - accuracy: 0.8858 - val_loss: 0.4320 - val_accuracy: 0.8122\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3217 - accuracy: 0.8828 - val_loss: 0.4219 - val_accuracy: 0.8122\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.3034 - accuracy: 0.8976 - val_loss: 0.4195 - val_accuracy: 0.8095\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/20\n",
      "68/68 - 4s - loss: 0.6719 - accuracy: 0.6248 - val_loss: 0.6325 - val_accuracy: 0.6870\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6368 - accuracy: 0.6321 - val_loss: 0.5997 - val_accuracy: 0.6870\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.6022 - accuracy: 0.6413 - val_loss: 0.5677 - val_accuracy: 0.6976\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5558 - accuracy: 0.7181 - val_loss: 0.5319 - val_accuracy: 0.7772\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.5071 - accuracy: 0.7784 - val_loss: 0.5035 - val_accuracy: 0.7878\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4602 - accuracy: 0.8255 - val_loss: 0.4798 - val_accuracy: 0.7878\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4229 - accuracy: 0.8376 - val_loss: 0.4623 - val_accuracy: 0.7878\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3917 - accuracy: 0.8579 - val_loss: 0.4522 - val_accuracy: 0.7931\n",
      "Epoch 9/20\n",
      "68/68 - 2s - loss: 0.3645 - accuracy: 0.8720 - val_loss: 0.4441 - val_accuracy: 0.7958\n",
      "Epoch 10/20\n",
      "68/68 - 2s - loss: 0.3442 - accuracy: 0.8729 - val_loss: 0.4413 - val_accuracy: 0.8011\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3200 - accuracy: 0.8893 - val_loss: 0.4387 - val_accuracy: 0.8011\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.3055 - accuracy: 0.8920 - val_loss: 0.4367 - val_accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2896 - accuracy: 0.9011 - val_loss: 0.4380 - val_accuracy: 0.8037\n",
      "Epoch 14/20\n",
      "68/68 - 2s - loss: 0.2710 - accuracy: 0.9088 - val_loss: 0.4430 - val_accuracy: 0.8117\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.2562 - accuracy: 0.9164 - val_loss: 0.4419 - val_accuracy: 0.8196\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.2492 - accuracy: 0.9173 - val_loss: 0.4459 - val_accuracy: 0.8090\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.2364 - accuracy: 0.9200 - val_loss: 0.4523 - val_accuracy: 0.8011\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.2265 - accuracy: 0.9273 - val_loss: 0.4505 - val_accuracy: 0.8143\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.2159 - accuracy: 0.9297 - val_loss: 0.4610 - val_accuracy: 0.7984\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.2054 - accuracy: 0.9341 - val_loss: 0.4622 - val_accuracy: 0.8037\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 81.9628655910492\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6696 - accuracy: 0.6330 - val_loss: 0.6544 - val_accuracy: 0.6154\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6330 - accuracy: 0.6401 - val_loss: 0.6308 - val_accuracy: 0.6154\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5996 - accuracy: 0.6436 - val_loss: 0.5943 - val_accuracy: 0.6233\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5553 - accuracy: 0.6995 - val_loss: 0.5520 - val_accuracy: 0.7268\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.5075 - accuracy: 0.7796 - val_loss: 0.5217 - val_accuracy: 0.7321\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4644 - accuracy: 0.8175 - val_loss: 0.4920 - val_accuracy: 0.7692\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4217 - accuracy: 0.8414 - val_loss: 0.4709 - val_accuracy: 0.7745\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3915 - accuracy: 0.8567 - val_loss: 0.4592 - val_accuracy: 0.7719\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3680 - accuracy: 0.8670 - val_loss: 0.4522 - val_accuracy: 0.7745\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3422 - accuracy: 0.8752 - val_loss: 0.4443 - val_accuracy: 0.7719\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3233 - accuracy: 0.8902 - val_loss: 0.4424 - val_accuracy: 0.7745\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.3096 - accuracy: 0.8917 - val_loss: 0.4420 - val_accuracy: 0.7745\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 77.45358347892761\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6653 - accuracy: 0.6380 - val_loss: 0.6467 - val_accuracy: 0.6233\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6262 - accuracy: 0.6392 - val_loss: 0.6204 - val_accuracy: 0.6233\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5918 - accuracy: 0.6495 - val_loss: 0.5807 - val_accuracy: 0.6552\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5457 - accuracy: 0.7187 - val_loss: 0.5389 - val_accuracy: 0.7401\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4997 - accuracy: 0.7858 - val_loss: 0.5024 - val_accuracy: 0.7851\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4539 - accuracy: 0.8208 - val_loss: 0.4730 - val_accuracy: 0.8143\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4232 - accuracy: 0.8434 - val_loss: 0.4513 - val_accuracy: 0.8249\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3856 - accuracy: 0.8620 - val_loss: 0.4366 - val_accuracy: 0.8302\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3629 - accuracy: 0.8682 - val_loss: 0.4237 - val_accuracy: 0.8276\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3410 - accuracy: 0.8743 - val_loss: 0.4179 - val_accuracy: 0.8382\n",
      "Epoch 11/20\n",
      "68/68 - 2s - loss: 0.3199 - accuracy: 0.8852 - val_loss: 0.4127 - val_accuracy: 0.8329\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.3013 - accuracy: 0.8973 - val_loss: 0.4091 - val_accuracy: 0.8302\n",
      "Epoch 13/20\n",
      "68/68 - 2s - loss: 0.2859 - accuracy: 0.9035 - val_loss: 0.4096 - val_accuracy: 0.8249\n",
      "Epoch 14/20\n",
      "68/68 - 2s - loss: 0.2685 - accuracy: 0.9097 - val_loss: 0.4064 - val_accuracy: 0.8223\n",
      "Epoch 15/20\n",
      "68/68 - 2s - loss: 0.2576 - accuracy: 0.9135 - val_loss: 0.4063 - val_accuracy: 0.8249\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 83.81962776184082\n",
      "Epoch 1/20\n",
      "68/68 - 2s - loss: 0.6727 - accuracy: 0.6298 - val_loss: 0.6652 - val_accuracy: 0.5995\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6374 - accuracy: 0.6418 - val_loss: 0.6487 - val_accuracy: 0.5995\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.6061 - accuracy: 0.6454 - val_loss: 0.6196 - val_accuracy: 0.6074\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5605 - accuracy: 0.7063 - val_loss: 0.5828 - val_accuracy: 0.6631\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.5058 - accuracy: 0.7861 - val_loss: 0.5522 - val_accuracy: 0.7029\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4596 - accuracy: 0.8275 - val_loss: 0.5308 - val_accuracy: 0.7268\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4220 - accuracy: 0.8346 - val_loss: 0.5155 - val_accuracy: 0.7480\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3894 - accuracy: 0.8579 - val_loss: 0.5100 - val_accuracy: 0.7454\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3621 - accuracy: 0.8708 - val_loss: 0.5078 - val_accuracy: 0.7560\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3397 - accuracy: 0.8776 - val_loss: 0.5058 - val_accuracy: 0.7613\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3191 - accuracy: 0.8840 - val_loss: 0.5051 - val_accuracy: 0.7507\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2962 - accuracy: 0.9002 - val_loss: 0.5090 - val_accuracy: 0.7507\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2842 - accuracy: 0.9002 - val_loss: 0.5125 - val_accuracy: 0.7586\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.2688 - accuracy: 0.9085 - val_loss: 0.5159 - val_accuracy: 0.7586\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.2552 - accuracy: 0.9129 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 76.1273205280304\n",
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 0.6681 - accuracy: 0.6310 - val_loss: 0.6276 - val_accuracy: 0.6817\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.6298 - accuracy: 0.6327 - val_loss: 0.6014 - val_accuracy: 0.6817\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.5902 - accuracy: 0.6504 - val_loss: 0.5722 - val_accuracy: 0.6950\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.5404 - accuracy: 0.7443 - val_loss: 0.5410 - val_accuracy: 0.7268\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.4900 - accuracy: 0.7993 - val_loss: 0.5198 - val_accuracy: 0.7480\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.4447 - accuracy: 0.8346 - val_loss: 0.5033 - val_accuracy: 0.7454\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.4115 - accuracy: 0.8464 - val_loss: 0.4923 - val_accuracy: 0.7507\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.3808 - accuracy: 0.8640 - val_loss: 0.4845 - val_accuracy: 0.7586\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.3601 - accuracy: 0.8696 - val_loss: 0.4758 - val_accuracy: 0.7533\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.3340 - accuracy: 0.8767 - val_loss: 0.4721 - val_accuracy: 0.7586\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.3159 - accuracy: 0.8932 - val_loss: 0.4703 - val_accuracy: 0.7560\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.2969 - accuracy: 0.8952 - val_loss: 0.4694 - val_accuracy: 0.7533\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.2793 - accuracy: 0.9023 - val_loss: 0.4704 - val_accuracy: 0.7480\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 75.86206793785095\n",
      "\n",
      "The test ccuracy for each training:\n",
      "[0.77777779 0.78835976 0.79365081 0.7962963  0.81481481 0.81962866\n",
      " 0.77453583 0.83819628 0.76127321 0.75862068]\n",
      "The mean of the test accuracy:  0.792315411567688\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Define the vocabulary #\n",
    "#########################\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "    \n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # filter out stop words\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) >= 1]\n",
    "    # Stem the token\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def add_doc_to_vocab(docs, vocab):\n",
    "    '''\n",
    "    input:\n",
    "        docs: a list of sentences (docs)\n",
    "        vocab: a vocabulary dictionary\n",
    "    output:\n",
    "        return an updated vocabulary\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        tokens = clean_doc(doc)\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "        \n",
    "def doc_to_line(doc, vocab):\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [token for token in tokens if token in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    return line\n",
    "\n",
    "def clean_docs(docs, vocab):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        line = doc_to_line(doc, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "def create_tokenizer(sentences):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    return tokenizer\n",
    "\n",
    "def train_mlp_1(train_x, train_y, test_x, test_y, batch_size = 50, epochs = 20, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose, callbacks = [callbacks], validation_data=(test_x, test_y))\n",
    "    return model\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "for train, test in kfold.split(sentences):\n",
    "    # Instantiate a vocab object\n",
    "    vocab = Counter()\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "    \n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "    \n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "    \n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Define a vocabulary for each fold\n",
    "    vocab = add_doc_to_vocab(train_x, vocab)\n",
    "    # print('The number of vocab: ', len(vocab))\n",
    "    \n",
    "    # Clean the sentences\n",
    "    train_x = clean_docs(train_x, vocab)\n",
    "    test_x = clean_docs(test_x, vocab)\n",
    "    \n",
    "    # Define the tokenizer\n",
    "    tokenizer = create_tokenizer(train_x)\n",
    "    \n",
    "    # encode data using freq mode\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_x, mode='freq')\n",
    "    Xtest = tokenizer.texts_to_matrix(test_x, mode='freq')\n",
    "       \n",
    "    # train the model\n",
    "    model = train_mlp_1(Xtrain, train_y, Xtest, test_y)\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "\n",
    "acc_list = np.array(acc_list)\n",
    "print()\n",
    "print('The test ccuracy for each training:\\n{}'.format(acc_list))\n",
    "print('The mean of the test accuracy: ', acc_list.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Word Scoring Methods\n",
    "\n",
    "When we use `text_to_matrix()` function, we are given 4 different methods for scoring words:\n",
    "- `binary`: words are marked as 1 (present) or 0 (absent)\n",
    "- `count`: words are counted based on their occurrence (integer)\n",
    "- `tfidf`: words are scored  based on their frequency of occurrence in their own document, but also are being penalized if they are common across  all documents\n",
    "- `freq`: wrods are scored based on their frequency of occurrence in their own document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode:  binary\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.57142686843872\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 77.51322984695435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "The test ccuracy for each training:\n",
      "[0.78835976 0.80952382 0.78571427 0.79365081 0.7751323  0.79575598\n",
      " 0.79045093 0.80106103 0.79310346 0.80901855]\n",
      "The mean of the test accuracy:  0.7941770911216736\n",
      "\n",
      "mode:  count\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 77.77777910232544\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "The test ccuracy for each training:\n",
      "[0.78835976 0.77777779 0.76719576 0.80687833 0.78835976 0.81167108\n",
      " 0.79045093 0.80636603 0.79575598 0.82228118]\n",
      "The mean of the test accuracy:  0.7955096602439881\n",
      "\n",
      "mode:  tfidf\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 78.04232835769653\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.8624358177185\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 76.98412537574768\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.37135004997253\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 76.39257311820984\n",
      "The test ccuracy for each training:\n",
      "[0.78042328 0.7962963  0.83862436 0.76984125 0.80952382 0.8037135\n",
      " 0.81167108 0.78514588 0.81167108 0.76392573]\n",
      "The mean of the test accuracy:  0.7970836281776428\n",
      "\n",
      "mode:  freq\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 77.51322984695435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 75.86206793785095\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 83.81962776184082\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 76.65782570838928\n",
      "The test ccuracy for each training:\n",
      "[0.7751323  0.81481481 0.78835976 0.80687833 0.80158728 0.78514588\n",
      " 0.75862068 0.83819628 0.80106103 0.76657826]\n",
      "The mean of the test accuracy:  0.7936374604701996\n",
      "\n",
      "     binary     count     tfidf      freq\n",
      "0  0.788360  0.788360  0.780423  0.775132\n",
      "1  0.809524  0.777778  0.796296  0.814815\n",
      "2  0.785714  0.767196  0.838624  0.788360\n",
      "3  0.793651  0.806878  0.769841  0.806878\n",
      "4  0.775132  0.788360  0.809524  0.801587\n",
      "5  0.795756  0.811671  0.803714  0.785146\n",
      "6  0.790451  0.790451  0.811671  0.758621\n",
      "7  0.801061  0.806366  0.785146  0.838196\n",
      "8  0.793103  0.795756  0.811671  0.801061\n",
      "9  0.809019  0.822281  0.763926  0.766578\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Define the vocabulary #\n",
    "#########################\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "    \n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # filter out stop words\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) >= 1]\n",
    "    # Stem the token\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def add_doc_to_vocab(docs, vocab):\n",
    "    '''\n",
    "    input:\n",
    "        docs: a list of sentences (docs)\n",
    "        vocab: a vocabulary dictionary\n",
    "    output:\n",
    "        return an updated vocabulary\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        tokens = clean_doc(doc)\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "        \n",
    "def doc_to_line(doc, vocab):\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [token for token in tokens if token in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    return line\n",
    "\n",
    "def clean_docs(docs, vocab):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        line = doc_to_line(doc, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "# prepare bag-of-words encoding of docs\n",
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode test data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    return Xtrain, Xtest\n",
    "\n",
    "def train_mlp_1(train_x, train_y, test_x, test_y, batch_size = 50, epochs = 20, verbose =2):\n",
    "    \n",
    "    n_words = train_x.shape[1]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(n_words,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size, epochs, verbose, callbacks = [callbacks], validation_data=(test_x, test_y))\n",
    "    return model\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Run Experiment of 4 different modes\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for mode in modes:\n",
    "    print('mode: ', mode)\n",
    "    acc_list = []\n",
    "    \n",
    "    # kfold.split() will return set indices for each split\n",
    "    for train, test in kfold.split(sentences):\n",
    "        # Instantiate a vocab object\n",
    "        vocab = Counter()\n",
    "\n",
    "        train_x, test_x = [], []\n",
    "        train_y, test_y = [], []\n",
    "\n",
    "        for i in train:\n",
    "            train_x.append(sentences[i])\n",
    "            train_y.append(labels[i])\n",
    "\n",
    "        for i in test:\n",
    "            test_x.append(sentences[i])\n",
    "            test_y.append(labels[i])\n",
    "\n",
    "        # Turn the labels into a numpy array\n",
    "        train_y = np.array(train_y)\n",
    "        test_y = np.array(test_y)\n",
    "\n",
    "        # Define a vocabulary for each fold\n",
    "        vocab = add_doc_to_vocab(train_x, vocab)\n",
    "        # print('The number of vocab: ', len(vocab))\n",
    "\n",
    "        # Clean the sentences\n",
    "        train_x = clean_docs(train_x, vocab)\n",
    "        test_x = clean_docs(test_x, vocab)\n",
    "\n",
    "        # encode data using freq mode\n",
    "        Xtrain, Xtest = prepare_data(train_x, test_x, mode)\n",
    "\n",
    "        # train the model\n",
    "        model = train_mlp_1(Xtrain, train_y, Xtest, test_y, verbose=0)\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "        print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "        acc_list.append(acc)\n",
    "    \n",
    "    results[mode] = acc_list\n",
    "    acc_list = np.array(acc_list)\n",
    "    print('The test ccuracy for each training:\\n{}'.format(acc_list))\n",
    "    print('The mean of the test accuracy: ', acc_list.mean())\n",
    "    print()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary</th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.780423</td>\n",
       "      <td>0.775132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.838624</td>\n",
       "      <td>0.788360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.806878</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.806878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.775132</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.801587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.795756</td>\n",
       "      <td>0.811671</td>\n",
       "      <td>0.803714</td>\n",
       "      <td>0.785146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.790451</td>\n",
       "      <td>0.790451</td>\n",
       "      <td>0.811671</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.801061</td>\n",
       "      <td>0.806366</td>\n",
       "      <td>0.785146</td>\n",
       "      <td>0.838196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.795756</td>\n",
       "      <td>0.811671</td>\n",
       "      <td>0.801061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.809019</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>0.766578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     binary     count     tfidf      freq\n",
       "0  0.788360  0.788360  0.780423  0.775132\n",
       "1  0.809524  0.777778  0.796296  0.814815\n",
       "2  0.785714  0.767196  0.838624  0.788360\n",
       "3  0.793651  0.806878  0.769841  0.806878\n",
       "4  0.775132  0.788360  0.809524  0.801587\n",
       "5  0.795756  0.811671  0.803714  0.785146\n",
       "6  0.790451  0.790451  0.811671  0.758621\n",
       "7  0.801061  0.806366  0.785146  0.838196\n",
       "8  0.793103  0.795756  0.811671  0.801061\n",
       "9  0.809019  0.822281  0.763926  0.766578"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary</th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.794177</td>\n",
       "      <td>0.795510</td>\n",
       "      <td>0.797084</td>\n",
       "      <td>0.793637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.016563</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.023871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.775132</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.788883</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.781604</td>\n",
       "      <td>0.777636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.793377</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.800005</td>\n",
       "      <td>0.794710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.799735</td>\n",
       "      <td>0.806750</td>\n",
       "      <td>0.811134</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>0.838624</td>\n",
       "      <td>0.838196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          binary      count      tfidf       freq\n",
       "count  10.000000  10.000000  10.000000  10.000000\n",
       "mean    0.794177   0.795510   0.797084   0.793637\n",
       "std     0.010484   0.016563   0.022638   0.023871\n",
       "min     0.775132   0.767196   0.763926   0.758621\n",
       "25%     0.788883   0.788360   0.781604   0.777636\n",
       "50%     0.793377   0.793103   0.800005   0.794710\n",
       "75%     0.799735   0.806750   0.811134   0.805556\n",
       "max     0.809524   0.822281   0.838624   0.838196"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = results\n",
    "report = report.to_excel('BoW_MLP_CR_1.xlsx', sheet_name='model_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
