{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN Classification with MR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using TCN model on the Movie Review Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5952, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>who was the 22nd president of the us ?</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>what is the money they use in zambia ?</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>how many feet in a mile ?</td>\n",
       "      <td>5</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>what is the birthstone of october ?</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>what is e coli ?</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     how did serfdom develop in and then leave russ...      0  train\n",
       "1      what films featured the character popeye doyle ?      1  train\n",
       "2     how can i find a list of celebrities ' real na...      0  train\n",
       "3     what fowl grabs the spotlight after the chines...      1  train\n",
       "4                       what is the full form of .com ?      2  train\n",
       "...                                                 ...    ...    ...\n",
       "5947             who was the 22nd president of the us ?      3   test\n",
       "5948             what is the money they use in zambia ?      1   test\n",
       "5949                          how many feet in a mile ?      5   test\n",
       "5950                what is the birthstone of october ?      1   test\n",
       "5951                                   what is e coli ?      0   test\n",
       "\n",
       "[5952 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/TREC/TREC.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5952 entries, 0 to 5951\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  5952 non-null   object\n",
      " 1   label     5952 non-null   int32 \n",
      " 2   split     5952 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 116.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">train</th>\n",
       "      <th>0</th>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentence\n",
       "split label          \n",
       "test  0           138\n",
       "      1            94\n",
       "      2             9\n",
       "      3            65\n",
       "      4            81\n",
       "      5           113\n",
       "train 0          1162\n",
       "      1          1250\n",
       "      2            86\n",
       "      3          1223\n",
       "      4           835\n",
       "      5           896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby(by=['split', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452\n",
      "5452\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "# Separate the sentences and the labels for training and testing\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how did serfdom develop in and then leave russia ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  what is the full form of .com ?\n",
      "Into a sequence of int: [3, 4, 2, 471, 261, 5, 372]\n",
      "Into a padded sequence: [  3   4   2 471 261   5 372   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "print(\"Example of sentence: \", train_x[4])\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "what 3\n",
      "is 4\n",
      "of 5\n",
      "in 6\n",
      "a 7\n",
      "how 8\n",
      "'s 9\n",
      "was 10\n",
      "8461\n"
     ]
    }
   ],
   "source": [
    "# See the first 10 words in the vocabulary\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Model\n",
    "\n",
    "Now, we will build Temporal Convolutional Network (CNN) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "The model takes inspiration from https://github.com/philipperemy/keras-tcn and https://www.kaggle.com/christofhenkel/temporal-convolutional-network\n",
    "\n",
    "__Arguments__\n",
    "`TCN(nb_filters=64, kernel_size=2, nb_stacks=1, dilations=[1, 2, 4, 8, 16, 32], padding='causal', use_skip_connections=False, dropout_rate=0.0, return_sequences=True, activation='relu', kernel_initializer='he_normal', use_batch_norm=False, **kwargs)`\n",
    "\n",
    "- `nb_filters`: Integer. The number of filters to use in the convolutional layers. Would be similar to units for LSTM.\n",
    "- `kernel_size`: Integer. The size of the kernel to use in each convolutional layer.\n",
    "- `dilations`: List. A dilation list. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
    "- `nb_stacks`: Integer. The number of stacks of residual blocks to use.\n",
    "- `padding`: String. The padding to use in the convolutions. 'causal' for a causal network (as in the original implementation) and - `'same' for a non-causal network.\n",
    "- `use_skip_connections`: Boolean. If we want to add skip connections from input to each residual block.\n",
    "- `return_sequences`: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "- `dropout_rate`: Float between 0 and 1. Fraction of the input units to drop.\n",
    "- `activation`: The activation used in the residual blocks o = activation(x + F(x)).\n",
    "- `kernel_initializer`: Initializer for the kernel weights matrix (Conv1D).\n",
    "- `use_batch_norm`: Whether to use batch normalization in the residual layers or not.\n",
    "- `kwargs`: Any other arguments for configuring parent class Layer. For example \"name=str\", Name of the model. Use unique names when using multiple TCN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define our TCN model as follows:\n",
    "- One TCN layer with 100 filters, kernel size 1-6, and relu and tanh activation function;\n",
    "- Dropout size = 0.5;\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)\n",
    "\n",
    "**Note**: \n",
    "- The whole purpose of dropout layers is to tackle the problem of over-fitting and to introduce generalization to the model. Hence it is advisable to keep dropout parameter near 0.5 in hidden layers. \n",
    "- https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcn import TCN, tcn_full_summary\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.layers import concatenate, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def define_model(kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    inp = Input( shape=(max_length,))\n",
    "    x = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=max_length)(inp)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn1')(x)\n",
    "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn2')(x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    conc = Dense(16, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(6, activation=\"softmax\")(conc)    \n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 300)     300000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 100, 300)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tcn1 (TCN)                      (None, 100, 128)     279936      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tcn2 (TCN)                      (None, 100, 64)      65984       tcn1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           tcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 64)           0           tcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           2064        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            102         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 648,086\n",
      "Trainable params: 648,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tcn_full_summary(model_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#     # Overide the method on_epoch_end() for our benefit\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         if (logs.get('accuracy') > 0.93):\n",
    "#             print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "#             self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=20, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Training 1: relu activation, 1 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 24s 139ms/step - loss: 1.5604 - accuracy: 0.3325 - val_loss: 0.8038 - val_accuracy: 0.7200\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.6618 - accuracy: 0.7846 - val_loss: 0.5389 - val_accuracy: 0.8120\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.3117 - accuracy: 0.9115 - val_loss: 0.4700 - val_accuracy: 0.8760\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1802 - accuracy: 0.9460 - val_loss: 0.5101 - val_accuracy: 0.8640\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1116 - accuracy: 0.9617 - val_loss: 0.5702 - val_accuracy: 0.8620 0.1115 - accuracy\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0821 - accuracy: 0.9690 - val_loss: 0.5980 - val_accuracy: 0.8420\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2799 - accuracy: 0.9056 - val_loss: 0.8327 - val_accuracy: 0.8580\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.6182 - val_accuracy: 0.8820\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.7054 - val_accuracy: 0.8760\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.7277 - val_accuracy: 0.8620\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0468 - accuracy: 0.9897 - val_loss: 0.7339 - val_accuracy: 0.8660\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0425 - accuracy: 0.9887 - val_loss: 0.7774 - val_accuracy: 0.8720\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0514 - accuracy: 0.9909 - val_loss: 1.0066 - val_accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0538 - accuracy: 0.9908 - val_loss: 0.9368 - val_accuracy: 0.8720\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.7842 - val_accuracy: 0.8680\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0192 - accuracy: 0.9967 - val_loss: 0.7877 - val_accuracy: 0.8760\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 0.8220 - val_accuracy: 0.8680\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.8399 - val_accuracy: 0.8420\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0609 - accuracy: 0.9858 - val_loss: 0.7149 - val_accuracy: 0.8680\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.9409 - val_accuracy: 0.8700\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.9915 - val_accuracy: 0.8680\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 1.1301 - val_accuracy: 0.8700\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 1.3223 - val_accuracy: 0.8480\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0271 - accuracy: 0.9948 - val_loss: 0.7895 - val_accuracy: 0.8720\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.7392 - val_accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0281 - accuracy: 0.9951 - val_loss: 0.7615 - val_accuracy: 0.8560\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0223 - accuracy: 0.9962 - val_loss: 1.0475 - val_accuracy: 0.8540\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0191 - accuracy: 0.9965 - val_loss: 0.8612 - val_accuracy: 0.8700\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 88.20000290870667\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "\n",
      "-------------------------------------------\n",
      "Training 2: relu activation, 2 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 15s 98ms/step - loss: 1.5191 - accuracy: 0.3592 - val_loss: 0.6674 - val_accuracy: 0.7700\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.5972 - accuracy: 0.7956 - val_loss: 0.4412 - val_accuracy: 0.8680\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2754 - accuracy: 0.9134 - val_loss: 0.5438 - val_accuracy: 0.8380\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1619 - accuracy: 0.9497 - val_loss: 0.5266 - val_accuracy: 0.8680\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0962 - accuracy: 0.9700 - val_loss: 0.6383 - val_accuracy: 0.8600\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0612 - accuracy: 0.9833 - val_loss: 0.6902 - val_accuracy: 0.8720\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0782 - accuracy: 0.9827 - val_loss: 0.7112 - val_accuracy: 0.8700\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0704 - accuracy: 0.9818 - val_loss: 1.0214 - val_accuracy: 0.8240\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0919 - accuracy: 0.9786 - val_loss: 0.7743 - val_accuracy: 0.8680\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.7885 - val_accuracy: 0.8680\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.7305 - val_accuracy: 0.8720\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.6378 - val_accuracy: 0.8740\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0322 - accuracy: 0.9911 - val_loss: 0.8051 - val_accuracy: 0.8600\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0332 - accuracy: 0.9937 - val_loss: 0.7549 - val_accuracy: 0.8740\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.8510 - val_accuracy: 0.8860\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 0.7560 - val_accuracy: 0.8740\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0212 - accuracy: 0.9955 - val_loss: 0.7273 - val_accuracy: 0.8780\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.7476 - val_accuracy: 0.8460\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.7515 - val_accuracy: 0.8820\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.7394 - val_accuracy: 0.8540\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.7298 - val_accuracy: 0.8720\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.9161 - val_accuracy: 0.8520\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0186 - accuracy: 0.9967 - val_loss: 1.0669 - val_accuracy: 0.8680\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.9762 - val_accuracy: 0.8780\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.9517 - val_accuracy: 0.8880\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 1.0137 - val_accuracy: 0.8840\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 1.0557 - val_accuracy: 0.8840\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.1287 - val_accuracy: 0.8860\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.1974 - val_accuracy: 0.8800\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.9813 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.7349 - val_accuracy: 0.8780\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0331 - accuracy: 0.9947 - val_loss: 1.2165 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0203 - accuracy: 0.9953 - val_loss: 1.2049 - val_accuracy: 0.8440\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 0.7187 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0298 - accuracy: 0.9931 - val_loss: 0.8013 - val_accuracy: 0.8680\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 1.0092 - val_accuracy: 0.8420\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 1.4035 - val_accuracy: 0.8680\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 1.0928 - val_accuracy: 0.8700\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.1471 - val_accuracy: 0.8780\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.2717 - val_accuracy: 0.8760\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 1.3219 - val_accuracy: 0.8780\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 1.3479 - val_accuracy: 0.8800\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 1.3626 - val_accuracy: 0.8680\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.3388 - val_accuracy: 0.8740\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 9.9021e-04 - accuracy: 0.9998 - val_loss: 1.4603 - val_accuracy: 0.8680\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "Test Accuracy: 88.80000114440918\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "\n",
      "-------------------------------------------\n",
      "Training 3: relu activation, 3 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 15s 100ms/step - loss: 1.5584 - accuracy: 0.3216 - val_loss: 0.7291 - val_accuracy: 0.7660\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.6804 - accuracy: 0.7592 - val_loss: 0.4316 - val_accuracy: 0.8660\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.3406 - accuracy: 0.9020 - val_loss: 0.3643 - val_accuracy: 0.8860\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1595 - accuracy: 0.9517 - val_loss: 0.4170 - val_accuracy: 0.8940\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1091 - accuracy: 0.9634 - val_loss: 0.4246 - val_accuracy: 0.8940\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0908 - accuracy: 0.9708 - val_loss: 0.4363 - val_accuracy: 0.8860\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0537 - accuracy: 0.9820 - val_loss: 0.7193 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.5267 - val_accuracy: 0.8900\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0664 - accuracy: 0.9866 - val_loss: 0.5239 - val_accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0173 - accuracy: 0.9955 - val_loss: 0.5980 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.7098 - val_accuracy: 0.8660\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.8574 - val_accuracy: 0.8760\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.7688 - val_accuracy: 0.8820\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.7742 - val_accuracy: 0.8900\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0186 - accuracy: 0.9965 - val_loss: 0.5375 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.7872 - val_accuracy: 0.8480\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1326 - accuracy: 0.9729 - val_loss: 0.6477 - val_accuracy: 0.8840\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.6820 - val_accuracy: 0.8980\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.5316 - val_accuracy: 0.8960\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.6586 - val_accuracy: 0.8860\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.6010 - val_accuracy: 0.8780\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.8107 - val_accuracy: 0.8700\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.5918 - val_accuracy: 0.8940\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 0.6290 - val_accuracy: 0.8760\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.7436 - val_accuracy: 0.8940\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.7148 - val_accuracy: 0.8700\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.6312 - val_accuracy: 0.8860\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.6175 - val_accuracy: 0.8860\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.8619 - val_accuracy: 0.8840\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.8843 - val_accuracy: 0.8840\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.8335 - val_accuracy: 0.8820\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.8269 - val_accuracy: 0.8860\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.9818 - val_accuracy: 0.8860\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 1.1059 - val_accuracy: 0.8840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0196 - accuracy: 0.9959 - val_loss: 0.6489 - val_accuracy: 0.8680\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "Test Accuracy: 89.99999761581421\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "\n",
      "-------------------------------------------\n",
      "Training 4: relu activation, 4 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 15s 98ms/step - loss: 1.6547 - accuracy: 0.2595 - val_loss: 1.1950 - val_accuracy: 0.4580\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 1.0219 - accuracy: 0.5726 - val_loss: 0.5496 - val_accuracy: 0.8540\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.4838 - accuracy: 0.8317 - val_loss: 0.5225 - val_accuracy: 0.8520\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.2770 - accuracy: 0.9057 - val_loss: 0.5601 - val_accuracy: 0.8320\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1825 - accuracy: 0.9279 - val_loss: 0.5994 - val_accuracy: 0.8400\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1595 - accuracy: 0.9448 - val_loss: 0.6006 - val_accuracy: 0.8580curacy: 0.\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1334 - accuracy: 0.9648 - val_loss: 0.6903 - val_accuracy: 0.8620\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1158 - accuracy: 0.9738 - val_loss: 0.7426 - val_accuracy: 0.8740\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0827 - accuracy: 0.9792 - val_loss: 0.6325 - val_accuracy: 0.8680\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0759 - accuracy: 0.9857 - val_loss: 0.7566 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0669 - accuracy: 0.9870 - val_loss: 0.8413 - val_accuracy: 0.8840\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0668 - accuracy: 0.9871 - val_loss: 0.5743 - val_accuracy: 0.8940\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0668 - accuracy: 0.9844 - val_loss: 0.7054 - val_accuracy: 0.8780\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0639 - accuracy: 0.9859 - val_loss: 0.8414 - val_accuracy: 0.8800\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0705 - accuracy: 0.9884 - val_loss: 0.8902 - val_accuracy: 0.8780\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0643 - accuracy: 0.9897 - val_loss: 0.8173 - val_accuracy: 0.8720\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0422 - accuracy: 0.9930 - val_loss: 0.6346 - val_accuracy: 0.8940\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0410 - accuracy: 0.9933 - val_loss: 0.6021 - val_accuracy: 0.8840\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0641 - accuracy: 0.9882 - val_loss: 0.8654 - val_accuracy: 0.8560\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.0536 - accuracy: 0.9896 - val_loss: 0.7728 - val_accuracy: 0.8680\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0364 - accuracy: 0.9946 - val_loss: 1.0141 - val_accuracy: 0.8860\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 16s 141ms/step - loss: 0.0310 - accuracy: 0.9938 - val_loss: 0.9193 - val_accuracy: 0.8680\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0435 - accuracy: 0.9918 - val_loss: 1.0900 - val_accuracy: 0.8680\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.0558 - accuracy: 0.9890 - val_loss: 0.8680 - val_accuracy: 0.8680\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0327 - accuracy: 0.9923 - val_loss: 1.0897 - val_accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0275 - accuracy: 0.9932 - val_loss: 1.1951 - val_accuracy: 0.8560\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0474 - accuracy: 0.9903 - val_loss: 0.6585 - val_accuracy: 0.8540\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0408 - accuracy: 0.9924 - val_loss: 1.0202 - val_accuracy: 0.8740\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 0.0376 - accuracy: 0.9941 - val_loss: 1.1162 - val_accuracy: 0.8780\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0275 - accuracy: 0.9955 - val_loss: 0.9110 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.0183 - accuracy: 0.9981 - val_loss: 1.3515 - val_accuracy: 0.8520\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1150 - accuracy: 0.9834 - val_loss: 0.8477 - val_accuracy: 0.8600\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "Test Accuracy: 89.3999993801117\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "3       relu       4  0.894\n",
      "\n",
      "-------------------------------------------\n",
      "Training 5: relu activation, 5 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 16s 100ms/step - loss: 1.6806 - accuracy: 0.2735 - val_loss: 0.9741 - val_accuracy: 0.5800\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.9977 - accuracy: 0.5757 - val_loss: 0.6461 - val_accuracy: 0.7900\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.5211 - accuracy: 0.8158 - val_loss: 0.5609 - val_accuracy: 0.8140\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2790 - accuracy: 0.9012 - val_loss: 0.4674 - val_accuracy: 0.8580\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1294 - accuracy: 0.9608 - val_loss: 0.5910 - val_accuracy: 0.8660\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0603 - accuracy: 0.9769 - val_loss: 0.6626 - val_accuracy: 0.8420\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0803 - accuracy: 0.9738 - val_loss: 0.6017 - val_accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.9024 - val_accuracy: 0.8420\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0287 - accuracy: 0.9926 - val_loss: 0.7803 - val_accuracy: 0.8560\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 0.6623 - val_accuracy: 0.8580\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0474 - accuracy: 0.9883 - val_loss: 0.6672 - val_accuracy: 0.8640\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0513 - accuracy: 0.9890 - val_loss: 0.8303 - val_accuracy: 0.8480\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 1.1380 - val_accuracy: 0.8520\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0643 - accuracy: 0.9839 - val_loss: 0.7114 - val_accuracy: 0.8740\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.5977 - val_accuracy: 0.8800\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0354 - accuracy: 0.9948 - val_loss: 0.7267 - val_accuracy: 0.8840\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.8820 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0202 - accuracy: 0.9955 - val_loss: 0.7004 - val_accuracy: 0.8820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.9825 - val_accuracy: 0.8800\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.2073 - val_accuracy: 0.8880\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 1.0428 - val_accuracy: 0.8640\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 0.8475 - val_accuracy: 0.8620\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0523 - accuracy: 0.9888 - val_loss: 0.8480 - val_accuracy: 0.8720\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 0.9073 - val_accuracy: 0.8760\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 1.1943 - val_accuracy: 0.8860\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 1.3679 - val_accuracy: 0.8880\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.4475 - val_accuracy: 0.8900\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 1.0011 - val_accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0576 - accuracy: 0.9860 - val_loss: 0.9286 - val_accuracy: 0.8660\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 0.0188 - accuracy: 0.9971 - val_loss: 1.0344 - val_accuracy: 0.8680\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 1.5171 - val_accuracy: 0.8480\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0472 - accuracy: 0.9883 - val_loss: 0.9935 - val_accuracy: 0.8680\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 1.0441 - val_accuracy: 0.8680\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 1.2268 - val_accuracy: 0.8760\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 1.2424 - val_accuracy: 0.8720\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3503 - val_accuracy: 0.8780\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 1.3819 - val_accuracy: 0.8780\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 1.3649 - val_accuracy: 0.8800\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.5271 - val_accuracy: 0.8660\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.5302 - val_accuracy: 0.8780\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.6124 - val_accuracy: 0.8700\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 1.3589 - val_accuracy: 0.8700\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.9749 - val_accuracy: 0.8680\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0246 - accuracy: 0.9951 - val_loss: 1.3196 - val_accuracy: 0.8600\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 1.1164 - val_accuracy: 0.8660\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.4840 - val_accuracy: 0.8620\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.9487 - val_accuracy: 0.8720\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "Test Accuracy: 88.99999856948853\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "3       relu       4  0.894\n",
      "4       relu       5  0.890\n",
      "\n",
      "-------------------------------------------\n",
      "Training 6: relu activation, 6 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 20s 113ms/step - loss: 1.5811 - accuracy: 0.3208 - val_loss: 0.9471 - val_accuracy: 0.6620\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.9461 - accuracy: 0.6394 - val_loss: 0.6312 - val_accuracy: 0.8300\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.5936 - accuracy: 0.7843 - val_loss: 0.5586 - val_accuracy: 0.8620\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.4540 - accuracy: 0.8391 - val_loss: 0.5832 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.3254 - accuracy: 0.8658 - val_loss: 0.6097 - val_accuracy: 0.8780\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2469 - accuracy: 0.8907 - val_loss: 0.8270 - val_accuracy: 0.8580\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 0.1849 - accuracy: 0.9227 - val_loss: 0.8853 - val_accuracy: 0.8640\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 16s 141ms/step - loss: 0.1754 - accuracy: 0.9288 - val_loss: 0.9890 - val_accuracy: 0.8540\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.1467 - accuracy: 0.9402 - val_loss: 1.1089 - val_accuracy: 0.8400\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1313 - accuracy: 0.9464 - val_loss: 0.7927 - val_accuracy: 0.8680\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1040 - accuracy: 0.9553 - val_loss: 1.1917 - val_accuracy: 0.8780\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1009 - accuracy: 0.9585 - val_loss: 0.9004 - val_accuracy: 0.8620\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1209 - accuracy: 0.9550 - val_loss: 1.1390 - val_accuracy: 0.8580\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0824 - accuracy: 0.9673 - val_loss: 1.1350 - val_accuracy: 0.8860\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0736 - accuracy: 0.9803 - val_loss: 1.1307 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0734 - accuracy: 0.9828 - val_loss: 0.9313 - val_accuracy: 0.7540\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0833 - accuracy: 0.9820 - val_loss: 1.0334 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0936 - accuracy: 0.9751 - val_loss: 1.2507 - val_accuracy: 0.8080\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0925 - accuracy: 0.9774 - val_loss: 1.4391 - val_accuracy: 0.8500\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.0617 - accuracy: 0.9845 - val_loss: 1.5685 - val_accuracy: 0.8560\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.0671 - accuracy: 0.9815 - val_loss: 0.9987 - val_accuracy: 0.8520\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.0817 - accuracy: 0.9776 - val_loss: 1.4889 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 1.0965 - val_accuracy: 0.8720\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0608 - accuracy: 0.9832 - val_loss: 1.4888 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0625 - accuracy: 0.9786 - val_loss: 1.0736 - val_accuracy: 0.8760\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.0601 - accuracy: 0.9848 - val_loss: 1.7107 - val_accuracy: 0.8640\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 1.5590 - val_accuracy: 0.8140\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0584 - accuracy: 0.9815 - val_loss: 2.7029 - val_accuracy: 0.8520\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1011 - accuracy: 0.9802 - val_loss: 1.5800 - val_accuracy: 0.8420\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.0830 - accuracy: 0.9794 - val_loss: 0.9759 - val_accuracy: 0.8760\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0751 - accuracy: 0.9780 - val_loss: 1.1136 - val_accuracy: 0.8720\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0589 - accuracy: 0.9818 - val_loss: 1.2071 - val_accuracy: 0.8740\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0497 - accuracy: 0.9817 - val_loss: 1.2313 - val_accuracy: 0.8820\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 1.4625 - val_accuracy: 0.8740\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "Test Accuracy: 88.59999775886536\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "3       relu       4  0.894\n",
      "4       relu       5  0.890\n",
      "5       relu       6  0.886\n",
      "\n",
      "-------------------------------------------\n",
      "Training 7: tanh activation, 1 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 17s 105ms/step - loss: 1.3973 - accuracy: 0.4448 - val_loss: 0.7346 - val_accuracy: 0.8120\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.6329 - accuracy: 0.8150 - val_loss: 0.5262 - val_accuracy: 0.8540\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2838 - accuracy: 0.9176 - val_loss: 0.5636 - val_accuracy: 0.8480\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1396 - accuracy: 0.9594 - val_loss: 0.5539 - val_accuracy: 0.8520\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0900 - accuracy: 0.9743 - val_loss: 0.6536 - val_accuracy: 0.8660\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0519 - accuracy: 0.9895 - val_loss: 0.6014 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0397 - accuracy: 0.9932 - val_loss: 0.6806 - val_accuracy: 0.8680\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0449 - accuracy: 0.9884 - val_loss: 0.9145 - val_accuracy: 0.8380\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 1.2447 - val_accuracy: 0.8060\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 0.8006 - val_accuracy: 0.8480\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.7531 - val_accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 0.9834 - val_accuracy: 0.8340\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 0.0299 - accuracy: 0.9919 - val_loss: 0.8306 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.6865 - val_accuracy: 0.8600\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.8560 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.9047 - val_accuracy: 0.8660\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.9401 - val_accuracy: 0.8660\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 1.0758 - val_accuracy: 0.8580\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 1.0504 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 1.0737 - val_accuracy: 0.8660\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 1.1045 - val_accuracy: 0.8660\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 1.0719 - val_accuracy: 0.8720\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 1.0447 - val_accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 1.0745 - val_accuracy: 0.8720\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 1.0502 - val_accuracy: 0.8180\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 0.9649 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0679 - accuracy: 0.9799 - val_loss: 0.8158 - val_accuracy: 0.8480\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0292 - accuracy: 0.9930 - val_loss: 0.8504 - val_accuracy: 0.8440\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0343 - accuracy: 0.9918 - val_loss: 0.9051 - val_accuracy: 0.8440\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0732 - accuracy: 0.9816 - val_loss: 0.9591 - val_accuracy: 0.8460\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 1.0265 - val_accuracy: 0.8600\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.9635 - val_accuracy: 0.8560\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 1.0171 - val_accuracy: 0.8600\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 1.0545 - val_accuracy: 0.8620\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1010 - val_accuracy: 0.8620\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 1.1155 - val_accuracy: 0.8620\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 1.1321 - val_accuracy: 0.8580\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.1400 - val_accuracy: 0.8580\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 1.1738 - val_accuracy: 0.8620\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.2474 - val_accuracy: 0.8500\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 1.2307 - val_accuracy: 0.8560\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 1.2296 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 12s 104ms/step - loss: 9.8509e-04 - accuracy: 0.9999 - val_loss: 1.2507 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00043: early stopping\n",
      "Test Accuracy: 87.99999952316284\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "3       relu       4  0.894\n",
      "4       relu       5  0.890\n",
      "5       relu       6  0.886\n",
      "6       tanh       1  0.880\n",
      "\n",
      "-------------------------------------------\n",
      "Training 8: tanh activation, 2 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 21s 146ms/step - loss: 1.3329 - accuracy: 0.4709 - val_loss: 0.5913 - val_accuracy: 0.8260\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.5408 - accuracy: 0.8256 - val_loss: 0.4436 - val_accuracy: 0.8460\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.2262 - accuracy: 0.9379 - val_loss: 0.4302 - val_accuracy: 0.8380\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.1353 - accuracy: 0.9633 - val_loss: 0.4314 - val_accuracy: 0.8820\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 15s 139ms/step - loss: 0.0696 - accuracy: 0.9856 - val_loss: 0.4791 - val_accuracy: 0.8760\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.0442 - accuracy: 0.9894 - val_loss: 0.6235 - val_accuracy: 0.8560\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.0450 - accuracy: 0.9880 - val_loss: 0.5288 - val_accuracy: 0.8380\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0312 - accuracy: 0.9931 - val_loss: 0.6155 - val_accuracy: 0.8660\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.7639 - val_accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0381 - accuracy: 0.9899 - val_loss: 0.6269 - val_accuracy: 0.8740\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0404 - accuracy: 0.9907 - val_loss: 0.6127 - val_accuracy: 0.8720\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.7194 - val_accuracy: 0.8420\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0170 - accuracy: 0.9970 - val_loss: 0.7399 - val_accuracy: 0.8860\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.7515 - val_accuracy: 0.8540\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0155 - accuracy: 0.9968 - val_loss: 0.8165 - val_accuracy: 0.8780\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.7552 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.6594 - val_accuracy: 0.8780\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.6410 - val_accuracy: 0.8800\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0268 - accuracy: 0.9947 - val_loss: 0.6639 - val_accuracy: 0.8640\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0261 - accuracy: 0.9941 - val_loss: 0.7568 - val_accuracy: 0.7700\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.7553 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.6881 - val_accuracy: 0.8720\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.8148 - val_accuracy: 0.8880\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.8195 - val_accuracy: 0.8840\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.9266 - val_accuracy: 0.8900\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.8037 - val_accuracy: 0.8920\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.9007 - val_accuracy: 0.8840\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.9298 - val_accuracy: 0.8840\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.9401 - val_accuracy: 0.8880\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.9939 - val_accuracy: 0.8760\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0824 - val_accuracy: 0.8780\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.0704 - val_accuracy: 0.8840\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.8840\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.0856 - val_accuracy: 0.8760\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 1.1117 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1404 - val_accuracy: 0.8800\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.1284 - val_accuracy: 0.8740\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 1.1678 - val_accuracy: 0.8860\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 1.1753 - val_accuracy: 0.8820\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.2044 - val_accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.3098 - val_accuracy: 0.8760\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0460 - accuracy: 0.9860 - val_loss: 0.9577 - val_accuracy: 0.8440\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0785 - accuracy: 0.9775 - val_loss: 0.7347 - val_accuracy: 0.8560\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0807 - accuracy: 0.9770 - val_loss: 0.6860 - val_accuracy: 0.8560\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.7031 - val_accuracy: 0.8680\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.7446 - val_accuracy: 0.8740\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "Test Accuracy: 89.20000195503235\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "3       relu       4  0.894\n",
      "4       relu       5  0.890\n",
      "5       relu       6  0.886\n",
      "6       tanh       1  0.880\n",
      "7       tanh       2  0.892\n",
      "\n",
      "-------------------------------------------\n",
      "Training 9: tanh activation, 3 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 15s 99ms/step - loss: 1.4971 - accuracy: 0.3790 - val_loss: 0.8876 - val_accuracy: 0.6620\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.7636 - accuracy: 0.6940 - val_loss: 0.8512 - val_accuracy: 0.6560\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.4275 - accuracy: 0.8762 - val_loss: 0.5114 - val_accuracy: 0.8560\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1918 - accuracy: 0.9543 - val_loss: 0.7074 - val_accuracy: 0.8220\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0885 - accuracy: 0.9749 - val_loss: 0.5315 - val_accuracy: 0.8760\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0931 - accuracy: 0.9755 - val_loss: 0.7374 - val_accuracy: 0.8540\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0571 - accuracy: 0.9879 - val_loss: 0.7664 - val_accuracy: 0.8440\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0455 - accuracy: 0.9877 - val_loss: 0.7312 - val_accuracy: 0.8660\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.8911 - val_accuracy: 0.8560\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0403 - accuracy: 0.9885 - val_loss: 0.9226 - val_accuracy: 0.8340\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0540 - accuracy: 0.9838 - val_loss: 1.0076 - val_accuracy: 0.8300\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 1.5082 - val_accuracy: 0.6980\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0721 - accuracy: 0.9818 - val_loss: 0.8099 - val_accuracy: 0.8520\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0188 - accuracy: 0.9964 - val_loss: 0.8229 - val_accuracy: 0.8760\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 0.8272 - val_accuracy: 0.8800\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.8397 - val_accuracy: 0.8520\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0181 - accuracy: 0.9968 - val_loss: 0.8880 - val_accuracy: 0.8760\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.8629 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 1.0573 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 1.0549 - val_accuracy: 0.8360\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0457 - accuracy: 0.9900 - val_loss: 1.0035 - val_accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 1.1747 - val_accuracy: 0.8340\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 1.0400 - val_accuracy: 0.8520\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 1.3147 - val_accuracy: 0.8500\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0314 - accuracy: 0.9927 - val_loss: 1.0902 - val_accuracy: 0.8420\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0271 - accuracy: 0.9930 - val_loss: 0.9983 - val_accuracy: 0.8380\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 1.0864 - val_accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 1.1699 - val_accuracy: 0.8220\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 1.0861 - val_accuracy: 0.8560\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.8586 - val_accuracy: 0.8720\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 1.2258 - val_accuracy: 0.8440\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 1.2213 - val_accuracy: 0.8640\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 1.1431 - val_accuracy: 0.8660\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 1.1713 - val_accuracy: 0.8700\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.2553 - val_accuracy: 0.8680\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "Test Accuracy: 87.99999952316284\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "3       relu       4  0.894\n",
      "4       relu       5  0.890\n",
      "5       relu       6  0.886\n",
      "6       tanh       1  0.880\n",
      "7       tanh       2  0.892\n",
      "8       tanh       3  0.880\n",
      "\n",
      "-------------------------------------------\n",
      "Training 10: tanh activation, 4 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 15s 98ms/step - loss: 1.5861 - accuracy: 0.3518 - val_loss: 0.8555 - val_accuracy: 0.7740\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.6967 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.8500\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.3110 - accuracy: 0.9071 - val_loss: 0.4785 - val_accuracy: 0.8600\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1591 - accuracy: 0.9642 - val_loss: 0.3705 - val_accuracy: 0.8980\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0906 - accuracy: 0.9793 - val_loss: 0.4782 - val_accuracy: 0.8820\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0612 - accuracy: 0.9863 - val_loss: 0.4778 - val_accuracy: 0.8760\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0448 - accuracy: 0.9923 - val_loss: 0.5673 - val_accuracy: 0.8800\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0435 - accuracy: 0.9907 - val_loss: 0.6228 - val_accuracy: 0.8680\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0411 - accuracy: 0.9891 - val_loss: 0.7273 - val_accuracy: 0.8460\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0725 - accuracy: 0.9795 - val_loss: 0.6861 - val_accuracy: 0.8640\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.6272 - val_accuracy: 0.8840\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.8053 - val_accuracy: 0.8480\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0363 - accuracy: 0.9892 - val_loss: 0.7427 - val_accuracy: 0.8720\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.9041 - val_accuracy: 0.8300\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.7284 - val_accuracy: 0.8780\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.8301 - val_accuracy: 0.8660\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.8434 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.9804 - val_accuracy: 0.8660\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.8809 - val_accuracy: 0.8760\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0313 - accuracy: 0.9916 - val_loss: 0.6857 - val_accuracy: 0.8700\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0323 - accuracy: 0.9930 - val_loss: 0.9627 - val_accuracy: 0.8380\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0348 - accuracy: 0.9914 - val_loss: 0.7701 - val_accuracy: 0.8720\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.8848 - val_accuracy: 0.8720\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 1.0880 - val_accuracy: 0.8420\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 89.80000019073486\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.882\n",
      "1       relu       2  0.888\n",
      "2       relu       3  0.900\n",
      "3       relu       4  0.894\n",
      "4       relu       5  0.890\n",
      "5       relu       6  0.886\n",
      "6       tanh       1  0.880\n",
      "7       tanh       2  0.892\n",
      "8       tanh       3  0.880\n",
      "9       tanh       4  0.898\n",
      "\n",
      "-------------------------------------------\n",
      "Training 11: tanh activation, 5 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 15s 99ms/step - loss: 1.4191 - accuracy: 0.4455 - val_loss: 0.7191 - val_accuracy: 0.7980\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.6316 - accuracy: 0.8110 - val_loss: 0.6655 - val_accuracy: 0.8060\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.3483 - accuracy: 0.9005 - val_loss: 0.6484 - val_accuracy: 0.8080\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.2104 - accuracy: 0.9390 - val_loss: 0.7483 - val_accuracy: 0.8020\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1769 - accuracy: 0.9542 - val_loss: 0.7753 - val_accuracy: 0.8080\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1243 - accuracy: 0.9696 - val_loss: 0.7563 - val_accuracy: 0.8060\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0893 - accuracy: 0.9765 - val_loss: 0.7825 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0727 - accuracy: 0.9796 - val_loss: 0.8669 - val_accuracy: 0.8380\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0659 - accuracy: 0.9812 - val_loss: 0.9123 - val_accuracy: 0.8420\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0456 - accuracy: 0.9873 - val_loss: 1.0175 - val_accuracy: 0.8280\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0471 - accuracy: 0.9885 - val_loss: 1.0616 - val_accuracy: 0.8480\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0445 - accuracy: 0.9891 - val_loss: 0.9218 - val_accuracy: 0.8640\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0442 - accuracy: 0.9904 - val_loss: 1.1630 - val_accuracy: 0.8320\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 1.2842 - val_accuracy: 0.8220\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0695 - accuracy: 0.9838 - val_loss: 1.1302 - val_accuracy: 0.8200\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0245 - accuracy: 0.9940 - val_loss: 1.1855 - val_accuracy: 0.8540\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0242 - accuracy: 0.9935 - val_loss: 1.1951 - val_accuracy: 0.8140\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0447 - accuracy: 0.9907 - val_loss: 1.0798 - val_accuracy: 0.7620\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0622 - accuracy: 0.9834 - val_loss: 1.0477 - val_accuracy: 0.8300\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0301 - accuracy: 0.9914 - val_loss: 1.0767 - val_accuracy: 0.8500\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0258 - accuracy: 0.9959 - val_loss: 1.1358 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 1.1564 - val_accuracy: 0.8460\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 1.1679 - val_accuracy: 0.8520\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 1.2747 - val_accuracy: 0.8420\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 1.3280 - val_accuracy: 0.7620\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.3152 - val_accuracy: 0.8360\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 1.6134 - val_accuracy: 0.8080\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.9899 - val_accuracy: 0.8380\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 1.1327 - val_accuracy: 0.8420\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0303 - accuracy: 0.9939 - val_loss: 1.2167 - val_accuracy: 0.8280\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0216 - accuracy: 0.9953 - val_loss: 1.1273 - val_accuracy: 0.8440\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.1499 - val_accuracy: 0.8400\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "Test Accuracy: 86.40000224113464\n",
      "Done!\n",
      "\n",
      "   Activation Filters    Acc\n",
      "0        relu       1  0.882\n",
      "1        relu       2  0.888\n",
      "2        relu       3  0.900\n",
      "3        relu       4  0.894\n",
      "4        relu       5  0.890\n",
      "5        relu       6  0.886\n",
      "6        tanh       1  0.880\n",
      "7        tanh       2  0.892\n",
      "8        tanh       3  0.880\n",
      "9        tanh       4  0.898\n",
      "10       tanh       5  0.864\n",
      "\n",
      "-------------------------------------------\n",
      "Training 12: tanh activation, 6 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 15s 97ms/step - loss: 1.3923 - accuracy: 0.4416 - val_loss: 0.7676 - val_accuracy: 0.7160\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.5811 - accuracy: 0.8192 - val_loss: 0.5788 - val_accuracy: 0.8320\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.3228 - accuracy: 0.9033 - val_loss: 0.5051 - val_accuracy: 0.8400\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1561 - accuracy: 0.9549 - val_loss: 0.5172 - val_accuracy: 0.8440\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1284 - accuracy: 0.9621 - val_loss: 0.5555 - val_accuracy: 0.8520\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: 0.6333 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0759 - accuracy: 0.9799 - val_loss: 0.7027 - val_accuracy: 0.8220\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0644 - accuracy: 0.9839 - val_loss: 0.6830 - val_accuracy: 0.8420\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.7342 - val_accuracy: 0.8280\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0434 - accuracy: 0.9868 - val_loss: 1.0161 - val_accuracy: 0.7200\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.7952 - val_accuracy: 0.8320\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.8372 - val_accuracy: 0.8300\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0673 - accuracy: 0.9802 - val_loss: 0.8786 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.8340 - val_accuracy: 0.8660\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 1.0325 - val_accuracy: 0.8220\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.8398 - val_accuracy: 0.8580\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.9733 - val_accuracy: 0.8380\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 1.0710 - val_accuracy: 0.8300\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 1.1054 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 1.2212 - val_accuracy: 0.8360\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.9842 - val_accuracy: 0.8520\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.9603 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.9823 - val_accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.8479 - val_accuracy: 0.8580\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.8907 - val_accuracy: 0.8660\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 1.3456 - val_accuracy: 0.8260\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0304 - accuracy: 0.9916 - val_loss: 1.0215 - val_accuracy: 0.8420\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 1.0274 - val_accuracy: 0.8540\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.1166 - val_accuracy: 0.8460\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 1.1336 - val_accuracy: 0.8460\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 1.2004 - val_accuracy: 0.8440\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 1.3042 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3004 - val_accuracy: 0.8440\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 1.2883 - val_accuracy: 0.8320\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "Test Accuracy: 86.59999966621399\n",
      "Done!\n",
      "\n",
      "   Activation Filters    Acc\n",
      "0        relu       1  0.882\n",
      "1        relu       2  0.888\n",
      "2        relu       3  0.900\n",
      "3        relu       4  0.894\n",
      "4        relu       5  0.890\n",
      "5        relu       6  0.886\n",
      "6        tanh       1  0.880\n",
      "7        tanh       2  0.892\n",
      "8        tanh       3  0.880\n",
      "9        tanh       4  0.898\n",
      "10       tanh       5  0.864\n",
      "11       tanh       6  0.866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu', 'tanh']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'Acc']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "exp = 0\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "        \n",
    "        exp+=1\n",
    "        print('-------------------------------------------')\n",
    "        print('Training {}: {} activation, {} kernel size.'.format(exp, activation, kernel_size))\n",
    "        print('-------------------------------------------')\n",
    "        \n",
    "        # encode data using\n",
    "        # Cleaning and Tokenization\n",
    "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "        # Turn the text into sequence\n",
    "        training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "        test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "        max_len = max_length(training_sequences)\n",
    "\n",
    "        # Pad the sequence to have the same size\n",
    "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        vocab_size = len(word_index)+1\n",
    "\n",
    "        # Define the input shape\n",
    "        model = define_model(kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "        # Train the model and initialize test accuracy with 0\n",
    "        acc = 0\n",
    "        while(acc<0.7):\n",
    "\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=100, verbose=1, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            if (acc<0.6):\n",
    "                print('The model suffered from local minimum. Retrain the model!')\n",
    "                model = define_model(kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "            else:\n",
    "                print('Done!')\n",
    "\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + [acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record = record.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh</td>\n",
       "      <td>5</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activation Filters    Acc\n",
       "2        relu       3  0.900\n",
       "9        tanh       4  0.898\n",
       "3        relu       4  0.894\n",
       "7        tanh       2  0.892\n",
       "4        relu       5  0.890\n",
       "1        relu       2  0.888\n",
       "5        relu       6  0.886\n",
       "0        relu       1  0.882\n",
       "6        tanh       1  0.880\n",
       "8        tanh       3  0.880\n",
       "11       tanh       6  0.866\n",
       "10       tanh       5  0.864"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.sort_values(by='Acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record.sort_values(by='Acc', ascending=False)\n",
    "report = report.to_excel('TCN_TREC.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7526 words present from 8761 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mean = word2vec.vectors.mean()\n",
    "emb_std = word2vec.vectors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index, emb_mean, emb_std):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    np.random.seed(2021)\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    # initialize the matrix with generic normal distribution values\n",
    "    embed_matrix = np.random.normal(emb_mean, emb_std, (vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.get_vector(word)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19468211,  0.08648376, -0.05924511, ..., -0.16683994,\n",
       "        -0.09975549, -0.08595189],\n",
       "       [-0.13509196, -0.07441947,  0.15388953, ..., -0.05400787,\n",
       "        -0.13156594, -0.05996158],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i, emb_mean, emb_std)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2(kernel_size = 3, activation='relu', input_dim = None, \n",
    "                   output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    inp = Input( shape=(max_length,))\n",
    "    x = Embedding(input_dim=input_dim, \n",
    "                  output_dim=output_dim, \n",
    "                  input_length=max_length,\n",
    "                  # Assign the embedding weight with word2vec embedding marix\n",
    "                  weights = [emb_matrix],\n",
    "                  # Set the weight to be not trainable (static)\n",
    "                  trainable = False)(inp)\n",
    "    \n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn1')(x)\n",
    "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn2')(x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    conc = Dense(16, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(6, activation=\"softmax\")(conc)    \n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 100, 300)     300000      input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 100, 300)     0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn1 (TCN)                      (None, 100, 128)     279936      spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tcn2 (TCN)                      (None, 100, 64)      65984       tcn1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 64)           0           tcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 64)           0           tcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 128)          0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 16)           2064        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16)           0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 6)            102         dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 648,086\n",
      "Trainable params: 348,086\n",
      "Non-trainable params: 300,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#     # Overide the method on_epoch_end() for our benefit\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         if (logs.get('accuracy') >= 0.9):\n",
    "#             print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "#             self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=20, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Training 1: relu activation, 1 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 8s 51ms/step - loss: 1.6586 - accuracy: 0.2539 - val_loss: 1.1601 - val_accuracy: 0.5320\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 1.0465 - accuracy: 0.5740 - val_loss: 0.7761 - val_accuracy: 0.7300\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.7100 - accuracy: 0.7412 - val_loss: 0.6517 - val_accuracy: 0.8280\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5298 - accuracy: 0.8058 - val_loss: 0.4062 - val_accuracy: 0.8560\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.3496 - accuracy: 0.8829 - val_loss: 0.3442 - val_accuracy: 0.8820\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2555 - accuracy: 0.9135 - val_loss: 0.4897 - val_accuracy: 0.8440\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.3203 - accuracy: 0.8888 - val_loss: 0.3376 - val_accuracy: 0.8940\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.1902 - accuracy: 0.9335 - val_loss: 0.3990 - val_accuracy: 0.8920\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.1398 - accuracy: 0.9542 - val_loss: 0.3339 - val_accuracy: 0.9100\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.1282 - accuracy: 0.9558 - val_loss: 0.4657 - val_accuracy: 0.8580\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.1166 - accuracy: 0.9627 - val_loss: 0.3652 - val_accuracy: 0.8960\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.1231 - accuracy: 0.9570 - val_loss: 0.4489 - val_accuracy: 0.8860\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1003 - accuracy: 0.9682 - val_loss: 0.4257 - val_accuracy: 0.9040\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0820 - accuracy: 0.9761 - val_loss: 0.5239 - val_accuracy: 0.8820\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0968 - accuracy: 0.9671 - val_loss: 0.4569 - val_accuracy: 0.8940\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0669 - accuracy: 0.9785 - val_loss: 0.4383 - val_accuracy: 0.9080\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0636 - accuracy: 0.9811 - val_loss: 0.4992 - val_accuracy: 0.7960\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1021 - accuracy: 0.9739 - val_loss: 0.4608 - val_accuracy: 0.8840\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0652 - accuracy: 0.9793 - val_loss: 0.5732 - val_accuracy: 0.8940\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.5148 - val_accuracy: 0.9020\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.5309 - val_accuracy: 0.9060\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.5638 - val_accuracy: 0.8940\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0473 - accuracy: 0.9867 - val_loss: 0.4729 - val_accuracy: 0.9180\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.5098 - val_accuracy: 0.8980\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0501 - accuracy: 0.9860 - val_loss: 0.5787 - val_accuracy: 0.8840\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0603 - accuracy: 0.9840 - val_loss: 0.5067 - val_accuracy: 0.9120\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0418 - accuracy: 0.9849 - val_loss: 0.4713 - val_accuracy: 0.9340\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0552 - accuracy: 0.9842 - val_loss: 0.3812 - val_accuracy: 0.9320\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 0.4757 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0362 - accuracy: 0.9899 - val_loss: 0.5092 - val_accuracy: 0.9160\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.5957 - val_accuracy: 0.9240\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0410 - accuracy: 0.9916 - val_loss: 0.3946 - val_accuracy: 0.9140\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0313 - accuracy: 0.9930 - val_loss: 0.3733 - val_accuracy: 0.9220\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0349 - accuracy: 0.9910 - val_loss: 0.4861 - val_accuracy: 0.9320\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.5066 - val_accuracy: 0.9180\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.5587 - val_accuracy: 0.9100\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0307 - accuracy: 0.9929 - val_loss: 0.6107 - val_accuracy: 0.9100\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.9091 - val_accuracy: 0.8220\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.5512 - val_accuracy: 0.8380\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0442 - accuracy: 0.9895 - val_loss: 0.4444 - val_accuracy: 0.9180\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0360 - accuracy: 0.9906 - val_loss: 0.4632 - val_accuracy: 0.9360\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 0.6614 - val_accuracy: 0.9160\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.8239 - val_accuracy: 0.7980\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.6767 - val_accuracy: 0.9140\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.7094 - val_accuracy: 0.9120\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.5325 - val_accuracy: 0.8900\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.5926 - val_accuracy: 0.8980\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.6531 - val_accuracy: 0.9060\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.5960 - val_accuracy: 0.9060\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0443 - accuracy: 0.9864 - val_loss: 0.6159 - val_accuracy: 0.9220\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.5719 - val_accuracy: 0.8980\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.1073 - accuracy: 0.9719 - val_loss: 0.4511 - val_accuracy: 0.8800\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0467 - accuracy: 0.9906 - val_loss: 0.4375 - val_accuracy: 0.9020\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0325 - accuracy: 0.9927 - val_loss: 0.5963 - val_accuracy: 0.9040\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.6056 - val_accuracy: 0.9080\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.6490 - val_accuracy: 0.8920\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0297 - accuracy: 0.9938 - val_loss: 0.6143 - val_accuracy: 0.9140\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.6116 - val_accuracy: 0.9080\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.7037 - val_accuracy: 0.9160\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.9179 - val_accuracy: 0.8880\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.6727 - val_accuracy: 0.8820\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "Test Accuracy: 93.59999895095825\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.936\n",
      "\n",
      "-------------------------------------------\n",
      "Training 2: relu activation, 2 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 13s 70ms/step - loss: 1.7684 - accuracy: 0.2311 - val_loss: 1.3843 - val_accuracy: 0.5020\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.1967 - accuracy: 0.5379 - val_loss: 0.8983 - val_accuracy: 0.7040\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.8603 - accuracy: 0.6753 - val_loss: 0.5464 - val_accuracy: 0.8840\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.7350 - accuracy: 0.7198 - val_loss: 0.4482 - val_accuracy: 0.8920\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.5684 - accuracy: 0.7766 - val_loss: 0.4407 - val_accuracy: 0.8660\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.4532 - accuracy: 0.8459 - val_loss: 0.4045 - val_accuracy: 0.8720\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.4481 - accuracy: 0.8399 - val_loss: 0.4592 - val_accuracy: 0.8640\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3166 - accuracy: 0.8823 - val_loss: 0.4890 - val_accuracy: 0.8900\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.2904 - accuracy: 0.8885 - val_loss: 0.4409 - val_accuracy: 0.8860\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.2505 - accuracy: 0.9038 - val_loss: 0.4442 - val_accuracy: 0.8740\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.2498 - accuracy: 0.9018 - val_loss: 0.5184 - val_accuracy: 0.8900\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.2676 - accuracy: 0.8961 - val_loss: 0.4536 - val_accuracy: 0.8920\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.1969 - accuracy: 0.9151 - val_loss: 0.5016 - val_accuracy: 0.8920\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1752 - accuracy: 0.9298 - val_loss: 0.5777 - val_accuracy: 0.8960\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1620 - accuracy: 0.9422 - val_loss: 0.4895 - val_accuracy: 0.8900\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1484 - accuracy: 0.9466 - val_loss: 0.5650 - val_accuracy: 0.8960\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1745 - accuracy: 0.9424 - val_loss: 0.7242 - val_accuracy: 0.8660\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1473 - accuracy: 0.9486 - val_loss: 0.5936 - val_accuracy: 0.8820\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1666 - accuracy: 0.9441 - val_loss: 0.6175 - val_accuracy: 0.8720\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.1249 - accuracy: 0.9553 - val_loss: 0.6337 - val_accuracy: 0.8700\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1084 - accuracy: 0.9647 - val_loss: 0.7278 - val_accuracy: 0.7660\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1523 - accuracy: 0.9505 - val_loss: 0.5289 - val_accuracy: 0.9020\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1685 - accuracy: 0.9486 - val_loss: 0.5689 - val_accuracy: 0.8840\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.1140 - accuracy: 0.9622 - val_loss: 0.8254 - val_accuracy: 0.8840\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1140 - accuracy: 0.9605 - val_loss: 0.8455 - val_accuracy: 0.8480\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0951 - accuracy: 0.9705 - val_loss: 0.7275 - val_accuracy: 0.8860\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0993 - accuracy: 0.9676 - val_loss: 0.8493 - val_accuracy: 0.7760\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.1058 - accuracy: 0.9622 - val_loss: 0.9023 - val_accuracy: 0.7940\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1023 - accuracy: 0.9705 - val_loss: 0.6984 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0860 - accuracy: 0.9707 - val_loss: 0.8692 - val_accuracy: 0.9100\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1318 - accuracy: 0.9623 - val_loss: 0.6388 - val_accuracy: 0.9020\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.0950 - accuracy: 0.9723 - val_loss: 0.6727 - val_accuracy: 0.8840\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0911 - accuracy: 0.9679 - val_loss: 1.2889 - val_accuracy: 0.8760\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0908 - accuracy: 0.9696 - val_loss: 0.7295 - val_accuracy: 0.9040\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1091 - accuracy: 0.9685 - val_loss: 0.5925 - val_accuracy: 0.8960\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0991 - accuracy: 0.9696 - val_loss: 0.8026 - val_accuracy: 0.8940\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0920 - accuracy: 0.9659 - val_loss: 0.8758 - val_accuracy: 0.8640\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.0670 - accuracy: 0.9758 - val_loss: 1.1933 - val_accuracy: 0.7900\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0813 - accuracy: 0.9727 - val_loss: 0.8942 - val_accuracy: 0.8920\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.1167 - accuracy: 0.9685 - val_loss: 0.8856 - val_accuracy: 0.8940\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0885 - accuracy: 0.9772 - val_loss: 0.7944 - val_accuracy: 0.8960\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0583 - accuracy: 0.9809 - val_loss: 1.0959 - val_accuracy: 0.8940\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0562 - accuracy: 0.9777 - val_loss: 0.8180 - val_accuracy: 0.8760\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0678 - accuracy: 0.9784 - val_loss: 1.1281 - val_accuracy: 0.8660\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0599 - accuracy: 0.9765 - val_loss: 1.0672 - val_accuracy: 0.8980\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0574 - accuracy: 0.9796 - val_loss: 1.3843 - val_accuracy: 0.8560\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0622 - accuracy: 0.9760 - val_loss: 0.7013 - val_accuracy: 0.9080\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0490 - accuracy: 0.9842 - val_loss: 0.8495 - val_accuracy: 0.8220\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0615 - accuracy: 0.9788 - val_loss: 0.8444 - val_accuracy: 0.8240\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0767 - accuracy: 0.9752 - val_loss: 0.7402 - val_accuracy: 0.8820\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "Test Accuracy: 91.00000262260437\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.936\n",
      "1       relu       2  0.910\n",
      "\n",
      "-------------------------------------------\n",
      "Training 3: relu activation, 3 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 18s 66ms/step - loss: 1.7882 - accuracy: 0.2228 - val_loss: 1.4385 - val_accuracy: 0.4820\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 1.4610 - accuracy: 0.3582 - val_loss: 1.2057 - val_accuracy: 0.5220\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 1.1936 - accuracy: 0.4613 - val_loss: 1.0314 - val_accuracy: 0.6480\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.0230 - accuracy: 0.5493 - val_loss: 0.9234 - val_accuracy: 0.5460\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.8895 - accuracy: 0.6172 - val_loss: 0.8260 - val_accuracy: 0.6540\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6848 - accuracy: 0.7260 - val_loss: 0.5684 - val_accuracy: 0.8860\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.4920 - accuracy: 0.8143 - val_loss: 0.4428 - val_accuracy: 0.8840\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.4871 - accuracy: 0.8408 - val_loss: 0.5091 - val_accuracy: 0.8700\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3275 - accuracy: 0.8872 - val_loss: 0.4805 - val_accuracy: 0.8760\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.2538 - accuracy: 0.9165 - val_loss: 0.4318 - val_accuracy: 0.8840\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.2180 - accuracy: 0.9236 - val_loss: 0.4072 - val_accuracy: 0.8920\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.2250 - accuracy: 0.9276 - val_loss: 0.4641 - val_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1956 - accuracy: 0.9316 - val_loss: 0.3772 - val_accuracy: 0.8940\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1710 - accuracy: 0.9425 - val_loss: 0.5313 - val_accuracy: 0.8200\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1572 - accuracy: 0.9427 - val_loss: 0.4890 - val_accuracy: 0.8880\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1455 - accuracy: 0.9488 - val_loss: 0.5887 - val_accuracy: 0.8920\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1604 - accuracy: 0.9494 - val_loss: 0.5345 - val_accuracy: 0.8980\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.1078 - accuracy: 0.9608 - val_loss: 0.6402 - val_accuracy: 0.8940\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1062 - accuracy: 0.9641 - val_loss: 0.6174 - val_accuracy: 0.8360\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1046 - accuracy: 0.9651 - val_loss: 0.6201 - val_accuracy: 0.8860\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0977 - accuracy: 0.9636 - val_loss: 0.7629 - val_accuracy: 0.8920\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.0656 - accuracy: 0.9722 - val_loss: 0.7648 - val_accuracy: 0.9080\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0715 - accuracy: 0.9696 - val_loss: 0.6148 - val_accuracy: 0.8960\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.0792 - accuracy: 0.9669 - val_loss: 0.5066 - val_accuracy: 0.9060\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0711 - accuracy: 0.9760 - val_loss: 0.5330 - val_accuracy: 0.9120\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0816 - accuracy: 0.9695 - val_loss: 0.6907 - val_accuracy: 0.8920\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 9s 84ms/step - loss: 0.0659 - accuracy: 0.9744 - val_loss: 0.9178 - val_accuracy: 0.8900\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.0719 - accuracy: 0.9735 - val_loss: 0.6953 - val_accuracy: 0.9080\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 0.0620 - accuracy: 0.9754 - val_loss: 0.6555 - val_accuracy: 0.8940\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.0585 - accuracy: 0.9750 - val_loss: 0.8231 - val_accuracy: 0.8940\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.0400 - accuracy: 0.9826 - val_loss: 0.6075 - val_accuracy: 0.9040\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 9s 78ms/step - loss: 0.0380 - accuracy: 0.9846 - val_loss: 0.6129 - val_accuracy: 0.8360\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.0553 - accuracy: 0.9765 - val_loss: 0.7054 - val_accuracy: 0.9020\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0492 - accuracy: 0.9803 - val_loss: 0.8628 - val_accuracy: 0.8820\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0932 - accuracy: 0.9721 - val_loss: 0.5532 - val_accuracy: 0.8980\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0507 - accuracy: 0.9797 - val_loss: 0.6415 - val_accuracy: 0.9040\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.0454 - accuracy: 0.9827 - val_loss: 0.7328 - val_accuracy: 0.8860\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.0801 - accuracy: 0.9752 - val_loss: 0.6730 - val_accuracy: 0.9020\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0736 - accuracy: 0.9772 - val_loss: 0.8519 - val_accuracy: 0.8340\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0521 - accuracy: 0.9792 - val_loss: 0.6765 - val_accuracy: 0.9080\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0430 - accuracy: 0.9822 - val_loss: 0.8644 - val_accuracy: 0.8920\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0575 - accuracy: 0.9749 - val_loss: 0.6192 - val_accuracy: 0.9120\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0367 - accuracy: 0.9833 - val_loss: 0.6526 - val_accuracy: 0.9060\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0498 - accuracy: 0.9786 - val_loss: 0.6931 - val_accuracy: 0.9060\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.7456 - val_accuracy: 0.9120\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "Test Accuracy: 91.20000004768372\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.936\n",
      "1       relu       2  0.910\n",
      "2       relu       3  0.912\n",
      "\n",
      "-------------------------------------------\n",
      "Training 4: relu activation, 4 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 11s 67ms/step - loss: 1.6160 - accuracy: 0.3038 - val_loss: 0.7737 - val_accuracy: 0.7340\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.8118 - accuracy: 0.6887 - val_loss: 0.5565 - val_accuracy: 0.8280\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5316 - accuracy: 0.8082 - val_loss: 0.3781 - val_accuracy: 0.8720\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.4033 - accuracy: 0.8635 - val_loss: 0.3678 - val_accuracy: 0.8820\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.2998 - accuracy: 0.9032 - val_loss: 0.3806 - val_accuracy: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2674 - accuracy: 0.9113 - val_loss: 0.6068 - val_accuracy: 0.8060\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2851 - accuracy: 0.9007 - val_loss: 0.3536 - val_accuracy: 0.8900\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2393 - accuracy: 0.9139 - val_loss: 0.3946 - val_accuracy: 0.8960\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2003 - accuracy: 0.9306 - val_loss: 0.4479 - val_accuracy: 0.8700\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1575 - accuracy: 0.9452 - val_loss: 0.4717 - val_accuracy: 0.8940\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1561 - accuracy: 0.9423 - val_loss: 0.4414 - val_accuracy: 0.8900\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1084 - accuracy: 0.9629 - val_loss: 0.4624 - val_accuracy: 0.9100\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1353 - accuracy: 0.9631 - val_loss: 0.4543 - val_accuracy: 0.8900\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0850 - accuracy: 0.9727 - val_loss: 0.5295 - val_accuracy: 0.8880\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0887 - accuracy: 0.9699 - val_loss: 0.5320 - val_accuracy: 0.8800\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0906 - accuracy: 0.9716 - val_loss: 0.6047 - val_accuracy: 0.8940\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0664 - accuracy: 0.9781 - val_loss: 0.5702 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0666 - accuracy: 0.9795 - val_loss: 0.6375 - val_accuracy: 0.8960\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0578 - accuracy: 0.9817 - val_loss: 0.6263 - val_accuracy: 0.8860\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0649 - accuracy: 0.9776 - val_loss: 0.6706 - val_accuracy: 0.8160\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0698 - accuracy: 0.9782 - val_loss: 0.5063 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0705 - accuracy: 0.9774 - val_loss: 1.0927 - val_accuracy: 0.8320\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5738 - accuracy: 0.8299 - val_loss: 0.4792 - val_accuracy: 0.9040\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0993 - accuracy: 0.9789 - val_loss: 0.5760 - val_accuracy: 0.8940\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.5319 - val_accuracy: 0.8940\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.5823 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0574 - accuracy: 0.9787 - val_loss: 0.6382 - val_accuracy: 0.8980\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 0.5185 - val_accuracy: 0.8880\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.5773 - val_accuracy: 0.8960\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0417 - accuracy: 0.9887 - val_loss: 0.5258 - val_accuracy: 0.9180\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.5497 - val_accuracy: 0.8360\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 0.6199 - val_accuracy: 0.8280\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0780 - accuracy: 0.9806 - val_loss: 0.4653 - val_accuracy: 0.9020\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 0.5098 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0409 - accuracy: 0.9857 - val_loss: 0.6495 - val_accuracy: 0.8380\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.7525 - val_accuracy: 0.8980\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0330 - accuracy: 0.9930 - val_loss: 0.7205 - val_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 0.5782 - val_accuracy: 0.9120\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.7570 - val_accuracy: 0.8020\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.8671 - val_accuracy: 0.8060\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.7419 - val_accuracy: 0.8220\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.8112 - val_accuracy: 0.8980\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.6101 - val_accuracy: 0.9080\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0547 - accuracy: 0.9860 - val_loss: 0.7601 - val_accuracy: 0.8300\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0264 - accuracy: 0.9932 - val_loss: 0.5378 - val_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.7705 - val_accuracy: 0.8420\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0393 - accuracy: 0.9903 - val_loss: 0.5183 - val_accuracy: 0.9080\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0324 - accuracy: 0.9923 - val_loss: 0.5960 - val_accuracy: 0.8420\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0274 - accuracy: 0.9922 - val_loss: 0.4572 - val_accuracy: 0.9200\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0260 - accuracy: 0.9895 - val_loss: 0.6676 - val_accuracy: 0.9020\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0860 - accuracy: 0.9771 - val_loss: 0.6154 - val_accuracy: 0.9120\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1740 - accuracy: 0.9594 - val_loss: 0.5959 - val_accuracy: 0.8980\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.6209 - val_accuracy: 0.9080\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.7503 - val_accuracy: 0.9020\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.9372 - val_accuracy: 0.8880\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0321 - accuracy: 0.9894 - val_loss: 0.5101 - val_accuracy: 0.8960\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0382 - accuracy: 0.9910 - val_loss: 0.7207 - val_accuracy: 0.8880\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.7081 - val_accuracy: 0.8980\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.7832 - val_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.7162 - val_accuracy: 0.9100\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.7865 - val_accuracy: 0.8960\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.5750 - val_accuracy: 0.9020\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.6299 - val_accuracy: 0.9100\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.6744 - val_accuracy: 0.9140\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.8550 - val_accuracy: 0.9140\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.8194 - val_accuracy: 0.9040\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.9543 - val_accuracy: 0.8980\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.6462 - val_accuracy: 0.9080\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0146 - accuracy: 0.9936 - val_loss: 0.7425 - val_accuracy: 0.8940\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00069: early stopping\n",
      "Test Accuracy: 92.00000166893005\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.936\n",
      "1       relu       2  0.910\n",
      "2       relu       3  0.912\n",
      "3       relu       4  0.920\n",
      "\n",
      "-------------------------------------------\n",
      "Training 5: relu activation, 5 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 11s 65ms/step - loss: 2.1963 - accuracy: 0.2725 - val_loss: 1.2220 - val_accuracy: 0.5300\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 1.0031 - accuracy: 0.6149 - val_loss: 0.5648 - val_accuracy: 0.8480\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5696 - accuracy: 0.7983 - val_loss: 0.4720 - val_accuracy: 0.8460\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.4302 - accuracy: 0.8594 - val_loss: 0.3776 - val_accuracy: 0.8660\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.3713 - accuracy: 0.8736 - val_loss: 0.3644 - val_accuracy: 0.8820\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.2795 - accuracy: 0.9109 - val_loss: 0.3305 - val_accuracy: 0.9080\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.2179 - accuracy: 0.9323 - val_loss: 0.3706 - val_accuracy: 0.8920\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.1584 - accuracy: 0.9502 - val_loss: 0.4041 - val_accuracy: 0.8840\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1383 - accuracy: 0.9588 - val_loss: 0.4228 - val_accuracy: 0.8920\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1102 - accuracy: 0.9686 - val_loss: 0.5006 - val_accuracy: 0.8960\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.1076 - accuracy: 0.9670 - val_loss: 0.5657 - val_accuracy: 0.8780\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.1039 - accuracy: 0.9685 - val_loss: 0.5074 - val_accuracy: 0.8980\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.1269 - accuracy: 0.9613 - val_loss: 0.5355 - val_accuracy: 0.8280\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.2425 - accuracy: 0.9275 - val_loss: 0.4268 - val_accuracy: 0.8920\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0886 - accuracy: 0.9707 - val_loss: 0.6597 - val_accuracy: 0.8020\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0483 - accuracy: 0.9845 - val_loss: 0.5622 - val_accuracy: 0.8920\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0521 - accuracy: 0.9828 - val_loss: 0.4892 - val_accuracy: 0.9080\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 0.7570 - val_accuracy: 0.8140\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0465 - accuracy: 0.9886 - val_loss: 0.5820 - val_accuracy: 0.8100\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0411 - accuracy: 0.9881 - val_loss: 0.5578 - val_accuracy: 0.8980\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0443 - accuracy: 0.9855 - val_loss: 0.7098 - val_accuracy: 0.8900\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0437 - accuracy: 0.9865 - val_loss: 0.6306 - val_accuracy: 0.8900\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0395 - accuracy: 0.9897 - val_loss: 0.5445 - val_accuracy: 0.8940\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0454 - accuracy: 0.9909 - val_loss: 0.6202 - val_accuracy: 0.8120\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.5855 - val_accuracy: 0.8260\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0328 - accuracy: 0.9917 - val_loss: 0.5438 - val_accuracy: 0.9140\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.6962 - val_accuracy: 0.7940\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0557 - accuracy: 0.9858 - val_loss: 0.8493 - val_accuracy: 0.8640\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0357 - accuracy: 0.9919 - val_loss: 0.8084 - val_accuracy: 0.7960\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 0.5741 - val_accuracy: 0.9140\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 0.6225 - val_accuracy: 0.8940\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.7478 - val_accuracy: 0.8860\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0433 - accuracy: 0.9882 - val_loss: 0.4506 - val_accuracy: 0.8340\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 0.6709 - val_accuracy: 0.8920\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.7664 - val_accuracy: 0.8920\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.7842 - val_accuracy: 0.8780\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 1.0413 - val_accuracy: 0.8860\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0419 - accuracy: 0.9888 - val_loss: 0.6678 - val_accuracy: 0.8940\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 1.0144 - val_accuracy: 0.8680\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.1090 - accuracy: 0.9753 - val_loss: 0.7806 - val_accuracy: 0.8900\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.9201 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 0.8305 - val_accuracy: 0.8880\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0658 - accuracy: 0.9836 - val_loss: 0.6795 - val_accuracy: 0.8140\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.7223 - val_accuracy: 0.8940\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.8584 - val_accuracy: 0.8300\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.7915 - val_accuracy: 0.8360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.936\n",
      "1       relu       2  0.910\n",
      "2       relu       3  0.912\n",
      "3       relu       4  0.920\n",
      "4       relu       5  0.914\n",
      "\n",
      "-------------------------------------------\n",
      "Training 6: relu activation, 6 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 11s 67ms/step - loss: 1.8668 - accuracy: 0.2596 - val_loss: 1.3181 - val_accuracy: 0.4660\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 1.1485 - accuracy: 0.5459 - val_loss: 0.7227 - val_accuracy: 0.7620\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.7327 - accuracy: 0.7379 - val_loss: 0.5461 - val_accuracy: 0.8020\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5719 - accuracy: 0.7999 - val_loss: 0.4055 - val_accuracy: 0.8620\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.3848 - accuracy: 0.8773 - val_loss: 0.3859 - val_accuracy: 0.8740\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.2895 - accuracy: 0.9079 - val_loss: 0.4010 - val_accuracy: 0.8960\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.2420 - accuracy: 0.9211 - val_loss: 0.3302 - val_accuracy: 0.9060\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.2711 - accuracy: 0.9166 - val_loss: 0.4581 - val_accuracy: 0.8740\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.1602 - accuracy: 0.9480 - val_loss: 0.4314 - val_accuracy: 0.8880\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.1105 - accuracy: 0.9604 - val_loss: 0.3402 - val_accuracy: 0.9180\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1162 - accuracy: 0.9595 - val_loss: 0.3879 - val_accuracy: 0.9020\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0931 - accuracy: 0.9685 - val_loss: 0.4391 - val_accuracy: 0.8340\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 0.5213 - val_accuracy: 0.8200\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0801 - accuracy: 0.9743 - val_loss: 0.4567 - val_accuracy: 0.8980\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1791 - accuracy: 0.9414 - val_loss: 0.5407 - val_accuracy: 0.8340\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0797 - accuracy: 0.9739 - val_loss: 0.6153 - val_accuracy: 0.8760\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0721 - accuracy: 0.9738 - val_loss: 0.5235 - val_accuracy: 0.8940\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.6436 - val_accuracy: 0.8880\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0770 - accuracy: 0.9711 - val_loss: 0.6936 - val_accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.7978 - val_accuracy: 0.8840\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0593 - accuracy: 0.9786 - val_loss: 0.6059 - val_accuracy: 0.8840\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0715 - accuracy: 0.9780 - val_loss: 0.7450 - val_accuracy: 0.7980\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0952 - accuracy: 0.9670 - val_loss: 0.5092 - val_accuracy: 0.8940\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0628 - accuracy: 0.9763 - val_loss: 0.6962 - val_accuracy: 0.8740\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1156 - accuracy: 0.9652 - val_loss: 0.6268 - val_accuracy: 0.8860\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.6143 - val_accuracy: 0.8920\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0664 - accuracy: 0.9812 - val_loss: 0.6854 - val_accuracy: 0.8900\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.5282 - val_accuracy: 0.8940\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.7300 - val_accuracy: 0.8940\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.0247 - accuracy: 0.9929 - val_loss: 0.5711 - val_accuracy: 0.8980\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.936\n",
      "1       relu       2  0.910\n",
      "2       relu       3  0.912\n",
      "3       relu       4  0.920\n",
      "4       relu       5  0.914\n",
      "5       relu       6  0.918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "\n",
    "columns = ['Activation', 'Filters', 'Acc']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "exp = 0\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "        \n",
    "        exp+=1\n",
    "        print('-------------------------------------------')\n",
    "        print('Training {}: {} activation, {} kernel size.'.format(exp, activation, kernel_size))\n",
    "        print('-------------------------------------------')\n",
    "        \n",
    "        # encode data using\n",
    "        # Cleaning and Tokenization\n",
    "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "        # Turn the text into sequence\n",
    "        training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "        test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "        max_len = max_length(training_sequences)\n",
    "\n",
    "        # Pad the sequence to have the same size\n",
    "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        vocab_size = len(word_index)+1\n",
    "\n",
    "        emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "\n",
    "        # Define the input shape\n",
    "        model = define_model_2(kernel_size, activation, input_dim=vocab_size, \n",
    "                             max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "        # Train the model and initialize test accuracy with 0\n",
    "        acc = 0\n",
    "        while(acc<0.6):\n",
    "\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=100, verbose=1, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            if (acc<0.6):\n",
    "                print('The model suffered from local minimum. Retrain the model!')\n",
    "                model = define_model_2(kernel_size, activation, input_dim=vocab_size, \n",
    "                                       max_length=max_len, emb_matrix=emb_matrix)\n",
    "            else:\n",
    "                print('Done!')\n",
    "\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + [acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record2 = record2.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record2)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters    Acc\n",
       "0       relu       1  0.936\n",
       "3       relu       4  0.920\n",
       "5       relu       6  0.918\n",
       "4       relu       5  0.914\n",
       "2       relu       3  0.912\n",
       "1       relu       2  0.910"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2.sort_values(by='Acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2.sort_values(by='Acc', ascending=False)\n",
    "report = report.to_excel('TCN_TREC_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_3(kernel_size = 3, activation='relu', input_dim = None, \n",
    "                   output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    inp = Input( shape=(max_length,))\n",
    "    x = Embedding(input_dim=input_dim, \n",
    "                  output_dim=output_dim, \n",
    "                  input_length=max_length,\n",
    "                  # Assign the embedding weight with word2vec embedding marix\n",
    "                  weights = [emb_matrix],\n",
    "                  # Set the weight to be not trainable (static)\n",
    "                  trainable = True)(inp)\n",
    "    \n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn1')(x)\n",
    "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn2')(x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    conc = Dense(16, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(6, activation=\"softmax\")(conc)    \n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 100, 300)     300000      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 100, 300)     0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn1 (TCN)                      (None, 100, 128)     279936      spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tcn2 (TCN)                      (None, 100, 64)      65984       tcn1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 64)           0           tcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 64)           0           tcn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 128)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 16)           2064        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16)           0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 6)            102         dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 648,086\n",
      "Trainable params: 648,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=20, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Training 1: relu activation, 1 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 16s 105ms/step - loss: 1.7516 - accuracy: 0.2901 - val_loss: 0.9225 - val_accuracy: 0.6700\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.8424 - accuracy: 0.6706 - val_loss: 0.6787 - val_accuracy: 0.7800\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.4505 - accuracy: 0.8515 - val_loss: 0.3809 - val_accuracy: 0.8900\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.2638 - accuracy: 0.9109 - val_loss: 0.3444 - val_accuracy: 0.8740\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.1397 - accuracy: 0.9541 - val_loss: 0.6288 - val_accuracy: 0.8160\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1158 - accuracy: 0.9593 - val_loss: 0.4092 - val_accuracy: 0.9000\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0834 - accuracy: 0.9692 - val_loss: 0.4955 - val_accuracy: 0.9080\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0843 - accuracy: 0.9701 - val_loss: 1.0062 - val_accuracy: 0.8400\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0688 - accuracy: 0.9756 - val_loss: 0.6516 - val_accuracy: 0.8860\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.7158 - val_accuracy: 0.8780\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0713 - accuracy: 0.9793 - val_loss: 0.7521 - val_accuracy: 0.8560\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 0.5951 - val_accuracy: 0.8860\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.8378 - val_accuracy: 0.8580\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.6158 - val_accuracy: 0.8900\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.7227 - val_accuracy: 0.8780\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0596 - accuracy: 0.9841 - val_loss: 1.0022 - val_accuracy: 0.8820\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0531 - accuracy: 0.9858 - val_loss: 0.9123 - val_accuracy: 0.8540\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.6033 - val_accuracy: 0.9020\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.8228 - val_accuracy: 0.8700\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.3418 - accuracy: 0.9169 - val_loss: 0.5869 - val_accuracy: 0.8860\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0323 - accuracy: 0.9936 - val_loss: 0.7167 - val_accuracy: 0.8600\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.0243 - accuracy: 0.9953 - val_loss: 1.2085 - val_accuracy: 0.8400\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 0.9070 - val_accuracy: 0.8740\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.9643 - val_accuracy: 0.8660\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.8347 - val_accuracy: 0.8840\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0285 - accuracy: 0.9942 - val_loss: 0.9499 - val_accuracy: 0.8700\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 0.0492 - accuracy: 0.9936 - val_loss: 0.8579 - val_accuracy: 0.8820\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.908\n",
      "\n",
      "-------------------------------------------\n",
      "Training 2: relu activation, 2 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 17s 105ms/step - loss: 1.9122 - accuracy: 0.2446 - val_loss: 1.0028 - val_accuracy: 0.6640\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.9632 - accuracy: 0.6106 - val_loss: 0.4967 - val_accuracy: 0.8380\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.4720 - accuracy: 0.8409 - val_loss: 0.3873 - val_accuracy: 0.8980\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2550 - accuracy: 0.9234 - val_loss: 0.4167 - val_accuracy: 0.8920\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1632 - accuracy: 0.9436 - val_loss: 0.4496 - val_accuracy: 0.8940\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1305 - accuracy: 0.9593 - val_loss: 0.6310 - val_accuracy: 0.8720\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0792 - accuracy: 0.9763 - val_loss: 0.5516 - val_accuracy: 0.8900\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.5802 - val_accuracy: 0.8920\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.7471 - val_accuracy: 0.8820\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1333 - accuracy: 0.9656 - val_loss: 0.8602 - val_accuracy: 0.8580\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0518 - accuracy: 0.9847 - val_loss: 0.4637 - val_accuracy: 0.9000\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.7575 - val_accuracy: 0.8780\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0510 - accuracy: 0.9859 - val_loss: 0.5935 - val_accuracy: 0.9060\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.6504 - val_accuracy: 0.9020\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0282 - accuracy: 0.9883 - val_loss: 0.9312 - val_accuracy: 0.8860\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0662 - accuracy: 0.9835 - val_loss: 0.6040 - val_accuracy: 0.8900\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.6847 - val_accuracy: 0.8920\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.9597 - val_accuracy: 0.8820\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 10s 96ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 1.1239 - val_accuracy: 0.8820\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 1.1022 - val_accuracy: 0.8700\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0283 - accuracy: 0.9929 - val_loss: 0.9089 - val_accuracy: 0.8860\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0480 - accuracy: 0.9901 - val_loss: 1.0349 - val_accuracy: 0.8080\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 1.0862 - val_accuracy: 0.8780\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 1.0507 - val_accuracy: 0.7780\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0175 - accuracy: 0.9971 - val_loss: 0.8097 - val_accuracy: 0.8760\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.7458 - val_accuracy: 0.8840\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0134 - accuracy: 0.9966 - val_loss: 1.1205 - val_accuracy: 0.8840\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.9473 - val_accuracy: 0.8080\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0247 - accuracy: 0.9952 - val_loss: 0.7900 - val_accuracy: 0.8040\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.7014 - val_accuracy: 0.8800\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0582 - accuracy: 0.9847 - val_loss: 0.7420 - val_accuracy: 0.8920\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 1.1498 - val_accuracy: 0.8740\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.3990 - val_accuracy: 0.8660\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "Test Accuracy: 90.6000018119812\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.908\n",
      "1       relu       2  0.906\n",
      "\n",
      "-------------------------------------------\n",
      "Training 3: relu activation, 3 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 15s 99ms/step - loss: 1.9986 - accuracy: 0.2842 - val_loss: 0.9770 - val_accuracy: 0.6860\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.8622 - accuracy: 0.6783 - val_loss: 0.4721 - val_accuracy: 0.8920\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.4651 - accuracy: 0.8415 - val_loss: 0.4102 - val_accuracy: 0.8680\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2660 - accuracy: 0.9164 - val_loss: 0.3796 - val_accuracy: 0.8980\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1971 - accuracy: 0.9367 - val_loss: 0.4863 - val_accuracy: 0.8900\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1469 - accuracy: 0.9564 - val_loss: 0.4557 - val_accuracy: 0.8900\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1530 - accuracy: 0.9535 - val_loss: 0.4994 - val_accuracy: 0.8860\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1398 - accuracy: 0.9591 - val_loss: 0.4730 - val_accuracy: 0.8940\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1639 - accuracy: 0.9530 - val_loss: 0.5180 - val_accuracy: 0.8760\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0914 - accuracy: 0.9747 - val_loss: 0.5008 - val_accuracy: 0.8880\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.7051 - val_accuracy: 0.8720\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0680 - accuracy: 0.9807 - val_loss: 0.6184 - val_accuracy: 0.8820\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0565 - accuracy: 0.9881 - val_loss: 0.7276 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0536 - accuracy: 0.9881 - val_loss: 0.5582 - val_accuracy: 0.8900\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0547 - accuracy: 0.9867 - val_loss: 0.8501 - val_accuracy: 0.7720\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0677 - accuracy: 0.9853 - val_loss: 0.6490 - val_accuracy: 0.8840\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0562 - accuracy: 0.9904 - val_loss: 0.7554 - val_accuracy: 0.8880\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0384 - accuracy: 0.9933 - val_loss: 0.9344 - val_accuracy: 0.8820\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0439 - accuracy: 0.9882 - val_loss: 0.6805 - val_accuracy: 0.8880\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0629 - accuracy: 0.9871 - val_loss: 0.5302 - val_accuracy: 0.8880\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0564 - accuracy: 0.9871 - val_loss: 0.7332 - val_accuracy: 0.8740\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0594 - accuracy: 0.9866 - val_loss: 0.9232 - val_accuracy: 0.7900\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0395 - accuracy: 0.9946 - val_loss: 0.6469 - val_accuracy: 0.8900\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0373 - accuracy: 0.9942 - val_loss: 0.8932 - val_accuracy: 0.8900\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 89.80000019073486\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.908\n",
      "1       relu       2  0.906\n",
      "2       relu       3  0.898\n",
      "\n",
      "-------------------------------------------\n",
      "Training 4: relu activation, 4 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 15s 103ms/step - loss: 1.9312 - accuracy: 0.2093 - val_loss: 1.7748 - val_accuracy: 0.1880\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 1.7641 - accuracy: 0.2284 - val_loss: 1.7604 - val_accuracy: 0.1880\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 1.7458 - accuracy: 0.2294 - val_loss: 1.7489 - val_accuracy: 0.1880\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 1.7301 - accuracy: 0.2359 - val_loss: 1.7399 - val_accuracy: 0.1880\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 1.7184 - accuracy: 0.2364 - val_loss: 1.7317 - val_accuracy: 0.1880\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 1.7085 - accuracy: 0.2291 - val_loss: 1.7253 - val_accuracy: 0.1880\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 1.7031 - accuracy: 0.2297 - val_loss: 1.7201 - val_accuracy: 0.1880\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 1.6913 - accuracy: 0.2348 - val_loss: 1.7158 - val_accuracy: 0.1880\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 1.6881 - accuracy: 0.2375 - val_loss: 1.7110 - val_accuracy: 0.1880\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 1.6839 - accuracy: 0.2243 - val_loss: 1.7074 - val_accuracy: 0.1880\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 1.6799 - accuracy: 0.2321 - val_loss: 1.7040 - val_accuracy: 0.1880\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 1.6750 - accuracy: 0.2386 - val_loss: 1.7026 - val_accuracy: 0.1880\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 1.6746 - accuracy: 0.2291 - val_loss: 1.6995 - val_accuracy: 0.1880\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 1.6673 - accuracy: 0.2225 - val_loss: 1.6982 - val_accuracy: 0.1880\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 1.6650 - accuracy: 0.2199 - val_loss: 1.6970 - val_accuracy: 0.1880\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 1.6650 - accuracy: 0.2304 - val_loss: 1.6943 - val_accuracy: 0.1880\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 1.6653 - accuracy: 0.2379 - val_loss: 1.6931 - val_accuracy: 0.1880\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 1.6635 - accuracy: 0.2355 - val_loss: 1.6918 - val_accuracy: 0.1880\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 1.6566 - accuracy: 0.2383 - val_loss: 1.6913 - val_accuracy: 0.1880\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 1.6634 - accuracy: 0.2145 - val_loss: 1.6906 - val_accuracy: 0.1880\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 11s 96ms/step - loss: 1.6574 - accuracy: 0.2416 - val_loss: 1.6894 - val_accuracy: 0.1880\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 18.799999356269836\n",
      "The model suffered from local minimum. Retrain the model!\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 19s 126ms/step - loss: 2.0384 - accuracy: 0.1778 - val_loss: 1.6052 - val_accuracy: 0.4180\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 1.3653 - accuracy: 0.4320 - val_loss: 0.6360 - val_accuracy: 0.7820\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.6451 - accuracy: 0.7603 - val_loss: 0.5350 - val_accuracy: 0.8220\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3969 - accuracy: 0.8350 - val_loss: 0.4327 - val_accuracy: 0.8800\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2960 - accuracy: 0.8716 - val_loss: 0.5018 - val_accuracy: 0.8700\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2433 - accuracy: 0.8989 - val_loss: 0.4255 - val_accuracy: 0.8840\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1461 - accuracy: 0.9499 - val_loss: 0.5212 - val_accuracy: 0.8740\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0963 - accuracy: 0.9659 - val_loss: 0.6823 - val_accuracy: 0.7880\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0737 - accuracy: 0.9838 - val_loss: 0.6629 - val_accuracy: 0.8540\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0758 - accuracy: 0.9758 - val_loss: 0.5024 - val_accuracy: 0.8920\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0599 - accuracy: 0.9827 - val_loss: 0.7873 - val_accuracy: 0.8820\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.0453 - accuracy: 0.9879 - val_loss: 0.7582 - val_accuracy: 0.8720\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 0.0354 - accuracy: 0.9904 - val_loss: 0.6290 - val_accuracy: 0.8960\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.9653 - val_accuracy: 0.8700\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0226 - accuracy: 0.9943 - val_loss: 0.7033 - val_accuracy: 0.8980\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0440 - accuracy: 0.9873 - val_loss: 0.7230 - val_accuracy: 0.7700\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 1.1687 - val_accuracy: 0.7340\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 1.0737 - val_accuracy: 0.8740\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.8628 - val_accuracy: 0.9000\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.7783 - val_accuracy: 0.8840\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0186 - accuracy: 0.9955 - val_loss: 1.0548 - val_accuracy: 0.8580\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.0245 - accuracy: 0.9951 - val_loss: 0.8952 - val_accuracy: 0.8920\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.0342 - val_accuracy: 0.8800\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 1.2724 - val_accuracy: 0.8820\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 1.3775 - val_accuracy: 0.8880\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 1.3081 - val_accuracy: 0.8840\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 1.0535 - val_accuracy: 0.8720\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0444 - accuracy: 0.9905 - val_loss: 0.7127 - val_accuracy: 0.8840\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0348 - accuracy: 0.9920 - val_loss: 0.6504 - val_accuracy: 0.9040\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.9935 - val_accuracy: 0.8940\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.9001 - val_accuracy: 0.8980\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 1.2115 - val_accuracy: 0.8960\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.9993 - val_accuracy: 0.8640\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0400 - accuracy: 0.9910 - val_loss: 0.6988 - val_accuracy: 0.8840\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.8152 - val_accuracy: 0.8920\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.7913 - val_accuracy: 0.9040\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.8032 - val_accuracy: 0.8940\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 1.0175 - val_accuracy: 0.9040\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.7133 - val_accuracy: 0.8820\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.6351 - val_accuracy: 0.9080\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.9064 - val_accuracy: 0.8900\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.8244 - val_accuracy: 0.8980\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.9195 - val_accuracy: 0.9080\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.0170 - val_accuracy: 0.9060\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.9615 - val_accuracy: 0.9040\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 1.0294 - val_accuracy: 0.9020\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 7.3976e-04 - accuracy: 0.9997 - val_loss: 1.0601 - val_accuracy: 0.9000\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.1826 - val_accuracy: 0.9000\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.2861 - val_accuracy: 0.8960\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.3183 - val_accuracy: 0.9000\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 1.4599 - val_accuracy: 0.8980\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.4542 - val_accuracy: 0.8940\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0412 - accuracy: 0.9935 - val_loss: 2.2003 - val_accuracy: 0.7540\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0940 - accuracy: 0.9729 - val_loss: 1.1989 - val_accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0295 - accuracy: 0.9941 - val_loss: 1.1467 - val_accuracy: 0.8460\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0274 - accuracy: 0.9946 - val_loss: 0.9191 - val_accuracy: 0.8700\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 1.0247 - val_accuracy: 0.8720\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 1.0522 - val_accuracy: 0.8540\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 1.1068 - val_accuracy: 0.8820\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 1.1741 - val_accuracy: 0.8800\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00060: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.908\n",
      "1       relu       2  0.906\n",
      "2       relu       3  0.898\n",
      "3       relu       4  0.908\n",
      "\n",
      "-------------------------------------------\n",
      "Training 5: relu activation, 5 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 15s 98ms/step - loss: 1.7425 - accuracy: 0.2672 - val_loss: 0.9405 - val_accuracy: 0.6520\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.8566 - accuracy: 0.6888 - val_loss: 0.5972 - val_accuracy: 0.8120\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.4693 - accuracy: 0.8351 - val_loss: 0.3556 - val_accuracy: 0.9000\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2795 - accuracy: 0.9014 - val_loss: 0.4328 - val_accuracy: 0.8660\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1657 - accuracy: 0.9368 - val_loss: 0.4627 - val_accuracy: 0.8920\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1359 - accuracy: 0.9607 - val_loss: 0.5703 - val_accuracy: 0.8940\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1174 - accuracy: 0.9669 - val_loss: 0.4485 - val_accuracy: 0.9040\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0751 - accuracy: 0.9781 - val_loss: 0.3765 - val_accuracy: 0.9120\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0797 - accuracy: 0.9772 - val_loss: 0.5202 - val_accuracy: 0.8780\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0547 - accuracy: 0.9842 - val_loss: 0.6358 - val_accuracy: 0.8800\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0709 - accuracy: 0.9791 - val_loss: 0.5085 - val_accuracy: 0.8660\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0582 - accuracy: 0.9834 - val_loss: 0.5571 - val_accuracy: 0.8880\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0494 - accuracy: 0.9837 - val_loss: 0.4518 - val_accuracy: 0.9160\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0762 - accuracy: 0.9783 - val_loss: 0.5132 - val_accuracy: 0.9040\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0558 - accuracy: 0.9797 - val_loss: 0.6020 - val_accuracy: 0.9040\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0744 - accuracy: 0.9767 - val_loss: 0.4793 - val_accuracy: 0.8960\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0515 - accuracy: 0.9818 - val_loss: 0.7548 - val_accuracy: 0.9060\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0706 - accuracy: 0.9798 - val_loss: 0.4787 - val_accuracy: 0.9040\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.5379 - val_accuracy: 0.9080\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.5748 - val_accuracy: 0.9060\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0485 - accuracy: 0.9840 - val_loss: 0.9052 - val_accuracy: 0.8780\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0587 - accuracy: 0.9793 - val_loss: 0.7711 - val_accuracy: 0.8920\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.6659 - val_accuracy: 0.8880\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0510 - accuracy: 0.9840 - val_loss: 0.6454 - val_accuracy: 0.8860\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0399 - accuracy: 0.9900 - val_loss: 0.6507 - val_accuracy: 0.9080\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 0.6228 - val_accuracy: 0.9040\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0346 - accuracy: 0.9867 - val_loss: 0.6653 - val_accuracy: 0.9020\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.7723 - val_accuracy: 0.8940\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0412 - accuracy: 0.9843 - val_loss: 0.8200 - val_accuracy: 0.8900\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0599 - accuracy: 0.9804 - val_loss: 0.7096 - val_accuracy: 0.8160\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0281 - accuracy: 0.9883 - val_loss: 0.9627 - val_accuracy: 0.8880\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0293 - accuracy: 0.9858 - val_loss: 1.3458 - val_accuracy: 0.8940\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0304 - accuracy: 0.9844 - val_loss: 0.7852 - val_accuracy: 0.8900\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.908\n",
      "1       relu       2  0.906\n",
      "2       relu       3  0.898\n",
      "3       relu       4  0.908\n",
      "4       relu       5  0.916\n",
      "\n",
      "-------------------------------------------\n",
      "Training 6: relu activation, 6 kernel size.\n",
      "-------------------------------------------\n",
      "Epoch 1/200\n",
      "110/110 [==============================] - 15s 99ms/step - loss: 1.7258 - accuracy: 0.2707 - val_loss: 1.3444 - val_accuracy: 0.3640\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 1.0333 - accuracy: 0.5803 - val_loss: 0.6335 - val_accuracy: 0.8260\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.5101 - accuracy: 0.8211 - val_loss: 0.5157 - val_accuracy: 0.8540\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2753 - accuracy: 0.9092 - val_loss: 0.4581 - val_accuracy: 0.8760\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.2192 - accuracy: 0.9238 - val_loss: 0.5201 - val_accuracy: 0.8620\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1771 - accuracy: 0.9463 - val_loss: 0.5121 - val_accuracy: 0.8980\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1244 - accuracy: 0.9587 - val_loss: 0.5145 - val_accuracy: 0.9000\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1756 - accuracy: 0.9443 - val_loss: 0.6142 - val_accuracy: 0.8760\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0820 - accuracy: 0.9648 - val_loss: 0.6326 - val_accuracy: 0.8860\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0961 - accuracy: 0.9614 - val_loss: 0.5568 - val_accuracy: 0.8980\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.9491 - val_accuracy: 0.8400\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0646 - accuracy: 0.9743 - val_loss: 0.6265 - val_accuracy: 0.9040\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0650 - accuracy: 0.9817 - val_loss: 0.6115 - val_accuracy: 0.9040\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0539 - accuracy: 0.9836 - val_loss: 0.6074 - val_accuracy: 0.8980\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 0.6731 - val_accuracy: 0.8920\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0424 - accuracy: 0.9862 - val_loss: 0.6615 - val_accuracy: 0.8940\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.9204 - val_accuracy: 0.8760\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0700 - accuracy: 0.9793 - val_loss: 0.5299 - val_accuracy: 0.9040\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0438 - accuracy: 0.9897 - val_loss: 0.6373 - val_accuracy: 0.8960\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.7592 - val_accuracy: 0.8860\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.7039 - val_accuracy: 0.9140\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0200 - accuracy: 0.9920 - val_loss: 1.1254 - val_accuracy: 0.8800\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0195 - accuracy: 0.9915 - val_loss: 0.8313 - val_accuracy: 0.9040\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0414 - accuracy: 0.9895 - val_loss: 1.1121 - val_accuracy: 0.8880\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.7617 - val_accuracy: 0.9040\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0385 - accuracy: 0.9894 - val_loss: 0.6244 - val_accuracy: 0.9180\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0530 - accuracy: 0.9845 - val_loss: 0.8047 - val_accuracy: 0.8880\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0419 - accuracy: 0.9915 - val_loss: 0.5539 - val_accuracy: 0.9140\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0326 - accuracy: 0.9908 - val_loss: 1.0346 - val_accuracy: 0.8720\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.8421 - val_accuracy: 0.8860\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.8056 - val_accuracy: 0.9000\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.8978 - val_accuracy: 0.8920\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 1.2017 - val_accuracy: 0.8680\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.9936 - val_accuracy: 0.8780\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.8987 - val_accuracy: 0.9020\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0323 - accuracy: 0.9924 - val_loss: 0.6744 - val_accuracy: 0.8440\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0378 - accuracy: 0.9908 - val_loss: 0.5766 - val_accuracy: 0.9040\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0249 - accuracy: 0.9895 - val_loss: 0.6712 - val_accuracy: 0.9100\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.8598 - val_accuracy: 0.8800\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0420 - accuracy: 0.9898 - val_loss: 0.6884 - val_accuracy: 0.8780\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.8193 - val_accuracy: 0.8840\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.8572 - val_accuracy: 0.9080\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.0123 - accuracy: 0.9946 - val_loss: 1.0489 - val_accuracy: 0.8880\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 1.0477 - val_accuracy: 0.8940\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 1.1696 - val_accuracy: 0.8840\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.7098 - val_accuracy: 0.9080\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Done!\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.908\n",
      "1       relu       2  0.906\n",
      "2       relu       3  0.898\n",
      "3       relu       4  0.908\n",
      "4       relu       5  0.916\n",
      "5       relu       6  0.918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "\n",
    "columns = ['Activation', 'Filters', 'Acc']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "exp = 0\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "        \n",
    "        exp+=1\n",
    "        print('-------------------------------------------')\n",
    "        print('Training {}: {} activation, {} kernel size.'.format(exp, activation, kernel_size))\n",
    "        print('-------------------------------------------')\n",
    "        \n",
    "        # encode data using\n",
    "        # Cleaning and Tokenization\n",
    "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "        # Turn the text into sequence\n",
    "        training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "        test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "        max_len = max_length(training_sequences)\n",
    "\n",
    "        # Pad the sequence to have the same size\n",
    "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        vocab_size = len(word_index)+1\n",
    "\n",
    "        emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "\n",
    "        # Define the input shape\n",
    "        model = define_model_3(kernel_size, activation, input_dim=vocab_size, \n",
    "                             max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "        # Train the model and initialize test accuracy with 0\n",
    "        acc = 0\n",
    "        while(acc<0.6):\n",
    "\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=200, verbose=1, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            if (acc<0.6):\n",
    "                print('The model suffered from local minimum. Retrain the model!')\n",
    "                model = define_model_3(kernel_size, activation, input_dim=vocab_size, \n",
    "                                       max_length=max_len, emb_matrix=emb_matrix)\n",
    "            else:\n",
    "                print('Done!')\n",
    "\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + [acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record3 = record3.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record3)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters    Acc\n",
       "5       relu       6  0.918\n",
       "4       relu       5  0.916\n",
       "0       relu       1  0.908\n",
       "3       relu       4  0.908\n",
       "1       relu       2  0.906\n",
       "2       relu       3  0.898"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3.sort_values(by='Acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3.sort_values(by='Acc', ascending=False)\n",
    "report = report.to_excel('TCN_TREC_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
