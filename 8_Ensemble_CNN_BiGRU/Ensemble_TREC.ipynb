{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU2pVpwQeAwi"
   },
   "source": [
    "# MLP Classification with TREC Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using MLP model on the TREC Dataset. \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1592,
     "status": "ok",
     "timestamp": 1613881735526,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "co02_OrOeAxK",
    "outputId": "b73caa50-9bb1-4383-a5eb-9ce553cabb9d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import time\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIaHVCBveAxM"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 2615,
     "status": "ok",
     "timestamp": 1613881784144,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "S6pw277beAxN",
    "outputId": "36745604-7817-49cf-9000-baabc84bb554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5952, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>who was the 22nd president of the us ?</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>what is the money they use in zambia ?</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>how many feet in a mile ?</td>\n",
       "      <td>5</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>what is the birthstone of october ?</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>what is e coli ?</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     how did serfdom develop in and then leave russ...      0  train\n",
       "1      what films featured the character popeye doyle ?      1  train\n",
       "2     how can i find a list of celebrities ' real na...      0  train\n",
       "3     what fowl grabs the spotlight after the chines...      1  train\n",
       "4                       what is the full form of .com ?      2  train\n",
       "...                                                 ...    ...    ...\n",
       "5947             who was the 22nd president of the us ?      3   test\n",
       "5948             what is the money they use in zambia ?      1   test\n",
       "5949                          how many feet in a mile ?      5   test\n",
       "5950                what is the birthstone of october ?      1   test\n",
       "5951                                   what is e coli ?      0   test\n",
       "\n",
       "[5952 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/TREC/TREC.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2660,
     "status": "ok",
     "timestamp": 1613881796000,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "ardMFHDJeAxQ",
    "outputId": "4036087a-056d-4803-e294-e7cbbe754c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5952 entries, 0 to 5951\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  5952 non-null   object\n",
      " 1   label     5952 non-null   int32 \n",
      " 2   split     5952 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 116.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 2502,
     "status": "ok",
     "timestamp": 1613881796004,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "4_lhbpYGeAxS",
    "outputId": "19c8839e-4422-4108-f47a-cd252d309a1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">train</th>\n",
       "      <th>0</th>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentence\n",
       "split label          \n",
       "test  0           138\n",
       "      1            94\n",
       "      2             9\n",
       "      3            65\n",
       "      4            81\n",
       "      5           113\n",
       "train 0          1162\n",
       "      1          1250\n",
       "      2            86\n",
       "      3          1223\n",
       "      4           835\n",
       "      5           896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by=['split','label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 2302,
     "status": "ok",
     "timestamp": 1613881798729,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "2jwK-HoaeAxT",
    "outputId": "b773f7ef-c31f-4796-a73a-e973f3e22cf2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>5452</td>\n",
       "      <td>5452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  label\n",
       "split                 \n",
       "test        500    500\n",
       "train      5452   5452"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby(by='split').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2596,
     "status": "ok",
     "timestamp": 1613881801371,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "-q4r3grgeAxT",
    "outputId": "a038241c-8238-4eb6-892c-16571b98cfbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452\n",
      "5452\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "# Separate the sentences and the labels for training and testing\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJV8dGfzeAxX"
   },
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>## Develop Vocabulary\n",
    "\n",
    "A part of preparing text for text classification involves defining and tailoring the vocabulary of words supported by the model. **We can do this by loading all of the documents in the dataset and building a set of words.**\n",
    "\n",
    "The larger the vocabulary, the more sparse the representation of each word or document. So, we may decide to support all of these words, or perhaps discard some. The final chosen vocabulary can then be saved to a file for later use, such as filtering words in new documents in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1613881803995,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "8ozAFDk3eAxe"
   },
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1650,
     "status": "ok",
     "timestamp": 1613881808491,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "fWW5xE8peAxl",
    "outputId": "e29c9383-98b8-4e99-b2f3-85f7c62fbda1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  what is the full form of .com ?\n",
      "Into a sequence of int: [3, 4, 2, 471, 261, 5, 372]\n",
      "Into a padded sequence: [  3   4   2 471 261   5 372   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "print(\"Example of sentence: \", train_x[4])\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1586,
     "status": "ok",
     "timestamp": 1613881812377,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "pO2INZaHeAxm",
    "outputId": "09eb9a33-b69b-432e-c86a-5e63d59e022c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "what 3\n",
      "is 4\n",
      "of 5\n",
      "in 6\n",
      "a 7\n",
      "how 8\n",
      "'s 9\n",
      "was 10\n",
      "8461\n"
     ]
    }
   ],
   "source": [
    "# See the first 10 words in the vocabulary\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odRK28LIeAxn"
   },
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "A __standard model__ for document classification is to use (quoted from __Jason Brownlee__, the author of [machinelearningmastery.com](https://machinelearningmastery.com)):\n",
    ">- Word Embedding: A distributed representation of words where different words that have a similar meaning (based on their usage) also have a similar representation.\n",
    ">- Convolutional Model: A feature extraction model that learns to extract salient features from documents represented using a word embedding.\n",
    ">- Fully Connected Model: The interpretation of extracted features in terms of a predictive output.\n",
    "\n",
    "\n",
    "Therefore, the model is comprised of the following elements:\n",
    "- __Input layer__ that defines the length of input sequences.\n",
    "- __Embedding layer__ set to the size of the vocabulary and 100-dimensional real-valued representations.\n",
    "- __Conv1D layer__ with 32 filters and a kernel size set to the number of words to read at once.\n",
    "- __MaxPooling1D layer__ to consolidate the output from the convolutional layer.\n",
    "- __Flatten layer__ to reduce the three-dimensional output to two dimensional for concatenation.\n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 1-8.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- L2 Constraint: 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "We will perform the best parameter using __grid search__ and 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK3clvOgeAxo"
   },
   "source": [
    "## CNN Model\n",
    "\n",
    "Now, we will build Convolutional Neural Network (CNN) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "The model takes inspiration from `CNN for Sentence Classification` by *Yoon Kim*.\n",
    "\n",
    "Now, we will define our CNN model as follows:\n",
    "- One Conv layer with 100 filters, kernel size 5, and relu activation function;\n",
    "- One MaxPool layer with pool size = 2;\n",
    "- One Dropout layer after flattened;\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)\n",
    "\n",
    "**Note**: \n",
    "- The whole purpose of dropout layers is to tackle the problem of over-fitting and to introduce generalization to the model. Hence it is advisable to keep dropout parameter near 0.5 in hidden layers. \n",
    "- https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, Dropout, MaxPool1D, Flatten, Dense, Bidirectional, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(filters = 100, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
    "  \n",
    "    # Channel 1\n",
    "    input1 = Input(shape=(max_length,))\n",
    "    embeddding1 = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=max_length)(input1)\n",
    "    conv1 = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', \n",
    "                   kernel_constraint= MaxNorm( max_value=3, axis=[0,1]))(embeddding1)\n",
    "    pool1 = MaxPool1D(pool_size=2, strides=2)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    drop1 = Dropout(0.5)(flat1)\n",
    "    dense1 = Dense(10, activation='relu')(drop1)\n",
    "    drop1 = Dropout(0.5)(dense1)\n",
    "    out1 = Dense(units=6, activation='softmax')(drop1)\n",
    "    \n",
    "    # Channel 2\n",
    "    input2 = Input(shape=(max_length,))\n",
    "    embeddding2 = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=max_length, mask_zero=True)(input2)\n",
    "    gru2 = Bidirectional(GRU(64))(embeddding2)\n",
    "    drop2 = Dropout(0.5)(gru2)\n",
    "    out2 = Dense(units=6, activation='softmax')(drop2)\n",
    "    \n",
    "    # Merge\n",
    "    merged = concatenate([out1, out2])\n",
    "    \n",
    "    # Interpretation\n",
    "    outputs = Dense(units=6, activation='softmax')(merged)\n",
    "    model = Model(inputs=[input1, input2], outputs=outputs)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile( loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1613883207761,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "aOwVZzKkeAxy",
    "outputId": "a921d83c-3d4a-4a0a-f963-06ae5c9e7472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 100, 300)     300000      input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 98, 100)      90100       embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 49, 100)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 4900)         0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 4900)         0           flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 100, 300)     300000      input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 10)           49010       dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 128)          140544      embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 10)           0           dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 128)          0           bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 6)            66          dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 6)            774         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 12)           0           dense_93[0][0]                   \n",
      "                                                                 dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 6)            78          concatenate_23[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 880,572\n",
      "Trainable params: 880,572\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1670,
     "status": "ok",
     "timestamp": 1613883808199,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "n9AjiIuBeAxz"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=20, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)\n",
    "# callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKzlhfLjljQR"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 82232,
     "status": "error",
     "timestamp": 1613883893355,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "a5s8LOGseAxz",
    "outputId": "93a04a62-5f72-48f9-de12-7bc52a78913f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 33s 155ms/step - loss: 1.6845 - accuracy: 0.2857 - val_loss: 1.3982 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 1.2695 - accuracy: 0.6811 - val_loss: 1.1214 - val_accuracy: 0.8400\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 1.0042 - accuracy: 0.8732 - val_loss: 0.9079 - val_accuracy: 0.8360\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.7675 - accuracy: 0.9236 - val_loss: 0.8332 - val_accuracy: 0.8420\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.6072 - accuracy: 0.9392 - val_loss: 0.7146 - val_accuracy: 0.8340\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.4988 - accuracy: 0.9470 - val_loss: 0.6558 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.4226 - accuracy: 0.9505 - val_loss: 0.6518 - val_accuracy: 0.8300\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3711 - accuracy: 0.9531 - val_loss: 0.6160 - val_accuracy: 0.8540\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3258 - accuracy: 0.9613 - val_loss: 0.6130 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2782 - accuracy: 0.9684 - val_loss: 0.6102 - val_accuracy: 0.8560\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 15s 139ms/step - loss: 0.2536 - accuracy: 0.9682 - val_loss: 0.6171 - val_accuracy: 0.8640\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.2359 - accuracy: 0.9658 - val_loss: 0.6211 - val_accuracy: 0.8340\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.2203 - accuracy: 0.9650 - val_loss: 0.6118 - val_accuracy: 0.8480\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.2069 - accuracy: 0.9661 - val_loss: 0.6011 - val_accuracy: 0.8480\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.1838 - accuracy: 0.9685 - val_loss: 0.5937 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.1700 - accuracy: 0.9698 - val_loss: 0.6183 - val_accuracy: 0.8400\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.1551 - accuracy: 0.9728 - val_loss: 0.6212 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.1452 - accuracy: 0.9705 - val_loss: 0.5963 - val_accuracy: 0.8420\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.1578 - accuracy: 0.9640 - val_loss: 0.6154 - val_accuracy: 0.8280\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 0.1402 - accuracy: 0.9691 - val_loss: 0.6317 - val_accuracy: 0.8300\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1245 - accuracy: 0.9701 - val_loss: 0.6206 - val_accuracy: 0.8460\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1240 - accuracy: 0.9708 - val_loss: 0.7064 - val_accuracy: 0.8080\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.1119 - accuracy: 0.9858 - val_loss: 0.6963 - val_accuracy: 0.8140\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.1153 - accuracy: 0.9796 - val_loss: 0.6729 - val_accuracy: 0.8220\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.1216 - accuracy: 0.9781 - val_loss: 0.7333 - val_accuracy: 0.8280\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.1122 - accuracy: 0.9807 - val_loss: 0.8076 - val_accuracy: 0.7880\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 15s 139ms/step - loss: 0.0926 - accuracy: 0.9861 - val_loss: 0.6761 - val_accuracy: 0.8520\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.0884 - accuracy: 0.9848 - val_loss: 0.6217 - val_accuracy: 0.8600\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 17s 155ms/step - loss: 0.0831 - accuracy: 0.9889 - val_loss: 0.6648 - val_accuracy: 0.8640\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0804 - accuracy: 0.9840 - val_loss: 0.7138 - val_accuracy: 0.8440\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 0.0760 - accuracy: 0.9865 - val_loss: 0.6624 - val_accuracy: 0.8520\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Done!\n",
      "Test Accuracy: 86.40000224113464\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.864\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 67s 156ms/step - loss: 1.7044 - accuracy: 0.3116 - val_loss: 1.2952 - val_accuracy: 0.7040\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 1.2492 - accuracy: 0.7131 - val_loss: 1.0712 - val_accuracy: 0.8260\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.9623 - accuracy: 0.8978 - val_loss: 0.8736 - val_accuracy: 0.8460\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.7405 - accuracy: 0.9474 - val_loss: 0.7658 - val_accuracy: 0.8480\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 15s 139ms/step - loss: 0.5834 - accuracy: 0.9620 - val_loss: 0.6844 - val_accuracy: 0.8640\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.4882 - accuracy: 0.9650 - val_loss: 0.6515 - val_accuracy: 0.8440\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.4089 - accuracy: 0.9691 - val_loss: 0.6050 - val_accuracy: 0.8520\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.3457 - accuracy: 0.9746 - val_loss: 0.5623 - val_accuracy: 0.8700\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3087 - accuracy: 0.9724 - val_loss: 0.5609 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2791 - accuracy: 0.9721 - val_loss: 0.5797 - val_accuracy: 0.8540\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.2668 - accuracy: 0.9652 - val_loss: 0.5306 - val_accuracy: 0.8680\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2378 - accuracy: 0.9670 - val_loss: 0.5196 - val_accuracy: 0.8660\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.2389 - accuracy: 0.9595 - val_loss: 0.5387 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.1984 - accuracy: 0.9733 - val_loss: 0.4980 - val_accuracy: 0.8740\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.1827 - accuracy: 0.9698 - val_loss: 0.5370 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.1668 - accuracy: 0.9754 - val_loss: 0.5288 - val_accuracy: 0.8520\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.1513 - accuracy: 0.9771 - val_loss: 0.5426 - val_accuracy: 0.8400\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.1472 - accuracy: 0.9743 - val_loss: 0.5645 - val_accuracy: 0.8340\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.1308 - accuracy: 0.9769 - val_loss: 0.5306 - val_accuracy: 0.8580\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1160 - accuracy: 0.9816 - val_loss: 0.5433 - val_accuracy: 0.8620\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1172 - accuracy: 0.9905 - val_loss: 0.5541 - val_accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 0.1052 - accuracy: 0.9931 - val_loss: 0.5685 - val_accuracy: 0.8560\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.0933 - accuracy: 0.9937 - val_loss: 0.5690 - val_accuracy: 0.8560\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 15s 134ms/step - loss: 0.0982 - accuracy: 0.9919 - val_loss: 0.6070 - val_accuracy: 0.8220\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.0925 - accuracy: 0.9902 - val_loss: 0.5649 - val_accuracy: 0.8660\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.0853 - accuracy: 0.9928 - val_loss: 0.5499 - val_accuracy: 0.8460\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.0779 - accuracy: 0.9932 - val_loss: 0.5392 - val_accuracy: 0.8620\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.0817 - accuracy: 0.9931 - val_loss: 0.5585 - val_accuracy: 0.8620\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0716 - accuracy: 0.9932 - val_loss: 0.5986 - val_accuracy: 0.8360\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.0641 - accuracy: 0.9944 - val_loss: 0.6136 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.0694 - accuracy: 0.9936 - val_loss: 0.5526 - val_accuracy: 0.8720\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.0614 - accuracy: 0.9948 - val_loss: 0.5702 - val_accuracy: 0.8680\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0554 - accuracy: 0.9949 - val_loss: 0.5375 - val_accuracy: 0.8760\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0562 - accuracy: 0.9939 - val_loss: 0.5523 - val_accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0541 - accuracy: 0.9942 - val_loss: 0.5548 - val_accuracy: 0.8720\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.0502 - accuracy: 0.9941 - val_loss: 0.5649 - val_accuracy: 0.8720\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0514 - accuracy: 0.9946 - val_loss: 0.5872 - val_accuracy: 0.8680\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0514 - accuracy: 0.9932 - val_loss: 0.5923 - val_accuracy: 0.8660\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0453 - accuracy: 0.9956 - val_loss: 0.5928 - val_accuracy: 0.8640\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0422 - accuracy: 0.9943 - val_loss: 0.7531 - val_accuracy: 0.8120\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.0518 - accuracy: 0.9885 - val_loss: 0.6621 - val_accuracy: 0.8540\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.0424 - accuracy: 0.9953 - val_loss: 0.6322 - val_accuracy: 0.8620\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.0440 - accuracy: 0.9954 - val_loss: 0.6349 - val_accuracy: 0.8540\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0461 - accuracy: 0.9938 - val_loss: 0.6617 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.0337 - accuracy: 0.9962 - val_loss: 0.6071 - val_accuracy: 0.8660\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.0418 - accuracy: 0.9923 - val_loss: 0.6096 - val_accuracy: 0.8720\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.0330 - accuracy: 0.9957 - val_loss: 0.6356 - val_accuracy: 0.8640\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0391 - accuracy: 0.9953 - val_loss: 0.6286 - val_accuracy: 0.8720\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.0346 - accuracy: 0.9961 - val_loss: 0.6090 - val_accuracy: 0.8720\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.0267 - accuracy: 0.9967 - val_loss: 0.5995 - val_accuracy: 0.8680\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0253 - accuracy: 0.9968 - val_loss: 0.6117 - val_accuracy: 0.8720\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.6622 - val_accuracy: 0.8680\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.0214 - accuracy: 0.9980 - val_loss: 0.6847 - val_accuracy: 0.8580\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.0245 - accuracy: 0.9972 - val_loss: 0.6670 - val_accuracy: 0.8700\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00054: early stopping\n",
      "Done!\n",
      "Test Accuracy: 87.99999952316284\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.864\n",
      "1       relu       2  0.880\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 34s 176ms/step - loss: 1.7443 - accuracy: 0.1789 - val_loss: 1.4545 - val_accuracy: 0.6100\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 1.4254 - accuracy: 0.5832 - val_loss: 1.2293 - val_accuracy: 0.8360\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 1.1472 - accuracy: 0.7893 - val_loss: 1.0202 - val_accuracy: 0.8340\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.9335 - accuracy: 0.8660 - val_loss: 0.8944 - val_accuracy: 0.8560\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.7853 - accuracy: 0.8824 - val_loss: 0.7873 - val_accuracy: 0.8540\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.6766 - accuracy: 0.9047 - val_loss: 0.7200 - val_accuracy: 0.8580\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.5915 - accuracy: 0.9023 - val_loss: 0.6794 - val_accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.5252 - accuracy: 0.9097 - val_loss: 0.6450 - val_accuracy: 0.8640\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.4640 - accuracy: 0.9149 - val_loss: 0.6236 - val_accuracy: 0.8460\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 16s 141ms/step - loss: 0.4104 - accuracy: 0.9203 - val_loss: 0.5926 - val_accuracy: 0.8520\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.3797 - accuracy: 0.9300 - val_loss: 0.5795 - val_accuracy: 0.8520\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.3369 - accuracy: 0.9515 - val_loss: 0.5763 - val_accuracy: 0.8440\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3108 - accuracy: 0.9519 - val_loss: 0.5878 - val_accuracy: 0.8400\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.2927 - accuracy: 0.9500 - val_loss: 0.6019 - val_accuracy: 0.8380\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.2756 - accuracy: 0.9482 - val_loss: 0.6064 - val_accuracy: 0.8380\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.2621 - accuracy: 0.9493 - val_loss: 0.6209 - val_accuracy: 0.8320\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.2360 - accuracy: 0.9547 - val_loss: 0.6391 - val_accuracy: 0.8080\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.2245 - accuracy: 0.9534 - val_loss: 0.6085 - val_accuracy: 0.8240\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.2155 - accuracy: 0.9511 - val_loss: 0.6043 - val_accuracy: 0.8320\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2076 - accuracy: 0.9476 - val_loss: 0.6126 - val_accuracy: 0.8360\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.2045 - accuracy: 0.9503 - val_loss: 0.6209 - val_accuracy: 0.8460\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.1846 - accuracy: 0.9616 - val_loss: 0.6148 - val_accuracy: 0.8440\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.1895 - accuracy: 0.9536 - val_loss: 0.6552 - val_accuracy: 0.8400\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 14s 126ms/step - loss: 0.1749 - accuracy: 0.9629 - val_loss: 0.5882 - val_accuracy: 0.8440\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.1587 - accuracy: 0.9635 - val_loss: 0.6233 - val_accuracy: 0.8340\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.1739 - accuracy: 0.9582 - val_loss: 0.5920 - val_accuracy: 0.8480\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.1521 - accuracy: 0.9639 - val_loss: 0.6192 - val_accuracy: 0.8380\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1623 - accuracy: 0.9559 - val_loss: 0.6763 - val_accuracy: 0.8180\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "Done!\n",
      "Test Accuracy: 86.40000224113464\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.864\n",
      "1       relu       2  0.880\n",
      "2       relu       3  0.864\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 31s 152ms/step - loss: 1.7336 - accuracy: 0.2079 - val_loss: 1.5273 - val_accuracy: 0.4520\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 1.4769 - accuracy: 0.5535 - val_loss: 1.3036 - val_accuracy: 0.7160\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 1.2561 - accuracy: 0.6889 - val_loss: 1.0805 - val_accuracy: 0.7320\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 1.0523 - accuracy: 0.7522 - val_loss: 0.9217 - val_accuracy: 0.8080\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.9120 - accuracy: 0.7866 - val_loss: 0.8269 - val_accuracy: 0.8400\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.7963 - accuracy: 0.8259 - val_loss: 0.7397 - val_accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.7030 - accuracy: 0.8619 - val_loss: 0.6806 - val_accuracy: 0.8480\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.6045 - accuracy: 0.9019 - val_loss: 0.6715 - val_accuracy: 0.8300\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 0.5377 - accuracy: 0.9098 - val_loss: 0.6198 - val_accuracy: 0.8360\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.4880 - accuracy: 0.9117 - val_loss: 0.5669 - val_accuracy: 0.8560\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.4396 - accuracy: 0.9183 - val_loss: 0.5619 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.4008 - accuracy: 0.9211 - val_loss: 0.5567 - val_accuracy: 0.8480\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.3527 - accuracy: 0.9327 - val_loss: 0.5423 - val_accuracy: 0.8540\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3380 - accuracy: 0.9295 - val_loss: 0.5254 - val_accuracy: 0.8580\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.3081 - accuracy: 0.9367 - val_loss: 0.5260 - val_accuracy: 0.8520\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.2911 - accuracy: 0.9442 - val_loss: 0.5152 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.2771 - accuracy: 0.9417 - val_loss: 0.5265 - val_accuracy: 0.8580\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.2534 - accuracy: 0.9469 - val_loss: 0.5203 - val_accuracy: 0.8500\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.2398 - accuracy: 0.9480 - val_loss: 0.5323 - val_accuracy: 0.8560\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.2327 - accuracy: 0.9424 - val_loss: 0.5312 - val_accuracy: 0.8560\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.2064 - accuracy: 0.9627 - val_loss: 0.5246 - val_accuracy: 0.8660\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.1990 - accuracy: 0.9625 - val_loss: 0.5073 - val_accuracy: 0.8620\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.1755 - accuracy: 0.9712 - val_loss: 0.5191 - val_accuracy: 0.8580\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.1763 - accuracy: 0.9686 - val_loss: 0.5183 - val_accuracy: 0.8680\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1614 - accuracy: 0.9733 - val_loss: 0.5119 - val_accuracy: 0.8700\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1526 - accuracy: 0.9725 - val_loss: 0.5090 - val_accuracy: 0.8700\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1609 - accuracy: 0.9670 - val_loss: 0.4990 - val_accuracy: 0.8760\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.1359 - accuracy: 0.9774 - val_loss: 0.5140 - val_accuracy: 0.8740\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.1402 - accuracy: 0.9722 - val_loss: 0.5342 - val_accuracy: 0.8680\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.1282 - accuracy: 0.9763 - val_loss: 0.5177 - val_accuracy: 0.8720\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.1202 - accuracy: 0.9782 - val_loss: 0.5290 - val_accuracy: 0.8680\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.1216 - accuracy: 0.9752 - val_loss: 0.5215 - val_accuracy: 0.8720\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.1126 - accuracy: 0.9766 - val_loss: 0.5489 - val_accuracy: 0.8660\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1198 - accuracy: 0.9719 - val_loss: 0.5618 - val_accuracy: 0.8680\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.1123 - accuracy: 0.9758 - val_loss: 0.5614 - val_accuracy: 0.8640\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0962 - accuracy: 0.9809 - val_loss: 0.5577 - val_accuracy: 0.8680\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.1034 - accuracy: 0.9754 - val_loss: 0.5637 - val_accuracy: 0.8680\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.1075 - accuracy: 0.9716 - val_loss: 0.5846 - val_accuracy: 0.8580\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0934 - accuracy: 0.9767 - val_loss: 0.5992 - val_accuracy: 0.8560\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.0933 - accuracy: 0.9782 - val_loss: 0.6018 - val_accuracy: 0.8580\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.0861 - accuracy: 0.9774 - val_loss: 0.6270 - val_accuracy: 0.8460\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.0779 - accuracy: 0.9801 - val_loss: 0.6101 - val_accuracy: 0.8520\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.0860 - accuracy: 0.9755 - val_loss: 0.6048 - val_accuracy: 0.8600\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0718 - accuracy: 0.9833 - val_loss: 0.6110 - val_accuracy: 0.8560\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.0779 - accuracy: 0.9782 - val_loss: 0.6249 - val_accuracy: 0.8600\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0741 - accuracy: 0.9805 - val_loss: 0.6596 - val_accuracy: 0.8540\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.0736 - accuracy: 0.9794 - val_loss: 0.6702 - val_accuracy: 0.8520\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "Done!\n",
      "Test Accuracy: 87.59999871253967\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.864\n",
      "1       relu       2  0.880\n",
      "2       relu       3  0.864\n",
      "3       relu       4  0.876\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 31s 156ms/step - loss: 1.7965 - accuracy: 0.1757 - val_loss: 1.3777 - val_accuracy: 0.6100\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 1.3515 - accuracy: 0.6353 - val_loss: 1.1043 - val_accuracy: 0.7140\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 17s 155ms/step - loss: 1.0481 - accuracy: 0.7746 - val_loss: 0.9692 - val_accuracy: 0.8380\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.8551 - accuracy: 0.9018 - val_loss: 0.8761 - val_accuracy: 0.8480\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.7235 - accuracy: 0.9193 - val_loss: 0.7800 - val_accuracy: 0.8620\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.6412 - accuracy: 0.9096 - val_loss: 0.7065 - val_accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.5416 - accuracy: 0.9360 - val_loss: 0.7011 - val_accuracy: 0.8440\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4746 - accuracy: 0.9364 - val_loss: 0.6783 - val_accuracy: 0.8380\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4136 - accuracy: 0.9539 - val_loss: 0.6297 - val_accuracy: 0.8420\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.3754 - accuracy: 0.9521 - val_loss: 0.6681 - val_accuracy: 0.8360\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3476 - accuracy: 0.9437 - val_loss: 0.6458 - val_accuracy: 0.8380\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.2975 - accuracy: 0.9575 - val_loss: 0.6258 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.2727 - accuracy: 0.9606 - val_loss: 0.6278 - val_accuracy: 0.8320\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.2509 - accuracy: 0.9660 - val_loss: 0.5901 - val_accuracy: 0.8660\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.2323 - accuracy: 0.9694 - val_loss: 0.5770 - val_accuracy: 0.8640\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.2142 - accuracy: 0.9746 - val_loss: 0.6017 - val_accuracy: 0.8520\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.2043 - accuracy: 0.9642 - val_loss: 0.6359 - val_accuracy: 0.8420\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 0.1815 - accuracy: 0.9712 - val_loss: 0.6860 - val_accuracy: 0.8360\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 0.1746 - accuracy: 0.9767 - val_loss: 0.5818 - val_accuracy: 0.8600\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1635 - accuracy: 0.9778 - val_loss: 0.5538 - val_accuracy: 0.8740\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1513 - accuracy: 0.9810 - val_loss: 0.5859 - val_accuracy: 0.8580\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1264 - accuracy: 0.9897 - val_loss: 0.6306 - val_accuracy: 0.8560\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1240 - accuracy: 0.9895 - val_loss: 0.6133 - val_accuracy: 0.8520\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1198 - accuracy: 0.9854 - val_loss: 0.6290 - val_accuracy: 0.8560\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1179 - accuracy: 0.9857 - val_loss: 0.6464 - val_accuracy: 0.8540\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1032 - accuracy: 0.9906 - val_loss: 0.6228 - val_accuracy: 0.8560\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1053 - accuracy: 0.9863 - val_loss: 0.6455 - val_accuracy: 0.8600\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0962 - accuracy: 0.9891 - val_loss: 0.6366 - val_accuracy: 0.8580\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.0900 - accuracy: 0.9903 - val_loss: 0.6381 - val_accuracy: 0.8540\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0826 - accuracy: 0.9902 - val_loss: 0.6256 - val_accuracy: 0.8580\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0809 - accuracy: 0.9909 - val_loss: 0.6276 - val_accuracy: 0.8580\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0756 - accuracy: 0.9899 - val_loss: 0.6412 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0714 - accuracy: 0.9925 - val_loss: 0.6466 - val_accuracy: 0.8620\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0717 - accuracy: 0.9869 - val_loss: 0.6735 - val_accuracy: 0.8580\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0725 - accuracy: 0.9860 - val_loss: 0.6781 - val_accuracy: 0.8580\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0706 - accuracy: 0.9881 - val_loss: 0.6772 - val_accuracy: 0.8600\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0657 - accuracy: 0.9900 - val_loss: 0.6547 - val_accuracy: 0.8640\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.0664 - accuracy: 0.9905 - val_loss: 0.6550 - val_accuracy: 0.8620\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0636 - accuracy: 0.9882 - val_loss: 0.6596 - val_accuracy: 0.8640\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0556 - accuracy: 0.9910 - val_loss: 0.7631 - val_accuracy: 0.8380\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "Done!\n",
      "Test Accuracy: 87.40000128746033\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.864\n",
      "1       relu       2  0.880\n",
      "2       relu       3  0.864\n",
      "3       relu       4  0.876\n",
      "4       relu       5  0.874\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 30s 150ms/step - loss: 1.7123 - accuracy: 0.2930 - val_loss: 1.4144 - val_accuracy: 0.5060\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 1.2968 - accuracy: 0.6868 - val_loss: 1.0318 - val_accuracy: 0.8560\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.9493 - accuracy: 0.8973 - val_loss: 0.8715 - val_accuracy: 0.8420\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.7260 - accuracy: 0.9454 - val_loss: 0.7824 - val_accuracy: 0.8380\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.5944 - accuracy: 0.9565 - val_loss: 0.6956 - val_accuracy: 0.8600\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.5041 - accuracy: 0.9604 - val_loss: 0.6494 - val_accuracy: 0.8520\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.4226 - accuracy: 0.9674 - val_loss: 0.6178 - val_accuracy: 0.8440\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.3690 - accuracy: 0.9667 - val_loss: 0.6034 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.3147 - accuracy: 0.9691 - val_loss: 0.5632 - val_accuracy: 0.8440\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.2854 - accuracy: 0.9686 - val_loss: 0.5628 - val_accuracy: 0.8480\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.2481 - accuracy: 0.9717 - val_loss: 0.5596 - val_accuracy: 0.8460\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.2413 - accuracy: 0.9649 - val_loss: 0.5421 - val_accuracy: 0.8380\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.2034 - accuracy: 0.9734 - val_loss: 0.5082 - val_accuracy: 0.8520\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.1878 - accuracy: 0.9701 - val_loss: 0.4960 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1679 - accuracy: 0.9748 - val_loss: 0.4927 - val_accuracy: 0.8560\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1551 - accuracy: 0.9745 - val_loss: 0.4953 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1479 - accuracy: 0.9731 - val_loss: 0.5105 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.1239 - accuracy: 0.9846 - val_loss: 0.5131 - val_accuracy: 0.8620\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1292 - accuracy: 0.9847 - val_loss: 0.4740 - val_accuracy: 0.8720\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.1154 - accuracy: 0.9866 - val_loss: 0.5115 - val_accuracy: 0.8660\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.1050 - accuracy: 0.9887 - val_loss: 0.5139 - val_accuracy: 0.8660\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.1016 - accuracy: 0.9867 - val_loss: 0.5101 - val_accuracy: 0.8720\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0972 - accuracy: 0.9855 - val_loss: 0.5348 - val_accuracy: 0.8680\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0895 - accuracy: 0.9873 - val_loss: 0.5473 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0926 - accuracy: 0.9845 - val_loss: 0.5232 - val_accuracy: 0.8680\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0876 - accuracy: 0.9845 - val_loss: 0.5918 - val_accuracy: 0.8520\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0752 - accuracy: 0.9897 - val_loss: 0.5834 - val_accuracy: 0.8440\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0788 - accuracy: 0.9882 - val_loss: 0.6114 - val_accuracy: 0.8320\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0749 - accuracy: 0.9856 - val_loss: 0.5308 - val_accuracy: 0.8640\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0600 - accuracy: 0.9914 - val_loss: 0.5690 - val_accuracy: 0.8540\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0655 - accuracy: 0.9880 - val_loss: 0.5506 - val_accuracy: 0.8500\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0581 - accuracy: 0.9893 - val_loss: 0.5295 - val_accuracy: 0.8580\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0590 - accuracy: 0.9892 - val_loss: 0.5969 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0556 - accuracy: 0.9889 - val_loss: 0.5851 - val_accuracy: 0.8540\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0528 - accuracy: 0.9898 - val_loss: 0.6087 - val_accuracy: 0.8540\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 0.0550 - accuracy: 0.9888 - val_loss: 0.6144 - val_accuracy: 0.8600\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0519 - accuracy: 0.9900 - val_loss: 0.6176 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0463 - accuracy: 0.9909 - val_loss: 0.6104 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0471 - accuracy: 0.9903 - val_loss: 0.6193 - val_accuracy: 0.8460\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "Done!\n",
      "Test Accuracy: 87.1999979019165\n",
      "\n",
      "  Activation Filters    Acc\n",
      "0       relu       1  0.864\n",
      "1       relu       2  0.880\n",
      "2       relu       3  0.864\n",
      "3       relu       4  0.876\n",
      "4       relu       5  0.874\n",
      "5       relu       6  0.872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'Acc']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "\n",
    "        # encode data using\n",
    "        # Cleaning and Tokenization\n",
    "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "        # Turn the text into sequence\n",
    "        training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "        test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "        max_len = max_length(training_sequences)\n",
    "\n",
    "        # Pad the sequence to have the same size\n",
    "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        vocab_size = len(word_index)+1\n",
    "\n",
    "        # Define the model\n",
    "        model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "        # Train the model\n",
    "        acc = 0 \n",
    "        while (acc<0.85):\n",
    "            \n",
    "            model.fit([Xtrain, Xtrain], train_y, batch_size=50, epochs=100, verbose=1, \n",
    "                      callbacks=[callbacks], validation_data=([Xtest, Xtest], test_y))\n",
    "            \n",
    "            loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
    "            \n",
    "            if (acc<0.7):\n",
    "                # Re-define the model\n",
    "                model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "                print('The model is suffered from optimizing the local minimum :(')\n",
    "                \n",
    "            else:\n",
    "                print('Done!')\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
    "        print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + [acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record = record.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_RMogwG67hY"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1613879041863,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "w5GFLqMQp6Xi",
    "outputId": "a79042df-04c0-4f1c-d901-a155353c2fab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters    Acc\n",
       "1       relu       2  0.880\n",
       "3       relu       4  0.876\n",
       "4       relu       5  0.874\n",
       "5       relu       6  0.872\n",
       "0       relu       1  0.864\n",
       "2       relu       3  0.864"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.sort_values(by='Acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "jzBU87pOeAx0"
   },
   "outputs": [],
   "source": [
    "report = record.sort_values(by='Acc', ascending=False)\n",
    "report = report.to_excel('HYBRID_TREC.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiUaxK0aykWU"
   },
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4pUgiWpyutx"
   },
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5qt581_y1Q_"
   },
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 75542,
     "status": "ok",
     "timestamp": 1613881905874,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "awd7t-EdtGzb"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74169,
     "status": "ok",
     "timestamp": 1613881905881,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "jFKze3SHtG4Y",
    "outputId": "4d7c17a1-4002-4890-ca5f-e212055e2b64",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zfs__-mLzRAI"
   },
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 71200,
     "status": "ok",
     "timestamp": 1613881905883,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "mOBPMjI2tG8a"
   },
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68950,
     "status": "ok",
     "timestamp": 1613881905884,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "bpd4CXWdtHAn",
    "outputId": "cbac8ec2-fb33-4204-8608-351d38e7a994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7526 words present from 8761 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dk90wzj20A5"
   },
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_mean:  -0.003527845\n",
      "emb_std:  0.13315111\n"
     ]
    }
   ],
   "source": [
    "emb_mean = word2vec.vectors.mean()\n",
    "emb_std = word2vec.vectors.std()\n",
    "print('emb_mean: ', emb_mean)\n",
    "print('emb_std: ', emb_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1613881918001,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "KN8eakpJ21TV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index, emb_mean, emb_std):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    np.random.seed(2021)\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    # initialize the matrix with generic normal distribution values\n",
    "    embed_matrix = np.random.normal(emb_mean, emb_std, (vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.get_vector(word)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1613881920544,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "W7Mq_4fE21sO",
    "outputId": "43400d9a-9f0d-45f0-b3a1-01559f238b2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19468211,  0.08648376, -0.05924511, ..., -0.16683994,\n",
       "        -0.09975549, -0.08595189],\n",
       "       [-0.13509196, -0.07441947,  0.15388953, ..., -0.05400787,\n",
       "        -0.13156594, -0.05996158],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i, emb_mean, emb_std)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2OTr-Rm3QLP"
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2(filters = 100, kernel_size = 3, activation='relu', \n",
    "                   input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "  \n",
    "    # Channel 1\n",
    "    input1 = Input(shape=(max_length,))\n",
    "    embeddding1 = Embedding(input_dim=input_dim, \n",
    "                            output_dim=output_dim, \n",
    "                            input_length=max_length, \n",
    "                            input_shape=(max_length, ),\n",
    "                            # Assign the embedding weight with word2vec embedding marix\n",
    "                            weights = [emb_matrix],\n",
    "                            # Set the weight to be not trainable (static)\n",
    "                            trainable = False)(input1)\n",
    "    conv1 = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', \n",
    "                   kernel_constraint= MaxNorm( max_value=3, axis=[0,1]))(embeddding1)\n",
    "    pool1 = MaxPool1D(pool_size=2, strides=2)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    drop1 = Dropout(0.5)(flat1)\n",
    "    dense1 = Dense(10, activation='relu')(drop1)\n",
    "    drop1 = Dropout(0.5)(dense1)\n",
    "    out1 = Dense(units=6, activation='softmax')(drop1)\n",
    "    \n",
    "    # Channel 2\n",
    "    input2 = Input(shape=(max_length,))\n",
    "    embeddding2 = Embedding(input_dim=input_dim, \n",
    "                            output_dim=output_dim, \n",
    "                            input_length=max_length, \n",
    "                            input_shape=(max_length, ),\n",
    "                            # Assign the embedding weight with word2vec embedding marix\n",
    "                            weights = [emb_matrix],\n",
    "                            # Set the weight to be not trainable (static)\n",
    "                            trainable = False,\n",
    "                            mask_zero=True)(input2)\n",
    "    gru2 = Bidirectional(GRU(64))(embeddding2)\n",
    "    drop2 = Dropout(0.5)(gru2)\n",
    "    out2 = Dense(units=6, activation='softmax')(drop2)\n",
    "    \n",
    "    # Merge\n",
    "    merged = concatenate([out1, out2])\n",
    "    \n",
    "    # Interpretation\n",
    "    outputs = Dense(units=6, activation='softmax')(merged)\n",
    "    model = Model(inputs=[input1, input2], outputs=outputs)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile( loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1613882166955,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "x0xGZJsx3Ud0",
    "outputId": "c21cd79b-0239-4288-889a-c486500d2d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_60 (Embedding)        (None, 100, 300)     300000      input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 98, 100)      90100       embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 49, 100)      0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 4900)         0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 4900)         0           flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, 100, 300)     300000      input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 10)           49010       dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_30 (Bidirectional (None, 128)          140544      embedding_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 10)           0           dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 128)          0           bidirectional_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 6)            66          dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 6)            774         dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 12)           0           dense_121[0][0]                  \n",
      "                                                                 dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 6)            78          concatenate_30[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 880,572\n",
      "Trainable params: 280,572\n",
      "Non-trainable params: 600,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9lxRUZc3cZp"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1613884001572,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "2PAHGhxb3b4A"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=30, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1457608,
     "status": "ok",
     "timestamp": 1613885460118,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "UBgOBSen3fbO",
    "outputId": "7f4f36ad-f3a3-427f-89ec-29351db68ef2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 25s 98ms/step - loss: 1.7059 - accuracy: 0.2474 - val_loss: 1.5266 - val_accuracy: 0.4800\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.4838 - accuracy: 0.4814 - val_loss: 1.3780 - val_accuracy: 0.5540\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 1.3362 - accuracy: 0.5428 - val_loss: 1.2007 - val_accuracy: 0.7380\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.2001 - accuracy: 0.6386 - val_loss: 1.0186 - val_accuracy: 0.8120\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.0487 - accuracy: 0.7232 - val_loss: 0.8937 - val_accuracy: 0.8120\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.9167 - accuracy: 0.7750 - val_loss: 0.7844 - val_accuracy: 0.8420\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.8305 - accuracy: 0.7980 - val_loss: 0.6991 - val_accuracy: 0.8600\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.7277 - accuracy: 0.8230 - val_loss: 0.6531 - val_accuracy: 0.8540\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6935 - accuracy: 0.8219 - val_loss: 0.5924 - val_accuracy: 0.8640\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6044 - accuracy: 0.8535 - val_loss: 0.5652 - val_accuracy: 0.8660\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5710 - accuracy: 0.8551 - val_loss: 0.5384 - val_accuracy: 0.8660\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5249 - accuracy: 0.8680 - val_loss: 0.5094 - val_accuracy: 0.8680\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5016 - accuracy: 0.8656 - val_loss: 0.4694 - val_accuracy: 0.8760\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4606 - accuracy: 0.8794 - val_loss: 0.4404 - val_accuracy: 0.8780\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4192 - accuracy: 0.9022 - val_loss: 0.4246 - val_accuracy: 0.8900\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.3892 - accuracy: 0.9011 - val_loss: 0.4343 - val_accuracy: 0.8760\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.3689 - accuracy: 0.9017 - val_loss: 0.4159 - val_accuracy: 0.8780\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3516 - accuracy: 0.9135 - val_loss: 0.3978 - val_accuracy: 0.8820\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.3463 - accuracy: 0.9081 - val_loss: 0.4065 - val_accuracy: 0.8740\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.3102 - accuracy: 0.9160 - val_loss: 0.3991 - val_accuracy: 0.8800\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3075 - accuracy: 0.9161 - val_loss: 0.3824 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3063 - accuracy: 0.9190 - val_loss: 0.3794 - val_accuracy: 0.8880\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2729 - accuracy: 0.9315 - val_loss: 0.3879 - val_accuracy: 0.8900\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2664 - accuracy: 0.9343 - val_loss: 0.3918 - val_accuracy: 0.8800\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.2733 - accuracy: 0.9296 - val_loss: 0.3906 - val_accuracy: 0.8920\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2749 - accuracy: 0.9265 - val_loss: 0.3624 - val_accuracy: 0.8980\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2471 - accuracy: 0.9291 - val_loss: 0.3864 - val_accuracy: 0.8920\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2465 - accuracy: 0.9277 - val_loss: 0.3649 - val_accuracy: 0.9020\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2303 - accuracy: 0.9345 - val_loss: 0.3877 - val_accuracy: 0.8940\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2152 - accuracy: 0.9344 - val_loss: 0.4147 - val_accuracy: 0.8840\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2239 - accuracy: 0.9342 - val_loss: 0.3839 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2080 - accuracy: 0.9392 - val_loss: 0.4171 - val_accuracy: 0.8800\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.2239 - accuracy: 0.9355 - val_loss: 0.3873 - val_accuracy: 0.8920\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.2155 - accuracy: 0.9359 - val_loss: 0.3697 - val_accuracy: 0.8980\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1938 - accuracy: 0.9407 - val_loss: 0.3774 - val_accuracy: 0.8960\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1948 - accuracy: 0.9416 - val_loss: 0.3809 - val_accuracy: 0.8940\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1853 - accuracy: 0.9418 - val_loss: 0.3641 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1908 - accuracy: 0.9365 - val_loss: 0.3879 - val_accuracy: 0.8960\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1967 - accuracy: 0.9354 - val_loss: 0.4056 - val_accuracy: 0.8860\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1945 - accuracy: 0.9371 - val_loss: 0.4322 - val_accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.1819 - accuracy: 0.9408 - val_loss: 0.3939 - val_accuracy: 0.8920\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 9s 81ms/step - loss: 0.1923 - accuracy: 0.9404 - val_loss: 0.3617 - val_accuracy: 0.9020\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.1861 - accuracy: 0.9343 - val_loss: 0.4284 - val_accuracy: 0.8840\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1942 - accuracy: 0.9363 - val_loss: 0.3769 - val_accuracy: 0.8900\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.2054 - accuracy: 0.9335 - val_loss: 0.3651 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1717 - accuracy: 0.9442 - val_loss: 0.3654 - val_accuracy: 0.9040\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.1826 - accuracy: 0.9379 - val_loss: 0.4135 - val_accuracy: 0.8800\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1758 - accuracy: 0.9361 - val_loss: 0.3769 - val_accuracy: 0.8940\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.3774 - val_accuracy: 0.8960\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1809 - accuracy: 0.9363 - val_loss: 0.3853 - val_accuracy: 0.8980\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1760 - accuracy: 0.9352 - val_loss: 0.3937 - val_accuracy: 0.8920\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1580 - accuracy: 0.9483 - val_loss: 0.3347 - val_accuracy: 0.9140\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1560 - accuracy: 0.9471 - val_loss: 0.3371 - val_accuracy: 0.9100\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1665 - accuracy: 0.9409 - val_loss: 0.3605 - val_accuracy: 0.9020\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1601 - accuracy: 0.9524 - val_loss: 0.3406 - val_accuracy: 0.9100\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1535 - accuracy: 0.9480 - val_loss: 0.3983 - val_accuracy: 0.8920\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1617 - accuracy: 0.9477 - val_loss: 0.3507 - val_accuracy: 0.9060\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1503 - accuracy: 0.9499 - val_loss: 0.3460 - val_accuracy: 0.9020\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1591 - accuracy: 0.9478 - val_loss: 0.3734 - val_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1445 - accuracy: 0.9507 - val_loss: 0.3574 - val_accuracy: 0.9080\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.1559 - accuracy: 0.9490 - val_loss: 0.3532 - val_accuracy: 0.9120\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 9s 82ms/step - loss: 0.1383 - accuracy: 0.9571 - val_loss: 0.3703 - val_accuracy: 0.8980\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 9s 81ms/step - loss: 0.1456 - accuracy: 0.9521 - val_loss: 0.3738 - val_accuracy: 0.9060\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 9s 79ms/step - loss: 0.1458 - accuracy: 0.9492 - val_loss: 0.3742 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.1486 - accuracy: 0.9528 - val_loss: 0.3593 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.1415 - accuracy: 0.9550 - val_loss: 0.3520 - val_accuracy: 0.9120\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 9s 82ms/step - loss: 0.1475 - accuracy: 0.9512 - val_loss: 0.3829 - val_accuracy: 0.8980\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.1557 - accuracy: 0.9468 - val_loss: 0.4044 - val_accuracy: 0.8920\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.1511 - accuracy: 0.9522 - val_loss: 0.4087 - val_accuracy: 0.9020\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.1615 - accuracy: 0.9425 - val_loss: 0.4095 - val_accuracy: 0.8940\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.1626 - accuracy: 0.9495 - val_loss: 0.3958 - val_accuracy: 0.8980\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.1355 - accuracy: 0.9562 - val_loss: 0.4747 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1631 - accuracy: 0.9454 - val_loss: 0.4433 - val_accuracy: 0.8880\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1543 - accuracy: 0.9476 - val_loss: 0.4173 - val_accuracy: 0.8960\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.1556 - accuracy: 0.9459 - val_loss: 0.4130 - val_accuracy: 0.8940\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1453 - accuracy: 0.9492 - val_loss: 0.4407 - val_accuracy: 0.8860\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.1489 - accuracy: 0.9519 - val_loss: 0.4038 - val_accuracy: 0.9020\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1506 - accuracy: 0.9497 - val_loss: 0.4457 - val_accuracy: 0.8880\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.1481 - accuracy: 0.9501 - val_loss: 0.3924 - val_accuracy: 0.9040\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1364 - accuracy: 0.9520 - val_loss: 0.3988 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1419 - accuracy: 0.9511 - val_loss: 0.4500 - val_accuracy: 0.8860\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1414 - accuracy: 0.9503 - val_loss: 0.4269 - val_accuracy: 0.8960\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "Done!\n",
      "Test Accuracy: 91.39999747276306\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  91.399997\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 25s 97ms/step - loss: 1.6897 - accuracy: 0.3149 - val_loss: 1.4810 - val_accuracy: 0.4420\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 1.4884 - accuracy: 0.4420 - val_loss: 1.3263 - val_accuracy: 0.5300\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 1.3392 - accuracy: 0.5244 - val_loss: 1.1539 - val_accuracy: 0.7400\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 1.1870 - accuracy: 0.6744 - val_loss: 1.0267 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 1.0316 - accuracy: 0.7551 - val_loss: 0.8603 - val_accuracy: 0.8560\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.8830 - accuracy: 0.8091 - val_loss: 0.7956 - val_accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 0.7981 - accuracy: 0.8194 - val_loss: 0.6985 - val_accuracy: 0.8640\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.7180 - accuracy: 0.8427 - val_loss: 0.6389 - val_accuracy: 0.8760\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6421 - accuracy: 0.8598 - val_loss: 0.5967 - val_accuracy: 0.8760\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5666 - accuracy: 0.8787 - val_loss: 0.5894 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5119 - accuracy: 0.8913 - val_loss: 0.5245 - val_accuracy: 0.8840\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.4803 - accuracy: 0.9000 - val_loss: 0.4926 - val_accuracy: 0.8800\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 9s 79ms/step - loss: 0.4628 - accuracy: 0.8891 - val_loss: 0.4735 - val_accuracy: 0.8780\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.4149 - accuracy: 0.9068 - val_loss: 0.4648 - val_accuracy: 0.8800\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.3744 - accuracy: 0.9192 - val_loss: 0.4357 - val_accuracy: 0.8900\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.3474 - accuracy: 0.9281 - val_loss: 0.4331 - val_accuracy: 0.8820\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.3279 - accuracy: 0.9231 - val_loss: 0.4409 - val_accuracy: 0.8720\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.3045 - accuracy: 0.9242 - val_loss: 0.4266 - val_accuracy: 0.8800\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2830 - accuracy: 0.9370 - val_loss: 0.3869 - val_accuracy: 0.8960\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2645 - accuracy: 0.9391 - val_loss: 0.4019 - val_accuracy: 0.8960\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2608 - accuracy: 0.9350 - val_loss: 0.4544 - val_accuracy: 0.8640\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.2509 - accuracy: 0.9362 - val_loss: 0.4188 - val_accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.2393 - accuracy: 0.9326 - val_loss: 0.3632 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 9s 81ms/step - loss: 0.2135 - accuracy: 0.9467 - val_loss: 0.4318 - val_accuracy: 0.8660\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.2169 - accuracy: 0.9361 - val_loss: 0.3732 - val_accuracy: 0.8880\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.2020 - accuracy: 0.9393 - val_loss: 0.3501 - val_accuracy: 0.8940\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1771 - accuracy: 0.9492 - val_loss: 0.3773 - val_accuracy: 0.8880\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1883 - accuracy: 0.9416 - val_loss: 0.3424 - val_accuracy: 0.9100\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1784 - accuracy: 0.9474 - val_loss: 0.3641 - val_accuracy: 0.9040\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1615 - accuracy: 0.9502 - val_loss: 0.3528 - val_accuracy: 0.9080\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1588 - accuracy: 0.9531 - val_loss: 0.3233 - val_accuracy: 0.9180\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1597 - accuracy: 0.9609 - val_loss: 0.3432 - val_accuracy: 0.9100\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1511 - accuracy: 0.9548 - val_loss: 0.3401 - val_accuracy: 0.9120\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1482 - accuracy: 0.9607 - val_loss: 0.3749 - val_accuracy: 0.9020\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1583 - accuracy: 0.9631 - val_loss: 0.3648 - val_accuracy: 0.9120\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 9s 80ms/step - loss: 0.1404 - accuracy: 0.9606 - val_loss: 0.3913 - val_accuracy: 0.8940\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.1293 - accuracy: 0.9680 - val_loss: 0.3795 - val_accuracy: 0.9040\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.1201 - accuracy: 0.9669 - val_loss: 0.3910 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1167 - accuracy: 0.9685 - val_loss: 0.3565 - val_accuracy: 0.9040\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1189 - accuracy: 0.9650 - val_loss: 0.3903 - val_accuracy: 0.9040\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1204 - accuracy: 0.9683 - val_loss: 0.3609 - val_accuracy: 0.9040\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 0.1219 - accuracy: 0.9638 - val_loss: 0.3842 - val_accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1146 - accuracy: 0.9659 - val_loss: 0.4049 - val_accuracy: 0.9020\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1131 - accuracy: 0.9641 - val_loss: 0.3738 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.1082 - accuracy: 0.9680 - val_loss: 0.4008 - val_accuracy: 0.8960\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1039 - accuracy: 0.9698 - val_loss: 0.4101 - val_accuracy: 0.8920\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1050 - accuracy: 0.9712 - val_loss: 0.4036 - val_accuracy: 0.8960\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0981 - accuracy: 0.9699 - val_loss: 0.3385 - val_accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0944 - accuracy: 0.9683 - val_loss: 0.3552 - val_accuracy: 0.9140\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1014 - accuracy: 0.9702 - val_loss: 0.3659 - val_accuracy: 0.9080\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1050 - accuracy: 0.9703 - val_loss: 0.4061 - val_accuracy: 0.9020\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0926 - accuracy: 0.9710 - val_loss: 0.3757 - val_accuracy: 0.9100\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0859 - accuracy: 0.9755 - val_loss: 0.3869 - val_accuracy: 0.9140\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0936 - accuracy: 0.9707 - val_loss: 0.3703 - val_accuracy: 0.9060\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0820 - accuracy: 0.9767 - val_loss: 0.4693 - val_accuracy: 0.8900\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0891 - accuracy: 0.9774 - val_loss: 0.4142 - val_accuracy: 0.9100\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0905 - accuracy: 0.9720 - val_loss: 0.4605 - val_accuracy: 0.8980\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0941 - accuracy: 0.9688 - val_loss: 0.4332 - val_accuracy: 0.9020\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0986 - accuracy: 0.9688 - val_loss: 0.3837 - val_accuracy: 0.9100\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1067 - accuracy: 0.9673 - val_loss: 0.4389 - val_accuracy: 0.9020\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0912 - accuracy: 0.9712 - val_loss: 0.3829 - val_accuracy: 0.9140\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "Done!\n",
      "Test Accuracy: 91.79999828338623\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  91.399997\n",
      "1       relu       2  91.799998\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 27s 96ms/step - loss: 1.6867 - accuracy: 0.3010 - val_loss: 1.5294 - val_accuracy: 0.4580\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 1.4753 - accuracy: 0.4804 - val_loss: 1.2816 - val_accuracy: 0.5720\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 1.2530 - accuracy: 0.6315 - val_loss: 1.1212 - val_accuracy: 0.6880\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 1.1053 - accuracy: 0.7364 - val_loss: 0.9535 - val_accuracy: 0.7880\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.9556 - accuracy: 0.7864 - val_loss: 0.8262 - val_accuracy: 0.8180\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.9014 - accuracy: 0.7872 - val_loss: 0.7697 - val_accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.7603 - accuracy: 0.8377 - val_loss: 0.6795 - val_accuracy: 0.8360\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6963 - accuracy: 0.8466 - val_loss: 0.6317 - val_accuracy: 0.8360\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6216 - accuracy: 0.8664 - val_loss: 0.5463 - val_accuracy: 0.8840\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5651 - accuracy: 0.8797 - val_loss: 0.5692 - val_accuracy: 0.8460\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.5055 - accuracy: 0.8994 - val_loss: 0.5160 - val_accuracy: 0.8640\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.4747 - accuracy: 0.9000 - val_loss: 0.4659 - val_accuracy: 0.8760\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.4317 - accuracy: 0.9065 - val_loss: 0.5216 - val_accuracy: 0.8520\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.3839 - accuracy: 0.9184 - val_loss: 0.5016 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.4040 - accuracy: 0.9105 - val_loss: 0.5385 - val_accuracy: 0.8420\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.3512 - accuracy: 0.9214 - val_loss: 0.3886 - val_accuracy: 0.8980\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 0.3379 - accuracy: 0.9288 - val_loss: 0.4185 - val_accuracy: 0.8760\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.2968 - accuracy: 0.9340 - val_loss: 0.3963 - val_accuracy: 0.8860\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.2917 - accuracy: 0.9370 - val_loss: 0.4054 - val_accuracy: 0.8840\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.2643 - accuracy: 0.9405 - val_loss: 0.3672 - val_accuracy: 0.8960\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2452 - accuracy: 0.9463 - val_loss: 0.3890 - val_accuracy: 0.8920\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2476 - accuracy: 0.9445 - val_loss: 0.4092 - val_accuracy: 0.8840\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2369 - accuracy: 0.9490 - val_loss: 0.4347 - val_accuracy: 0.8720\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2066 - accuracy: 0.9523 - val_loss: 0.4273 - val_accuracy: 0.8900\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2068 - accuracy: 0.9489 - val_loss: 0.4039 - val_accuracy: 0.8860\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.2046 - accuracy: 0.9496 - val_loss: 0.3717 - val_accuracy: 0.8940\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 9s 80ms/step - loss: 0.1883 - accuracy: 0.9509 - val_loss: 0.4048 - val_accuracy: 0.8880\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1878 - accuracy: 0.9517 - val_loss: 0.3959 - val_accuracy: 0.8860\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1848 - accuracy: 0.9526 - val_loss: 0.4301 - val_accuracy: 0.8840\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1834 - accuracy: 0.9522 - val_loss: 0.3767 - val_accuracy: 0.8920\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1690 - accuracy: 0.9591 - val_loss: 0.3910 - val_accuracy: 0.8940\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.1735 - accuracy: 0.9620 - val_loss: 0.3580 - val_accuracy: 0.9060\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1522 - accuracy: 0.9633 - val_loss: 0.4003 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1474 - accuracy: 0.9683 - val_loss: 0.3631 - val_accuracy: 0.9080\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1628 - accuracy: 0.9586 - val_loss: 0.4241 - val_accuracy: 0.8960\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1402 - accuracy: 0.9666 - val_loss: 0.3727 - val_accuracy: 0.9080\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1414 - accuracy: 0.9700 - val_loss: 0.3560 - val_accuracy: 0.9200\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1530 - accuracy: 0.9625 - val_loss: 0.3793 - val_accuracy: 0.9180\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1218 - accuracy: 0.9708 - val_loss: 0.3492 - val_accuracy: 0.9180\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1413 - accuracy: 0.9610 - val_loss: 0.3773 - val_accuracy: 0.9080\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1313 - accuracy: 0.9668 - val_loss: 0.3667 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1283 - accuracy: 0.9719 - val_loss: 0.3445 - val_accuracy: 0.9200\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1158 - accuracy: 0.9729 - val_loss: 0.4045 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1149 - accuracy: 0.9724 - val_loss: 0.3679 - val_accuracy: 0.9120\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.1196 - accuracy: 0.9701 - val_loss: 0.3682 - val_accuracy: 0.9080\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.1127 - accuracy: 0.9720 - val_loss: 0.4682 - val_accuracy: 0.8920\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1178 - accuracy: 0.9710 - val_loss: 0.3446 - val_accuracy: 0.9140\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1109 - accuracy: 0.9725 - val_loss: 0.4063 - val_accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1188 - accuracy: 0.9694 - val_loss: 0.3836 - val_accuracy: 0.9120\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1188 - accuracy: 0.9676 - val_loss: 0.3146 - val_accuracy: 0.9160\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1229 - accuracy: 0.9619 - val_loss: 0.3149 - val_accuracy: 0.9260\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1232 - accuracy: 0.9661 - val_loss: 0.3163 - val_accuracy: 0.9260\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1119 - accuracy: 0.9687 - val_loss: 0.3264 - val_accuracy: 0.9280\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1128 - accuracy: 0.9694 - val_loss: 0.3528 - val_accuracy: 0.9200\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1222 - accuracy: 0.9654 - val_loss: 0.5992 - val_accuracy: 0.8620\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1278 - accuracy: 0.9609 - val_loss: 0.3637 - val_accuracy: 0.9240\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0998 - accuracy: 0.9762 - val_loss: 0.3553 - val_accuracy: 0.9160\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1062 - accuracy: 0.9732 - val_loss: 0.3722 - val_accuracy: 0.9100\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0927 - accuracy: 0.9756 - val_loss: 0.3984 - val_accuracy: 0.9100\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1040 - accuracy: 0.9693 - val_loss: 0.4112 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.1016 - accuracy: 0.9744 - val_loss: 0.3887 - val_accuracy: 0.9080\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0977 - accuracy: 0.9751 - val_loss: 0.4548 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0981 - accuracy: 0.9738 - val_loss: 0.4124 - val_accuracy: 0.9060\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0890 - accuracy: 0.9759 - val_loss: 0.3785 - val_accuracy: 0.9180\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1046 - accuracy: 0.9726 - val_loss: 0.3924 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1026 - accuracy: 0.9705 - val_loss: 0.4227 - val_accuracy: 0.9100\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0935 - accuracy: 0.9737 - val_loss: 0.4718 - val_accuracy: 0.9020\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0953 - accuracy: 0.9734 - val_loss: 0.4532 - val_accuracy: 0.9040\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.0922 - accuracy: 0.9758 - val_loss: 0.4331 - val_accuracy: 0.9060\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0900 - accuracy: 0.9744 - val_loss: 0.4707 - val_accuracy: 0.9000\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.0913 - accuracy: 0.9739 - val_loss: 0.4329 - val_accuracy: 0.8920\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.0984 - accuracy: 0.9723 - val_loss: 0.4502 - val_accuracy: 0.8980\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1013 - accuracy: 0.9716 - val_loss: 0.4778 - val_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.0834 - accuracy: 0.9748 - val_loss: 0.4615 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0857 - accuracy: 0.9764 - val_loss: 0.4493 - val_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1012 - accuracy: 0.9743 - val_loss: 0.4209 - val_accuracy: 0.9000\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0939 - accuracy: 0.9736 - val_loss: 0.4006 - val_accuracy: 0.9020\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0884 - accuracy: 0.9772 - val_loss: 0.4094 - val_accuracy: 0.9060\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.0886 - accuracy: 0.9735 - val_loss: 0.4566 - val_accuracy: 0.9020\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 8s 71ms/step - loss: 0.0903 - accuracy: 0.9756 - val_loss: 0.4016 - val_accuracy: 0.9020\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.0919 - accuracy: 0.9755 - val_loss: 0.4290 - val_accuracy: 0.8960\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0836 - accuracy: 0.9760 - val_loss: 0.4773 - val_accuracy: 0.9020\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0912 - accuracy: 0.9753 - val_loss: 0.4746 - val_accuracy: 0.8980\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00083: early stopping\n",
      "Done!\n",
      "Test Accuracy: 92.79999732971191\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  91.399997\n",
      "1       relu       2  91.799998\n",
      "2       relu       3  92.799997\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 25s 96ms/step - loss: 1.6981 - accuracy: 0.2671 - val_loss: 1.4761 - val_accuracy: 0.6040\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 1.3965 - accuracy: 0.6102 - val_loss: 1.1882 - val_accuracy: 0.7680\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 1.1383 - accuracy: 0.7914 - val_loss: 0.9576 - val_accuracy: 0.8500\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.9548 - accuracy: 0.8390 - val_loss: 0.8247 - val_accuracy: 0.8560\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.8027 - accuracy: 0.8650 - val_loss: 0.7164 - val_accuracy: 0.8620\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.6825 - accuracy: 0.8906 - val_loss: 0.6666 - val_accuracy: 0.8640\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.6647 - accuracy: 0.8648 - val_loss: 0.6021 - val_accuracy: 0.8620\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.5309 - accuracy: 0.9136 - val_loss: 0.5958 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.4850 - accuracy: 0.9119 - val_loss: 0.4979 - val_accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.4234 - accuracy: 0.9359 - val_loss: 0.4490 - val_accuracy: 0.8960\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.3752 - accuracy: 0.9381 - val_loss: 0.4779 - val_accuracy: 0.8720\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.3471 - accuracy: 0.9438 - val_loss: 0.4833 - val_accuracy: 0.8620\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.3193 - accuracy: 0.9459 - val_loss: 0.3995 - val_accuracy: 0.9100\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2895 - accuracy: 0.9494 - val_loss: 0.4140 - val_accuracy: 0.8920\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.2627 - accuracy: 0.9527 - val_loss: 0.3848 - val_accuracy: 0.8980\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.2373 - accuracy: 0.9587 - val_loss: 0.3967 - val_accuracy: 0.8880\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.2339 - accuracy: 0.9545 - val_loss: 0.3479 - val_accuracy: 0.9040\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2121 - accuracy: 0.9563 - val_loss: 0.3565 - val_accuracy: 0.9020\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.1987 - accuracy: 0.9610 - val_loss: 0.3813 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 9s 79ms/step - loss: 0.1970 - accuracy: 0.9568 - val_loss: 0.3724 - val_accuracy: 0.8940\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 9s 78ms/step - loss: 0.1762 - accuracy: 0.9617 - val_loss: 0.3710 - val_accuracy: 0.8960\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.1734 - accuracy: 0.9608 - val_loss: 0.3641 - val_accuracy: 0.8900\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 9s 84ms/step - loss: 0.1639 - accuracy: 0.9619 - val_loss: 0.3778 - val_accuracy: 0.8900\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.1638 - accuracy: 0.9602 - val_loss: 0.4114 - val_accuracy: 0.8740\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1559 - accuracy: 0.9590 - val_loss: 0.3903 - val_accuracy: 0.8920\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1852 - accuracy: 0.9552 - val_loss: 0.3395 - val_accuracy: 0.9020\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1466 - accuracy: 0.9651 - val_loss: 0.3781 - val_accuracy: 0.8980\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1345 - accuracy: 0.9630 - val_loss: 0.3403 - val_accuracy: 0.9020\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1398 - accuracy: 0.9690 - val_loss: 0.3459 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.1187 - accuracy: 0.9781 - val_loss: 0.3069 - val_accuracy: 0.9300\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 9s 78ms/step - loss: 0.1200 - accuracy: 0.9752 - val_loss: 0.3468 - val_accuracy: 0.9020\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1216 - accuracy: 0.9754 - val_loss: 0.3462 - val_accuracy: 0.9160\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1005 - accuracy: 0.9809 - val_loss: 0.3668 - val_accuracy: 0.8920\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1054 - accuracy: 0.9786 - val_loss: 0.3502 - val_accuracy: 0.9120\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0983 - accuracy: 0.9807 - val_loss: 0.3711 - val_accuracy: 0.9040\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0916 - accuracy: 0.9818 - val_loss: 0.3943 - val_accuracy: 0.9080\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0976 - accuracy: 0.9777 - val_loss: 0.3443 - val_accuracy: 0.9180\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0900 - accuracy: 0.9821 - val_loss: 0.3889 - val_accuracy: 0.8940\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1118 - accuracy: 0.9736 - val_loss: 0.2815 - val_accuracy: 0.9160\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0920 - accuracy: 0.9792 - val_loss: 0.3229 - val_accuracy: 0.9220\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0875 - accuracy: 0.9815 - val_loss: 0.3667 - val_accuracy: 0.9060\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0849 - accuracy: 0.9819 - val_loss: 0.3590 - val_accuracy: 0.9120\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0799 - accuracy: 0.9823 - val_loss: 0.4612 - val_accuracy: 0.8940\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0780 - accuracy: 0.9832 - val_loss: 0.3210 - val_accuracy: 0.9180\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0815 - accuracy: 0.9822 - val_loss: 0.3729 - val_accuracy: 0.9040\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0840 - accuracy: 0.9821 - val_loss: 0.3661 - val_accuracy: 0.9080\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0716 - accuracy: 0.9850 - val_loss: 0.3555 - val_accuracy: 0.9100\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0688 - accuracy: 0.9845 - val_loss: 0.3659 - val_accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0715 - accuracy: 0.9854 - val_loss: 0.3515 - val_accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0625 - accuracy: 0.9859 - val_loss: 0.4159 - val_accuracy: 0.8980\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0643 - accuracy: 0.9874 - val_loss: 0.4345 - val_accuracy: 0.8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0778 - accuracy: 0.9807 - val_loss: 0.3107 - val_accuracy: 0.9260\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0717 - accuracy: 0.9842 - val_loss: 0.3756 - val_accuracy: 0.9180\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0790 - accuracy: 0.9786 - val_loss: 0.4059 - val_accuracy: 0.8840\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0715 - accuracy: 0.9838 - val_loss: 0.4571 - val_accuracy: 0.8320\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0743 - accuracy: 0.9817 - val_loss: 0.3965 - val_accuracy: 0.8880\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0663 - accuracy: 0.9842 - val_loss: 0.4182 - val_accuracy: 0.8960\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0603 - accuracy: 0.9859 - val_loss: 0.2956 - val_accuracy: 0.9280\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0628 - accuracy: 0.9863 - val_loss: 0.3573 - val_accuracy: 0.9020\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0573 - accuracy: 0.9863 - val_loss: 0.3362 - val_accuracy: 0.9160\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00060: early stopping\n",
      "Done!\n",
      "Test Accuracy: 93.00000071525574\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  91.399997\n",
      "1       relu       2  91.799998\n",
      "2       relu       3  92.799997\n",
      "3       relu       4  93.000001\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 24s 93ms/step - loss: 1.7049 - accuracy: 0.2885 - val_loss: 1.5139 - val_accuracy: 0.4880\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 1.4233 - accuracy: 0.5640 - val_loss: 1.3087 - val_accuracy: 0.7240\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 1.2612 - accuracy: 0.6945 - val_loss: 1.1330 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 1.1268 - accuracy: 0.7286 - val_loss: 1.0627 - val_accuracy: 0.7620\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.0393 - accuracy: 0.7370 - val_loss: 0.9535 - val_accuracy: 0.7820\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.9666 - accuracy: 0.7419 - val_loss: 0.9084 - val_accuracy: 0.7560\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.8978 - accuracy: 0.7427 - val_loss: 0.8534 - val_accuracy: 0.7720\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.8399 - accuracy: 0.7449 - val_loss: 0.8064 - val_accuracy: 0.7820\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.7785 - accuracy: 0.7598 - val_loss: 0.7336 - val_accuracy: 0.7860\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6956 - accuracy: 0.8186 - val_loss: 0.6289 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6021 - accuracy: 0.8707 - val_loss: 0.5488 - val_accuracy: 0.8680\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5144 - accuracy: 0.8923 - val_loss: 0.5107 - val_accuracy: 0.8620\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4577 - accuracy: 0.9159 - val_loss: 0.4884 - val_accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4139 - accuracy: 0.9213 - val_loss: 0.4479 - val_accuracy: 0.8860\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.3806 - accuracy: 0.9220 - val_loss: 0.4971 - val_accuracy: 0.8480\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3461 - accuracy: 0.9318 - val_loss: 0.4232 - val_accuracy: 0.8760\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.3039 - accuracy: 0.9431 - val_loss: 0.4184 - val_accuracy: 0.8780\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.3051 - accuracy: 0.9342 - val_loss: 0.3767 - val_accuracy: 0.8980\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2457 - accuracy: 0.9527 - val_loss: 0.4140 - val_accuracy: 0.8740\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2270 - accuracy: 0.9539 - val_loss: 0.3871 - val_accuracy: 0.8820\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2273 - accuracy: 0.9476 - val_loss: 0.4036 - val_accuracy: 0.8660\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.2283 - accuracy: 0.9479 - val_loss: 0.3934 - val_accuracy: 0.8820\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1985 - accuracy: 0.9508 - val_loss: 0.3976 - val_accuracy: 0.8720\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1865 - accuracy: 0.9538 - val_loss: 0.3771 - val_accuracy: 0.8860\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2316 - accuracy: 0.9343 - val_loss: 0.3651 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1665 - accuracy: 0.9601 - val_loss: 0.3905 - val_accuracy: 0.8760\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1640 - accuracy: 0.9560 - val_loss: 0.3949 - val_accuracy: 0.8920\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1436 - accuracy: 0.9663 - val_loss: 0.3457 - val_accuracy: 0.9040\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1391 - accuracy: 0.9657 - val_loss: 0.3899 - val_accuracy: 0.8860\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1189 - accuracy: 0.9759 - val_loss: 0.3894 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1221 - accuracy: 0.9712 - val_loss: 0.3760 - val_accuracy: 0.8880\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1256 - accuracy: 0.9711 - val_loss: 0.3989 - val_accuracy: 0.8880\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1173 - accuracy: 0.9748 - val_loss: 0.3756 - val_accuracy: 0.8920\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1062 - accuracy: 0.9744 - val_loss: 0.3619 - val_accuracy: 0.9060\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1103 - accuracy: 0.9757 - val_loss: 0.3576 - val_accuracy: 0.9120\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1190 - accuracy: 0.9700 - val_loss: 0.3817 - val_accuracy: 0.8860\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1055 - accuracy: 0.9750 - val_loss: 0.4105 - val_accuracy: 0.8960\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1066 - accuracy: 0.9746 - val_loss: 0.3784 - val_accuracy: 0.8960\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0952 - accuracy: 0.9781 - val_loss: 0.3808 - val_accuracy: 0.8980\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0869 - accuracy: 0.9797 - val_loss: 0.3776 - val_accuracy: 0.9040\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0884 - accuracy: 0.9775 - val_loss: 0.3792 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0976 - accuracy: 0.9762 - val_loss: 0.3907 - val_accuracy: 0.8980\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0821 - accuracy: 0.9777 - val_loss: 0.3799 - val_accuracy: 0.8960\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0826 - accuracy: 0.9803 - val_loss: 0.4168 - val_accuracy: 0.8840\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0768 - accuracy: 0.9830 - val_loss: 0.3731 - val_accuracy: 0.9040\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0796 - accuracy: 0.9817 - val_loss: 0.3769 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0682 - accuracy: 0.9825 - val_loss: 0.3888 - val_accuracy: 0.8960\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0771 - accuracy: 0.9780 - val_loss: 0.3949 - val_accuracy: 0.9020\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0695 - accuracy: 0.9816 - val_loss: 0.4051 - val_accuracy: 0.9020\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0721 - accuracy: 0.9817 - val_loss: 0.4368 - val_accuracy: 0.8920\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0632 - accuracy: 0.9846 - val_loss: 0.4209 - val_accuracy: 0.8980\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0653 - accuracy: 0.9792 - val_loss: 0.4022 - val_accuracy: 0.8940\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0692 - accuracy: 0.9816 - val_loss: 0.4168 - val_accuracy: 0.8940\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0735 - accuracy: 0.9791 - val_loss: 0.3712 - val_accuracy: 0.9100\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0615 - accuracy: 0.9824 - val_loss: 0.4003 - val_accuracy: 0.9080\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0776 - accuracy: 0.9780 - val_loss: 0.4017 - val_accuracy: 0.8940\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0598 - accuracy: 0.9818 - val_loss: 0.4108 - val_accuracy: 0.9060\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0555 - accuracy: 0.9841 - val_loss: 0.4137 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0571 - accuracy: 0.9849 - val_loss: 0.4463 - val_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0592 - accuracy: 0.9827 - val_loss: 0.4270 - val_accuracy: 0.8980\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0715 - accuracy: 0.9810 - val_loss: 0.4302 - val_accuracy: 0.8980\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0576 - accuracy: 0.9847 - val_loss: 0.4435 - val_accuracy: 0.8900\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0594 - accuracy: 0.9852 - val_loss: 0.4031 - val_accuracy: 0.9020\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0514 - accuracy: 0.9886 - val_loss: 0.4263 - val_accuracy: 0.9020\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0580 - accuracy: 0.9840 - val_loss: 0.4324 - val_accuracy: 0.8920\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "Done!\n",
      "Test Accuracy: 91.20000004768372\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  91.399997\n",
      "1       relu       2  91.799998\n",
      "2       relu       3  92.799997\n",
      "3       relu       4  93.000001\n",
      "4       relu       5  91.200000\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 23s 94ms/step - loss: 1.7192 - accuracy: 0.2593 - val_loss: 1.5373 - val_accuracy: 0.2360\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.5112 - accuracy: 0.3983 - val_loss: 1.3254 - val_accuracy: 0.5380\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.2792 - accuracy: 0.6263 - val_loss: 1.1292 - val_accuracy: 0.7240\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 1.1058 - accuracy: 0.7078 - val_loss: 0.9828 - val_accuracy: 0.7700\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.9496 - accuracy: 0.7809 - val_loss: 0.9226 - val_accuracy: 0.7540\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.8405 - accuracy: 0.8141 - val_loss: 0.7960 - val_accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.7318 - accuracy: 0.8559 - val_loss: 0.7213 - val_accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6614 - accuracy: 0.8817 - val_loss: 0.6917 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5845 - accuracy: 0.8942 - val_loss: 0.6402 - val_accuracy: 0.8620\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5233 - accuracy: 0.9154 - val_loss: 0.5664 - val_accuracy: 0.8880\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4769 - accuracy: 0.9165 - val_loss: 0.6273 - val_accuracy: 0.8360\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4352 - accuracy: 0.9226 - val_loss: 0.5550 - val_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3770 - accuracy: 0.9433 - val_loss: 0.5032 - val_accuracy: 0.8840\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.3549 - accuracy: 0.9444 - val_loss: 0.4919 - val_accuracy: 0.8760\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.3097 - accuracy: 0.9540 - val_loss: 0.4619 - val_accuracy: 0.8880\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2884 - accuracy: 0.9531 - val_loss: 0.4720 - val_accuracy: 0.8720\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2674 - accuracy: 0.9544 - val_loss: 0.4953 - val_accuracy: 0.8560\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2418 - accuracy: 0.9600 - val_loss: 0.3953 - val_accuracy: 0.8960\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2219 - accuracy: 0.9629 - val_loss: 0.4659 - val_accuracy: 0.8720\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2140 - accuracy: 0.9633 - val_loss: 0.4120 - val_accuracy: 0.8960\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.2134 - accuracy: 0.9637 - val_loss: 0.4103 - val_accuracy: 0.8960\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1939 - accuracy: 0.9675 - val_loss: 0.3993 - val_accuracy: 0.9040\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1765 - accuracy: 0.9751 - val_loss: 0.3939 - val_accuracy: 0.8980\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1690 - accuracy: 0.9754 - val_loss: 0.3858 - val_accuracy: 0.9060\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1643 - accuracy: 0.9726 - val_loss: 0.4164 - val_accuracy: 0.8960\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1515 - accuracy: 0.9766 - val_loss: 0.4018 - val_accuracy: 0.8980\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1418 - accuracy: 0.9787 - val_loss: 0.4060 - val_accuracy: 0.8940\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1318 - accuracy: 0.9814 - val_loss: 0.3821 - val_accuracy: 0.9120\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1454 - accuracy: 0.9748 - val_loss: 0.3602 - val_accuracy: 0.9140\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1397 - accuracy: 0.9765 - val_loss: 0.3871 - val_accuracy: 0.9060\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1241 - accuracy: 0.9789 - val_loss: 0.3614 - val_accuracy: 0.9080\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1215 - accuracy: 0.9790 - val_loss: 0.3868 - val_accuracy: 0.8920\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.1272 - accuracy: 0.9774 - val_loss: 0.4324 - val_accuracy: 0.8960\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2067 - accuracy: 0.9412 - val_loss: 0.4296 - val_accuracy: 0.8840\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 62ms/step - loss: 0.1228 - accuracy: 0.9741 - val_loss: 0.4451 - val_accuracy: 0.8880\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0992 - accuracy: 0.9846 - val_loss: 0.4293 - val_accuracy: 0.8880\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0841 - accuracy: 0.9881 - val_loss: 0.3981 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.1003 - accuracy: 0.9827 - val_loss: 0.4736 - val_accuracy: 0.8720\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0875 - accuracy: 0.9854 - val_loss: 0.3895 - val_accuracy: 0.8960\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.0813 - accuracy: 0.9848 - val_loss: 0.3887 - val_accuracy: 0.9060\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0866 - accuracy: 0.9843 - val_loss: 0.4327 - val_accuracy: 0.8980\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0929 - accuracy: 0.9822 - val_loss: 0.4057 - val_accuracy: 0.8960\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0807 - accuracy: 0.9829 - val_loss: 0.3815 - val_accuracy: 0.9120\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.4485 - val_accuracy: 0.8920\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0787 - accuracy: 0.9857 - val_loss: 0.4280 - val_accuracy: 0.9020\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0816 - accuracy: 0.9837 - val_loss: 0.4219 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0839 - accuracy: 0.9835 - val_loss: 0.4038 - val_accuracy: 0.9020\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0736 - accuracy: 0.9871 - val_loss: 0.4261 - val_accuracy: 0.8980\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0802 - accuracy: 0.9830 - val_loss: 0.3628 - val_accuracy: 0.9180\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0765 - accuracy: 0.9842 - val_loss: 0.3941 - val_accuracy: 0.9080\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0730 - accuracy: 0.9838 - val_loss: 0.3748 - val_accuracy: 0.9120\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0847 - accuracy: 0.9823 - val_loss: 0.4222 - val_accuracy: 0.9100\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0605 - accuracy: 0.9880 - val_loss: 0.4049 - val_accuracy: 0.9020\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0629 - accuracy: 0.9868 - val_loss: 0.4469 - val_accuracy: 0.8960\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0648 - accuracy: 0.9859 - val_loss: 0.3659 - val_accuracy: 0.9120\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0815 - accuracy: 0.9824 - val_loss: 0.4089 - val_accuracy: 0.9040\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0752 - accuracy: 0.9831 - val_loss: 0.4071 - val_accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0614 - accuracy: 0.9872 - val_loss: 0.3618 - val_accuracy: 0.9120\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0733 - accuracy: 0.9823 - val_loss: 0.3640 - val_accuracy: 0.9060\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0672 - accuracy: 0.9843 - val_loss: 0.3767 - val_accuracy: 0.9140\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0770 - accuracy: 0.9836 - val_loss: 0.3780 - val_accuracy: 0.9080\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0708 - accuracy: 0.9843 - val_loss: 0.5427 - val_accuracy: 0.8780\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0600 - accuracy: 0.9874 - val_loss: 0.4057 - val_accuracy: 0.9040\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0735 - accuracy: 0.9823 - val_loss: 0.4147 - val_accuracy: 0.9040\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0537 - accuracy: 0.9895 - val_loss: 0.3976 - val_accuracy: 0.9080\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0605 - accuracy: 0.9849 - val_loss: 0.4338 - val_accuracy: 0.9020\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.0565 - accuracy: 0.9874 - val_loss: 0.4204 - val_accuracy: 0.9060\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.0625 - accuracy: 0.9865 - val_loss: 0.4362 - val_accuracy: 0.8980\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0550 - accuracy: 0.9858 - val_loss: 0.4450 - val_accuracy: 0.9060\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0587 - accuracy: 0.9867 - val_loss: 0.4560 - val_accuracy: 0.9020\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0571 - accuracy: 0.9880 - val_loss: 0.4439 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0605 - accuracy: 0.9862 - val_loss: 0.4794 - val_accuracy: 0.9020\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0503 - accuracy: 0.9883 - val_loss: 0.4376 - val_accuracy: 0.8960\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0474 - accuracy: 0.9890 - val_loss: 0.4494 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0579 - accuracy: 0.9877 - val_loss: 0.4515 - val_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0476 - accuracy: 0.9890 - val_loss: 0.5638 - val_accuracy: 0.8840\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0505 - accuracy: 0.9876 - val_loss: 0.4211 - val_accuracy: 0.9140\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0524 - accuracy: 0.9874 - val_loss: 0.4123 - val_accuracy: 0.9100\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0469 - accuracy: 0.9892 - val_loss: 0.4550 - val_accuracy: 0.9100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "Done!\n",
      "Test Accuracy: 91.79999828338623\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  91.399997\n",
      "1       relu       2  91.799998\n",
      "2       relu       3  92.799997\n",
      "3       relu       4  93.000001\n",
      "4       relu       5  91.200000\n",
      "5       relu       6  91.799998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "\n",
    "columns = ['Activation', 'Filters', 'Acc']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "            \n",
    "        # encode data using\n",
    "        # Cleaning and Tokenization\n",
    "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "        # Turn the text into sequence\n",
    "        training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "        test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "        max_len = max_length(training_sequences)\n",
    "\n",
    "        # Pad the sequence to have the same size\n",
    "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        vocab_size = len(word_index)+1\n",
    "        \n",
    "        emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "        \n",
    "        # Define the input shape\n",
    "        model = define_model_2(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                              max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "        # Train the model\n",
    "        acc = 0 \n",
    "        while (acc<0.85):\n",
    "            \n",
    "            model.fit([Xtrain, Xtrain], train_y, batch_size=50, epochs=100, verbose=1, \n",
    "                      callbacks=[callbacks], validation_data=([Xtest, Xtest], test_y))\n",
    "            \n",
    "            loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
    "            \n",
    "            if (acc<0.7):\n",
    "                # Re-define the model\n",
    "                model = define_model_2(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                       max_length=max_len, emb_matrix=emb_matrix)\n",
    "                print('The model is suffered from optimizing the local minimum :(')\n",
    "                \n",
    "            else:\n",
    "                print('Done!')\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
    "        print('Test Accuracy: {}'.format(acc*100))\n",
    "            \n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + [acc*100]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record2 = record2.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record2)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KPnmNi--jBK"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 1628,
     "status": "ok",
     "timestamp": 1613885469787,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "fWnzfK3r-l_N",
    "outputId": "7ac02a5a-ce7f-4831-bde6-fcd6cfb7af3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>93.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>92.799997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>91.799998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>91.799998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>91.399997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>91.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters        Acc\n",
       "3       relu       4  93.000001\n",
       "2       relu       3  92.799997\n",
       "1       relu       2  91.799998\n",
       "5       relu       6  91.799998\n",
       "0       relu       1  91.399997\n",
       "4       relu       5  91.200000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2.sort_values(by='Acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 2583,
     "status": "ok",
     "timestamp": 1613885511976,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "tVg5sjoC-70O"
   },
   "outputs": [],
   "source": [
    "report = record2.sort_values(by='Acc', ascending=False)\n",
    "report = report.to_excel('HYBRID_TREC_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzHRdT3xCrVO"
   },
   "source": [
    "# Model 3: Word2Vec Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZptM1m0C4j2"
   },
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x23ReO7fC5gW"
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 1648,
     "status": "ok",
     "timestamp": 1613885575617,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "vltDrSwlCviE"
   },
   "outputs": [],
   "source": [
    "def define_model_3(filters = 100, kernel_size = 3, activation='relu', \n",
    "                   input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "  \n",
    "    # Channel 1\n",
    "    input1 = Input(shape=(max_length,))\n",
    "    embeddding1 = Embedding(input_dim=input_dim, \n",
    "                            output_dim=output_dim, \n",
    "                            input_length=max_length, \n",
    "                            input_shape=(max_length, ),\n",
    "                            # Assign the embedding weight with word2vec embedding marix\n",
    "                            weights = [emb_matrix],\n",
    "                            # Set the weight to be not trainable (static)\n",
    "                            trainable = True)(input1)\n",
    "    conv1 = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', \n",
    "                   kernel_constraint= MaxNorm( max_value=3, axis=[0,1]))(embeddding1)\n",
    "    pool1 = MaxPool1D(pool_size=2, strides=2)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    drop1 = Dropout(0.5)(flat1)\n",
    "    dense1 = Dense(10, activation='relu')(drop1)\n",
    "    drop1 = Dropout(0.5)(dense1)\n",
    "    out1 = Dense(units=6, activation='softmax')(drop1)\n",
    "    \n",
    "    # Channel 2\n",
    "    input2 = Input(shape=(max_length,))\n",
    "    embeddding2 = Embedding(input_dim=input_dim, \n",
    "                            output_dim=output_dim, \n",
    "                            input_length=max_length, \n",
    "                            input_shape=(max_length, ),\n",
    "                            # Assign the embedding weight with word2vec embedding marix\n",
    "                            weights = [emb_matrix],\n",
    "                            # Set the weight to be not trainable (static)\n",
    "                            trainable = True,\n",
    "                            mask_zero=True)(input2)\n",
    "    gru2 = Bidirectional(GRU(64))(embeddding2)\n",
    "    drop2 = Dropout(0.5)(gru2)\n",
    "    out2 = Dense(units=6, activation='softmax')(drop2)\n",
    "    \n",
    "    # Merge\n",
    "    merged = concatenate([out1, out2])\n",
    "    \n",
    "    # Interpretation\n",
    "    outputs = Dense(units=6, activation='softmax')(merged)\n",
    "    model = Model(inputs=[input1, input2], outputs=outputs)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile( loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2791,
     "status": "ok",
     "timestamp": 1613885584226,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "ORayWvkPEAeX",
    "outputId": "cd1727ad-b0de-47eb-82a1-8cfdac702225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_75 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)        (None, 100, 300)     300000      input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 98, 100)      90100       embedding_74[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 49, 100)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 4900)         0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_76 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 4900)         0           flatten_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_75 (Embedding)        (None, 100, 300)     300000      input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 10)           49010       dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 128)          140544      embedding_75[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 10)           0           dense_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 128)          0           bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 6)            66          dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 6)            774         dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 12)           0           dense_149[0][0]                  \n",
      "                                                                 dense_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 6)            78          concatenate_37[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 880,572\n",
      "Trainable params: 880,572\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wyz3lOreDAqC"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1613885591367,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "rTsFU0aOCvys"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=30, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3474923,
     "status": "ok",
     "timestamp": 1613889168123,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "qNEEyLB1CwAj",
    "outputId": "0a9da556-87ed-41d7-92de-ec10aea1744e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 81s 147ms/step - loss: 1.6744 - accuracy: 0.3014 - val_loss: 1.4577 - val_accuracy: 0.3480\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 1.3593 - accuracy: 0.5510 - val_loss: 1.2436 - val_accuracy: 0.6360\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 1.1638 - accuracy: 0.6565 - val_loss: 1.0714 - val_accuracy: 0.6740\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.9866 - accuracy: 0.7447 - val_loss: 0.9237 - val_accuracy: 0.7360\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.8598 - accuracy: 0.7699 - val_loss: 0.8451 - val_accuracy: 0.7520\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.7280 - accuracy: 0.8416 - val_loss: 0.6887 - val_accuracy: 0.8760\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.5655 - accuracy: 0.9414 - val_loss: 0.6144 - val_accuracy: 0.8720\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.4659 - accuracy: 0.9477 - val_loss: 0.5632 - val_accuracy: 0.8880\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.3928 - accuracy: 0.9577 - val_loss: 0.5164 - val_accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.3442 - accuracy: 0.9578 - val_loss: 0.5032 - val_accuracy: 0.8760\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.3067 - accuracy: 0.9544 - val_loss: 0.5086 - val_accuracy: 0.8700\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.2667 - accuracy: 0.9652 - val_loss: 0.5006 - val_accuracy: 0.8660\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.2456 - accuracy: 0.9632 - val_loss: 0.4800 - val_accuracy: 0.8760\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.2329 - accuracy: 0.9630 - val_loss: 0.5129 - val_accuracy: 0.8720\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.2076 - accuracy: 0.9637 - val_loss: 0.4997 - val_accuracy: 0.8720\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1965 - accuracy: 0.9623 - val_loss: 0.5170 - val_accuracy: 0.8680\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1721 - accuracy: 0.9696 - val_loss: 0.5041 - val_accuracy: 0.8720\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1677 - accuracy: 0.9675 - val_loss: 0.5040 - val_accuracy: 0.8680\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1498 - accuracy: 0.9692 - val_loss: 0.5123 - val_accuracy: 0.8640\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1551 - accuracy: 0.9647 - val_loss: 0.5360 - val_accuracy: 0.8680\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1366 - accuracy: 0.9796 - val_loss: 0.5370 - val_accuracy: 0.8740\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1274 - accuracy: 0.9836 - val_loss: 0.5810 - val_accuracy: 0.8640\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.1158 - accuracy: 0.9821 - val_loss: 0.5610 - val_accuracy: 0.8660\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1172 - accuracy: 0.9781 - val_loss: 0.5167 - val_accuracy: 0.8840\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1093 - accuracy: 0.9826 - val_loss: 0.5187 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.1009 - accuracy: 0.9880 - val_loss: 0.5209 - val_accuracy: 0.8780\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0917 - accuracy: 0.9902 - val_loss: 0.5439 - val_accuracy: 0.8760\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0891 - accuracy: 0.9855 - val_loss: 0.5576 - val_accuracy: 0.8680\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0852 - accuracy: 0.9866 - val_loss: 0.5577 - val_accuracy: 0.8760\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0901 - accuracy: 0.9859 - val_loss: 0.5629 - val_accuracy: 0.8680\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0847 - accuracy: 0.9844 - val_loss: 0.5585 - val_accuracy: 0.8600\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0770 - accuracy: 0.9870 - val_loss: 0.5660 - val_accuracy: 0.8680\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0687 - accuracy: 0.9888 - val_loss: 0.5712 - val_accuracy: 0.8680\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0716 - accuracy: 0.9863 - val_loss: 0.6020 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0641 - accuracy: 0.9886 - val_loss: 0.5972 - val_accuracy: 0.8720\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0599 - accuracy: 0.9872 - val_loss: 0.5651 - val_accuracy: 0.8660\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0619 - accuracy: 0.9878 - val_loss: 0.5717 - val_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0578 - accuracy: 0.9874 - val_loss: 0.6556 - val_accuracy: 0.8540\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "Done!\n",
      "Test Accuracy: 88.80000114440918\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 29s 146ms/step - loss: 1.6617 - accuracy: 0.3044 - val_loss: 1.4648 - val_accuracy: 0.4440\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 1.3416 - accuracy: 0.5879 - val_loss: 1.2180 - val_accuracy: 0.7460\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 1.0854 - accuracy: 0.8195 - val_loss: 1.0124 - val_accuracy: 0.8520\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.8738 - accuracy: 0.9043 - val_loss: 0.8547 - val_accuracy: 0.8820\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.7290 - accuracy: 0.9248 - val_loss: 0.8171 - val_accuracy: 0.8400\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.6187 - accuracy: 0.9433 - val_loss: 0.7428 - val_accuracy: 0.8620\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.5322 - accuracy: 0.9511 - val_loss: 0.6994 - val_accuracy: 0.8540\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.4654 - accuracy: 0.9521 - val_loss: 0.6558 - val_accuracy: 0.8680\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.4140 - accuracy: 0.9581 - val_loss: 0.6608 - val_accuracy: 0.8460\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.3609 - accuracy: 0.9763 - val_loss: 0.6135 - val_accuracy: 0.8580\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.3237 - accuracy: 0.9725 - val_loss: 0.5675 - val_accuracy: 0.8700\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.2870 - accuracy: 0.9791 - val_loss: 0.5422 - val_accuracy: 0.8680\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.2462 - accuracy: 0.9845 - val_loss: 0.4976 - val_accuracy: 0.8880\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.2322 - accuracy: 0.9832 - val_loss: 0.5386 - val_accuracy: 0.8580\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.2082 - accuracy: 0.9837 - val_loss: 0.4861 - val_accuracy: 0.8760\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1850 - accuracy: 0.9843 - val_loss: 0.5111 - val_accuracy: 0.8660\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1733 - accuracy: 0.9855 - val_loss: 0.4871 - val_accuracy: 0.8840\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1580 - accuracy: 0.9845 - val_loss: 0.4857 - val_accuracy: 0.8820\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1461 - accuracy: 0.9882 - val_loss: 0.5048 - val_accuracy: 0.8700\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.1400 - accuracy: 0.9880 - val_loss: 0.5471 - val_accuracy: 0.8520\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1330 - accuracy: 0.9858 - val_loss: 0.4792 - val_accuracy: 0.8860\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1250 - accuracy: 0.9869 - val_loss: 0.4628 - val_accuracy: 0.8820\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.1257 - accuracy: 0.9842 - val_loss: 0.5008 - val_accuracy: 0.8740\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1174 - accuracy: 0.9881 - val_loss: 0.5529 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1024 - accuracy: 0.9908 - val_loss: 0.5897 - val_accuracy: 0.8380\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1021 - accuracy: 0.9872 - val_loss: 0.5251 - val_accuracy: 0.8680\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0933 - accuracy: 0.9885 - val_loss: 0.5165 - val_accuracy: 0.8760\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0801 - accuracy: 0.9946 - val_loss: 0.5140 - val_accuracy: 0.8760\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0756 - accuracy: 0.9920 - val_loss: 0.5283 - val_accuracy: 0.8720\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0795 - accuracy: 0.9899 - val_loss: 0.5178 - val_accuracy: 0.8760\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0800 - accuracy: 0.9893 - val_loss: 0.5382 - val_accuracy: 0.8740\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0689 - accuracy: 0.9911 - val_loss: 0.5897 - val_accuracy: 0.8660\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0672 - accuracy: 0.9911 - val_loss: 0.5707 - val_accuracy: 0.8740\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0690 - accuracy: 0.9908 - val_loss: 0.5579 - val_accuracy: 0.8780\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0619 - accuracy: 0.9908 - val_loss: 0.5651 - val_accuracy: 0.8740\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0603 - accuracy: 0.9906 - val_loss: 0.6199 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0555 - accuracy: 0.9930 - val_loss: 0.5644 - val_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0586 - accuracy: 0.9914 - val_loss: 0.6224 - val_accuracy: 0.8620\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0536 - accuracy: 0.9899 - val_loss: 0.6117 - val_accuracy: 0.8660\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0516 - accuracy: 0.9915 - val_loss: 0.5874 - val_accuracy: 0.8620\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0435 - accuracy: 0.9952 - val_loss: 0.5981 - val_accuracy: 0.8620\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0438 - accuracy: 0.9931 - val_loss: 0.6216 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0457 - accuracy: 0.9926 - val_loss: 0.6165 - val_accuracy: 0.8640\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00043: early stopping\n",
      "Done!\n",
      "Test Accuracy: 88.80000114440918\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "1       relu       2  88.800001\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 29s 143ms/step - loss: 1.6672 - accuracy: 0.2869 - val_loss: 1.3593 - val_accuracy: 0.5780\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 1.3057 - accuracy: 0.6495 - val_loss: 1.1542 - val_accuracy: 0.6600\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 1.0809 - accuracy: 0.7402 - val_loss: 1.0495 - val_accuracy: 0.6620\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.9147 - accuracy: 0.7845 - val_loss: 0.9892 - val_accuracy: 0.6500\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.8124 - accuracy: 0.7903 - val_loss: 0.9245 - val_accuracy: 0.6640\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.7408 - accuracy: 0.7868 - val_loss: 0.8793 - val_accuracy: 0.6680\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.6752 - accuracy: 0.7974 - val_loss: 0.8687 - val_accuracy: 0.6620\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.6280 - accuracy: 0.8067 - val_loss: 0.8217 - val_accuracy: 0.6740\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.6024 - accuracy: 0.7959 - val_loss: 0.8947 - val_accuracy: 0.6400\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.5639 - accuracy: 0.7979 - val_loss: 0.8090 - val_accuracy: 0.6520\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.5177 - accuracy: 0.8151 - val_loss: 0.7831 - val_accuracy: 0.6600\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.5025 - accuracy: 0.8158 - val_loss: 0.7593 - val_accuracy: 0.6720\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.4938 - accuracy: 0.8100 - val_loss: 0.7570 - val_accuracy: 0.6700\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.4703 - accuracy: 0.8138 - val_loss: 0.7373 - val_accuracy: 0.6580\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.4597 - accuracy: 0.8093 - val_loss: 0.7171 - val_accuracy: 0.6680\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.4432 - accuracy: 0.8051 - val_loss: 0.7543 - val_accuracy: 0.6640\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.4316 - accuracy: 0.8078 - val_loss: 0.7578 - val_accuracy: 0.6760\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.4223 - accuracy: 0.8203 - val_loss: 0.7125 - val_accuracy: 0.6860\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.4196 - accuracy: 0.8185 - val_loss: 0.6948 - val_accuracy: 0.7220\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.3980 - accuracy: 0.8462 - val_loss: 0.7537 - val_accuracy: 0.7360\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.3696 - accuracy: 0.9154 - val_loss: 0.7439 - val_accuracy: 0.7920\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.3049 - accuracy: 0.9499 - val_loss: 0.6560 - val_accuracy: 0.8320\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.2569 - accuracy: 0.9634 - val_loss: 0.6377 - val_accuracy: 0.8440\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.2314 - accuracy: 0.9609 - val_loss: 0.6278 - val_accuracy: 0.8440\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1925 - accuracy: 0.9686 - val_loss: 0.6602 - val_accuracy: 0.8360\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1934 - accuracy: 0.9664 - val_loss: 0.6432 - val_accuracy: 0.8420\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1720 - accuracy: 0.9674 - val_loss: 0.6401 - val_accuracy: 0.8340\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1582 - accuracy: 0.9712 - val_loss: 0.6203 - val_accuracy: 0.8540\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.1560 - accuracy: 0.9763 - val_loss: 0.6192 - val_accuracy: 0.8580\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.1331 - accuracy: 0.9838 - val_loss: 0.6233 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.1248 - accuracy: 0.9831 - val_loss: 0.6124 - val_accuracy: 0.8600\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1324 - accuracy: 0.9806 - val_loss: 0.6302 - val_accuracy: 0.8560\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1224 - accuracy: 0.9832 - val_loss: 0.6266 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1208 - accuracy: 0.9818 - val_loss: 0.6405 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1215 - accuracy: 0.9794 - val_loss: 0.7286 - val_accuracy: 0.8360\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1119 - accuracy: 0.9828 - val_loss: 0.6731 - val_accuracy: 0.8440\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1117 - accuracy: 0.9809 - val_loss: 0.7353 - val_accuracy: 0.8360\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0976 - accuracy: 0.9853 - val_loss: 0.7051 - val_accuracy: 0.8540\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.1024 - accuracy: 0.9830 - val_loss: 0.7480 - val_accuracy: 0.8420\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0853 - accuracy: 0.9885 - val_loss: 0.7013 - val_accuracy: 0.8660\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0976 - accuracy: 0.9838 - val_loss: 0.7402 - val_accuracy: 0.8440\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0919 - accuracy: 0.9841 - val_loss: 0.6839 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 0.0831 - accuracy: 0.9869 - val_loss: 0.6178 - val_accuracy: 0.8700\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0867 - accuracy: 0.9836 - val_loss: 0.7443 - val_accuracy: 0.8440\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0922 - accuracy: 0.9846 - val_loss: 0.7789 - val_accuracy: 0.8460\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0885 - accuracy: 0.9833 - val_loss: 0.7448 - val_accuracy: 0.8580\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0880 - accuracy: 0.9830 - val_loss: 0.7773 - val_accuracy: 0.8480\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0817 - accuracy: 0.9839 - val_loss: 0.7850 - val_accuracy: 0.8520\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0869 - accuracy: 0.9822 - val_loss: 0.7718 - val_accuracy: 0.8480\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0722 - accuracy: 0.9867 - val_loss: 0.7953 - val_accuracy: 0.8520\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0807 - accuracy: 0.9848 - val_loss: 0.8014 - val_accuracy: 0.8460\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0753 - accuracy: 0.9854 - val_loss: 0.7974 - val_accuracy: 0.8540\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0845 - accuracy: 0.9845 - val_loss: 0.8086 - val_accuracy: 0.8420\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0714 - accuracy: 0.9845 - val_loss: 0.8114 - val_accuracy: 0.8520\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0793 - accuracy: 0.9830 - val_loss: 0.8104 - val_accuracy: 0.8520\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0911 - accuracy: 0.9779 - val_loss: 0.7745 - val_accuracy: 0.8580\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0769 - accuracy: 0.9836 - val_loss: 0.7746 - val_accuracy: 0.8340\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0697 - accuracy: 0.9853 - val_loss: 0.7266 - val_accuracy: 0.8640\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0762 - accuracy: 0.9824 - val_loss: 0.7464 - val_accuracy: 0.8600\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0641 - accuracy: 0.9856 - val_loss: 0.7757 - val_accuracy: 0.8580\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0622 - accuracy: 0.9865 - val_loss: 0.7489 - val_accuracy: 0.8620\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0714 - accuracy: 0.9841 - val_loss: 0.8448 - val_accuracy: 0.8440\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0541 - accuracy: 0.9889 - val_loss: 0.8225 - val_accuracy: 0.8420\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0672 - accuracy: 0.9852 - val_loss: 0.7700 - val_accuracy: 0.8520\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0495 - accuracy: 0.9907 - val_loss: 0.8087 - val_accuracy: 0.8580\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0570 - accuracy: 0.9877 - val_loss: 0.8056 - val_accuracy: 0.8500\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0717 - accuracy: 0.9833 - val_loss: 0.8255 - val_accuracy: 0.8460\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0691 - accuracy: 0.9819 - val_loss: 0.8151 - val_accuracy: 0.8520\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0661 - accuracy: 0.9851 - val_loss: 0.8683 - val_accuracy: 0.8500\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0711 - accuracy: 0.9832 - val_loss: 0.8994 - val_accuracy: 0.8560\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0655 - accuracy: 0.9841 - val_loss: 0.8733 - val_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.0655 - accuracy: 0.9836 - val_loss: 0.8496 - val_accuracy: 0.8480\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0557 - accuracy: 0.9854 - val_loss: 0.8872 - val_accuracy: 0.8600\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00073: early stopping\n",
      "Done!\n",
      "Test Accuracy: 87.00000047683716\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "1       relu       2  88.800001\n",
      "2       relu       3  87.000000\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 29s 145ms/step - loss: 1.7443 - accuracy: 0.2502 - val_loss: 1.5570 - val_accuracy: 0.3220\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 1.4357 - accuracy: 0.4767 - val_loss: 1.2702 - val_accuracy: 0.8080\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 1.1390 - accuracy: 0.7976 - val_loss: 1.0594 - val_accuracy: 0.8220\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.9233 - accuracy: 0.8849 - val_loss: 0.9171 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.7615 - accuracy: 0.9179 - val_loss: 0.8400 - val_accuracy: 0.8420\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.6427 - accuracy: 0.9319 - val_loss: 0.7210 - val_accuracy: 0.8720\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.5675 - accuracy: 0.9326 - val_loss: 0.7215 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.5030 - accuracy: 0.9322 - val_loss: 0.6679 - val_accuracy: 0.8600\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 13s 119ms/step - loss: 0.4259 - accuracy: 0.9473 - val_loss: 0.6046 - val_accuracy: 0.8720\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.3813 - accuracy: 0.9483 - val_loss: 0.6293 - val_accuracy: 0.8480\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.3468 - accuracy: 0.9511 - val_loss: 0.5748 - val_accuracy: 0.8680\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.3111 - accuracy: 0.9569 - val_loss: 0.5639 - val_accuracy: 0.8640\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.2887 - accuracy: 0.9579 - val_loss: 0.5463 - val_accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.2541 - accuracy: 0.9710 - val_loss: 0.5377 - val_accuracy: 0.8780\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.2407 - accuracy: 0.9752 - val_loss: 0.5633 - val_accuracy: 0.8680\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.2209 - accuracy: 0.9724 - val_loss: 0.5585 - val_accuracy: 0.8720\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.2057 - accuracy: 0.9739 - val_loss: 0.5345 - val_accuracy: 0.8740\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1867 - accuracy: 0.9784 - val_loss: 0.5329 - val_accuracy: 0.8720\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1765 - accuracy: 0.9767 - val_loss: 0.5085 - val_accuracy: 0.8740\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1686 - accuracy: 0.9771 - val_loss: 0.6184 - val_accuracy: 0.8220\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1533 - accuracy: 0.9798 - val_loss: 0.5328 - val_accuracy: 0.8720\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1445 - accuracy: 0.9798 - val_loss: 0.5816 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1304 - accuracy: 0.9832 - val_loss: 0.5536 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1268 - accuracy: 0.9798 - val_loss: 0.5508 - val_accuracy: 0.8700\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1229 - accuracy: 0.9805 - val_loss: 0.5767 - val_accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1121 - accuracy: 0.9819 - val_loss: 0.6267 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1172 - accuracy: 0.9787 - val_loss: 0.6048 - val_accuracy: 0.8540\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0974 - accuracy: 0.9852 - val_loss: 0.6084 - val_accuracy: 0.8560\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.1083 - accuracy: 0.9799 - val_loss: 0.5541 - val_accuracy: 0.8660\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1010 - accuracy: 0.9806 - val_loss: 0.5687 - val_accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0925 - accuracy: 0.9827 - val_loss: 0.5906 - val_accuracy: 0.8660\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0870 - accuracy: 0.9844 - val_loss: 0.6051 - val_accuracy: 0.8660\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0830 - accuracy: 0.9854 - val_loss: 0.5910 - val_accuracy: 0.8560\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0827 - accuracy: 0.9818 - val_loss: 0.6064 - val_accuracy: 0.8560\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0748 - accuracy: 0.9830 - val_loss: 0.6020 - val_accuracy: 0.8560\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0730 - accuracy: 0.9822 - val_loss: 0.6035 - val_accuracy: 0.8580\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0702 - accuracy: 0.9840 - val_loss: 0.6516 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0643 - accuracy: 0.9851 - val_loss: 0.6195 - val_accuracy: 0.8600\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0686 - accuracy: 0.9847 - val_loss: 0.6172 - val_accuracy: 0.8580\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0664 - accuracy: 0.9853 - val_loss: 0.6218 - val_accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0595 - accuracy: 0.9853 - val_loss: 0.6219 - val_accuracy: 0.8580\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0652 - accuracy: 0.9784 - val_loss: 0.6629 - val_accuracy: 0.8620\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0661 - accuracy: 0.9829 - val_loss: 0.6798 - val_accuracy: 0.8540\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.0705 - accuracy: 0.9803 - val_loss: 0.5920 - val_accuracy: 0.8640\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "Done!\n",
      "Test Accuracy: 87.8000020980835\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "1       relu       2  88.800001\n",
      "2       relu       3  87.000000\n",
      "3       relu       4  87.800002\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 46s 301ms/step - loss: 1.6629 - accuracy: 0.3070 - val_loss: 1.4299 - val_accuracy: 0.5080\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 1.3052 - accuracy: 0.6538 - val_loss: 1.1866 - val_accuracy: 0.6840\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 1.0858 - accuracy: 0.7501 - val_loss: 1.0564 - val_accuracy: 0.8440\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.9201 - accuracy: 0.9123 - val_loss: 0.9710 - val_accuracy: 0.8280\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.7733 - accuracy: 0.9354 - val_loss: 0.8449 - val_accuracy: 0.8460\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.6467 - accuracy: 0.9420 - val_loss: 0.8298 - val_accuracy: 0.8060\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.5582 - accuracy: 0.9483 - val_loss: 0.7360 - val_accuracy: 0.8260\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.4762 - accuracy: 0.9613 - val_loss: 0.6837 - val_accuracy: 0.8320\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.4457 - accuracy: 0.9493 - val_loss: 0.6567 - val_accuracy: 0.8380\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.3866 - accuracy: 0.9564 - val_loss: 0.6175 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.3301 - accuracy: 0.9668 - val_loss: 0.6494 - val_accuracy: 0.8220\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.2952 - accuracy: 0.9676 - val_loss: 0.5697 - val_accuracy: 0.8540\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.2675 - accuracy: 0.9710 - val_loss: 0.5678 - val_accuracy: 0.8520\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.2487 - accuracy: 0.9684 - val_loss: 0.5651 - val_accuracy: 0.8480\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.2329 - accuracy: 0.9688 - val_loss: 0.5945 - val_accuracy: 0.8400\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.2104 - accuracy: 0.9704 - val_loss: 0.5319 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.1969 - accuracy: 0.9704 - val_loss: 0.5324 - val_accuracy: 0.8600\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.1852 - accuracy: 0.9704 - val_loss: 0.5023 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1673 - accuracy: 0.9722 - val_loss: 0.6672 - val_accuracy: 0.8160\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1598 - accuracy: 0.9704 - val_loss: 0.5024 - val_accuracy: 0.8640\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1456 - accuracy: 0.9746 - val_loss: 0.5629 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1395 - accuracy: 0.9728 - val_loss: 0.5605 - val_accuracy: 0.8400\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1232 - accuracy: 0.9772 - val_loss: 0.5352 - val_accuracy: 0.8520\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1295 - accuracy: 0.9732 - val_loss: 0.5808 - val_accuracy: 0.8460\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.1285 - accuracy: 0.9818 - val_loss: 0.5517 - val_accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.1070 - accuracy: 0.9888 - val_loss: 0.6107 - val_accuracy: 0.8480\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.1120 - accuracy: 0.9851 - val_loss: 0.6073 - val_accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0942 - accuracy: 0.9911 - val_loss: 0.5906 - val_accuracy: 0.8440\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0931 - accuracy: 0.9889 - val_loss: 0.5877 - val_accuracy: 0.8520\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0870 - accuracy: 0.9907 - val_loss: 0.6119 - val_accuracy: 0.8520\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.0875 - accuracy: 0.9887 - val_loss: 0.5877 - val_accuracy: 0.8560\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.0820 - accuracy: 0.9892 - val_loss: 0.6106 - val_accuracy: 0.8540\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.0782 - accuracy: 0.9905 - val_loss: 0.6138 - val_accuracy: 0.8520\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.0817 - accuracy: 0.9884 - val_loss: 0.5976 - val_accuracy: 0.8520\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 16s 141ms/step - loss: 0.0738 - accuracy: 0.9899 - val_loss: 0.6032 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.0761 - accuracy: 0.9875 - val_loss: 0.5959 - val_accuracy: 0.8540\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0711 - accuracy: 0.9889 - val_loss: 0.6231 - val_accuracy: 0.8460\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0702 - accuracy: 0.9897 - val_loss: 0.6236 - val_accuracy: 0.8460\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0668 - accuracy: 0.9895 - val_loss: 0.6686 - val_accuracy: 0.8500\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0569 - accuracy: 0.9922 - val_loss: 0.7196 - val_accuracy: 0.8340\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.0569 - accuracy: 0.9919 - val_loss: 0.6501 - val_accuracy: 0.8460\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.0621 - accuracy: 0.9893 - val_loss: 0.6085 - val_accuracy: 0.8520\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0523 - accuracy: 0.9925 - val_loss: 0.6513 - val_accuracy: 0.8500\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0578 - accuracy: 0.9892 - val_loss: 0.6745 - val_accuracy: 0.8420\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.0535 - accuracy: 0.9906 - val_loss: 0.6905 - val_accuracy: 0.8460\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.0447 - accuracy: 0.9935 - val_loss: 0.7010 - val_accuracy: 0.8520\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.0642 - accuracy: 0.9858 - val_loss: 0.6404 - val_accuracy: 0.8540\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.0562 - accuracy: 0.9899 - val_loss: 0.6507 - val_accuracy: 0.8520\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00048: early stopping\n",
      "Done!\n",
      "Test Accuracy: 86.40000224113464\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "1       relu       2  88.800001\n",
      "2       relu       3  87.000000\n",
      "3       relu       4  87.800002\n",
      "4       relu       5  86.400002\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 32s 162ms/step - loss: 1.6691 - accuracy: 0.3061 - val_loss: 1.5034 - val_accuracy: 0.4980\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 1.4218 - accuracy: 0.5393 - val_loss: 1.3591 - val_accuracy: 0.5940\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 1.2817 - accuracy: 0.6172 - val_loss: 1.3260 - val_accuracy: 0.6100\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 1.1735 - accuracy: 0.6759 - val_loss: 1.2367 - val_accuracy: 0.6020\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 1.0919 - accuracy: 0.6466 - val_loss: 1.1737 - val_accuracy: 0.5280\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 1.0091 - accuracy: 0.6491 - val_loss: 1.1212 - val_accuracy: 0.5300\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.9429 - accuracy: 0.6507 - val_loss: 1.0891 - val_accuracy: 0.5260\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.8889 - accuracy: 0.6651 - val_loss: 1.0684 - val_accuracy: 0.5200\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.8546 - accuracy: 0.6746 - val_loss: 0.8612 - val_accuracy: 0.7180\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.6917 - accuracy: 0.8145 - val_loss: 0.7734 - val_accuracy: 0.8640\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.5524 - accuracy: 0.9492 - val_loss: 0.6894 - val_accuracy: 0.8720\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.4797 - accuracy: 0.9587 - val_loss: 0.6606 - val_accuracy: 0.8460\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.4085 - accuracy: 0.9673 - val_loss: 0.6183 - val_accuracy: 0.8740\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3753 - accuracy: 0.9657 - val_loss: 0.6170 - val_accuracy: 0.8640\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.3406 - accuracy: 0.9644 - val_loss: 0.5881 - val_accuracy: 0.8660\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.3091 - accuracy: 0.9643 - val_loss: 0.6009 - val_accuracy: 0.8540\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.2741 - accuracy: 0.9681 - val_loss: 0.6036 - val_accuracy: 0.8560\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.2581 - accuracy: 0.9687 - val_loss: 0.5862 - val_accuracy: 0.8540\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.2381 - accuracy: 0.9671 - val_loss: 0.6157 - val_accuracy: 0.8420\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.2173 - accuracy: 0.9722 - val_loss: 0.5954 - val_accuracy: 0.8400\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.2019 - accuracy: 0.9723 - val_loss: 0.5893 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.1787 - accuracy: 0.9763 - val_loss: 0.6009 - val_accuracy: 0.8440\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.1679 - accuracy: 0.9747 - val_loss: 0.5940 - val_accuracy: 0.8540\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 14s 128ms/step - loss: 0.1610 - accuracy: 0.9751 - val_loss: 0.6230 - val_accuracy: 0.8460\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.1427 - accuracy: 0.9780 - val_loss: 0.5802 - val_accuracy: 0.8660\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.1412 - accuracy: 0.9835 - val_loss: 0.6101 - val_accuracy: 0.8600\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.1333 - accuracy: 0.9854 - val_loss: 0.6478 - val_accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.1297 - accuracy: 0.9847 - val_loss: 0.6248 - val_accuracy: 0.8600\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 15s 139ms/step - loss: 0.1318 - accuracy: 0.9835 - val_loss: 0.6858 - val_accuracy: 0.8380\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.1160 - accuracy: 0.9897 - val_loss: 0.6829 - val_accuracy: 0.8420\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.1101 - accuracy: 0.9894 - val_loss: 0.6050 - val_accuracy: 0.8560\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.1032 - accuracy: 0.9892 - val_loss: 0.6839 - val_accuracy: 0.8360\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 0.1049 - accuracy: 0.9869 - val_loss: 0.6897 - val_accuracy: 0.8440\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0875 - accuracy: 0.9909 - val_loss: 0.6464 - val_accuracy: 0.8580\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0935 - accuracy: 0.9896 - val_loss: 0.6738 - val_accuracy: 0.8520\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.0740 - accuracy: 0.9940 - val_loss: 0.7039 - val_accuracy: 0.8460\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0774 - accuracy: 0.9923 - val_loss: 0.7390 - val_accuracy: 0.8300\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.0719 - accuracy: 0.9925 - val_loss: 0.6942 - val_accuracy: 0.8380\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0737 - accuracy: 0.9916 - val_loss: 0.7325 - val_accuracy: 0.8460\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.0755 - accuracy: 0.9917 - val_loss: 0.7248 - val_accuracy: 0.8500\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0778 - accuracy: 0.9895 - val_loss: 0.7510 - val_accuracy: 0.8360\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.0727 - accuracy: 0.9911 - val_loss: 0.7277 - val_accuracy: 0.8440\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.0631 - accuracy: 0.9924 - val_loss: 0.7690 - val_accuracy: 0.8300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00043: early stopping\n",
      "Done!\n",
      "Test Accuracy: 87.40000128746033\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "1       relu       2  88.800001\n",
      "2       relu       3  87.000000\n",
      "3       relu       4  87.800002\n",
      "4       relu       5  86.400002\n",
      "5       relu       6  87.400001\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 34s 165ms/step - loss: 1.7882 - accuracy: 0.1983 - val_loss: 1.4702 - val_accuracy: 0.7180\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 1.3502 - accuracy: 0.7081 - val_loss: 1.1209 - val_accuracy: 0.8420\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 1.0272 - accuracy: 0.8824 - val_loss: 0.9527 - val_accuracy: 0.8580\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.8274 - accuracy: 0.9285 - val_loss: 0.8119 - val_accuracy: 0.8760\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.6661 - accuracy: 0.9505 - val_loss: 0.7257 - val_accuracy: 0.8700\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.5560 - accuracy: 0.9576 - val_loss: 0.6756 - val_accuracy: 0.8680\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.4714 - accuracy: 0.9673 - val_loss: 0.6224 - val_accuracy: 0.8860\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.4076 - accuracy: 0.9704 - val_loss: 0.5856 - val_accuracy: 0.8820\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.3620 - accuracy: 0.9722 - val_loss: 0.5853 - val_accuracy: 0.8680\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.3318 - accuracy: 0.9691 - val_loss: 0.5375 - val_accuracy: 0.8780\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.2960 - accuracy: 0.9701 - val_loss: 0.5150 - val_accuracy: 0.8860\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 0.2735 - accuracy: 0.9704 - val_loss: 0.5374 - val_accuracy: 0.8720\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.2398 - accuracy: 0.9735 - val_loss: 0.5484 - val_accuracy: 0.8560\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2159 - accuracy: 0.9791 - val_loss: 0.5218 - val_accuracy: 0.8680\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2055 - accuracy: 0.9752 - val_loss: 0.5172 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.1883 - accuracy: 0.9755 - val_loss: 0.5071 - val_accuracy: 0.8640\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.1784 - accuracy: 0.9744 - val_loss: 0.5234 - val_accuracy: 0.8660\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1627 - accuracy: 0.9756 - val_loss: 0.5255 - val_accuracy: 0.8620\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.1518 - accuracy: 0.9757 - val_loss: 0.5179 - val_accuracy: 0.8800\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.1435 - accuracy: 0.9756 - val_loss: 0.5015 - val_accuracy: 0.8820\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1345 - accuracy: 0.9767 - val_loss: 0.5249 - val_accuracy: 0.8660\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.1255 - accuracy: 0.9788 - val_loss: 0.5253 - val_accuracy: 0.8660\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.1179 - accuracy: 0.9775 - val_loss: 0.5302 - val_accuracy: 0.8680\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.1084 - accuracy: 0.9873 - val_loss: 0.5374 - val_accuracy: 0.8800\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.1091 - accuracy: 0.9913 - val_loss: 0.5269 - val_accuracy: 0.8760\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.1034 - accuracy: 0.9916 - val_loss: 0.5398 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.1010 - accuracy: 0.9919 - val_loss: 0.5669 - val_accuracy: 0.8740\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0900 - accuracy: 0.9911 - val_loss: 0.5632 - val_accuracy: 0.8740\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0796 - accuracy: 0.9938 - val_loss: 0.5564 - val_accuracy: 0.8740\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.0812 - accuracy: 0.9932 - val_loss: 0.5520 - val_accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0773 - accuracy: 0.9925 - val_loss: 0.5695 - val_accuracy: 0.8720\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0766 - accuracy: 0.9926 - val_loss: 0.5566 - val_accuracy: 0.8760\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0748 - accuracy: 0.9925 - val_loss: 0.5674 - val_accuracy: 0.8760\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0664 - accuracy: 0.9933 - val_loss: 0.5935 - val_accuracy: 0.8620\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.0694 - accuracy: 0.9923 - val_loss: 0.6172 - val_accuracy: 0.8660\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.0588 - accuracy: 0.9938 - val_loss: 0.6332 - val_accuracy: 0.8640\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0618 - accuracy: 0.9936 - val_loss: 0.6043 - val_accuracy: 0.8700\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "Done!\n",
      "Test Accuracy: 88.59999775886536\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "1       relu       2  88.800001\n",
      "2       relu       3  87.000000\n",
      "3       relu       4  87.800002\n",
      "4       relu       5  86.400002\n",
      "5       relu       6  87.400001\n",
      "6       relu       7  88.599998\n",
      "\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 33s 166ms/step - loss: 1.6505 - accuracy: 0.2994 - val_loss: 1.4540 - val_accuracy: 0.3480\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 1.3240 - accuracy: 0.5982 - val_loss: 1.1986 - val_accuracy: 0.6160\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 1.1027 - accuracy: 0.7160 - val_loss: 1.0725 - val_accuracy: 0.6220\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.9513 - accuracy: 0.7432 - val_loss: 0.9787 - val_accuracy: 0.6240\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.8544 - accuracy: 0.7514 - val_loss: 0.9309 - val_accuracy: 0.6200\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 15s 139ms/step - loss: 0.7710 - accuracy: 0.7667 - val_loss: 0.8762 - val_accuracy: 0.6200\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.7162 - accuracy: 0.7561 - val_loss: 0.8357 - val_accuracy: 0.6300\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.6606 - accuracy: 0.7636 - val_loss: 0.7946 - val_accuracy: 0.6220\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.6187 - accuracy: 0.7721 - val_loss: 0.7619 - val_accuracy: 0.6360\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.5761 - accuracy: 0.7703 - val_loss: 0.7633 - val_accuracy: 0.6180\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.5586 - accuracy: 0.7644 - val_loss: 0.7478 - val_accuracy: 0.6220\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.5466 - accuracy: 0.7562 - val_loss: 0.7584 - val_accuracy: 0.6180\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.5214 - accuracy: 0.7625 - val_loss: 0.7357 - val_accuracy: 0.6260\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.4935 - accuracy: 0.7720 - val_loss: 0.7261 - val_accuracy: 0.6180\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.4792 - accuracy: 0.7591 - val_loss: 0.7196 - val_accuracy: 0.6220\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.4562 - accuracy: 0.7663 - val_loss: 0.7261 - val_accuracy: 0.6260\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.4466 - accuracy: 0.7675 - val_loss: 0.7180 - val_accuracy: 0.6340\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4296 - accuracy: 0.8076 - val_loss: 0.6373 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.3887 - accuracy: 0.9185 - val_loss: 0.5726 - val_accuracy: 0.8680\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2879 - accuracy: 0.9656 - val_loss: 0.5416 - val_accuracy: 0.8740\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.2260 - accuracy: 0.9799 - val_loss: 0.6252 - val_accuracy: 0.8640\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1928 - accuracy: 0.9862 - val_loss: 0.4853 - val_accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 0.1656 - accuracy: 0.9902 - val_loss: 0.5136 - val_accuracy: 0.8720\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.1434 - accuracy: 0.9924 - val_loss: 0.4662 - val_accuracy: 0.8900\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.1289 - accuracy: 0.9927 - val_loss: 0.4725 - val_accuracy: 0.8920\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 0.1117 - accuracy: 0.9948 - val_loss: 0.4767 - val_accuracy: 0.8860\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1070 - accuracy: 0.9933 - val_loss: 0.4794 - val_accuracy: 0.8800\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.0940 - accuracy: 0.9949 - val_loss: 0.5484 - val_accuracy: 0.8540\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0955 - accuracy: 0.9924 - val_loss: 0.4906 - val_accuracy: 0.8740\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0778 - accuracy: 0.9968 - val_loss: 0.4962 - val_accuracy: 0.8740\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 15s 136ms/step - loss: 0.0736 - accuracy: 0.9951 - val_loss: 0.4609 - val_accuracy: 0.8880\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.0726 - accuracy: 0.9947 - val_loss: 0.4584 - val_accuracy: 0.8960\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.0700 - accuracy: 0.9950 - val_loss: 0.4538 - val_accuracy: 0.8940\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 0.0618 - accuracy: 0.9965 - val_loss: 0.5207 - val_accuracy: 0.8660\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0674 - accuracy: 0.9931 - val_loss: 0.6238 - val_accuracy: 0.8380\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 0.0556 - accuracy: 0.9964 - val_loss: 0.5117 - val_accuracy: 0.8740\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.0620 - accuracy: 0.9926 - val_loss: 0.5853 - val_accuracy: 0.8600\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.0529 - accuracy: 0.9954 - val_loss: 0.6175 - val_accuracy: 0.8540\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.0558 - accuracy: 0.9937 - val_loss: 0.5373 - val_accuracy: 0.8720\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.0496 - accuracy: 0.9959 - val_loss: 0.5876 - val_accuracy: 0.8580\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.0453 - accuracy: 0.9959 - val_loss: 0.5545 - val_accuracy: 0.8660\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0542 - accuracy: 0.9940 - val_loss: 0.5492 - val_accuracy: 0.8700\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 0.0424 - accuracy: 0.9965 - val_loss: 0.5569 - val_accuracy: 0.8640\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0431 - accuracy: 0.9951 - val_loss: 0.6529 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.0346 - accuracy: 0.9975 - val_loss: 0.6340 - val_accuracy: 0.8560\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.0315 - accuracy: 0.9977 - val_loss: 0.6163 - val_accuracy: 0.8640\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.0393 - accuracy: 0.9945 - val_loss: 0.6038 - val_accuracy: 0.8680\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.0342 - accuracy: 0.9959 - val_loss: 0.5894 - val_accuracy: 0.8760\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.0341 - accuracy: 0.9957 - val_loss: 0.6889 - val_accuracy: 0.8380\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 13s 123ms/step - loss: 0.0331 - accuracy: 0.9956 - val_loss: 0.5835 - val_accuracy: 0.8640\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.0284 - accuracy: 0.9969 - val_loss: 0.5778 - val_accuracy: 0.8760\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.0277 - accuracy: 0.9976 - val_loss: 0.5864 - val_accuracy: 0.8720\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.0311 - accuracy: 0.9966 - val_loss: 0.5874 - val_accuracy: 0.8760\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0335 - accuracy: 0.9948 - val_loss: 0.5992 - val_accuracy: 0.8780\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0271 - accuracy: 0.9961 - val_loss: 0.6018 - val_accuracy: 0.8780\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0283 - accuracy: 0.9965 - val_loss: 0.5945 - val_accuracy: 0.8760\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0286 - accuracy: 0.9959 - val_loss: 0.6125 - val_accuracy: 0.8740\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 0.0258 - accuracy: 0.9964 - val_loss: 0.6215 - val_accuracy: 0.8720\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.6060 - val_accuracy: 0.8740\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0262 - accuracy: 0.9956 - val_loss: 0.6408 - val_accuracy: 0.8720\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.0176 - accuracy: 0.9987 - val_loss: 0.6493 - val_accuracy: 0.8720\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 0.6892 - val_accuracy: 0.8560\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "Done!\n",
      "Test Accuracy: 89.60000276565552\n",
      "\n",
      "  Activation Filters        Acc\n",
      "0       relu       1  88.800001\n",
      "1       relu       2  88.800001\n",
      "2       relu       3  87.000000\n",
      "3       relu       4  87.800002\n",
      "4       relu       5  86.400002\n",
      "5       relu       6  87.400001\n",
      "6       relu       7  88.599998\n",
      "7       relu       8  89.600003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "\n",
    "columns = ['Activation', 'Filters', 'Acc']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "            \n",
    "        # encode data using\n",
    "        # Cleaning and Tokenization\n",
    "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "        # Turn the text into sequence\n",
    "        training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "        test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "        max_len = max_length(training_sequences)\n",
    "\n",
    "        # Pad the sequence to have the same size\n",
    "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        vocab_size = len(word_index)+1\n",
    "        \n",
    "        emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "        \n",
    "        # Define the input shape\n",
    "        model = define_model_3(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                              max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "        # Train the model\n",
    "        acc = 0 \n",
    "        while (acc<0.85):\n",
    "            \n",
    "            model.fit([Xtrain, Xtrain], train_y, batch_size=50, epochs=100, verbose=1, \n",
    "                      callbacks=[callbacks], validation_data=([Xtest, Xtest], test_y))\n",
    "            \n",
    "            loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
    "            \n",
    "            if (acc<0.7):\n",
    "                # Re-define the model\n",
    "                model = define_model_3(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                       max_length=max_len, emb_matrix=emb_matrix)\n",
    "                print('The model is suffered from optimizing the local minimum :(')\n",
    "                \n",
    "            else:\n",
    "                print('Done!')\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
    "        print('Test Accuracy: {}'.format(acc*100))\n",
    "            \n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + [acc*100]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record3 = record3.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record3)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXNADu3GEtB0"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 2586,
     "status": "ok",
     "timestamp": 1613889170725,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "Qmucw0I1Cwjo",
    "outputId": "c049a8a6-38a8-4a3b-ba77-4354b3fad29c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>89.600003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>88.800001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>88.800001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>7</td>\n",
       "      <td>88.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>87.800002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>87.400001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>86.400002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters        Acc\n",
       "7       relu       8  89.600003\n",
       "0       relu       1  88.800001\n",
       "1       relu       2  88.800001\n",
       "6       relu       7  88.599998\n",
       "3       relu       4  87.800002\n",
       "5       relu       6  87.400001\n",
       "2       relu       3  87.000000\n",
       "4       relu       5  86.400002"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3.sort_values(by='Acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 2579,
     "status": "ok",
     "timestamp": 1613889170726,
     "user": {
      "displayName": "Diardano Raihan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gha7uiez3sFTDx1VaTwg2sO7Gvixa7HqFQO4k5j=s64",
      "userId": "15266981897338202066"
     },
     "user_tz": -480
    },
    "id": "5p5F4TDJCw9F"
   },
   "outputs": [],
   "source": [
    "report = record3.sort_values(by='Acc', ascending=False)\n",
    "report = report.to_excel('HYBRID_TREC_3.xlsx', sheet_name='dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "272CGDx0CxR3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_TREC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
