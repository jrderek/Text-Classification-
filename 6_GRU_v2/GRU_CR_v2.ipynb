{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKA28DEUYPzJ"
   },
   "source": [
    "# GRU Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using GRU model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWK_Q-ljYPzU",
    "outputId": "d0d9e217-e3dd-4fb5-c9a2-431118321727"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSnNPyHzYPzW",
    "outputId": "19052305-ba5f-4c61-ad72-840f79d483ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KIXYTu2YPzZ"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "jcJ8JUudYPza",
    "outputId": "5b10781d-36a2-41c7-9df9-51c3f8ccd6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3775, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaknesses are minor the feel and layout of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many of our disney movies do n 't play on this...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player has a problem with dual layer dvd 's su...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i know the saying is you get what you pay for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will never purchase apex again .</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>so far , the anti spam feature seems to be ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>i did not have any of the installation problem...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>their products have been great and have saved ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3775 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     weaknesses are minor the feel and layout of th...      0  train\n",
       "1     many of our disney movies do n 't play on this...      0  train\n",
       "2     player has a problem with dual layer dvd 's su...      0  train\n",
       "3     i know the saying is you get what you pay for ...      0  train\n",
       "4                      will never purchase apex again .      0  train\n",
       "...                                                 ...    ...    ...\n",
       "3770  so far , the anti spam feature seems to be ver...      1  train\n",
       "3771  i downloaded a trial version of computer assoc...      1  train\n",
       "3772  i did not have any of the installation problem...      1  train\n",
       "3773  their products have been great and have saved ...      1  train\n",
       "3774                                                         1  train\n",
       "\n",
       "[3775 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/CR/CR.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YHwDzxpYPzb",
    "outputId": "0813bbe6-8318-4be2-fbcf-868833d5df8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3775 entries, 0 to 3774\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  3775 non-null   object\n",
      " 1   label     3775 non-null   int32 \n",
      " 2   split     3775 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 73.9+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "Dzi17sevYPzb",
    "outputId": "b78955b4-0d0f-4a62-ec20-1b9902d4a5ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2407</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          1368   1368\n",
       "1          2407   2407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mnioByMAYPzc"
   },
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "MwXfKjBZYPzd",
    "outputId": "4c9236c0-c6db-43bd-d8ec-4e3e1ca92703"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weaknesses are minor the feel and layout of the remote control are only so so . it does n 't show the complete file names of mp3s with really long names . you must cycle through every zoom setting ( 2x , 3x , 4x , 1 2x , etc . ) before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly .\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLxjj-iYPzd"
   },
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJog7pYmYPze"
   },
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4P9StZhkYPzf"
   },
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bOinS4qYPzf",
    "outputId": "599a48ad-19f8-4e32-98ab-1aeaf24f2bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  will never purchase apex again .\n",
      "Into a sequence of int: [72, 194, 285, 207, 286]\n",
      "Into a padded sequence: [ 72 194 285 207 286   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "print(\"Example of sentence: \", sentences[4])\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVkf7xgwYPzg",
    "outputId": "4a569ae1-ca57-4eb0-ee0e-4f6c2ae83e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "and 3\n",
      "i 4\n",
      "it 5\n",
      "to 6\n",
      "a 7\n",
      "is 8\n",
      "of 9\n",
      "this 10\n",
      "5336\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgM2ytQqYPzh"
   },
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "<img src=\"model.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVam-lKUYPzh"
   },
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MQ2GQWBRYPzi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
    "        # tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8g9fHVKYPzj",
    "outputId": "6821ba5f-cc61-4aa5-e7bf-c43eb7e378a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_30 (Bidirectio (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 515,169\n",
      "Trainable params: 515,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VmbXpw1bYPzj"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbFpmDcxYPzk"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFQAIfevYPzk",
    "outputId": "d0e71b1a-6c8d-4d94-c313-3551330a6842",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 25s 119ms/step - loss: 0.6104 - accuracy: 0.6610 - val_loss: 0.4242 - val_accuracy: 0.7937\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.2523 - accuracy: 0.8941 - val_loss: 0.4385 - val_accuracy: 0.8122\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.1002 - accuracy: 0.9640 - val_loss: 0.5779 - val_accuracy: 0.7989\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0501 - accuracy: 0.9837 - val_loss: 0.8091 - val_accuracy: 0.7989\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.8833 - val_accuracy: 0.7989\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 1.0663 - val_accuracy: 0.7989\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 1.2112 - val_accuracy: 0.7910\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.3251 - val_accuracy: 0.8069\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 1.1125 - val_accuracy: 0.8016\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 1.1999 - val_accuracy: 0.7804\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 9s 74ms/step - loss: 0.0316 - accuracy: 0.9886 - val_loss: 1.2541 - val_accuracy: 0.7698\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 1.0335 - val_accuracy: 0.7963\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Training 2: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 24s 111ms/step - loss: 0.6111 - accuracy: 0.6674 - val_loss: 0.4002 - val_accuracy: 0.8069\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.2728 - accuracy: 0.8963 - val_loss: 0.4074 - val_accuracy: 0.8360\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1267 - accuracy: 0.9565 - val_loss: 0.5913 - val_accuracy: 0.8042\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 0.7626 - val_accuracy: 0.7831\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 0.8392 - val_accuracy: 0.8016\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 1.0010 - val_accuracy: 0.7751\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 1.0263 - val_accuracy: 0.7857\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.1267 - val_accuracy: 0.7884\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0025 - accuracy: 0.9980 - val_loss: 1.2265 - val_accuracy: 0.7804\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0015 - accuracy: 0.9989 - val_loss: 1.2875 - val_accuracy: 0.7910\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 9.8099e-04 - accuracy: 0.9996 - val_loss: 1.3366 - val_accuracy: 0.7884\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 7.1968e-04 - accuracy: 0.9994 - val_loss: 1.3771 - val_accuracy: 0.7884\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 83.59788656234741\n",
      "Training 3: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 28s 122ms/step - loss: 0.6005 - accuracy: 0.6692 - val_loss: 0.4315 - val_accuracy: 0.7910\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.2392 - accuracy: 0.9054 - val_loss: 0.4451 - val_accuracy: 0.7778\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1186 - accuracy: 0.9584 - val_loss: 0.7333 - val_accuracy: 0.7857\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0453 - accuracy: 0.9838 - val_loss: 0.7527 - val_accuracy: 0.7778\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 1.0180 - val_accuracy: 0.7672\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.9560 - val_accuracy: 0.7778\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 1.2343 - val_accuracy: 0.7646\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0098 - accuracy: 0.9956 - val_loss: 1.4676 - val_accuracy: 0.7698\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 1.4126 - val_accuracy: 0.7063\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 1.8770 - val_accuracy: 0.7698\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 1.7061 - val_accuracy: 0.7407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "Training 4: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 23s 104ms/step - loss: 0.6110 - accuracy: 0.6525 - val_loss: 0.4580 - val_accuracy: 0.7725\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.2488 - accuracy: 0.9021 - val_loss: 0.4936 - val_accuracy: 0.7593\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 7s 66ms/step - loss: 0.1069 - accuracy: 0.9637 - val_loss: 0.6023 - val_accuracy: 0.7566\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 0.8186 - val_accuracy: 0.7434\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 1.2056 - val_accuracy: 0.7328\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.4474 - val_accuracy: 0.7381\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 1.5566 - val_accuracy: 0.7302\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 1.7822 - val_accuracy: 0.7354\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 1.9035 - val_accuracy: 0.7328\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 2.0168 - val_accuracy: 0.7275\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 7s 67ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 2.1305 - val_accuracy: 0.7249\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 77.24867463111877\n",
      "Training 5: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 25s 120ms/step - loss: 0.6096 - accuracy: 0.6416 - val_loss: 0.4550 - val_accuracy: 0.7884\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.2415 - accuracy: 0.9052 - val_loss: 0.5981 - val_accuracy: 0.7646\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1016 - accuracy: 0.9639 - val_loss: 0.8185 - val_accuracy: 0.7566\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0423 - accuracy: 0.9825 - val_loss: 1.0868 - val_accuracy: 0.7275\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 1.3258 - val_accuracy: 0.7566\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0116 - accuracy: 0.9944 - val_loss: 1.3868 - val_accuracy: 0.7487\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 1.5688 - val_accuracy: 0.7460\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.6488 - val_accuracy: 0.7566\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 1.7233 - val_accuracy: 0.7540\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 8.5226e-04 - accuracy: 0.9993 - val_loss: 1.7704 - val_accuracy: 0.7540\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.8198 - val_accuracy: 0.7513\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Training 6: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 28s 120ms/step - loss: 0.6183 - accuracy: 0.6567 - val_loss: 0.3650 - val_accuracy: 0.8302\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2872 - accuracy: 0.8839 - val_loss: 0.3509 - val_accuracy: 0.8382\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1215 - accuracy: 0.9562 - val_loss: 0.4914 - val_accuracy: 0.8355\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0618 - accuracy: 0.9794 - val_loss: 0.6322 - val_accuracy: 0.8302\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.8594 - val_accuracy: 0.8196\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.8693 - val_accuracy: 0.8329\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.8925 - val_accuracy: 0.8276\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.9621 - val_accuracy: 0.8355\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.9727 - val_accuracy: 0.8276\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.9887 - val_accuracy: 0.8064\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.0064 - accuracy: 0.9971 - val_loss: 1.0352 - val_accuracy: 0.8249\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0047 - accuracy: 0.9973 - val_loss: 1.2565 - val_accuracy: 0.8355\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 83.81962776184082\n",
      "Training 7: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 25s 111ms/step - loss: 0.6055 - accuracy: 0.6746 - val_loss: 0.4627 - val_accuracy: 0.7745\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2625 - accuracy: 0.8993 - val_loss: 0.5336 - val_accuracy: 0.7851\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1115 - accuracy: 0.9629 - val_loss: 0.7530 - val_accuracy: 0.7772\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.8883 - val_accuracy: 0.7772\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 8s 73ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 1.1954 - val_accuracy: 0.7719\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.2301 - val_accuracy: 0.7586\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 1.3409 - val_accuracy: 0.7507\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.2675 - val_accuracy: 0.7772\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 1.5145 - val_accuracy: 0.7719\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 1.3596 - val_accuracy: 0.7719\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.7241 - val_accuracy: 0.7692\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 9s 74ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 1.6172 - val_accuracy: 0.7586\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Training 8: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 25s 118ms/step - loss: 0.6116 - accuracy: 0.6408 - val_loss: 0.4457 - val_accuracy: 0.7958\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.2624 - accuracy: 0.9029 - val_loss: 0.4770 - val_accuracy: 0.8011\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.1044 - accuracy: 0.9670 - val_loss: 0.7453 - val_accuracy: 0.7772\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 8s 65ms/step - loss: 0.0468 - accuracy: 0.9871 - val_loss: 0.9918 - val_accuracy: 0.7639\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 1.3127 - val_accuracy: 0.7586\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.4740 - val_accuracy: 0.7639\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 1.4856 - val_accuracy: 0.7507\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 1.6783 - val_accuracy: 0.7586\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0079 - accuracy: 0.9961 - val_loss: 1.5004 - val_accuracy: 0.7454\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 1.7542 - val_accuracy: 0.7639\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0076 - accuracy: 0.9966 - val_loss: 1.8584 - val_accuracy: 0.7560\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0067 - accuracy: 0.9965 - val_loss: 1.8503 - val_accuracy: 0.7560\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Training 9: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 23s 104ms/step - loss: 0.6090 - accuracy: 0.6742 - val_loss: 0.4497 - val_accuracy: 0.7825\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.2513 - accuracy: 0.9018 - val_loss: 0.4776 - val_accuracy: 0.7905\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.1256 - accuracy: 0.9559 - val_loss: 0.7296 - val_accuracy: 0.7825\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.8031 - val_accuracy: 0.7692\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.0233 - accuracy: 0.9893 - val_loss: 1.0791 - val_accuracy: 0.7507\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 1.4294 - val_accuracy: 0.7666\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 1.4389 - val_accuracy: 0.7560\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 1.2557 - val_accuracy: 0.7772\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.0074 - accuracy: 0.9966 - val_loss: 1.2861 - val_accuracy: 0.7639\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.2999 - val_accuracy: 0.7533\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 8s 67ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 1.3317 - val_accuracy: 0.7533\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.3125 - val_accuracy: 0.7613\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Training 10: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 23s 98ms/step - loss: 0.6189 - accuracy: 0.6563 - val_loss: 0.4928 - val_accuracy: 0.7692\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.2600 - accuracy: 0.9037 - val_loss: 0.4852 - val_accuracy: 0.7825\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.1139 - accuracy: 0.9653 - val_loss: 0.7302 - val_accuracy: 0.7639\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.8628 - val_accuracy: 0.7719\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 1.2690 - val_accuracy: 0.7692\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 6s 61ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 1.2409 - val_accuracy: 0.7958\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.3289 - val_accuracy: 0.7560\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 1.5009 - val_accuracy: 0.7772\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 1.5300 - val_accuracy: 0.7798\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 6s 61ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.6189 - val_accuracy: 0.7798\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 6s 52ms/step - loss: 0.0018 - accuracy: 0.9983 - val_loss: 1.6922 - val_accuracy: 0.7798\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 5.3921e-04 - accuracy: 0.9996 - val_loss: 1.7601 - val_accuracy: 0.7825\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - 6s 61ms/step - loss: 4.6011e-04 - accuracy: 0.9995 - val_loss: 1.8214 - val_accuracy: 0.7825\n",
      "Epoch 14/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 6.6879e-04 - accuracy: 0.9992 - val_loss: 1.8702 - val_accuracy: 0.7825\n",
      "Epoch 15/30\n",
      "107/107 [==============================] - 6s 61ms/step - loss: 3.0974e-04 - accuracy: 0.9998 - val_loss: 1.9159 - val_accuracy: 0.7825\n",
      "Epoch 16/30\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 2.7687e-04 - accuracy: 0.9997 - val_loss: 1.9534 - val_accuracy: 0.7851\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "\n",
      "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
      "0  81.216931  83.597887  79.100531  ...  79.045093  79.575598  80.106101\n",
      "\n",
      "[1 rows x 11 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model(input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=30, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHQDegZXYPzl"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "HpsR3FAyYPzn",
    "outputId": "a5df0068-38d4-4ff7-96e5-1cca35b7df7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.216931</td>\n",
       "      <td>83.597887</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>77.248675</td>\n",
       "      <td>78.835976</td>\n",
       "      <td>83.819628</td>\n",
       "      <td>78.514588</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>80.106101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
       "0  81.216931  83.597887  79.100531  ...  79.045093  79.575598  80.106101\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "biTRtInbkwGz",
    "outputId": "bd8e73e5-90e6-4cc7-d5e1-c75a7254ab4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.216931</td>\n",
       "      <td>83.597887</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>77.248675</td>\n",
       "      <td>78.835976</td>\n",
       "      <td>83.819628</td>\n",
       "      <td>78.514588</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>80.106101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
       "0  81.216931  83.597887  79.100531  ...  79.045093  79.575598  80.106101\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols = ['acc1',\t'acc2',\t'acc3',\t'acc4',\t'acc5',\t'acc6',\t'acc7',\t'acc8',\t'acc9',\t'acc10',\t'AVG']\n",
    "# values = [81.216931,\t83.597887,\t79.100531,\t77.248675,\t78.835976,\t83.819628,\t78.514588,\t80.106103,\t79.045093, 79.575598,\t80.106101]\n",
    "# record = pd.DataFrame(data=[values] ,columns=cols)\n",
    "# record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "URDmZ1QuYPzs"
   },
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('GRU_CR_v2.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrRxBV9pYPzs"
   },
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_RzjBnoYPzt"
   },
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2wFDPtkYPzt"
   },
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ls7_5Xm1YPzu"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMxwVkoBYPzu",
    "outputId": "0d0e93fb-35e7-4e4f-c486-87c7179566a4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYNT-uSvYPzv"
   },
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0EHN_hUEYPzv"
   },
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnvUanAjYPzw",
    "outputId": "a0ed0efd-3989-4f69-ca6c-46271514bc97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5046 words present from 5336 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw9EUgADYPzw"
   },
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_mean:  -0.003527845\n",
      "emb_std:  0.13315111\n"
     ]
    }
   ],
   "source": [
    "emb_mean = word2vec.vectors.mean()\n",
    "emb_std = word2vec.vectors.std()\n",
    "print('emb_mean: ', emb_mean)\n",
    "print('emb_std: ', emb_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KiR9ukJfYPzw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index, emb_mean, emb_std):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    np.random.seed(2021)\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    # initialize the matrix with generic normal distribution values\n",
    "    embed_matrix = np.random.normal(emb_mean, emb_std, (vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.get_vector(word)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0oP3TKkYPzx",
    "outputId": "d3af4420-b184-4836-b676-48d87cab3add"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19468211,  0.08648376, -0.05924511, ..., -0.16683994,\n",
       "        -0.09975549, -0.08595189],\n",
       "       [-0.13509196, -0.07441947,  0.15388953, ..., -0.05400787,\n",
       "        -0.13156594, -0.05996158],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i, emb_mean, emb_std)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFuDpfbaYPzx"
   },
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WJDgd66cYPzy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
    "        # tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4QEfU-gYPzy",
    "outputId": "65d56112-6a06-4933-a1b8-ebc1416701de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 515,169\n",
      "Trainable params: 215,169\n",
      "Non-trainable params: 300,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoPK6vPkYPzz"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jHY1NNPRYPzz"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNB2uep2YPz0",
    "outputId": "44350b2c-d565-4916-d8e4-491bdcecc3a4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 46s 277ms/step - loss: 0.6025 - accuracy: 0.6738 - val_loss: 0.4415 - val_accuracy: 0.7751\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 23s 212ms/step - loss: 0.4317 - accuracy: 0.7959 - val_loss: 0.4320 - val_accuracy: 0.7937\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.3674 - accuracy: 0.8359 - val_loss: 0.6002 - val_accuracy: 0.6852\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.3896 - accuracy: 0.8156 - val_loss: 0.4498 - val_accuracy: 0.7963\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.3033 - accuracy: 0.8617 - val_loss: 0.4465 - val_accuracy: 0.7725\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2532 - accuracy: 0.8989 - val_loss: 0.4679 - val_accuracy: 0.7831\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.2219 - accuracy: 0.9091 - val_loss: 0.4636 - val_accuracy: 0.7963\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.1706 - accuracy: 0.9357 - val_loss: 0.5441 - val_accuracy: 0.8016\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 25s 232ms/step - loss: 0.1339 - accuracy: 0.9451 - val_loss: 0.6915 - val_accuracy: 0.7593\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 25s 229ms/step - loss: 0.1249 - accuracy: 0.9528 - val_loss: 0.6472 - val_accuracy: 0.7884\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 0.0720 - accuracy: 0.9746 - val_loss: 0.7599 - val_accuracy: 0.7725\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.0414 - accuracy: 0.9857 - val_loss: 0.9077 - val_accuracy: 0.7751\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 1.0450 - val_accuracy: 0.7698\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 1.0188 - val_accuracy: 0.7884\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.9957 - val_accuracy: 0.7989\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 24s 221ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 1.2298 - val_accuracy: 0.7646\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 1.1526 - val_accuracy: 0.7857\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 1.2009 - val_accuracy: 0.7725\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 61s 406ms/step - loss: 0.5970 - accuracy: 0.6800 - val_loss: 0.4524 - val_accuracy: 0.8069\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 30s 284ms/step - loss: 0.4106 - accuracy: 0.8081 - val_loss: 0.4177 - val_accuracy: 0.8095\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 36s 336ms/step - loss: 0.3623 - accuracy: 0.8432 - val_loss: 0.4258 - val_accuracy: 0.7857\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.3413 - accuracy: 0.8563 - val_loss: 0.4298 - val_accuracy: 0.7937\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.2946 - accuracy: 0.8727 - val_loss: 0.4105 - val_accuracy: 0.7804\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 36s 337ms/step - loss: 0.2665 - accuracy: 0.8847 - val_loss: 0.4658 - val_accuracy: 0.7857\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 38s 356ms/step - loss: 0.2266 - accuracy: 0.9158 - val_loss: 0.4682 - val_accuracy: 0.7831\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 40s 372ms/step - loss: 0.1847 - accuracy: 0.9274 - val_loss: 0.5586 - val_accuracy: 0.7963\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 37s 350ms/step - loss: 0.1453 - accuracy: 0.9427 - val_loss: 0.5883 - val_accuracy: 0.8016\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 37s 346ms/step - loss: 0.1043 - accuracy: 0.9658 - val_loss: 0.7008 - val_accuracy: 0.7831\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 37s 347ms/step - loss: 0.0630 - accuracy: 0.9741 - val_loss: 0.7813 - val_accuracy: 0.7884\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 36s 340ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 0.8360 - val_accuracy: 0.7910\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 50s 318ms/step - loss: 0.5932 - accuracy: 0.6717 - val_loss: 0.4551 - val_accuracy: 0.7619\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.4207 - accuracy: 0.8095 - val_loss: 0.4681 - val_accuracy: 0.7434\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 30s 284ms/step - loss: 0.3820 - accuracy: 0.8220 - val_loss: 0.4305 - val_accuracy: 0.7751\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 31s 293ms/step - loss: 0.3484 - accuracy: 0.8499 - val_loss: 0.4423 - val_accuracy: 0.7831\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 32s 295ms/step - loss: 0.3054 - accuracy: 0.8666 - val_loss: 0.4266 - val_accuracy: 0.7910\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.2755 - accuracy: 0.8888 - val_loss: 0.4472 - val_accuracy: 0.7989\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.2178 - accuracy: 0.9101 - val_loss: 0.4981 - val_accuracy: 0.7937\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 32s 300ms/step - loss: 0.1818 - accuracy: 0.9171 - val_loss: 0.5301 - val_accuracy: 0.7857\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 32s 297ms/step - loss: 0.1456 - accuracy: 0.9420 - val_loss: 0.5943 - val_accuracy: 0.7910\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 31s 288ms/step - loss: 0.1006 - accuracy: 0.9663 - val_loss: 0.6442 - val_accuracy: 0.8042\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 30s 282ms/step - loss: 0.1049 - accuracy: 0.9623 - val_loss: 0.8387 - val_accuracy: 0.7619\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 28s 263ms/step - loss: 0.0637 - accuracy: 0.9813 - val_loss: 0.8532 - val_accuracy: 0.7857\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 29s 270ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.9612 - val_accuracy: 0.8095\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 28s 266ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 1.0430 - val_accuracy: 0.8042\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 27s 251ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.9651 - val_accuracy: 0.8095\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 28s 260ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 1.1203 - val_accuracy: 0.8122\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.1511 - val_accuracy: 0.8175\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 1.1643 - val_accuracy: 0.8148\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 28s 260ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 1.2207 - val_accuracy: 0.8069\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 28s 260ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 1.2560 - val_accuracy: 0.8122\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 27s 255ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.2729 - val_accuracy: 0.8148\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 26s 245ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.3298 - val_accuracy: 0.8148\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 25s 230ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.3018 - val_accuracy: 0.8148\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 26s 239ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 1.5157 - val_accuracy: 0.8016\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 25s 237ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 1.4201 - val_accuracy: 0.8122\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 26s 241ms/step - loss: 0.0271 - accuracy: 0.9893 - val_loss: 1.1162 - val_accuracy: 0.7910\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 25s 235ms/step - loss: 0.0564 - accuracy: 0.9776 - val_loss: 0.9567 - val_accuracy: 0.7910\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Test Accuracy: 81.7460298538208\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 71s 493ms/step - loss: 0.5910 - accuracy: 0.6693 - val_loss: 0.4641 - val_accuracy: 0.8016\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 38s 353ms/step - loss: 0.4117 - accuracy: 0.8163 - val_loss: 0.4529 - val_accuracy: 0.7831\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 37s 341ms/step - loss: 0.3820 - accuracy: 0.8224 - val_loss: 0.4549 - val_accuracy: 0.7963\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 36s 338ms/step - loss: 0.3425 - accuracy: 0.8494 - val_loss: 0.4392 - val_accuracy: 0.8095\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 37s 347ms/step - loss: 0.2927 - accuracy: 0.8694 - val_loss: 0.4768 - val_accuracy: 0.7831\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.2801 - accuracy: 0.8803 - val_loss: 0.5339 - val_accuracy: 0.7751\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 37s 343ms/step - loss: 0.2352 - accuracy: 0.8978 - val_loss: 0.5849 - val_accuracy: 0.7593\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 37s 349ms/step - loss: 0.1861 - accuracy: 0.9202 - val_loss: 0.5044 - val_accuracy: 0.7884\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 36s 338ms/step - loss: 0.1509 - accuracy: 0.9414 - val_loss: 0.6796 - val_accuracy: 0.7910\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 36s 341ms/step - loss: 0.1283 - accuracy: 0.9492 - val_loss: 0.6421 - val_accuracy: 0.7884\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 36s 339ms/step - loss: 0.0990 - accuracy: 0.9649 - val_loss: 0.7610 - val_accuracy: 0.8175\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 36s 333ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.8630 - val_accuracy: 0.8016\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 0.9818 - val_accuracy: 0.8122\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 36s 334ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.9289 - val_accuracy: 0.8228\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 35s 323ms/step - loss: 0.0135 - accuracy: 0.9967 - val_loss: 1.0751 - val_accuracy: 0.8069\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 36s 338ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 1.0939 - val_accuracy: 0.8228\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 35s 325ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 1.1420 - val_accuracy: 0.8175\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 36s 333ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.2095 - val_accuracy: 0.8228\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 36s 336ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 1.2403 - val_accuracy: 0.8201\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 1.2100 - val_accuracy: 0.8095\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 35s 327ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 1.2973 - val_accuracy: 0.7963\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 36s 336ms/step - loss: 0.0876 - accuracy: 0.9708 - val_loss: 0.9817 - val_accuracy: 0.7910\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 35s 332ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 1.0768 - val_accuracy: 0.8042\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 36s 338ms/step - loss: 0.0142 - accuracy: 0.9944 - val_loss: 1.1505 - val_accuracy: 0.8095\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 82.27513432502747\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 61s 423ms/step - loss: 0.5929 - accuracy: 0.6731 - val_loss: 0.4599 - val_accuracy: 0.7751\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 37s 349ms/step - loss: 0.4154 - accuracy: 0.8070 - val_loss: 0.5106 - val_accuracy: 0.7222\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 41s 379ms/step - loss: 0.3923 - accuracy: 0.8207 - val_loss: 0.4340 - val_accuracy: 0.7804\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 43s 403ms/step - loss: 0.3428 - accuracy: 0.8464 - val_loss: 0.4344 - val_accuracy: 0.8042\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 45s 422ms/step - loss: 0.3019 - accuracy: 0.8641 - val_loss: 0.4738 - val_accuracy: 0.7698\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 45s 418ms/step - loss: 0.2656 - accuracy: 0.8874 - val_loss: 0.4948 - val_accuracy: 0.7751\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.2467 - accuracy: 0.8949 - val_loss: 0.5717 - val_accuracy: 0.7725\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.1864 - accuracy: 0.9273 - val_loss: 0.5325 - val_accuracy: 0.8042\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.1597 - accuracy: 0.9384 - val_loss: 0.6182 - val_accuracy: 0.7910\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 43s 400ms/step - loss: 0.1230 - accuracy: 0.9610 - val_loss: 0.6692 - val_accuracy: 0.8016\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 43s 399ms/step - loss: 0.0822 - accuracy: 0.9713 - val_loss: 0.7027 - val_accuracy: 0.8069\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.0530 - accuracy: 0.9851 - val_loss: 1.0536 - val_accuracy: 0.7831\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.0380 - accuracy: 0.9850 - val_loss: 1.0772 - val_accuracy: 0.7751\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 45s 419ms/step - loss: 0.0519 - accuracy: 0.9837 - val_loss: 1.0324 - val_accuracy: 0.8016\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 1.1677 - val_accuracy: 0.7937\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 44s 407ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 1.0059 - val_accuracy: 0.7910\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 0.9809 - val_accuracy: 0.8016\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.0451 - val_accuracy: 0.7963\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 43s 407ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 1.1711 - val_accuracy: 0.7963\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 44s 410ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 1.1473 - val_accuracy: 0.8069\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 43s 407ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.1763 - val_accuracy: 0.8095\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 42s 395ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.2236 - val_accuracy: 0.8016\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 43s 404ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 1.3693 - val_accuracy: 0.8042\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 43s 400ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 1.3198 - val_accuracy: 0.8069\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 42s 389ms/step - loss: 8.7901e-04 - accuracy: 0.9996 - val_loss: 1.3411 - val_accuracy: 0.8016\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 43s 401ms/step - loss: 7.7847e-04 - accuracy: 0.9997 - val_loss: 1.3827 - val_accuracy: 0.8042\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 1.4087 - val_accuracy: 0.8016\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 45s 418ms/step - loss: 9.0736e-04 - accuracy: 0.9996 - val_loss: 1.3971 - val_accuracy: 0.8016\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 1.3758 - val_accuracy: 0.7937\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 42s 395ms/step - loss: 0.1409 - accuracy: 0.9456 - val_loss: 0.9278 - val_accuracy: 0.7831\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 44s 407ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 1.1570 - val_accuracy: 0.7804\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 55s 368ms/step - loss: 0.6022 - accuracy: 0.6597 - val_loss: 0.4451 - val_accuracy: 0.7851\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 49s 461ms/step - loss: 0.4236 - accuracy: 0.8134 - val_loss: 0.4142 - val_accuracy: 0.8090\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 42s 393ms/step - loss: 0.3726 - accuracy: 0.8361 - val_loss: 0.4107 - val_accuracy: 0.8090\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 40s 373ms/step - loss: 0.3418 - accuracy: 0.8478 - val_loss: 0.4149 - val_accuracy: 0.8143\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 39s 366ms/step - loss: 0.3029 - accuracy: 0.8617 - val_loss: 0.3950 - val_accuracy: 0.8143\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 38s 352ms/step - loss: 0.2648 - accuracy: 0.8856 - val_loss: 0.3958 - val_accuracy: 0.8117\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 37s 346ms/step - loss: 0.2250 - accuracy: 0.9058 - val_loss: 0.4916 - val_accuracy: 0.7931\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 36s 339ms/step - loss: 0.1953 - accuracy: 0.9257 - val_loss: 0.4289 - val_accuracy: 0.8090\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 37s 343ms/step - loss: 0.1456 - accuracy: 0.9447 - val_loss: 0.4644 - val_accuracy: 0.7931\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0991 - accuracy: 0.9628 - val_loss: 0.5018 - val_accuracy: 0.7851\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 35s 327ms/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 0.6116 - val_accuracy: 0.8037\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.7201 - val_accuracy: 0.8037\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0370 - accuracy: 0.9854 - val_loss: 0.8296 - val_accuracy: 0.7798\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.8579 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 65s 460ms/step - loss: 0.5935 - accuracy: 0.6626 - val_loss: 0.4638 - val_accuracy: 0.7772\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 42s 388ms/step - loss: 0.4327 - accuracy: 0.7890 - val_loss: 0.3994 - val_accuracy: 0.8249\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 45s 420ms/step - loss: 0.3583 - accuracy: 0.8342 - val_loss: 0.3906 - val_accuracy: 0.8435\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 48s 451ms/step - loss: 0.3224 - accuracy: 0.8589 - val_loss: 0.4199 - val_accuracy: 0.7878\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 48s 449ms/step - loss: 0.3023 - accuracy: 0.8730 - val_loss: 0.3741 - val_accuracy: 0.8329\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 48s 449ms/step - loss: 0.2650 - accuracy: 0.8854 - val_loss: 0.4165 - val_accuracy: 0.7984\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 48s 448ms/step - loss: 0.2417 - accuracy: 0.8954 - val_loss: 0.4072 - val_accuracy: 0.8196\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 48s 447ms/step - loss: 0.1907 - accuracy: 0.9184 - val_loss: 0.4473 - val_accuracy: 0.8382\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 48s 447ms/step - loss: 0.1401 - accuracy: 0.9491 - val_loss: 0.5307 - val_accuracy: 0.8064\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 48s 449ms/step - loss: 0.1195 - accuracy: 0.9558 - val_loss: 0.4937 - val_accuracy: 0.8143\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 48s 447ms/step - loss: 0.0996 - accuracy: 0.9583 - val_loss: 0.6252 - val_accuracy: 0.8249\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 48s 447ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 0.9107 - val_accuracy: 0.7851\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 48s 447ms/step - loss: 0.0868 - accuracy: 0.9687 - val_loss: 0.7063 - val_accuracy: 0.8302\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 84.3501329421997\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 74s 539ms/step - loss: 0.6012 - accuracy: 0.6633 - val_loss: 0.4816 - val_accuracy: 0.7798\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.4188 - accuracy: 0.8057 - val_loss: 0.4363 - val_accuracy: 0.7878\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 54s 506ms/step - loss: 0.3710 - accuracy: 0.8403 - val_loss: 0.4498 - val_accuracy: 0.7958\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.3335 - accuracy: 0.8512 - val_loss: 0.4432 - val_accuracy: 0.7958\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 56s 521ms/step - loss: 0.2842 - accuracy: 0.8828 - val_loss: 0.4575 - val_accuracy: 0.7825\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 55s 518ms/step - loss: 0.2654 - accuracy: 0.8835 - val_loss: 0.4555 - val_accuracy: 0.7905\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.2197 - accuracy: 0.9056 - val_loss: 0.5286 - val_accuracy: 0.7931\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.1688 - accuracy: 0.9338 - val_loss: 0.5376 - val_accuracy: 0.7878\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.1425 - accuracy: 0.9402 - val_loss: 0.6273 - val_accuracy: 0.7878\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.1586 - accuracy: 0.9322 - val_loss: 0.6610 - val_accuracy: 0.8064\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.0666 - accuracy: 0.9764 - val_loss: 0.6918 - val_accuracy: 0.8064\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 55s 515ms/step - loss: 0.0519 - accuracy: 0.9846 - val_loss: 0.7975 - val_accuracy: 0.7958\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 56s 519ms/step - loss: 0.0364 - accuracy: 0.9854 - val_loss: 0.8897 - val_accuracy: 0.7905\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 55s 515ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.9255 - val_accuracy: 0.7984\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0258 - accuracy: 0.9892 - val_loss: 0.8756 - val_accuracy: 0.8037\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 55s 513ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 0.8227 - val_accuracy: 0.7878\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 55s 518ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.9097 - val_accuracy: 0.7984\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.9935 - val_accuracy: 0.8037\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 1.0403 - val_accuracy: 0.8037\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 55s 515ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 1.0797 - val_accuracy: 0.8090\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.1197 - val_accuracy: 0.8117\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 55s 518ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 1.1525 - val_accuracy: 0.8090\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 1.1874 - val_accuracy: 0.8064\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 1.1811 - val_accuracy: 0.8011\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 1.2057 - val_accuracy: 0.7958\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 55s 515ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 1.2515 - val_accuracy: 0.7958\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 9.9153e-04 - accuracy: 0.9993 - val_loss: 1.2585 - val_accuracy: 0.8011\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 1.3547 - val_accuracy: 0.7958\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 1.3226 - val_accuracy: 0.8090\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 55s 515ms/step - loss: 9.7342e-04 - accuracy: 0.9995 - val_loss: 1.3466 - val_accuracy: 0.7958\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0014 - accuracy: 0.9991 - val_loss: 1.3729 - val_accuracy: 0.8037\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 90s 655ms/step - loss: 0.6034 - accuracy: 0.6614 - val_loss: 0.4776 - val_accuracy: 0.7666\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 46s 432ms/step - loss: 0.4116 - accuracy: 0.8148 - val_loss: 0.5072 - val_accuracy: 0.7401\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 38s 358ms/step - loss: 0.3810 - accuracy: 0.8329 - val_loss: 0.4223 - val_accuracy: 0.7851\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 39s 362ms/step - loss: 0.3440 - accuracy: 0.8453 - val_loss: 0.4329 - val_accuracy: 0.8011\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 40s 370ms/step - loss: 0.2841 - accuracy: 0.8729 - val_loss: 0.4416 - val_accuracy: 0.8037\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 39s 362ms/step - loss: 0.2568 - accuracy: 0.8959 - val_loss: 0.4915 - val_accuracy: 0.7851\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.2074 - accuracy: 0.9144 - val_loss: 0.4970 - val_accuracy: 0.8117\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.1717 - accuracy: 0.9306 - val_loss: 0.5705 - val_accuracy: 0.7719\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 39s 368ms/step - loss: 0.1373 - accuracy: 0.9462 - val_loss: 0.6194 - val_accuracy: 0.8011\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.0842 - accuracy: 0.9727 - val_loss: 0.7346 - val_accuracy: 0.7692\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.0837 - accuracy: 0.9697 - val_loss: 0.7993 - val_accuracy: 0.7745\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 39s 369ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.9772 - val_accuracy: 0.7905\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.0800 - accuracy: 0.9735 - val_loss: 0.9212 - val_accuracy: 0.7878\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.9373 - val_accuracy: 0.8064\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 39s 368ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 1.0475 - val_accuracy: 0.8011\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 39s 365ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 1.1432 - val_accuracy: 0.7878\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 1.2842 - val_accuracy: 0.8064\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 60s 420ms/step - loss: 0.6055 - accuracy: 0.6438 - val_loss: 0.5611 - val_accuracy: 0.7082\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 39s 363ms/step - loss: 0.4329 - accuracy: 0.8050 - val_loss: 0.4403 - val_accuracy: 0.7878\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 35s 328ms/step - loss: 0.3844 - accuracy: 0.8364 - val_loss: 0.4506 - val_accuracy: 0.7851\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 35s 325ms/step - loss: 0.3252 - accuracy: 0.8609 - val_loss: 0.4749 - val_accuracy: 0.7825\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 34s 323ms/step - loss: 0.3178 - accuracy: 0.8585 - val_loss: 0.4699 - val_accuracy: 0.7905\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 34s 318ms/step - loss: 0.2638 - accuracy: 0.8876 - val_loss: 0.5249 - val_accuracy: 0.7772\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 34s 319ms/step - loss: 0.2250 - accuracy: 0.9057 - val_loss: 0.5415 - val_accuracy: 0.7958\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 34s 320ms/step - loss: 0.1730 - accuracy: 0.9357 - val_loss: 0.5666 - val_accuracy: 0.7905\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 34s 320ms/step - loss: 0.1346 - accuracy: 0.9536 - val_loss: 0.7259 - val_accuracy: 0.7798\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 34s 320ms/step - loss: 0.1160 - accuracy: 0.9559 - val_loss: 0.8031 - val_accuracy: 0.7692\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 34s 319ms/step - loss: 0.0699 - accuracy: 0.9748 - val_loss: 1.1350 - val_accuracy: 0.7586\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 34s 320ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 1.0099 - val_accuracy: 0.7851\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 34s 320ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 1.0892 - val_accuracy: 0.7931\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 34s 322ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 1.0178 - val_accuracy: 0.8037\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 34s 321ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 1.2578 - val_accuracy: 0.7825\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 34s 321ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 1.2580 - val_accuracy: 0.7958\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 34s 322ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 1.3817 - val_accuracy: 0.7772\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 35s 324ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.4108 - val_accuracy: 0.7851\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 35s 325ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 1.4974 - val_accuracy: 0.7719\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.3701 - val_accuracy: 0.8011\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0068 - accuracy: 0.9965 - val_loss: 1.3720 - val_accuracy: 0.8064\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 1.6227 - val_accuracy: 0.7984\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 35s 325ms/step - loss: 0.0112 - accuracy: 0.9955 - val_loss: 1.3639 - val_accuracy: 0.8064\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 35s 328ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 1.1782 - val_accuracy: 0.8064\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0202 - accuracy: 0.9914 - val_loss: 1.4872 - val_accuracy: 0.7798\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0152 - accuracy: 0.9919 - val_loss: 1.4134 - val_accuracy: 0.8037\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3730 - val_accuracy: 0.8117\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 35s 325ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 1.6436 - val_accuracy: 0.7745\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 1.3700 - val_accuracy: 0.8037\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 35s 324ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 1.4321 - val_accuracy: 0.8037\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0027 - accuracy: 0.9977 - val_loss: 1.5016 - val_accuracy: 0.8037\n",
      "Epoch 32/40\n",
      "107/107 [==============================] - 35s 328ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 1.5688 - val_accuracy: 0.7984\n",
      "Epoch 33/40\n",
      "107/107 [==============================] - 35s 328ms/step - loss: 6.1768e-04 - accuracy: 0.9998 - val_loss: 1.6007 - val_accuracy: 0.7958\n",
      "Epoch 34/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 1.6283 - val_accuracy: 0.7984\n",
      "Epoch 35/40\n",
      "107/107 [==============================] - 35s 327ms/step - loss: 0.0011 - accuracy: 0.9991 - val_loss: 1.6100 - val_accuracy: 0.8011\n",
      "Epoch 36/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 9.0478e-04 - accuracy: 0.9994 - val_loss: 1.6234 - val_accuracy: 0.8011\n",
      "Epoch 37/40\n",
      "107/107 [==============================] - 35s 327ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 1.6660 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "\n",
      "        acc1       acc2      acc3       acc4       acc5      acc6       acc7  \\\n",
      "0  80.158728  80.952382  81.74603  82.275134  80.952382  81.43236  84.350133   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  81.167108  81.167108  81.167108  81.536847  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_2(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU1CKA71YPz0"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "V0nl-0oFYPz1",
    "outputId": "ddeb34c1-8a20-4245-aed5-49b42d2a6416"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.158728</td>\n",
       "      <td>80.952382</td>\n",
       "      <td>81.74603</td>\n",
       "      <td>82.275134</td>\n",
       "      <td>80.952382</td>\n",
       "      <td>81.43236</td>\n",
       "      <td>84.350133</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>81.536847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2      acc3       acc4       acc5      acc6       acc7  \\\n",
       "0  80.158728  80.952382  81.74603  82.275134  80.952382  81.43236  84.350133   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  81.167108  81.167108  81.167108  81.536847  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oJKVliAAYPz2"
   },
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('GRU_CR_v2_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLeoO2GIYPz2"
   },
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YO3OHNuYPz3"
   },
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvYHnxUlYPz3"
   },
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4lx9ISs2YPz3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
    "        # tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5707NV6EYPz4",
    "outputId": "516babc0-14d4-4a5a-f4da-48c841d23860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 515,169\n",
      "Trainable params: 515,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0hmpKMBYPz4"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xbebTECUYPz5"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9fvfyaMYPz5",
    "outputId": "8f53ef1c-c42b-4ded-da89-8426fcbe1efc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 123s 1s/step - loss: 0.5835 - accuracy: 0.6830 - val_loss: 0.4057 - val_accuracy: 0.7831\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 99s 922ms/step - loss: 0.2994 - accuracy: 0.8766 - val_loss: 0.4068 - val_accuracy: 0.7857\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 77s 720ms/step - loss: 0.1561 - accuracy: 0.9444 - val_loss: 0.4691 - val_accuracy: 0.7989\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 77s 717ms/step - loss: 0.1064 - accuracy: 0.9623 - val_loss: 0.6173 - val_accuracy: 0.8307\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 78s 725ms/step - loss: 0.0370 - accuracy: 0.9871 - val_loss: 0.8014 - val_accuracy: 0.7989\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 77s 722ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.8809 - val_accuracy: 0.8069\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 76s 713ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 1.1286 - val_accuracy: 0.8016\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 77s 720ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 1.1653 - val_accuracy: 0.7910\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 76s 712ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.2383 - val_accuracy: 0.7963\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 76s 709ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 1.3080 - val_accuracy: 0.7963\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 76s 715ms/step - loss: 9.9221e-04 - accuracy: 0.9990 - val_loss: 1.3588 - val_accuracy: 0.7989\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 77s 720ms/step - loss: 6.8314e-04 - accuracy: 0.9995 - val_loss: 1.4058 - val_accuracy: 0.7910\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 76s 714ms/step - loss: 7.3591e-04 - accuracy: 0.9992 - val_loss: 1.4418 - val_accuracy: 0.7989\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 76s 713ms/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 1.4773 - val_accuracy: 0.7910\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 83.06878209114075\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 98s 767ms/step - loss: 0.5942 - accuracy: 0.6646 - val_loss: 0.4377 - val_accuracy: 0.7963\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 66s 621ms/step - loss: 0.2846 - accuracy: 0.8847 - val_loss: 0.5005 - val_accuracy: 0.7672\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 68s 637ms/step - loss: 0.1432 - accuracy: 0.9424 - val_loss: 0.5699 - val_accuracy: 0.8042\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 68s 637ms/step - loss: 0.0573 - accuracy: 0.9818 - val_loss: 0.6791 - val_accuracy: 0.7937\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 68s 637ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.9885 - val_accuracy: 0.7910\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 68s 639ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 1.2238 - val_accuracy: 0.7910\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 68s 639ms/step - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.9264 - val_accuracy: 0.7804\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 68s 639ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 1.1495 - val_accuracy: 0.7963\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 68s 639ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 1.2825 - val_accuracy: 0.7937\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 68s 638ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 1.4013 - val_accuracy: 0.7831\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 68s 638ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 1.4596 - val_accuracy: 0.7831\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 68s 638ms/step - loss: 8.4911e-04 - accuracy: 0.9998 - val_loss: 1.5199 - val_accuracy: 0.7804\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 68s 639ms/step - loss: 0.0015 - accuracy: 0.9981 - val_loss: 1.5744 - val_accuracy: 0.7937\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 114s 860ms/step - loss: 0.5898 - accuracy: 0.6836 - val_loss: 0.5152 - val_accuracy: 0.7407\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 79s 742ms/step - loss: 0.3128 - accuracy: 0.8654 - val_loss: 0.3798 - val_accuracy: 0.8228\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 62s 584ms/step - loss: 0.1569 - accuracy: 0.9500 - val_loss: 0.4634 - val_accuracy: 0.8042\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 62s 579ms/step - loss: 0.0797 - accuracy: 0.9740 - val_loss: 0.6302 - val_accuracy: 0.8016\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 62s 579ms/step - loss: 0.0343 - accuracy: 0.9913 - val_loss: 0.8546 - val_accuracy: 0.7857\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 62s 576ms/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.9595 - val_accuracy: 0.8016\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 62s 579ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 1.1285 - val_accuracy: 0.8016\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 61s 571ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.1762 - val_accuracy: 0.7963\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 61s 568ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 1.3686 - val_accuracy: 0.7937\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 61s 567ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 1.3851 - val_accuracy: 0.8069\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 60s 565ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 1.3967 - val_accuracy: 0.8042\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 60s 565ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 1.4590 - val_accuracy: 0.8095\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.27513432502747\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 87s 661ms/step - loss: 0.6053 - accuracy: 0.6481 - val_loss: 0.4069 - val_accuracy: 0.7937\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 57s 538ms/step - loss: 0.3236 - accuracy: 0.8617 - val_loss: 0.3712 - val_accuracy: 0.8254\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.1615 - accuracy: 0.9411 - val_loss: 0.4840 - val_accuracy: 0.7884\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.0726 - accuracy: 0.9722 - val_loss: 0.5851 - val_accuracy: 0.8016\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.0333 - accuracy: 0.9888 - val_loss: 0.7718 - val_accuracy: 0.7989\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 55s 512ms/step - loss: 0.0199 - accuracy: 0.9919 - val_loss: 0.8312 - val_accuracy: 0.7884\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 55s 513ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.1241 - val_accuracy: 0.8095\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0051 - accuracy: 0.9972 - val_loss: 0.9952 - val_accuracy: 0.7937\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 1.1277 - val_accuracy: 0.8016\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 56s 519ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.1696 - val_accuracy: 0.8069\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 55s 518ms/step - loss: 7.2778e-04 - accuracy: 0.9997 - val_loss: 1.2572 - val_accuracy: 0.8016\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 55s 518ms/step - loss: 7.0212e-04 - accuracy: 0.9992 - val_loss: 1.3113 - val_accuracy: 0.8016\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 79s 591ms/step - loss: 0.5861 - accuracy: 0.6899 - val_loss: 0.4453 - val_accuracy: 0.7672\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 113s 1s/step - loss: 0.2778 - accuracy: 0.8824 - val_loss: 0.4504 - val_accuracy: 0.7857\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.1444 - accuracy: 0.9457 - val_loss: 0.5264 - val_accuracy: 0.7778\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0726 - accuracy: 0.9765 - val_loss: 0.7791 - val_accuracy: 0.7937\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.8946 - val_accuracy: 0.7778\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 1.1486 - val_accuracy: 0.7989\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0233 - accuracy: 0.9903 - val_loss: 1.1863 - val_accuracy: 0.7593\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 112s 1s/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 1.3176 - val_accuracy: 0.8095\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 112s 1s/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 1.2344 - val_accuracy: 0.7989\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.3436 - val_accuracy: 0.7963\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 1.4063 - val_accuracy: 0.8016\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.4660 - val_accuracy: 0.8016\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 110s 1s/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.4929 - val_accuracy: 0.8016\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 112s 1s/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 1.5359 - val_accuracy: 0.8042\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.5633 - val_accuracy: 0.8016\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 113s 1s/step - loss: 7.5522e-04 - accuracy: 0.9995 - val_loss: 1.5902 - val_accuracy: 0.8016\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 112s 1s/step - loss: 4.7040e-04 - accuracy: 0.9997 - val_loss: 1.6252 - val_accuracy: 0.7989\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 113s 1s/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 1.6416 - val_accuracy: 0.8042\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 155s 1s/step - loss: 0.5791 - accuracy: 0.6887 - val_loss: 0.4093 - val_accuracy: 0.8170\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 111s 1s/step - loss: 0.2750 - accuracy: 0.8878 - val_loss: 0.4037 - val_accuracy: 0.8143\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 85s 796ms/step - loss: 0.1502 - accuracy: 0.9469 - val_loss: 0.6090 - val_accuracy: 0.8064\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 85s 792ms/step - loss: 0.0717 - accuracy: 0.9735 - val_loss: 0.7284 - val_accuracy: 0.8037\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 86s 808ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.8485 - val_accuracy: 0.8011\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 1.1731 - val_accuracy: 0.7984\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 85s 790ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.3128 - val_accuracy: 0.7772\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 86s 805ms/step - loss: 0.0706 - accuracy: 0.9733 - val_loss: 1.0283 - val_accuracy: 0.7878\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 85s 799ms/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 1.1695 - val_accuracy: 0.7851\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 85s 794ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.2999 - val_accuracy: 0.7772\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 1.4137 - val_accuracy: 0.7931\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 119s 957ms/step - loss: 0.6038 - accuracy: 0.6623 - val_loss: 0.4173 - val_accuracy: 0.8011\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 83s 772ms/step - loss: 0.2942 - accuracy: 0.8797 - val_loss: 0.4574 - val_accuracy: 0.7586\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 80s 747ms/step - loss: 0.1534 - accuracy: 0.9546 - val_loss: 0.5619 - val_accuracy: 0.7772\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 79s 736ms/step - loss: 0.0748 - accuracy: 0.9736 - val_loss: 0.7676 - val_accuracy: 0.8011\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 79s 739ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.8972 - val_accuracy: 0.7772\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 79s 742ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 1.0661 - val_accuracy: 0.7719\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 79s 737ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 1.1721 - val_accuracy: 0.7772\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 79s 736ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 1.2699 - val_accuracy: 0.7851\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 79s 740ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.3856 - val_accuracy: 0.7825\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 78s 733ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 1.4740 - val_accuracy: 0.7905\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 79s 734ms/step - loss: 0.0025 - accuracy: 0.9978 - val_loss: 1.5570 - val_accuracy: 0.7905\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 116s 886ms/step - loss: 0.5833 - accuracy: 0.6699 - val_loss: 0.4610 - val_accuracy: 0.7560\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 57s 530ms/step - loss: 0.2809 - accuracy: 0.8867 - val_loss: 0.4153 - val_accuracy: 0.8170\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 48s 453ms/step - loss: 0.1604 - accuracy: 0.9530 - val_loss: 0.4884 - val_accuracy: 0.7931\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 49s 460ms/step - loss: 0.0686 - accuracy: 0.9776 - val_loss: 0.6352 - val_accuracy: 0.8037\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 49s 460ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.8814 - val_accuracy: 0.8117\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 49s 460ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.9571 - val_accuracy: 0.7798\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 49s 458ms/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 1.0849 - val_accuracy: 0.7772\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 49s 458ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 1.0411 - val_accuracy: 0.7851\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 49s 458ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 1.2392 - val_accuracy: 0.7772\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 49s 454ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 1.3717 - val_accuracy: 0.7745\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 49s 454ms/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 1.3907 - val_accuracy: 0.7825\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 48s 453ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.4951 - val_accuracy: 0.7825\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 67s 475ms/step - loss: 0.5870 - accuracy: 0.6726 - val_loss: 0.4159 - val_accuracy: 0.8064\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 47s 436ms/step - loss: 0.2857 - accuracy: 0.8811 - val_loss: 0.4184 - val_accuracy: 0.8037\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 47s 443ms/step - loss: 0.1562 - accuracy: 0.9474 - val_loss: 0.6927 - val_accuracy: 0.7480\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 48s 451ms/step - loss: 0.0954 - accuracy: 0.9651 - val_loss: 0.6387 - val_accuracy: 0.7772\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 48s 450ms/step - loss: 0.0369 - accuracy: 0.9892 - val_loss: 0.8679 - val_accuracy: 0.7798\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 48s 449ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 1.0140 - val_accuracy: 0.7851\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 48s 449ms/step - loss: 0.0085 - accuracy: 0.9964 - val_loss: 1.1763 - val_accuracy: 0.7905\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 48s 451ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 1.2927 - val_accuracy: 0.7905\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 48s 450ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.1962 - val_accuracy: 0.8037\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 48s 448ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.2510 - val_accuracy: 0.8011\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 48s 448ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.3171 - val_accuracy: 0.8064\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 133s 1s/step - loss: 0.5866 - accuracy: 0.6737 - val_loss: 0.4118 - val_accuracy: 0.8011\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 100s 932ms/step - loss: 0.2929 - accuracy: 0.8807 - val_loss: 0.4420 - val_accuracy: 0.8011\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 70s 656ms/step - loss: 0.1853 - accuracy: 0.9323 - val_loss: 0.7591 - val_accuracy: 0.7613\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 70s 659ms/step - loss: 0.0822 - accuracy: 0.9688 - val_loss: 0.7312 - val_accuracy: 0.8223\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 71s 661ms/step - loss: 0.0337 - accuracy: 0.9876 - val_loss: 0.8511 - val_accuracy: 0.7613\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 69s 650ms/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 1.1180 - val_accuracy: 0.7745\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 69s 645ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.1026 - val_accuracy: 0.7692\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 69s 642ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 1.4308 - val_accuracy: 0.7719\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 69s 645ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.4152 - val_accuracy: 0.7586\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 69s 644ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 1.5037 - val_accuracy: 0.7772\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 69s 645ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 1.4470 - val_accuracy: 0.7719\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 69s 645ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 1.5875 - val_accuracy: 0.7745\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 69s 648ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.7420 - val_accuracy: 0.7772\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 69s 646ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.7767 - val_accuracy: 0.7719\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  83.068782  80.423278  82.275134  82.539684  80.952382  81.697613   \n",
      "\n",
      "        acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.106103  81.697613  80.636603  82.228118  81.562531  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_3(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPvTyfWoYPz6"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "MjN32qo5YPz6",
    "outputId": "ac2df982-6103-4f2c-e24f-fa2766c1d2a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.068782</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>82.275134</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>80.952382</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>82.228118</td>\n",
       "      <td>81.562531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  83.068782  80.423278  82.275134  82.539684  80.952382  81.697613   \n",
       "\n",
       "        acc7       acc8       acc9      acc10        AVG  \n",
       "0  80.106103  81.697613  80.636603  82.228118  81.562531  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "SP7NifVSYPz6"
   },
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('GRU_CR_v2_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GRU_CR_v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
