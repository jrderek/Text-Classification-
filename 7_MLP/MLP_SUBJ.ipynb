{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using Multi Layer Perceptron on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smart and alert , thirteen conversations about...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color , musical bounce and warm seas lapping o...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is not a mass market entertainment but an u...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a light hearted french film about the spiritua...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my wife is an actress has its moments in looki...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>in the end , they discover that balance in lif...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>a counterfeit 1000 tomin bank note is passed i...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>enter the beautiful and mysterious secret agen...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>after listening to a missionary from china spe...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>looking for a short cut to fame , glass concoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     smart and alert , thirteen conversations about...      0  train\n",
       "1     color , musical bounce and warm seas lapping o...      0  train\n",
       "2     it is not a mass market entertainment but an u...      0  train\n",
       "3     a light hearted french film about the spiritua...      0  train\n",
       "4     my wife is an actress has its moments in looki...      0  train\n",
       "...                                                 ...    ...    ...\n",
       "9995  in the end , they discover that balance in lif...      1  train\n",
       "9996  a counterfeit 1000 tomin bank note is passed i...      1  train\n",
       "9997  enter the beautiful and mysterious secret agen...      1  train\n",
       "9998  after listening to a missionary from china spe...      1  train\n",
       "9999  looking for a short cut to fame , glass concoc...      1  train\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/SUBJ/SUBJ.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  10000 non-null  object\n",
      " 1   label     10000 non-null  int32 \n",
      " 2   split     10000 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          5000   5000\n",
       "1          5000   5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smart and alert , thirteen conversations about one thing is a small gem .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Word2Vec Static\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Word Embedding: Word2Vec\n",
    "\n",
    "__1. Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17913 words present from 21324 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "oov_tok = '<OOV>'\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `clean_doc` function\n",
    "__2. Define a function to clean the document called __`clean_doc()`____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(sentences, word_index):\n",
    "    clean_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower().split()\n",
    "        clean_word = []\n",
    "        for word in sentence:\n",
    "            if word in word_index:\n",
    "                clean_word.append(word)\n",
    "        clean_sentence = ' '.join(clean_word)\n",
    "        clean_sentences.append(clean_sentence)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart and alert thirteen conversations about one thing is a small gem',\n",
       " 'color musical bounce and warm seas lapping on island shores and just enough science to send you home thinking',\n",
       " 'it is not a mass market entertainment but an uncompromising attempt by one artist to think about another']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences = clean_doc(sentences, word_index)\n",
    "clean_sentences[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `sentence_to_avg` function\n",
    "__3. Define a `sentence_to_avg` function__\n",
    "\n",
    "We will use this function to calculate the mean of word embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Split sentence into list of lower case words (â‰ˆ 1 line)\n",
    "    words = (sentence.lower()).split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros(word2vec.word_vec('i').shape)\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            total += word_to_vec_map.word_vec(w)\n",
    "            count += 1\n",
    "            \n",
    "    if count!= 0:\n",
    "        avg = total/count\n",
    "    else:\n",
    "        avg\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22558594\n",
      "-0.16699219\n",
      "0.11376953\n",
      "the mean of word embedding is:  -0.09293619791666667\n"
     ]
    }
   ],
   "source": [
    "i = word2vec.word_vec('i')[0]\n",
    "print(word2vec.word_vec('i')[0])\n",
    "j = word2vec.word_vec('am')[0]\n",
    "print(word2vec.word_vec('am')[0])\n",
    "k = word2vec.word_vec('handsome')[0]\n",
    "print(word2vec.word_vec('handsome')[0])\n",
    "mean = (i+j+k)/3\n",
    "print('the mean of word embedding is: ', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0929362 ,  0.03125   , -0.03914388,  0.09879557,  0.07088598,\n",
       "        0.03092448, -0.00651042, -0.04437256,  0.08068848,  0.07242838,\n",
       "        0.00160726, -0.10530599, -0.07389323, -0.08854166,  0.00565592,\n",
       "        0.15136719, -0.0460612 ,  0.19482422,  0.1101888 ,  0.05924479,\n",
       "       -0.18457031,  0.00716146,  0.16153972,  0.02437337, -0.01578776,\n",
       "        0.06119792, -0.25048828,  0.02799479,  0.0853475 , -0.14029948,\n",
       "        0.13688152, -0.01350911, -0.05493164, -0.01090495,  0.03352864,\n",
       "        0.09635416, -0.04239909,  0.00777181, -0.1438802 ,  0.06510416,\n",
       "        0.14560954, -0.11295573,  0.25520834,  0.08833822,  0.14339192,\n",
       "        0.037028  , -0.02832031, -0.00139872,  0.00309245, -0.17871094,\n",
       "        0.06852213,  0.07910156,  0.09513346,  0.11425781, -0.00488281,\n",
       "        0.11051432, -0.01139323, -0.08479818, -0.09277344, -0.03263346,\n",
       "       -0.00374349,  0.07977295, -0.26416016, -0.05135091,  0.06111654,\n",
       "       -0.06933594, -0.06486002,  0.18766277, -0.04826609,  0.03304036,\n",
       "        0.24267578,  0.11425781,  0.02310689,  0.06697591, -0.19010417,\n",
       "        0.03230794,  0.00317383, -0.03739421,  0.12434896,  0.1574707 ,\n",
       "       -0.05745443,  0.015625  ,  0.01456706, -0.05794271, -0.0549113 ,\n",
       "        0.0398763 , -0.01517741,  0.11263021, -0.03271484,  0.06758627,\n",
       "       -0.09594727,  0.06559245,  0.00217692,  0.03627523, -0.03776042,\n",
       "        0.02945963, -0.05960592, -0.02514648,  0.07128906, -0.04410807,\n",
       "       -0.21533203, -0.02174886, -0.05029297,  0.04264323,  0.08194987,\n",
       "        0.05502828,  0.09375   , -0.02050781,  0.04243978, -0.1439616 ,\n",
       "        0.        , -0.17805989,  0.0822347 ,  0.00140381,  0.17220052,\n",
       "       -0.08251953,  0.00450643, -0.24837239,  0.14001465,  0.01749674,\n",
       "        0.24576823, -0.06986491, -0.04370117,  0.01497396, -0.01534017,\n",
       "        0.09863281, -0.12027995,  0.14615886,  0.19580078,  0.08813477,\n",
       "       -0.2861328 , -0.0653483 , -0.03889974, -0.07784017, -0.12190755,\n",
       "       -0.04427083, -0.06233724,  0.08296712,  0.12670898,  0.1593221 ,\n",
       "        0.04296875,  0.08544922, -0.01513672,  0.        , -0.2101237 ,\n",
       "        0.11390177, -0.01127116, -0.06298828,  0.0198822 , -0.03000895,\n",
       "       -0.05118815, -0.00195312, -0.1007487 ,  0.09879557, -0.19702148,\n",
       "       -0.05611674, -0.03466797,  0.13932292, -0.0764974 , -0.00777181,\n",
       "        0.05948893,  0.11360677,  0.01757812,  0.07926432, -0.0104777 ,\n",
       "       -0.16145833,  0.17708333,  0.13507843, -0.06380209,  0.10839844,\n",
       "       -0.21500652, -0.0933431 ,  0.05853271, -0.14601643, -0.0369873 ,\n",
       "        0.02945963,  0.2747396 , -0.07006454,  0.06966146, -0.17203777,\n",
       "       -0.02294922, -0.09220377, -0.01790492, -0.0111084 , -0.03776042,\n",
       "        0.03540039, -0.03483073,  0.0764974 ,  0.07096354, -0.13916016,\n",
       "       -0.01989746,  0.06176758, -0.11336263, -0.03279241,  0.08687337,\n",
       "        0.15901692, -0.07185873,  0.02547201, -0.03220622, -0.125     ,\n",
       "       -0.12727864,  0.02563477, -0.06311035, -0.16959636, -0.10058594,\n",
       "       -0.05464681, -0.09391276,  0.06502279, -0.06184896,  0.14835612,\n",
       "       -0.1031901 ,  0.07779948, -0.06420898, -0.0892334 , -0.20214844,\n",
       "        0.13671875,  0.11507162, -0.00145467, -0.23079427, -0.04801432,\n",
       "       -0.06262207,  0.07454427,  0.0298055 , -0.01489258,  0.08854166,\n",
       "       -0.1608073 , -0.00372314, -0.056722  , -0.06841787, -0.16031902,\n",
       "        0.1538086 , -0.03597005, -0.09985352, -0.03483073,  0.07324219,\n",
       "        0.03672282,  0.03737386,  0.06705729,  0.10375977,  0.04850261,\n",
       "        0.20996094,  0.06673177,  0.03833008,  0.06363932, -0.18758138,\n",
       "       -0.10904948, -0.02693685,  0.02254232, -0.08405808,  0.02848307,\n",
       "        0.17675781,  0.01188151,  0.08610026,  0.18359375,  0.0764974 ,\n",
       "        0.03463237,  0.08015951,  0.00455729, -0.15309651,  0.00195312,\n",
       "        0.0965983 , -0.18180339, -0.02457682, -0.01757812, -0.08410645,\n",
       "        0.20092773, -0.12624104, -0.09566244, -0.03291829, -0.04532878,\n",
       "        0.04199219, -0.01635742,  0.04329427,  0.06469727,  0.04390462,\n",
       "        0.03625488, -0.04744466, -0.14420573, -0.17626953,  0.18603516,\n",
       "        0.01155599,  0.06009929, -0.02880859,  0.06738281,  0.0949707 ,\n",
       "        0.00325521, -0.07470703, -0.18782552, -0.00447591,  0.06038411,\n",
       "        0.0456543 ,  0.10611979, -0.11393229, -0.05623372, -0.03450521,\n",
       "        0.02193197, -0.12263998, -0.08158366, -0.0332845 ,  0.09596761],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the functions used in a sentence\n",
    "mysentence = 'I am handsome'\n",
    "sentence_to_avg(mysentence, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Sentence into Word2Vec Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_sentences(sentences):\n",
    "\n",
    "    encoded_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        encoded_sentence = sentence_to_avg(sentence, word2vec)\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "\n",
    "    encoded_sentences = np.array(encoded_sentences)\n",
    "    return encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.09899597, -0.01417236,  0.05629883, ..., -0.06938477,\n",
       "         0.01387939, -0.00507126],\n",
       "       [ 0.04263115,  0.09387779, -0.00069427, ..., -0.10138512,\n",
       "         0.10466766, -0.00714874],\n",
       "       [ 0.0633831 , -0.02400887,  0.03606033, ...,  0.00570297,\n",
       "         0.05516815, -0.03573942],\n",
       "       ...,\n",
       "       [ 0.06410436,  0.08607701, -0.04271589, ..., -0.09407915,\n",
       "        -0.00617327, -0.00680106],\n",
       "       [ 0.06500244,  0.01929146,  0.05882645, ..., -0.04457092,\n",
       "         0.11615753,  0.0254097 ],\n",
       "       [ 0.0687162 ,  0.07482617,  0.00492624, ..., -0.07861798,\n",
       "         0.02930979, -0.02104774]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = encoded_sentences(clean_sentences)\n",
    "print(embedded_sentences.shape)\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,101\n",
      "Trainable params: 15,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model(300)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "'''\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8349 - val_loss: 0.2632 - val_accuracy: 0.9080\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 0s 834us/step - loss: 0.2831 - accuracy: 0.8906 - val_loss: 0.2271 - val_accuracy: 0.9160\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 0s 826us/step - loss: 0.2627 - accuracy: 0.8982 - val_loss: 0.2151 - val_accuracy: 0.9140\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 0s 821us/step - loss: 0.2471 - accuracy: 0.9054 - val_loss: 0.2075 - val_accuracy: 0.9210\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 0s 837us/step - loss: 0.2415 - accuracy: 0.9048 - val_loss: 0.2025 - val_accuracy: 0.9170\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 0s 831us/step - loss: 0.2343 - accuracy: 0.9088 - val_loss: 0.2001 - val_accuracy: 0.9170\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 0s 811us/step - loss: 0.2280 - accuracy: 0.9110 - val_loss: 0.1965 - val_accuracy: 0.9200\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 0s 749us/step - loss: 0.2232 - accuracy: 0.9122 - val_loss: 0.1953 - val_accuracy: 0.9180\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 0s 865us/step - loss: 0.2195 - accuracy: 0.9129 - val_loss: 0.1920 - val_accuracy: 0.9160\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 0s 800us/step - loss: 0.2142 - accuracy: 0.9173 - val_loss: 0.1921 - val_accuracy: 0.9200\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 0s 791us/step - loss: 0.2114 - accuracy: 0.9186 - val_loss: 0.1911 - val_accuracy: 0.9190\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 0s 778us/step - loss: 0.2070 - accuracy: 0.9186 - val_loss: 0.1934 - val_accuracy: 0.9220\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 0s 783us/step - loss: 0.2053 - accuracy: 0.9204 - val_loss: 0.1909 - val_accuracy: 0.9240\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 0s 852us/step - loss: 0.2030 - accuracy: 0.9212 - val_loss: 0.1891 - val_accuracy: 0.9210\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 0s 823us/step - loss: 0.2023 - accuracy: 0.9216 - val_loss: 0.1892 - val_accuracy: 0.9240\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.92 - 0s 926us/step - loss: 0.1983 - accuracy: 0.9230 - val_loss: 0.1903 - val_accuracy: 0.9250\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9249 - val_loss: 0.1900 - val_accuracy: 0.9240\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 0s 808us/step - loss: 0.1967 - accuracy: 0.9259 - val_loss: 0.1879 - val_accuracy: 0.9230\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 0s 821us/step - loss: 0.1925 - accuracy: 0.9253 - val_loss: 0.1891 - val_accuracy: 0.9260\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 0s 793us/step - loss: 0.1934 - accuracy: 0.9284 - val_loss: 0.1900 - val_accuracy: 0.9240\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 0s 908us/step - loss: 0.1894 - accuracy: 0.9272 - val_loss: 0.1892 - val_accuracy: 0.9260\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 0s 817us/step - loss: 0.1860 - accuracy: 0.9264 - val_loss: 0.1930 - val_accuracy: 0.9210\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 0s 866us/step - loss: 0.1847 - accuracy: 0.9294 - val_loss: 0.1924 - val_accuracy: 0.9200\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 0s 962us/step - loss: 0.1824 - accuracy: 0.9296 - val_loss: 0.1884 - val_accuracy: 0.9240\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 0s 936us/step - loss: 0.1811 - accuracy: 0.9327 - val_loss: 0.1886 - val_accuracy: 0.9250\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 0s 995us/step - loss: 0.1820 - accuracy: 0.9299 - val_loss: 0.1872 - val_accuracy: 0.9240\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 0s 919us/step - loss: 0.1770 - accuracy: 0.9328 - val_loss: 0.1893 - val_accuracy: 0.9260\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.9329 - val_loss: 0.1910 - val_accuracy: 0.9240\n",
      "Epoch 29/40\n",
      "273/282 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9330Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 0s 926us/step - loss: 0.1742 - accuracy: 0.9329 - val_loss: 0.1892 - val_accuracy: 0.9260\n",
      "Epoch 00029: early stopping\n",
      "Test Accuracy: 92.59999990463257\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.8512 - val_loss: 0.3064 - val_accuracy: 0.8740\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.8944 - val_loss: 0.2908 - val_accuracy: 0.8780\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.9019 - val_loss: 0.2721 - val_accuracy: 0.8930\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.9064 - val_loss: 0.2699 - val_accuracy: 0.8940\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.9087 - val_loss: 0.2691 - val_accuracy: 0.8970\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2268 - accuracy: 0.9111 - val_loss: 0.2618 - val_accuracy: 0.9010\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2222 - accuracy: 0.9133 - val_loss: 0.2592 - val_accuracy: 0.9030\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2189 - accuracy: 0.9148 - val_loss: 0.2624 - val_accuracy: 0.9040\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9158 - val_loss: 0.2502 - val_accuracy: 0.9020\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9178 - val_loss: 0.2506 - val_accuracy: 0.9060\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9194 - val_loss: 0.2495 - val_accuracy: 0.9080\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2043 - accuracy: 0.9199 - val_loss: 0.2515 - val_accuracy: 0.9090\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.9252 - val_loss: 0.2668 - val_accuracy: 0.8980\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9222 - val_loss: 0.2581 - val_accuracy: 0.9010\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1968 - accuracy: 0.9228 - val_loss: 0.2641 - val_accuracy: 0.9010\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1926 - accuracy: 0.9270 - val_loss: 0.2710 - val_accuracy: 0.8950\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.9290 - val_loss: 0.2479 - val_accuracy: 0.9100\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1871 - accuracy: 0.9267 - val_loss: 0.2472 - val_accuracy: 0.9090\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.9280 - val_loss: 0.2496 - val_accuracy: 0.9130\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.9289 - val_loss: 0.2516 - val_accuracy: 0.9080\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.9290 - val_loss: 0.2594 - val_accuracy: 0.8980\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.9280 - val_loss: 0.2538 - val_accuracy: 0.9120\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.9309 - val_loss: 0.2429 - val_accuracy: 0.9150\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.9316 - val_loss: 0.2602 - val_accuracy: 0.9070\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9311 - val_loss: 0.2593 - val_accuracy: 0.9020\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9328 - val_loss: 0.2490 - val_accuracy: 0.9180\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9357 - val_loss: 0.2505 - val_accuracy: 0.9160\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1703 - accuracy: 0.9337 - val_loss: 0.2508 - val_accuracy: 0.9150\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1701 - accuracy: 0.9366 - val_loss: 0.2529 - val_accuracy: 0.9090\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1676 - accuracy: 0.9351 - val_loss: 0.2534 - val_accuracy: 0.9170\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1667 - accuracy: 0.9382 - val_loss: 0.2507 - val_accuracy: 0.9160\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9389 - val_loss: 0.2556 - val_accuracy: 0.9150\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9357 - val_loss: 0.2552 - val_accuracy: 0.9140\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1605 - accuracy: 0.9396 - val_loss: 0.2619 - val_accuracy: 0.9140\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1637 - accuracy: 0.9393 - val_loss: 0.2589 - val_accuracy: 0.9060\n",
      "Epoch 36/40\n",
      "277/282 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9398Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9398 - val_loss: 0.2657 - val_accuracy: 0.9010\n",
      "Epoch 00036: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4290 - accuracy: 0.8463 - val_loss: 0.2874 - val_accuracy: 0.8930\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.8894 - val_loss: 0.2523 - val_accuracy: 0.8940\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.9010 - val_loss: 0.2441 - val_accuracy: 0.8970\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.9042 - val_loss: 0.2393 - val_accuracy: 0.8980\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2419 - accuracy: 0.9069 - val_loss: 0.2422 - val_accuracy: 0.8970\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.9104 - val_loss: 0.2227 - val_accuracy: 0.9050\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2305 - accuracy: 0.9106 - val_loss: 0.2204 - val_accuracy: 0.9040\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2250 - accuracy: 0.9137 - val_loss: 0.2254 - val_accuracy: 0.9010\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2202 - accuracy: 0.9161 - val_loss: 0.2208 - val_accuracy: 0.8990\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2174 - accuracy: 0.9167 - val_loss: 0.2348 - val_accuracy: 0.9000\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.9167 - val_loss: 0.2199 - val_accuracy: 0.9010\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2095 - accuracy: 0.9187 - val_loss: 0.2129 - val_accuracy: 0.9100\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9208 - val_loss: 0.2269 - val_accuracy: 0.8990\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9213 - val_loss: 0.2342 - val_accuracy: 0.9010\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9231 - val_loss: 0.2211 - val_accuracy: 0.9030\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2008 - accuracy: 0.9223 - val_loss: 0.2245 - val_accuracy: 0.9000\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2023 - accuracy: 0.9211 - val_loss: 0.2161 - val_accuracy: 0.9060\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1966 - accuracy: 0.9236 - val_loss: 0.2184 - val_accuracy: 0.9060\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9271 - val_loss: 0.2453 - val_accuracy: 0.8970\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9270 - val_loss: 0.2175 - val_accuracy: 0.9060\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9291 - val_loss: 0.2158 - val_accuracy: 0.9050\n",
      "Epoch 22/40\n",
      "269/282 [===========================>..] - ETA: 0s - loss: 0.1876 - accuracy: 0.9304Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.9292 - val_loss: 0.2185 - val_accuracy: 0.9050\n",
      "Epoch 00022: early stopping\n",
      "Test Accuracy: 91.00000262260437\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4221 - accuracy: 0.8402 - val_loss: 0.2908 - val_accuracy: 0.8930\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2778 - accuracy: 0.8948 - val_loss: 0.2635 - val_accuracy: 0.9060\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.8986 - val_loss: 0.2561 - val_accuracy: 0.9080\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2430 - accuracy: 0.9031 - val_loss: 0.2518 - val_accuracy: 0.9060\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9073 - val_loss: 0.2483 - val_accuracy: 0.9040\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2305 - accuracy: 0.9114 - val_loss: 0.2597 - val_accuracy: 0.9030\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2250 - accuracy: 0.9118 - val_loss: 0.2444 - val_accuracy: 0.9040\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9122 - val_loss: 0.2452 - val_accuracy: 0.9070\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2129 - accuracy: 0.9173 - val_loss: 0.2451 - val_accuracy: 0.9080\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.8980\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2072 - accuracy: 0.9174 - val_loss: 0.2448 - val_accuracy: 0.9060\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9192 - val_loss: 0.2469 - val_accuracy: 0.9050\n",
      "Epoch 13/40\n",
      "278/282 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9197Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2032 - accuracy: 0.9193 - val_loss: 0.2496 - val_accuracy: 0.9080\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4293 - accuracy: 0.8419 - val_loss: 0.3184 - val_accuracy: 0.8750\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2776 - accuracy: 0.8920 - val_loss: 0.2898 - val_accuracy: 0.8850\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9003 - val_loss: 0.2819 - val_accuracy: 0.8830\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2472 - accuracy: 0.9043 - val_loss: 0.2706 - val_accuracy: 0.8880\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2357 - accuracy: 0.9056 - val_loss: 0.2643 - val_accuracy: 0.8840\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2272 - accuracy: 0.9114 - val_loss: 0.2581 - val_accuracy: 0.8890\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2209 - accuracy: 0.9157 - val_loss: 0.2537 - val_accuracy: 0.8940\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2150 - accuracy: 0.9186 - val_loss: 0.2558 - val_accuracy: 0.8970\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9178 - val_loss: 0.2522 - val_accuracy: 0.9010\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2103 - accuracy: 0.9188 - val_loss: 0.2516 - val_accuracy: 0.8990\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2082 - accuracy: 0.9199 - val_loss: 0.2441 - val_accuracy: 0.8990\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2029 - accuracy: 0.9207 - val_loss: 0.2555 - val_accuracy: 0.8990\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1997 - accuracy: 0.9237 - val_loss: 0.2486 - val_accuracy: 0.9010\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9230 - val_loss: 0.2436 - val_accuracy: 0.8970\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1939 - accuracy: 0.9238 - val_loss: 0.2486 - val_accuracy: 0.9040\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9253 - val_loss: 0.2423 - val_accuracy: 0.9000\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.9288 - val_loss: 0.2437 - val_accuracy: 0.9020\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1886 - accuracy: 0.9286 - val_loss: 0.2432 - val_accuracy: 0.9040\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9274 - val_loss: 0.2504 - val_accuracy: 0.9080\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.9286 - val_loss: 0.2374 - val_accuracy: 0.9040\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9316 - val_loss: 0.2437 - val_accuracy: 0.9020\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9304 - val_loss: 0.2431 - val_accuracy: 0.9040\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9347 - val_loss: 0.2542 - val_accuracy: 0.9050\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.9337 - val_loss: 0.2499 - val_accuracy: 0.9040\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1744 - accuracy: 0.9351 - val_loss: 0.2601 - val_accuracy: 0.9040\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1731 - accuracy: 0.9337 - val_loss: 0.2462 - val_accuracy: 0.9130\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9343 - val_loss: 0.2495 - val_accuracy: 0.9090\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9361 - val_loss: 0.2485 - val_accuracy: 0.9070\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9349 - val_loss: 0.2741 - val_accuracy: 0.9020\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9350 - val_loss: 0.2591 - val_accuracy: 0.9030\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9382 - val_loss: 0.2588 - val_accuracy: 0.9040\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9377 - val_loss: 0.2527 - val_accuracy: 0.9080\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9380 - val_loss: 0.2466 - val_accuracy: 0.9060\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1630 - accuracy: 0.9363 - val_loss: 0.2437 - val_accuracy: 0.9050\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1617 - accuracy: 0.9399 - val_loss: 0.2589 - val_accuracy: 0.9080\n",
      "Epoch 36/40\n",
      "268/282 [===========================>..] - ETA: 0s - loss: 0.1587 - accuracy: 0.9419Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1581 - accuracy: 0.9421 - val_loss: 0.2648 - val_accuracy: 0.9040\n",
      "Epoch 00036: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4218 - accuracy: 0.8463 - val_loss: 0.3013 - val_accuracy: 0.8810\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.8918 - val_loss: 0.2716 - val_accuracy: 0.8900\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.9010 - val_loss: 0.2606 - val_accuracy: 0.8950\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9042 - val_loss: 0.2525 - val_accuracy: 0.8990\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2331 - accuracy: 0.9090 - val_loss: 0.2484 - val_accuracy: 0.8960\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2268 - accuracy: 0.9116 - val_loss: 0.2471 - val_accuracy: 0.8930\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2219 - accuracy: 0.9117 - val_loss: 0.2419 - val_accuracy: 0.8980\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2186 - accuracy: 0.9167 - val_loss: 0.2425 - val_accuracy: 0.9000\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2136 - accuracy: 0.9166 - val_loss: 0.2449 - val_accuracy: 0.9050\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9197 - val_loss: 0.2402 - val_accuracy: 0.9030\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2065 - accuracy: 0.9187 - val_loss: 0.2366 - val_accuracy: 0.9020\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9197 - val_loss: 0.2369 - val_accuracy: 0.9010\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2029 - accuracy: 0.9211 - val_loss: 0.2358 - val_accuracy: 0.9040\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2006 - accuracy: 0.9237 - val_loss: 0.2334 - val_accuracy: 0.9050\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9224 - val_loss: 0.2378 - val_accuracy: 0.9100\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1944 - accuracy: 0.9237 - val_loss: 0.2331 - val_accuracy: 0.9070\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9250 - val_loss: 0.2324 - val_accuracy: 0.9120\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9229 - val_loss: 0.2330 - val_accuracy: 0.9100\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1869 - accuracy: 0.9256 - val_loss: 0.2367 - val_accuracy: 0.9110\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9264 - val_loss: 0.2353 - val_accuracy: 0.9110\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.9276 - val_loss: 0.2310 - val_accuracy: 0.9130\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.9306 - val_loss: 0.2323 - val_accuracy: 0.9120\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.9302 - val_loss: 0.2434 - val_accuracy: 0.9120\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1810 - accuracy: 0.9287 - val_loss: 0.2374 - val_accuracy: 0.9130\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9300 - val_loss: 0.2319 - val_accuracy: 0.9100\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.9311 - val_loss: 0.2342 - val_accuracy: 0.9140\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.9307 - val_loss: 0.2385 - val_accuracy: 0.9140\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9319 - val_loss: 0.2353 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.9333 - val_loss: 0.2348 - val_accuracy: 0.9110\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1702 - accuracy: 0.9340 - val_loss: 0.2329 - val_accuracy: 0.9150\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.9324 - val_loss: 0.2351 - val_accuracy: 0.9150\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9342 - val_loss: 0.2378 - val_accuracy: 0.9150\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1630 - accuracy: 0.9373 - val_loss: 0.2333 - val_accuracy: 0.9170\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9337 - val_loss: 0.2311 - val_accuracy: 0.9140\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1645 - accuracy: 0.9359 - val_loss: 0.2336 - val_accuracy: 0.9110\n",
      "Epoch 36/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1595 - accuracy: 0.9397 - val_loss: 0.2375 - val_accuracy: 0.9110\n",
      "Epoch 37/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1596 - accuracy: 0.9398 - val_loss: 0.2318 - val_accuracy: 0.9180\n",
      "Epoch 38/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1549 - accuracy: 0.9410 - val_loss: 0.2397 - val_accuracy: 0.9120\n",
      "Epoch 39/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1565 - accuracy: 0.9389 - val_loss: 0.2336 - val_accuracy: 0.9150\n",
      "Epoch 40/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1576 - accuracy: 0.9389 - val_loss: 0.2387 - val_accuracy: 0.9130\n",
      "Test Accuracy: 91.29999876022339\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.8379 - val_loss: 0.2856 - val_accuracy: 0.8950\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.8910 - val_loss: 0.2564 - val_accuracy: 0.9020\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2629 - accuracy: 0.8964 - val_loss: 0.2563 - val_accuracy: 0.9000\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2464 - accuracy: 0.9010 - val_loss: 0.2440 - val_accuracy: 0.9120\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9059 - val_loss: 0.2422 - val_accuracy: 0.9120\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2331 - accuracy: 0.9089 - val_loss: 0.2377 - val_accuracy: 0.9110\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2290 - accuracy: 0.9088 - val_loss: 0.2378 - val_accuracy: 0.9130\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9143 - val_loss: 0.2339 - val_accuracy: 0.9130\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2152 - accuracy: 0.9144 - val_loss: 0.2361 - val_accuracy: 0.9130\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9146 - val_loss: 0.2364 - val_accuracy: 0.9140\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9163 - val_loss: 0.2330 - val_accuracy: 0.9150\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2062 - accuracy: 0.9192 - val_loss: 0.2305 - val_accuracy: 0.9180\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9200 - val_loss: 0.2350 - val_accuracy: 0.9140\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.9171 - val_loss: 0.2423 - val_accuracy: 0.9040\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.9246 - val_loss: 0.2284 - val_accuracy: 0.9150\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1967 - accuracy: 0.9224 - val_loss: 0.2319 - val_accuracy: 0.9140\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1926 - accuracy: 0.9244 - val_loss: 0.2283 - val_accuracy: 0.9180\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9263 - val_loss: 0.2298 - val_accuracy: 0.9130\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1907 - accuracy: 0.9272 - val_loss: 0.2344 - val_accuracy: 0.9120\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.9284 - val_loss: 0.2299 - val_accuracy: 0.9170\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9259 - val_loss: 0.2300 - val_accuracy: 0.9180\n",
      "Epoch 22/40\n",
      "269/282 [===========================>..] - ETA: 0s - loss: 0.1793 - accuracy: 0.9299Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.9293 - val_loss: 0.2317 - val_accuracy: 0.9140\n",
      "Epoch 00022: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4302 - accuracy: 0.8449 - val_loss: 0.2940 - val_accuracy: 0.8900\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2847 - accuracy: 0.8906 - val_loss: 0.2614 - val_accuracy: 0.8880\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2606 - accuracy: 0.9000 - val_loss: 0.2453 - val_accuracy: 0.8930\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.9026 - val_loss: 0.2396 - val_accuracy: 0.8930\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2391 - accuracy: 0.9066 - val_loss: 0.2333 - val_accuracy: 0.8980\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2330 - accuracy: 0.9093 - val_loss: 0.2362 - val_accuracy: 0.8950\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2274 - accuracy: 0.9109 - val_loss: 0.2283 - val_accuracy: 0.8940\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2220 - accuracy: 0.9131 - val_loss: 0.2259 - val_accuracy: 0.9040\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2195 - accuracy: 0.9157 - val_loss: 0.2255 - val_accuracy: 0.8980\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.9183 - val_loss: 0.2227 - val_accuracy: 0.9010\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9193 - val_loss: 0.2288 - val_accuracy: 0.8940\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9180 - val_loss: 0.2238 - val_accuracy: 0.8960\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9184 - val_loss: 0.2274 - val_accuracy: 0.9020\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9221 - val_loss: 0.2197 - val_accuracy: 0.8990\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2010 - accuracy: 0.9222 - val_loss: 0.2188 - val_accuracy: 0.9020\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1996 - accuracy: 0.9207 - val_loss: 0.2214 - val_accuracy: 0.9020\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1986 - accuracy: 0.9227 - val_loss: 0.2206 - val_accuracy: 0.9030\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1989 - accuracy: 0.9228 - val_loss: 0.2206 - val_accuracy: 0.9060\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9271 - val_loss: 0.2199 - val_accuracy: 0.9020\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1940 - accuracy: 0.9250 - val_loss: 0.2179 - val_accuracy: 0.9080\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.9267 - val_loss: 0.2206 - val_accuracy: 0.9070\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.9254 - val_loss: 0.2218 - val_accuracy: 0.9070\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.9280 - val_loss: 0.2175 - val_accuracy: 0.9080\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9271 - val_loss: 0.2170 - val_accuracy: 0.9100\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9301 - val_loss: 0.2265 - val_accuracy: 0.9080\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.9303 - val_loss: 0.2254 - val_accuracy: 0.9080\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.9321 - val_loss: 0.2255 - val_accuracy: 0.9070\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.9297 - val_loss: 0.2190 - val_accuracy: 0.9080\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.9310 - val_loss: 0.2213 - val_accuracy: 0.9080\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.9331 - val_loss: 0.2274 - val_accuracy: 0.9110\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1747 - accuracy: 0.9322 - val_loss: 0.2218 - val_accuracy: 0.9080\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9320 - val_loss: 0.2230 - val_accuracy: 0.9070\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9339 - val_loss: 0.2247 - val_accuracy: 0.9110\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9370 - val_loss: 0.2226 - val_accuracy: 0.9090\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1683 - accuracy: 0.9361 - val_loss: 0.2253 - val_accuracy: 0.9080\n",
      "Epoch 36/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9347 - val_loss: 0.2249 - val_accuracy: 0.9130\n",
      "Epoch 37/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1646 - accuracy: 0.9398 - val_loss: 0.2216 - val_accuracy: 0.9090\n",
      "Epoch 38/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9374 - val_loss: 0.2215 - val_accuracy: 0.9120\n",
      "Epoch 39/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1636 - accuracy: 0.9378 - val_loss: 0.2302 - val_accuracy: 0.9120\n",
      "Epoch 40/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9366 - val_loss: 0.2287 - val_accuracy: 0.9110\n",
      "Test Accuracy: 91.10000133514404\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4190 - accuracy: 0.8500 - val_loss: 0.3148 - val_accuracy: 0.8770\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.8933 - val_loss: 0.2983 - val_accuracy: 0.8900\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9004 - val_loss: 0.2852 - val_accuracy: 0.8820\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2423 - accuracy: 0.9047 - val_loss: 0.2790 - val_accuracy: 0.8860\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2249 - accuracy: 0.9120 - val_loss: 0.2766 - val_accuracy: 0.8850\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9121 - val_loss: 0.2767 - val_accuracy: 0.8900\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2201 - accuracy: 0.9147 - val_loss: 0.2782 - val_accuracy: 0.8820\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9179 - val_loss: 0.2707 - val_accuracy: 0.8870\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9189 - val_loss: 0.2737 - val_accuracy: 0.8860\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9199 - val_loss: 0.2704 - val_accuracy: 0.8880\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2015 - accuracy: 0.9222 - val_loss: 0.2745 - val_accuracy: 0.8840\n",
      "Epoch 12/40\n",
      "275/282 [============================>.] - ETA: 0s - loss: 0.1987 - accuracy: 0.9212Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9211 - val_loss: 0.2731 - val_accuracy: 0.8860\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 88.99999856948853\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4301 - accuracy: 0.8378 - val_loss: 0.2837 - val_accuracy: 0.8930\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.8924 - val_loss: 0.2545 - val_accuracy: 0.8990\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.9006 - val_loss: 0.2416 - val_accuracy: 0.9060\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.9013 - val_loss: 0.2329 - val_accuracy: 0.9050\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2380 - accuracy: 0.9037 - val_loss: 0.2262 - val_accuracy: 0.9110\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2331 - accuracy: 0.9084 - val_loss: 0.2203 - val_accuracy: 0.9110\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.91 - 1s 2ms/step - loss: 0.2274 - accuracy: 0.9128 - val_loss: 0.2174 - val_accuracy: 0.9100\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2217 - accuracy: 0.9141 - val_loss: 0.2123 - val_accuracy: 0.9180\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9144 - val_loss: 0.2123 - val_accuracy: 0.9120\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2141 - accuracy: 0.9169 - val_loss: 0.2118 - val_accuracy: 0.9150\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9166 - val_loss: 0.2073 - val_accuracy: 0.9150\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2102 - accuracy: 0.9184 - val_loss: 0.2058 - val_accuracy: 0.9170\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9183 - val_loss: 0.2054 - val_accuracy: 0.9160\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2044 - accuracy: 0.9190 - val_loss: 0.2037 - val_accuracy: 0.9150\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2010 - accuracy: 0.9210 - val_loss: 0.2039 - val_accuracy: 0.9180\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9248 - val_loss: 0.2037 - val_accuracy: 0.9190\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9230 - val_loss: 0.2012 - val_accuracy: 0.9180\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1972 - accuracy: 0.9238 - val_loss: 0.2035 - val_accuracy: 0.9180\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9266 - val_loss: 0.2005 - val_accuracy: 0.9200\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1886 - accuracy: 0.9250 - val_loss: 0.1995 - val_accuracy: 0.9170\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9261 - val_loss: 0.1990 - val_accuracy: 0.9170\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1859 - accuracy: 0.9284 - val_loss: 0.1984 - val_accuracy: 0.9190\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.9258 - val_loss: 0.1969 - val_accuracy: 0.9240\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9263 - val_loss: 0.1994 - val_accuracy: 0.9240\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.9296 - val_loss: 0.2000 - val_accuracy: 0.9240\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.9321 - val_loss: 0.1977 - val_accuracy: 0.9230\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.9317 - val_loss: 0.1978 - val_accuracy: 0.9290\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.9299 - val_loss: 0.1994 - val_accuracy: 0.9240\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.9312 - val_loss: 0.2013 - val_accuracy: 0.9230\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1742 - accuracy: 0.9307 - val_loss: 0.2029 - val_accuracy: 0.9190\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.9300 - val_loss: 0.1997 - val_accuracy: 0.9250\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9340 - val_loss: 0.2026 - val_accuracy: 0.9220\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9331 - val_loss: 0.2032 - val_accuracy: 0.9250\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1651 - accuracy: 0.9368 - val_loss: 0.2007 - val_accuracy: 0.9220\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1693 - accuracy: 0.9314 - val_loss: 0.2013 - val_accuracy: 0.9240\n",
      "Epoch 36/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9343 - val_loss: 0.2002 - val_accuracy: 0.9220\n",
      "Epoch 37/40\n",
      "277/282 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9377 ETA: 0s - loss: 0Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1620 - accuracy: 0.9381 - val_loss: 0.2059 - val_accuracy: 0.9210\n",
      "Epoch 00037: early stopping\n",
      "Test Accuracy: 92.90000200271606\n",
      "\n",
      "\n",
      "   acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
      "0  92.6  91.799998  91.000003  90.799999  91.299999  91.299999  91.799998   \n",
      "\n",
      "        acc8       acc9      acc10    AVG  \n",
      "0  91.100001  88.999999  92.900002  91.36  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.6</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>91.000003</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>88.999999</td>\n",
       "      <td>92.900002</td>\n",
       "      <td>91.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
       "0  92.6  91.799998  91.000003  90.799999  91.299999  91.299999  91.799998   \n",
       "\n",
       "        acc8       acc9      acc10    AVG  \n",
       "0  91.100001  88.999999  92.900002  91.36  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('Emb_MLP_SUBJ.xlsx', sheet_name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,201\n",
      "Trainable params: 30,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = define_model_2(300)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.3872 - accuracy: 0.8611 - val_loss: 0.2514 - val_accuracy: 0.9030\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.2657 - accuracy: 0.8950 - val_loss: 0.2309 - val_accuracy: 0.9050\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.2487 - accuracy: 0.9032 - val_loss: 0.2213 - val_accuracy: 0.9120\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2340 - accuracy: 0.9079 - val_loss: 0.2164 - val_accuracy: 0.9130\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2250 - accuracy: 0.9108 - val_loss: 0.2161 - val_accuracy: 0.9230\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9123 - val_loss: 0.2124 - val_accuracy: 0.9140\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9168 - val_loss: 0.2096 - val_accuracy: 0.9120\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9130 - val_loss: 0.2080 - val_accuracy: 0.9180\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.2045 - accuracy: 0.9160 - val_loss: 0.2071 - val_accuracy: 0.9210\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.2003 - accuracy: 0.9223 - val_loss: 0.2087 - val_accuracy: 0.9110\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1977 - accuracy: 0.9218 - val_loss: 0.2105 - val_accuracy: 0.9200\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1923 - accuracy: 0.9241 - val_loss: 0.2070 - val_accuracy: 0.9210\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9254 - val_loss: 0.2063 - val_accuracy: 0.9160\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9250 - val_loss: 0.2066 - val_accuracy: 0.9170\n",
      "Epoch 15/40\n",
      "281/282 [============================>.] - ETA: 0s - loss: 0.1862 - accuracy: 0.9263Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1861 - accuracy: 0.9263 - val_loss: 0.2068 - val_accuracy: 0.9170\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.3819 - accuracy: 0.8603 - val_loss: 0.2857 - val_accuracy: 0.8960\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2586 - accuracy: 0.8989 - val_loss: 0.2706 - val_accuracy: 0.8950\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2423 - accuracy: 0.9032 - val_loss: 0.2698 - val_accuracy: 0.8930\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.9117 - val_loss: 0.2652 - val_accuracy: 0.8960\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2214 - accuracy: 0.9107 - val_loss: 0.2510 - val_accuracy: 0.8970\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.2182 - accuracy: 0.9123 - val_loss: 0.2486 - val_accuracy: 0.8970\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2122 - accuracy: 0.9146 - val_loss: 0.2599 - val_accuracy: 0.8980\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2066 - accuracy: 0.9197 - val_loss: 0.2432 - val_accuracy: 0.8990\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9183 - val_loss: 0.2410 - val_accuracy: 0.9000\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1997 - accuracy: 0.9223 - val_loss: 0.2395 - val_accuracy: 0.9000\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1963 - accuracy: 0.9227 - val_loss: 0.2602 - val_accuracy: 0.8920\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9232 - val_loss: 0.2476 - val_accuracy: 0.9070\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9260 - val_loss: 0.2390 - val_accuracy: 0.9010\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9268 - val_loss: 0.2381 - val_accuracy: 0.9000\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1807 - accuracy: 0.9271 - val_loss: 0.2409 - val_accuracy: 0.9050\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1798 - accuracy: 0.9288 - val_loss: 0.2361 - val_accuracy: 0.9080\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1823 - accuracy: 0.9289 - val_loss: 0.2375 - val_accuracy: 0.9060\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9316 - val_loss: 0.2389 - val_accuracy: 0.9060\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.9330 - val_loss: 0.2472 - val_accuracy: 0.9060\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1712 - accuracy: 0.9338 - val_loss: 0.2420 - val_accuracy: 0.9040\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1677 - accuracy: 0.9328 - val_loss: 0.2408 - val_accuracy: 0.9080\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1657 - accuracy: 0.9349 - val_loss: 0.2437 - val_accuracy: 0.9090\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1626 - accuracy: 0.9357 - val_loss: 0.2465 - val_accuracy: 0.9090\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1642 - accuracy: 0.9366 - val_loss: 0.2458 - val_accuracy: 0.9100\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9393 - val_loss: 0.2464 - val_accuracy: 0.9100\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.9388 - val_loss: 0.2412 - val_accuracy: 0.9080\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9392 - val_loss: 0.2442 - val_accuracy: 0.9080\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1495 - accuracy: 0.9438 - val_loss: 0.2450 - val_accuracy: 0.9100\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1491 - accuracy: 0.9417 - val_loss: 0.2507 - val_accuracy: 0.9070\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1487 - accuracy: 0.9418 - val_loss: 0.2431 - val_accuracy: 0.9120\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1438 - accuracy: 0.9442 - val_loss: 0.2510 - val_accuracy: 0.9090\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9466 - val_loss: 0.2470 - val_accuracy: 0.9100\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1420 - accuracy: 0.9440 - val_loss: 0.2424 - val_accuracy: 0.9080\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9461 - val_loss: 0.2596 - val_accuracy: 0.9100\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9473 - val_loss: 0.2531 - val_accuracy: 0.9090\n",
      "Epoch 36/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1332 - accuracy: 0.9507 - val_loss: 0.2599 - val_accuracy: 0.9090\n",
      "Epoch 37/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1336 - accuracy: 0.9482 - val_loss: 0.2485 - val_accuracy: 0.9100\n",
      "Epoch 38/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1250 - accuracy: 0.9532 - val_loss: 0.2566 - val_accuracy: 0.9120\n",
      "Epoch 39/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1278 - accuracy: 0.9524 - val_loss: 0.2557 - val_accuracy: 0.9070\n",
      "Epoch 40/40\n",
      "278/282 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.9520Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9522 - val_loss: 0.2565 - val_accuracy: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040: early stopping\n",
      "Test Accuracy: 91.20000004768372\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.3837 - accuracy: 0.8598 - val_loss: 0.2841 - val_accuracy: 0.8910\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2631 - accuracy: 0.8967 - val_loss: 0.2654 - val_accuracy: 0.8940\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2427 - accuracy: 0.9042 - val_loss: 0.2542 - val_accuracy: 0.9000\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2317 - accuracy: 0.9080 - val_loss: 0.2488 - val_accuracy: 0.9010\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2220 - accuracy: 0.9112 - val_loss: 0.2459 - val_accuracy: 0.9080\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2159 - accuracy: 0.9129 - val_loss: 0.2460 - val_accuracy: 0.8960\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2156 - accuracy: 0.9137 - val_loss: 0.2395 - val_accuracy: 0.9010\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2079 - accuracy: 0.9194 - val_loss: 0.2434 - val_accuracy: 0.8980\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9227 - val_loss: 0.2334 - val_accuracy: 0.9080\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1997 - accuracy: 0.9220 - val_loss: 0.2294 - val_accuracy: 0.9100\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1944 - accuracy: 0.9234 - val_loss: 0.2292 - val_accuracy: 0.9120\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9250 - val_loss: 0.2347 - val_accuracy: 0.9070\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9264 - val_loss: 0.2326 - val_accuracy: 0.9090\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1867 - accuracy: 0.9258 - val_loss: 0.2264 - val_accuracy: 0.9100\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1848 - accuracy: 0.9290 - val_loss: 0.2265 - val_accuracy: 0.9130\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9301 - val_loss: 0.2394 - val_accuracy: 0.9060\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1795 - accuracy: 0.9287 - val_loss: 0.2288 - val_accuracy: 0.9150\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1768 - accuracy: 0.9337 - val_loss: 0.2291 - val_accuracy: 0.9140\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9309 - val_loss: 0.2299 - val_accuracy: 0.9120\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9313 - val_loss: 0.2247 - val_accuracy: 0.9170\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9334 - val_loss: 0.2321 - val_accuracy: 0.9100\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9372 - val_loss: 0.2294 - val_accuracy: 0.9140\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.1641 - accuracy: 0.9347 - val_loss: 0.2266 - val_accuracy: 0.9160\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1636 - accuracy: 0.9373 - val_loss: 0.2263 - val_accuracy: 0.9160\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.1607 - accuracy: 0.9366 - val_loss: 0.2286 - val_accuracy: 0.9140\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1551 - accuracy: 0.9397 - val_loss: 0.2376 - val_accuracy: 0.9080\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9407 - val_loss: 0.2297 - val_accuracy: 0.9140\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9423 - val_loss: 0.2367 - val_accuracy: 0.9040\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1487 - accuracy: 0.9433 - val_loss: 0.2314 - val_accuracy: 0.9080\n",
      "Epoch 30/40\n",
      "280/282 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9423Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1466 - accuracy: 0.9424 - val_loss: 0.2404 - val_accuracy: 0.9010\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3873 - accuracy: 0.8564 - val_loss: 0.3087 - val_accuracy: 0.8720\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2621 - accuracy: 0.8973 - val_loss: 0.2879 - val_accuracy: 0.8840\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.9053 - val_loss: 0.2902 - val_accuracy: 0.8800\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2311 - accuracy: 0.9061 - val_loss: 0.2761 - val_accuracy: 0.8890\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2218 - accuracy: 0.9148 - val_loss: 0.2712 - val_accuracy: 0.8880\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2164 - accuracy: 0.9146 - val_loss: 0.2658 - val_accuracy: 0.8880\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2108 - accuracy: 0.9179 - val_loss: 0.2642 - val_accuracy: 0.8920\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9197 - val_loss: 0.2665 - val_accuracy: 0.8880\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9208 - val_loss: 0.2621 - val_accuracy: 0.8910\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.1982 - accuracy: 0.9214 - val_loss: 0.2600 - val_accuracy: 0.8910\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1955 - accuracy: 0.9228 - val_loss: 0.2626 - val_accuracy: 0.8930\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1919 - accuracy: 0.9242 - val_loss: 0.2585 - val_accuracy: 0.8950\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1884 - accuracy: 0.9263 - val_loss: 0.2729 - val_accuracy: 0.8950\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1837 - accuracy: 0.9284 - val_loss: 0.2598 - val_accuracy: 0.8940\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9288 - val_loss: 0.2598 - val_accuracy: 0.8960\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1810 - accuracy: 0.9312 - val_loss: 0.2616 - val_accuracy: 0.8980\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1805 - accuracy: 0.9298 - val_loss: 0.2624 - val_accuracy: 0.8950\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1764 - accuracy: 0.9307 - val_loss: 0.2722 - val_accuracy: 0.8920\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9339 - val_loss: 0.2655 - val_accuracy: 0.8960\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1699 - accuracy: 0.9319 - val_loss: 0.2680 - val_accuracy: 0.8960\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9334 - val_loss: 0.2659 - val_accuracy: 0.8960\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9363 - val_loss: 0.2679 - val_accuracy: 0.8980\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9363 - val_loss: 0.2680 - val_accuracy: 0.8980\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1583 - accuracy: 0.9407 - val_loss: 0.2722 - val_accuracy: 0.8960\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9373 - val_loss: 0.2667 - val_accuracy: 0.8940\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1574 - accuracy: 0.9394 - val_loss: 0.2656 - val_accuracy: 0.9000\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1564 - accuracy: 0.9413 - val_loss: 0.2757 - val_accuracy: 0.8980\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1555 - accuracy: 0.9410 - val_loss: 0.2675 - val_accuracy: 0.8970\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9432 - val_loss: 0.2686 - val_accuracy: 0.8970\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1492 - accuracy: 0.9432 - val_loss: 0.2663 - val_accuracy: 0.9000\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1461 - accuracy: 0.9439 - val_loss: 0.2807 - val_accuracy: 0.8940\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1463 - accuracy: 0.9442 - val_loss: 0.2750 - val_accuracy: 0.8990\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1409 - accuracy: 0.9474 - val_loss: 0.2699 - val_accuracy: 0.9010\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9479 - val_loss: 0.2832 - val_accuracy: 0.8990\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1379 - accuracy: 0.9480 - val_loss: 0.2698 - val_accuracy: 0.9010\n",
      "Epoch 36/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9500 - val_loss: 0.2875 - val_accuracy: 0.8960\n",
      "Epoch 37/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1333 - accuracy: 0.9507 - val_loss: 0.2962 - val_accuracy: 0.8930\n",
      "Epoch 38/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9492 - val_loss: 0.2863 - val_accuracy: 0.8980\n",
      "Epoch 39/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1295 - accuracy: 0.9519 - val_loss: 0.2937 - val_accuracy: 0.8960\n",
      "Epoch 40/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1270 - accuracy: 0.9546 - val_loss: 0.2863 - val_accuracy: 0.8980\n",
      "Test Accuracy: 89.80000019073486\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3857 - accuracy: 0.8594 - val_loss: 0.2668 - val_accuracy: 0.8970\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2677 - accuracy: 0.8937 - val_loss: 0.2416 - val_accuracy: 0.9030\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2466 - accuracy: 0.9008 - val_loss: 0.2278 - val_accuracy: 0.9040\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2346 - accuracy: 0.9072 - val_loss: 0.2300 - val_accuracy: 0.9040\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2252 - accuracy: 0.9096 - val_loss: 0.2160 - val_accuracy: 0.9080\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2189 - accuracy: 0.9141 - val_loss: 0.2087 - val_accuracy: 0.9100\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2157 - accuracy: 0.9170 - val_loss: 0.2022 - val_accuracy: 0.9150\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2090 - accuracy: 0.9163 - val_loss: 0.1992 - val_accuracy: 0.9150\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9209 - val_loss: 0.2004 - val_accuracy: 0.9190\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9219 - val_loss: 0.1967 - val_accuracy: 0.9150\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9191 - val_loss: 0.1969 - val_accuracy: 0.9140\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1976 - accuracy: 0.9246 - val_loss: 0.2026 - val_accuracy: 0.9180\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1914 - accuracy: 0.9260 - val_loss: 0.1993 - val_accuracy: 0.9160\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1874 - accuracy: 0.9261 - val_loss: 0.1897 - val_accuracy: 0.9180\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1846 - accuracy: 0.9266 - val_loss: 0.2022 - val_accuracy: 0.9170\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1849 - accuracy: 0.9292 - val_loss: 0.1920 - val_accuracy: 0.9140\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1817 - accuracy: 0.9296 - val_loss: 0.2048 - val_accuracy: 0.9190\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9302 - val_loss: 0.1929 - val_accuracy: 0.9140\n",
      "Epoch 19/40\n",
      "277/282 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9312Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1768 - accuracy: 0.9316 - val_loss: 0.2054 - val_accuracy: 0.9180\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8547 - val_loss: 0.2569 - val_accuracy: 0.9000\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8959 - val_loss: 0.2343 - val_accuracy: 0.9060\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2474 - accuracy: 0.9038 - val_loss: 0.2219 - val_accuracy: 0.9110\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2331 - accuracy: 0.9074 - val_loss: 0.2132 - val_accuracy: 0.9120\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2233 - accuracy: 0.9096 - val_loss: 0.2119 - val_accuracy: 0.9140\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2178 - accuracy: 0.9146 - val_loss: 0.2077 - val_accuracy: 0.9140\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2118 - accuracy: 0.9158 - val_loss: 0.2072 - val_accuracy: 0.9150\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2089 - accuracy: 0.9178 - val_loss: 0.2051 - val_accuracy: 0.9190\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2045 - accuracy: 0.9206 - val_loss: 0.2032 - val_accuracy: 0.9200\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9191 - val_loss: 0.2081 - val_accuracy: 0.9200\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9239 - val_loss: 0.2046 - val_accuracy: 0.9230\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1932 - accuracy: 0.9231 - val_loss: 0.2004 - val_accuracy: 0.9220\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1901 - accuracy: 0.9233 - val_loss: 0.1991 - val_accuracy: 0.9250\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1896 - accuracy: 0.9240 - val_loss: 0.1980 - val_accuracy: 0.9250\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1850 - accuracy: 0.9268 - val_loss: 0.2057 - val_accuracy: 0.9240\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1830 - accuracy: 0.9278 - val_loss: 0.1978 - val_accuracy: 0.9210\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1848 - accuracy: 0.9283 - val_loss: 0.2012 - val_accuracy: 0.9230\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1802 - accuracy: 0.9294 - val_loss: 0.1973 - val_accuracy: 0.9220\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1759 - accuracy: 0.9326 - val_loss: 0.2090 - val_accuracy: 0.9200\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1750 - accuracy: 0.9334 - val_loss: 0.2013 - val_accuracy: 0.9270\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1746 - accuracy: 0.9342 - val_loss: 0.1984 - val_accuracy: 0.9200\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9354 - val_loss: 0.1984 - val_accuracy: 0.9240\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1683 - accuracy: 0.9347 - val_loss: 0.1993 - val_accuracy: 0.9240\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1650 - accuracy: 0.9366 - val_loss: 0.1991 - val_accuracy: 0.9220\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1631 - accuracy: 0.9364 - val_loss: 0.2094 - val_accuracy: 0.9190\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9378 - val_loss: 0.2007 - val_accuracy: 0.9220\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9403 - val_loss: 0.2042 - val_accuracy: 0.9200\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1556 - accuracy: 0.9403 - val_loss: 0.2087 - val_accuracy: 0.9210\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1528 - accuracy: 0.9403 - val_loss: 0.2119 - val_accuracy: 0.9200\n",
      "Epoch 30/40\n",
      "280/282 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9419Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1503 - accuracy: 0.9420 - val_loss: 0.2027 - val_accuracy: 0.9220\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 92.69999861717224\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3859 - accuracy: 0.8579 - val_loss: 0.2839 - val_accuracy: 0.8840\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.8980 - val_loss: 0.2586 - val_accuracy: 0.9020\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2460 - accuracy: 0.9026 - val_loss: 0.2500 - val_accuracy: 0.9030\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2317 - accuracy: 0.9086 - val_loss: 0.2481 - val_accuracy: 0.9030\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2235 - accuracy: 0.9107 - val_loss: 0.2513 - val_accuracy: 0.9010\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2166 - accuracy: 0.9151 - val_loss: 0.2403 - val_accuracy: 0.9010\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2136 - accuracy: 0.9158 - val_loss: 0.2376 - val_accuracy: 0.9030\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2069 - accuracy: 0.9179 - val_loss: 0.2389 - val_accuracy: 0.9080\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2027 - accuracy: 0.9202 - val_loss: 0.2358 - val_accuracy: 0.9080\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1995 - accuracy: 0.9211 - val_loss: 0.2452 - val_accuracy: 0.9040\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9224 - val_loss: 0.2351 - val_accuracy: 0.9090\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1904 - accuracy: 0.9260 - val_loss: 0.2506 - val_accuracy: 0.9050\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1892 - accuracy: 0.9272 - val_loss: 0.2395 - val_accuracy: 0.9100\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1864 - accuracy: 0.9270 - val_loss: 0.2369 - val_accuracy: 0.9100\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1833 - accuracy: 0.9291 - val_loss: 0.2451 - val_accuracy: 0.9030\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1838 - accuracy: 0.9277 - val_loss: 0.2342 - val_accuracy: 0.9150\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1812 - accuracy: 0.9294 - val_loss: 0.2452 - val_accuracy: 0.9020\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9296 - val_loss: 0.2411 - val_accuracy: 0.9080\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1750 - accuracy: 0.9307 - val_loss: 0.2374 - val_accuracy: 0.9120\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1693 - accuracy: 0.9333 - val_loss: 0.2428 - val_accuracy: 0.9080\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1707 - accuracy: 0.9348 - val_loss: 0.2419 - val_accuracy: 0.9090\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9344 - val_loss: 0.2452 - val_accuracy: 0.9080\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1688 - accuracy: 0.9357 - val_loss: 0.2383 - val_accuracy: 0.9110\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9372 - val_loss: 0.2442 - val_accuracy: 0.9100\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1589 - accuracy: 0.9377 - val_loss: 0.2410 - val_accuracy: 0.9040\n",
      "Epoch 26/40\n",
      "272/282 [===========================>..] - ETA: 0s - loss: 0.1572 - accuracy: 0.9396Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9396 - val_loss: 0.2452 - val_accuracy: 0.9080\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 91.50000214576721\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3895 - accuracy: 0.8592 - val_loss: 0.2915 - val_accuracy: 0.8730\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.8994 - val_loss: 0.2726 - val_accuracy: 0.8860\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2450 - accuracy: 0.9044 - val_loss: 0.2578 - val_accuracy: 0.8850\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2324 - accuracy: 0.9099 - val_loss: 0.2648 - val_accuracy: 0.8930\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9130 - val_loss: 0.2531 - val_accuracy: 0.8910\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2148 - accuracy: 0.9154 - val_loss: 0.2444 - val_accuracy: 0.8940\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9162 - val_loss: 0.2557 - val_accuracy: 0.8960\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2067 - accuracy: 0.9213 - val_loss: 0.2401 - val_accuracy: 0.8980\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2036 - accuracy: 0.9180 - val_loss: 0.2446 - val_accuracy: 0.8960\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1984 - accuracy: 0.9220 - val_loss: 0.2340 - val_accuracy: 0.9020\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9226 - val_loss: 0.2371 - val_accuracy: 0.9010\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9250 - val_loss: 0.2363 - val_accuracy: 0.9030\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1884 - accuracy: 0.9282 - val_loss: 0.2407 - val_accuracy: 0.9020\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9264 - val_loss: 0.2445 - val_accuracy: 0.9000\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1864 - accuracy: 0.9277 - val_loss: 0.2335 - val_accuracy: 0.9120\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1800 - accuracy: 0.9306 - val_loss: 0.2361 - val_accuracy: 0.9130\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1800 - accuracy: 0.9311 - val_loss: 0.2317 - val_accuracy: 0.9080\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9314 - val_loss: 0.2348 - val_accuracy: 0.9110\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1726 - accuracy: 0.9327 - val_loss: 0.2400 - val_accuracy: 0.9100\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.9314 - val_loss: 0.2398 - val_accuracy: 0.9090\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9322 - val_loss: 0.2513 - val_accuracy: 0.8970\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1679 - accuracy: 0.9351 - val_loss: 0.2383 - val_accuracy: 0.9160\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9373 - val_loss: 0.2339 - val_accuracy: 0.9150\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9379 - val_loss: 0.2511 - val_accuracy: 0.8970\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1596 - accuracy: 0.9396 - val_loss: 0.2402 - val_accuracy: 0.9090\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.9368 - val_loss: 0.2420 - val_accuracy: 0.9030\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9394 - val_loss: 0.2431 - val_accuracy: 0.9020\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1513 - accuracy: 0.9431 - val_loss: 0.2419 - val_accuracy: 0.9080\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1516 - accuracy: 0.9430 - val_loss: 0.2452 - val_accuracy: 0.9070\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9417 - val_loss: 0.2453 - val_accuracy: 0.9080\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9428 - val_loss: 0.2519 - val_accuracy: 0.9120\n",
      "Epoch 32/40\n",
      "277/282 [============================>.] - ETA: 0s - loss: 0.1442 - accuracy: 0.9461Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1452 - accuracy: 0.9454 - val_loss: 0.2469 - val_accuracy: 0.9080\n",
      "Epoch 00032: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3850 - accuracy: 0.8564 - val_loss: 0.2685 - val_accuracy: 0.8980\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8953 - val_loss: 0.2473 - val_accuracy: 0.9040\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2436 - accuracy: 0.9030 - val_loss: 0.2428 - val_accuracy: 0.9080\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9086 - val_loss: 0.2471 - val_accuracy: 0.9000\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2244 - accuracy: 0.9112 - val_loss: 0.2362 - val_accuracy: 0.9040\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2164 - accuracy: 0.9131 - val_loss: 0.2345 - val_accuracy: 0.9060\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9159 - val_loss: 0.2338 - val_accuracy: 0.9080\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2058 - accuracy: 0.9169 - val_loss: 0.2325 - val_accuracy: 0.9120\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2016 - accuracy: 0.9198 - val_loss: 0.2330 - val_accuracy: 0.9120\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9218 - val_loss: 0.2336 - val_accuracy: 0.9100\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1919 - accuracy: 0.9226 - val_loss: 0.2330 - val_accuracy: 0.9120\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1923 - accuracy: 0.9254 - val_loss: 0.2338 - val_accuracy: 0.9130\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1882 - accuracy: 0.9252 - val_loss: 0.2389 - val_accuracy: 0.9090\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1856 - accuracy: 0.9254 - val_loss: 0.2340 - val_accuracy: 0.9180\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1814 - accuracy: 0.9294 - val_loss: 0.2418 - val_accuracy: 0.9100\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1804 - accuracy: 0.9262 - val_loss: 0.2376 - val_accuracy: 0.9160\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1776 - accuracy: 0.9314 - val_loss: 0.2367 - val_accuracy: 0.9180\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1746 - accuracy: 0.9321 - val_loss: 0.2376 - val_accuracy: 0.9150\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1725 - accuracy: 0.9323 - val_loss: 0.2430 - val_accuracy: 0.9140\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1723 - accuracy: 0.9313 - val_loss: 0.2467 - val_accuracy: 0.9120\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9317 - val_loss: 0.2483 - val_accuracy: 0.9140\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1672 - accuracy: 0.9333 - val_loss: 0.2525 - val_accuracy: 0.9100\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9329 - val_loss: 0.2539 - val_accuracy: 0.9110\n",
      "Epoch 24/40\n",
      "265/282 [===========================>..] - ETA: 0s - loss: 0.1640 - accuracy: 0.9349Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9348 - val_loss: 0.2461 - val_accuracy: 0.9180\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3824 - accuracy: 0.8603 - val_loss: 0.2888 - val_accuracy: 0.8890\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.8962 - val_loss: 0.2709 - val_accuracy: 0.8960\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2428 - accuracy: 0.9046 - val_loss: 0.2567 - val_accuracy: 0.8990\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2305 - accuracy: 0.9087 - val_loss: 0.2500 - val_accuracy: 0.8990\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9108 - val_loss: 0.2454 - val_accuracy: 0.8990\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2189 - accuracy: 0.9127 - val_loss: 0.2423 - val_accuracy: 0.8990\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2104 - accuracy: 0.9166 - val_loss: 0.2392 - val_accuracy: 0.9010\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2072 - accuracy: 0.9182 - val_loss: 0.2388 - val_accuracy: 0.9030\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2025 - accuracy: 0.9224 - val_loss: 0.2402 - val_accuracy: 0.9040\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9212 - val_loss: 0.2407 - val_accuracy: 0.9030\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1932 - accuracy: 0.9261 - val_loss: 0.2424 - val_accuracy: 0.9080\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.9276 - val_loss: 0.2397 - val_accuracy: 0.9080\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1848 - accuracy: 0.9282 - val_loss: 0.2526 - val_accuracy: 0.9030\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.9271 - val_loss: 0.2388 - val_accuracy: 0.9080\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9293 - val_loss: 0.2426 - val_accuracy: 0.9030\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1784 - accuracy: 0.9327 - val_loss: 0.2447 - val_accuracy: 0.9000\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1728 - accuracy: 0.9330 - val_loss: 0.2407 - val_accuracy: 0.9030\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1721 - accuracy: 0.9344 - val_loss: 0.2441 - val_accuracy: 0.9030\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9324 - val_loss: 0.2438 - val_accuracy: 0.9020\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1697 - accuracy: 0.9354 - val_loss: 0.2445 - val_accuracy: 0.9040\n",
      "Epoch 21/40\n",
      "281/282 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9372Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1637 - accuracy: 0.9372 - val_loss: 0.2524 - val_accuracy: 0.9030\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "\n",
      "\n",
      "        acc1  acc2  acc3  acc4       acc5       acc6       acc7       acc8  \\\n",
      "0  92.299998  91.2  91.7  89.8  91.900003  92.699999  91.500002  91.600001   \n",
      "\n",
      "        acc9      acc10    AVG  \n",
      "0  91.799998  90.799999  91.53  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_2(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.299998</td>\n",
       "      <td>91.2</td>\n",
       "      <td>91.7</td>\n",
       "      <td>89.8</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>92.699999</td>\n",
       "      <td>91.500002</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>91.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1  acc2  acc3  acc4       acc5       acc6       acc7       acc8  \\\n",
       "0  92.299998  91.2  91.7  89.8  91.900003  92.699999  91.500002  91.600001   \n",
       "\n",
       "        acc9      acc10    AVG  \n",
       "0  91.799998  90.799999  91.53  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('Emb_MLP_SUBJ_2.xlsx', sheet_name='model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_3(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 35,201\n",
      "Trainable params: 35,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = define_model_3(300)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3872 - accuracy: 0.8436 - val_loss: 0.2790 - val_accuracy: 0.8930\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.8956 - val_loss: 0.2640 - val_accuracy: 0.8920\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2448 - accuracy: 0.9063 - val_loss: 0.2572 - val_accuracy: 0.8950\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2329 - accuracy: 0.9087 - val_loss: 0.2511 - val_accuracy: 0.8940\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2181 - accuracy: 0.9149 - val_loss: 0.2615 - val_accuracy: 0.8930\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2108 - accuracy: 0.9171 - val_loss: 0.2584 - val_accuracy: 0.8960\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1998 - accuracy: 0.9241 - val_loss: 0.2634 - val_accuracy: 0.8900\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2020 - accuracy: 0.9219 - val_loss: 0.2552 - val_accuracy: 0.9000\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1887 - accuracy: 0.9310 - val_loss: 0.2663 - val_accuracy: 0.9030\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1834 - accuracy: 0.9297 - val_loss: 0.2671 - val_accuracy: 0.8980\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1789 - accuracy: 0.9296 - val_loss: 0.2582 - val_accuracy: 0.9010\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1780 - accuracy: 0.9340 - val_loss: 0.2784 - val_accuracy: 0.8940\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1697 - accuracy: 0.9372 - val_loss: 0.2712 - val_accuracy: 0.8930\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1624 - accuracy: 0.9369 - val_loss: 0.2717 - val_accuracy: 0.8990\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1638 - accuracy: 0.9376 - val_loss: 0.2891 - val_accuracy: 0.8940\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1580 - accuracy: 0.9422 - val_loss: 0.2728 - val_accuracy: 0.9010\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9450 - val_loss: 0.3010 - val_accuracy: 0.8950\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1464 - accuracy: 0.9453 - val_loss: 0.3204 - val_accuracy: 0.8880\n",
      "Epoch 19/40\n",
      "263/282 [==========================>...] - ETA: 0s - loss: 0.1469 - accuracy: 0.9443Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9453 - val_loss: 0.3031 - val_accuracy: 0.8980\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 90.2999997138977\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3948 - accuracy: 0.8352 - val_loss: 0.2956 - val_accuracy: 0.8820\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.8990 - val_loss: 0.2560 - val_accuracy: 0.9040\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2503 - accuracy: 0.9013 - val_loss: 0.2465 - val_accuracy: 0.8990\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2353 - accuracy: 0.9102 - val_loss: 0.2376 - val_accuracy: 0.9000\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2232 - accuracy: 0.9139 - val_loss: 0.2502 - val_accuracy: 0.8900\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2159 - accuracy: 0.9182 - val_loss: 0.2355 - val_accuracy: 0.9010\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2113 - accuracy: 0.9198 - val_loss: 0.2366 - val_accuracy: 0.9040\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2074 - accuracy: 0.9216 - val_loss: 0.2357 - val_accuracy: 0.9030\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2027 - accuracy: 0.9241 - val_loss: 0.2356 - val_accuracy: 0.9040\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1946 - accuracy: 0.9260 - val_loss: 0.2344 - val_accuracy: 0.9030\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1859 - accuracy: 0.9310 - val_loss: 0.2353 - val_accuracy: 0.9070\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1800 - accuracy: 0.9343 - val_loss: 0.2382 - val_accuracy: 0.9030\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1751 - accuracy: 0.9342 - val_loss: 0.2422 - val_accuracy: 0.8990\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9379 - val_loss: 0.2529 - val_accuracy: 0.9020\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9397 - val_loss: 0.2727 - val_accuracy: 0.8950\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9389 - val_loss: 0.2438 - val_accuracy: 0.9080\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9446 - val_loss: 0.2561 - val_accuracy: 0.8990\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1481 - accuracy: 0.9468 - val_loss: 0.2459 - val_accuracy: 0.9000\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1448 - accuracy: 0.9461 - val_loss: 0.2465 - val_accuracy: 0.8990\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1400 - accuracy: 0.9501 - val_loss: 0.2447 - val_accuracy: 0.9040\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9501 - val_loss: 0.2695 - val_accuracy: 0.9010\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1250 - accuracy: 0.9538 - val_loss: 0.2670 - val_accuracy: 0.9000\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1285 - accuracy: 0.9521 - val_loss: 0.2918 - val_accuracy: 0.8990\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1220 - accuracy: 0.9568 - val_loss: 0.2822 - val_accuracy: 0.8930\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1195 - accuracy: 0.9566 - val_loss: 0.2831 - val_accuracy: 0.8990\n",
      "Epoch 26/40\n",
      "264/282 [===========================>..] - ETA: 0s - loss: 0.1173 - accuracy: 0.9547Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1187 - accuracy: 0.9550 - val_loss: 0.2878 - val_accuracy: 0.9010\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3848 - accuracy: 0.8384 - val_loss: 0.2795 - val_accuracy: 0.8890\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.9006 - val_loss: 0.2681 - val_accuracy: 0.8890\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2453 - accuracy: 0.9044 - val_loss: 0.2659 - val_accuracy: 0.8880\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2322 - accuracy: 0.9089 - val_loss: 0.2573 - val_accuracy: 0.8930\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9166 - val_loss: 0.2772 - val_accuracy: 0.8820\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2092 - accuracy: 0.9204 - val_loss: 0.2725 - val_accuracy: 0.8980\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2054 - accuracy: 0.9239 - val_loss: 0.2660 - val_accuracy: 0.9020\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1957 - accuracy: 0.9246 - val_loss: 0.2668 - val_accuracy: 0.8850\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1928 - accuracy: 0.9289 - val_loss: 0.2599 - val_accuracy: 0.8990\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1827 - accuracy: 0.9299 - val_loss: 0.2913 - val_accuracy: 0.8930\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1828 - accuracy: 0.9329 - val_loss: 0.2692 - val_accuracy: 0.9000\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1778 - accuracy: 0.9346 - val_loss: 0.2838 - val_accuracy: 0.8870\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9378 - val_loss: 0.2788 - val_accuracy: 0.8890\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9388 - val_loss: 0.2717 - val_accuracy: 0.9000\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1589 - accuracy: 0.9409 - val_loss: 0.2876 - val_accuracy: 0.8930\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9430 - val_loss: 0.2870 - val_accuracy: 0.8950\n",
      "Epoch 17/40\n",
      "274/282 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9432Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1529 - accuracy: 0.9431 - val_loss: 0.2935 - val_accuracy: 0.8880\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 90.20000100135803\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.3875 - accuracy: 0.8394 - val_loss: 0.2432 - val_accuracy: 0.8990\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.8998 - val_loss: 0.2515 - val_accuracy: 0.9060\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.9033 - val_loss: 0.2235 - val_accuracy: 0.9140\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2353 - accuracy: 0.9078 - val_loss: 0.2031 - val_accuracy: 0.9200\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2250 - accuracy: 0.9109 - val_loss: 0.1938 - val_accuracy: 0.9190\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2193 - accuracy: 0.9164 - val_loss: 0.1984 - val_accuracy: 0.9220\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2116 - accuracy: 0.9186 - val_loss: 0.1890 - val_accuracy: 0.9220\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9229 - val_loss: 0.1860 - val_accuracy: 0.9260\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9241 - val_loss: 0.1813 - val_accuracy: 0.9260\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1936 - accuracy: 0.9266 - val_loss: 0.1852 - val_accuracy: 0.9280\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1865 - accuracy: 0.9269 - val_loss: 0.1880 - val_accuracy: 0.9270\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.1802 - accuracy: 0.9304 - val_loss: 0.1801 - val_accuracy: 0.9280\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1782 - accuracy: 0.9330 - val_loss: 0.1829 - val_accuracy: 0.9250\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9342 - val_loss: 0.1793 - val_accuracy: 0.9310\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9376 - val_loss: 0.1864 - val_accuracy: 0.9240\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9407 - val_loss: 0.1822 - val_accuracy: 0.9300\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9392 - val_loss: 0.1847 - val_accuracy: 0.9320\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1569 - accuracy: 0.9393 - val_loss: 0.2139 - val_accuracy: 0.9200\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1511 - accuracy: 0.9457 - val_loss: 0.1871 - val_accuracy: 0.9260\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1481 - accuracy: 0.9458 - val_loss: 0.1809 - val_accuracy: 0.9330\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9448 - val_loss: 0.1846 - val_accuracy: 0.9300\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9498 - val_loss: 0.1912 - val_accuracy: 0.9230\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1346 - accuracy: 0.9466 - val_loss: 0.2145 - val_accuracy: 0.9190\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1287 - accuracy: 0.9528 - val_loss: 0.1954 - val_accuracy: 0.9320\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1295 - accuracy: 0.9521 - val_loss: 0.1818 - val_accuracy: 0.9320\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1275 - accuracy: 0.9531 - val_loss: 0.1884 - val_accuracy: 0.9290\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9559 - val_loss: 0.2081 - val_accuracy: 0.9310\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1195 - accuracy: 0.9569 - val_loss: 0.2026 - val_accuracy: 0.9270\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1153 - accuracy: 0.9578 - val_loss: 0.2178 - val_accuracy: 0.9230\n",
      "Epoch 30/40\n",
      "269/282 [===========================>..] - ETA: 0s - loss: 0.1121 - accuracy: 0.9609Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9601 - val_loss: 0.2041 - val_accuracy: 0.9310\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 93.30000281333923\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3851 - accuracy: 0.8446 - val_loss: 0.2440 - val_accuracy: 0.9000\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.8964 - val_loss: 0.2240 - val_accuracy: 0.9170\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2485 - accuracy: 0.9040 - val_loss: 0.2171 - val_accuracy: 0.9240\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2357 - accuracy: 0.9076 - val_loss: 0.2100 - val_accuracy: 0.9240\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2210 - accuracy: 0.9139 - val_loss: 0.2077 - val_accuracy: 0.9180\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2155 - accuracy: 0.9180 - val_loss: 0.2140 - val_accuracy: 0.9170\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2071 - accuracy: 0.9212 - val_loss: 0.2064 - val_accuracy: 0.9240\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2000 - accuracy: 0.9217 - val_loss: 0.2073 - val_accuracy: 0.9290\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1938 - accuracy: 0.9258 - val_loss: 0.2014 - val_accuracy: 0.9270\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1922 - accuracy: 0.9264 - val_loss: 0.2055 - val_accuracy: 0.9240\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9282 - val_loss: 0.2098 - val_accuracy: 0.9290\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1784 - accuracy: 0.9324 - val_loss: 0.2105 - val_accuracy: 0.9220\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1719 - accuracy: 0.9354 - val_loss: 0.2105 - val_accuracy: 0.9260\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1684 - accuracy: 0.9361 - val_loss: 0.2074 - val_accuracy: 0.9280\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9404 - val_loss: 0.2163 - val_accuracy: 0.9220\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9393 - val_loss: 0.2136 - val_accuracy: 0.9280\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1545 - accuracy: 0.9442 - val_loss: 0.2181 - val_accuracy: 0.9240\n",
      "Epoch 18/40\n",
      "263/282 [==========================>...] - ETA: 0s - loss: 0.1450 - accuracy: 0.9459Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9462 - val_loss: 0.2343 - val_accuracy: 0.9250\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 92.90000200271606\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3828 - accuracy: 0.8376 - val_loss: 0.2759 - val_accuracy: 0.8860\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8987 - val_loss: 0.2517 - val_accuracy: 0.9020\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2441 - accuracy: 0.9103 - val_loss: 0.2285 - val_accuracy: 0.9100\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2305 - accuracy: 0.9081 - val_loss: 0.2242 - val_accuracy: 0.9070\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2225 - accuracy: 0.9144 - val_loss: 0.2157 - val_accuracy: 0.9130\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2108 - accuracy: 0.9180 - val_loss: 0.2277 - val_accuracy: 0.9040\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9221 - val_loss: 0.2149 - val_accuracy: 0.9190\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9229 - val_loss: 0.2305 - val_accuracy: 0.9020\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1925 - accuracy: 0.9278 - val_loss: 0.2241 - val_accuracy: 0.9130\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1879 - accuracy: 0.9294 - val_loss: 0.2278 - val_accuracy: 0.9090\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1846 - accuracy: 0.9303 - val_loss: 0.2291 - val_accuracy: 0.9040\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1764 - accuracy: 0.9356 - val_loss: 0.2145 - val_accuracy: 0.9200\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9370 - val_loss: 0.2229 - val_accuracy: 0.9210\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.9377 - val_loss: 0.2183 - val_accuracy: 0.9240\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1604 - accuracy: 0.9424 - val_loss: 0.2170 - val_accuracy: 0.9240\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1565 - accuracy: 0.9419 - val_loss: 0.2206 - val_accuracy: 0.9190\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1515 - accuracy: 0.9443 - val_loss: 0.2205 - val_accuracy: 0.9230\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.9480 - val_loss: 0.2395 - val_accuracy: 0.9190\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1451 - accuracy: 0.9450 - val_loss: 0.2545 - val_accuracy: 0.9110\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1366 - accuracy: 0.9502 - val_loss: 0.2480 - val_accuracy: 0.9160\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9467 - val_loss: 0.2350 - val_accuracy: 0.9220\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9519 - val_loss: 0.2458 - val_accuracy: 0.9110\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9538 - val_loss: 0.2479 - val_accuracy: 0.9210\n",
      "Epoch 24/40\n",
      "268/282 [===========================>..] - ETA: 0s - loss: 0.1216 - accuracy: 0.9562Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9561 - val_loss: 0.2538 - val_accuracy: 0.9220\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3962 - accuracy: 0.8353 - val_loss: 0.2776 - val_accuracy: 0.8850\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2606 - accuracy: 0.9000 - val_loss: 0.2616 - val_accuracy: 0.8900\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2425 - accuracy: 0.9078 - val_loss: 0.2636 - val_accuracy: 0.8950\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2259 - accuracy: 0.9156 - val_loss: 0.2519 - val_accuracy: 0.9010\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9153 - val_loss: 0.2547 - val_accuracy: 0.8990\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2084 - accuracy: 0.9188 - val_loss: 0.2394 - val_accuracy: 0.9040\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2036 - accuracy: 0.9227 - val_loss: 0.2389 - val_accuracy: 0.9050\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9277 - val_loss: 0.2518 - val_accuracy: 0.9010\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1950 - accuracy: 0.9240 - val_loss: 0.2374 - val_accuracy: 0.9090\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9274 - val_loss: 0.2467 - val_accuracy: 0.9090\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1836 - accuracy: 0.9302 - val_loss: 0.2448 - val_accuracy: 0.9080\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9358 - val_loss: 0.2485 - val_accuracy: 0.8980\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9356 - val_loss: 0.2437 - val_accuracy: 0.9070\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1695 - accuracy: 0.9401 - val_loss: 0.2373 - val_accuracy: 0.9090\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9422 - val_loss: 0.2425 - val_accuracy: 0.9100\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1567 - accuracy: 0.9399 - val_loss: 0.2550 - val_accuracy: 0.9110\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1496 - accuracy: 0.9449 - val_loss: 0.2560 - val_accuracy: 0.9100\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9461 - val_loss: 0.2527 - val_accuracy: 0.9060\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1444 - accuracy: 0.9490 - val_loss: 0.2628 - val_accuracy: 0.9110\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9481 - val_loss: 0.2679 - val_accuracy: 0.9070\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1392 - accuracy: 0.9501 - val_loss: 0.2724 - val_accuracy: 0.9050\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1278 - accuracy: 0.9534 - val_loss: 0.2739 - val_accuracy: 0.9080\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1231 - accuracy: 0.9571 - val_loss: 0.2814 - val_accuracy: 0.9030\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1188 - accuracy: 0.9562 - val_loss: 0.2764 - val_accuracy: 0.9100\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1082 - accuracy: 0.9624 - val_loss: 0.3020 - val_accuracy: 0.9040\n",
      "Epoch 26/40\n",
      "272/282 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9607Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9602 - val_loss: 0.3014 - val_accuracy: 0.9050\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8342 - val_loss: 0.2695 - val_accuracy: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.9027 - val_loss: 0.2448 - val_accuracy: 0.9060\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2493 - accuracy: 0.9021 - val_loss: 0.2441 - val_accuracy: 0.9030\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2328 - accuracy: 0.9082 - val_loss: 0.2294 - val_accuracy: 0.9140\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2235 - accuracy: 0.9148 - val_loss: 0.2373 - val_accuracy: 0.9090\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2185 - accuracy: 0.9176 - val_loss: 0.2205 - val_accuracy: 0.9190\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.91 - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9181 - val_loss: 0.2251 - val_accuracy: 0.9260\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9207 - val_loss: 0.2191 - val_accuracy: 0.9210\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9238 - val_loss: 0.2438 - val_accuracy: 0.9050\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1898 - accuracy: 0.9299 - val_loss: 0.2378 - val_accuracy: 0.9140\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.1897 - accuracy: 0.9286 - val_loss: 0.2262 - val_accuracy: 0.9170\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1833 - accuracy: 0.9308 - val_loss: 0.2188 - val_accuracy: 0.9200\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.2575 - val_accuracy: 0.9000\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1762 - accuracy: 0.9364 - val_loss: 0.2150 - val_accuracy: 0.9220\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1672 - accuracy: 0.9381 - val_loss: 0.2241 - val_accuracy: 0.9240\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1625 - accuracy: 0.9408 - val_loss: 0.2308 - val_accuracy: 0.9200\n",
      "Epoch 17/40\n",
      "274/282 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9418 ETA: 0s - loss: 0Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1561 - accuracy: 0.9414 - val_loss: 0.2363 - val_accuracy: 0.9250\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 92.59999990463257\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3947 - accuracy: 0.8359 - val_loss: 0.2584 - val_accuracy: 0.8950\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2661 - accuracy: 0.8979 - val_loss: 0.2428 - val_accuracy: 0.9040\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2458 - accuracy: 0.9061 - val_loss: 0.2459 - val_accuracy: 0.9030\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.9111 - val_loss: 0.2333 - val_accuracy: 0.9040\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2194 - accuracy: 0.9169 - val_loss: 0.2538 - val_accuracy: 0.9040\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9160 - val_loss: 0.2482 - val_accuracy: 0.9080\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9224 - val_loss: 0.2398 - val_accuracy: 0.9100\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9228 - val_loss: 0.2497 - val_accuracy: 0.9060\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9272 - val_loss: 0.2436 - val_accuracy: 0.9070\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9319 - val_loss: 0.2482 - val_accuracy: 0.9060\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1831 - accuracy: 0.9293 - val_loss: 0.2712 - val_accuracy: 0.9040\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1803 - accuracy: 0.9339 - val_loss: 0.2605 - val_accuracy: 0.9040\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.9369 - val_loss: 0.2805 - val_accuracy: 0.9000\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9380 - val_loss: 0.2586 - val_accuracy: 0.9010\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9406 - val_loss: 0.2788 - val_accuracy: 0.9030\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1553 - accuracy: 0.9412 - val_loss: 0.2748 - val_accuracy: 0.8990\n",
      "Epoch 17/40\n",
      "272/282 [===========================>..] - ETA: 0s - loss: 0.1524 - accuracy: 0.9421Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9419 - val_loss: 0.2823 - val_accuracy: 0.9090\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 91.00000262260437\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.4003 - accuracy: 0.8262 - val_loss: 0.2619 - val_accuracy: 0.8940\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.8964 - val_loss: 0.2589 - val_accuracy: 0.8930\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2462 - accuracy: 0.9047 - val_loss: 0.2342 - val_accuracy: 0.9030\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2305 - accuracy: 0.9131 - val_loss: 0.2370 - val_accuracy: 0.9000\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2228 - accuracy: 0.9138 - val_loss: 0.2350 - val_accuracy: 0.9020\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9158 - val_loss: 0.2300 - val_accuracy: 0.9050\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9189 - val_loss: 0.2289 - val_accuracy: 0.9060\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9218 - val_loss: 0.2332 - val_accuracy: 0.9070\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9214 - val_loss: 0.2247 - val_accuracy: 0.9040\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1887 - accuracy: 0.9299 - val_loss: 0.2333 - val_accuracy: 0.9140\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1868 - accuracy: 0.9286 - val_loss: 0.2366 - val_accuracy: 0.9060\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9304 - val_loss: 0.2402 - val_accuracy: 0.9080\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1764 - accuracy: 0.9324 - val_loss: 0.2310 - val_accuracy: 0.9150\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1695 - accuracy: 0.9373 - val_loss: 0.2441 - val_accuracy: 0.9100\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1675 - accuracy: 0.9357 - val_loss: 0.2410 - val_accuracy: 0.9100\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1644 - accuracy: 0.9356 - val_loss: 0.2539 - val_accuracy: 0.9080\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9397 - val_loss: 0.2486 - val_accuracy: 0.9110\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9416 - val_loss: 0.2518 - val_accuracy: 0.9100\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1497 - accuracy: 0.9461 - val_loss: 0.2445 - val_accuracy: 0.9090\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1465 - accuracy: 0.9452 - val_loss: 0.2560 - val_accuracy: 0.9180\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1357 - accuracy: 0.9518 - val_loss: 0.2632 - val_accuracy: 0.9150\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1391 - accuracy: 0.9479 - val_loss: 0.2735 - val_accuracy: 0.9070\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1335 - accuracy: 0.9509 - val_loss: 0.2626 - val_accuracy: 0.9110\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1313 - accuracy: 0.9519 - val_loss: 0.2657 - val_accuracy: 0.9170\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9543 - val_loss: 0.2776 - val_accuracy: 0.9170\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1229 - accuracy: 0.9528 - val_loss: 0.2749 - val_accuracy: 0.9160\n",
      "Epoch 27/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9590 - val_loss: 0.2805 - val_accuracy: 0.9120\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1120 - accuracy: 0.9599 - val_loss: 0.2792 - val_accuracy: 0.9150\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9594 - val_loss: 0.2852 - val_accuracy: 0.9100\n",
      "Epoch 30/40\n",
      "271/282 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.9588Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1132 - accuracy: 0.9583 - val_loss: 0.2730 - val_accuracy: 0.9160\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "\n",
      "\n",
      "   acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
      "0  90.3  90.799999  90.200001  93.300003  92.900002  92.400002  91.100001   \n",
      "\n",
      "   acc8       acc9      acc10        AVG  \n",
      "0  92.6  91.000003  91.799998  91.640001  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Define the word_index\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_3(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.3</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>90.200001</td>\n",
       "      <td>93.300003</td>\n",
       "      <td>92.900002</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>92.6</td>\n",
       "      <td>91.000003</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>91.640001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
       "0  90.3  90.799999  90.200001  93.300003  92.900002  92.400002  91.100001   \n",
       "\n",
       "   acc8       acc9      acc10        AVG  \n",
       "0  92.6  91.000003  91.799998  91.640001  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('Emb_MLP_SUBJ_3.xlsx', sheet_name='model_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
