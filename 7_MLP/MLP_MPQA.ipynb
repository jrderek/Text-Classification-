{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification with MPQA Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using Multi Layer Perceptron on the MPQA Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10606, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complaining</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing to support</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desperately needs</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many years of decay</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no quick fix</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>urged</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>hope</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10605</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10606 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence  label  split\n",
       "0              complaining      0  train\n",
       "1       failing to support      0  train\n",
       "2        desperately needs      0  train\n",
       "3      many years of decay      0  train\n",
       "4             no quick fix      0  train\n",
       "...                    ...    ...    ...\n",
       "10601                urged      1  train\n",
       "10602       strictly abide      1  train\n",
       "10603                 hope      1  train\n",
       "10604       strictly abide      1  train\n",
       "10605                           1  train\n",
       "\n",
       "[10606 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/MPQA/MPQA.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10606 entries, 0 to 10605\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  10606 non-null  object\n",
      " 1   label     10606 non-null  int32 \n",
      " 2   split     10606 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 207.3+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7294</td>\n",
       "      <td>7294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3312</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          7294   7294\n",
       "1          3312   3312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complaining'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Word2Vec Static\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Word Embedding: Word2Vec\n",
    "\n",
    "__1. Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6083 words present from 6236 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "oov_tok = '<OOV>'\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `clean_doc` function\n",
    "__2. Define a function to clean the document called __`clean_doc()`____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(sentences, word_index):\n",
    "    clean_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower().split()\n",
    "        clean_word = []\n",
    "        for word in sentence:\n",
    "            if word in word_index:\n",
    "                clean_word.append(word)\n",
    "        clean_sentence = ' '.join(clean_word)\n",
    "        clean_sentences.append(clean_sentence)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complaining', 'failing to support', 'desperately needs']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences = clean_doc(sentences, word_index)\n",
    "clean_sentences[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `sentence_to_avg` function\n",
    "__3. Define a `sentence_to_avg` function__\n",
    "\n",
    "We will use this function to calculate the mean of word embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Split sentence into list of lower case words (â‰ˆ 1 line)\n",
    "    words = (sentence.lower()).split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros(word2vec.word_vec('i').shape)\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            total += word_to_vec_map.word_vec(w)\n",
    "            count += 1\n",
    "            \n",
    "    if count!= 0:\n",
    "        avg = total/count\n",
    "    else:\n",
    "        avg\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22558594\n",
      "-0.16699219\n",
      "0.11376953\n",
      "the mean of word embedding is:  -0.09293619791666667\n"
     ]
    }
   ],
   "source": [
    "i = word2vec.word_vec('i')[0]\n",
    "print(word2vec.word_vec('i')[0])\n",
    "j = word2vec.word_vec('am')[0]\n",
    "print(word2vec.word_vec('am')[0])\n",
    "k = word2vec.word_vec('handsome')[0]\n",
    "print(word2vec.word_vec('handsome')[0])\n",
    "mean = (i+j+k)/3\n",
    "print('the mean of word embedding is: ', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0929362 ,  0.03125   , -0.03914388,  0.09879557,  0.07088598,\n",
       "        0.03092448, -0.00651042, -0.04437256,  0.08068848,  0.07242838,\n",
       "        0.00160726, -0.10530599, -0.07389323, -0.08854166,  0.00565592,\n",
       "        0.15136719, -0.0460612 ,  0.19482422,  0.1101888 ,  0.05924479,\n",
       "       -0.18457031,  0.00716146,  0.16153972,  0.02437337, -0.01578776,\n",
       "        0.06119792, -0.25048828,  0.02799479,  0.0853475 , -0.14029948,\n",
       "        0.13688152, -0.01350911, -0.05493164, -0.01090495,  0.03352864,\n",
       "        0.09635416, -0.04239909,  0.00777181, -0.1438802 ,  0.06510416,\n",
       "        0.14560954, -0.11295573,  0.25520834,  0.08833822,  0.14339192,\n",
       "        0.037028  , -0.02832031, -0.00139872,  0.00309245, -0.17871094,\n",
       "        0.06852213,  0.07910156,  0.09513346,  0.11425781, -0.00488281,\n",
       "        0.11051432, -0.01139323, -0.08479818, -0.09277344, -0.03263346,\n",
       "       -0.00374349,  0.07977295, -0.26416016, -0.05135091,  0.06111654,\n",
       "       -0.06933594, -0.06486002,  0.18766277, -0.04826609,  0.03304036,\n",
       "        0.24267578,  0.11425781,  0.02310689,  0.06697591, -0.19010417,\n",
       "        0.03230794,  0.00317383, -0.03739421,  0.12434896,  0.1574707 ,\n",
       "       -0.05745443,  0.015625  ,  0.01456706, -0.05794271, -0.0549113 ,\n",
       "        0.0398763 , -0.01517741,  0.11263021, -0.03271484,  0.06758627,\n",
       "       -0.09594727,  0.06559245,  0.00217692,  0.03627523, -0.03776042,\n",
       "        0.02945963, -0.05960592, -0.02514648,  0.07128906, -0.04410807,\n",
       "       -0.21533203, -0.02174886, -0.05029297,  0.04264323,  0.08194987,\n",
       "        0.05502828,  0.09375   , -0.02050781,  0.04243978, -0.1439616 ,\n",
       "        0.        , -0.17805989,  0.0822347 ,  0.00140381,  0.17220052,\n",
       "       -0.08251953,  0.00450643, -0.24837239,  0.14001465,  0.01749674,\n",
       "        0.24576823, -0.06986491, -0.04370117,  0.01497396, -0.01534017,\n",
       "        0.09863281, -0.12027995,  0.14615886,  0.19580078,  0.08813477,\n",
       "       -0.2861328 , -0.0653483 , -0.03889974, -0.07784017, -0.12190755,\n",
       "       -0.04427083, -0.06233724,  0.08296712,  0.12670898,  0.1593221 ,\n",
       "        0.04296875,  0.08544922, -0.01513672,  0.        , -0.2101237 ,\n",
       "        0.11390177, -0.01127116, -0.06298828,  0.0198822 , -0.03000895,\n",
       "       -0.05118815, -0.00195312, -0.1007487 ,  0.09879557, -0.19702148,\n",
       "       -0.05611674, -0.03466797,  0.13932292, -0.0764974 , -0.00777181,\n",
       "        0.05948893,  0.11360677,  0.01757812,  0.07926432, -0.0104777 ,\n",
       "       -0.16145833,  0.17708333,  0.13507843, -0.06380209,  0.10839844,\n",
       "       -0.21500652, -0.0933431 ,  0.05853271, -0.14601643, -0.0369873 ,\n",
       "        0.02945963,  0.2747396 , -0.07006454,  0.06966146, -0.17203777,\n",
       "       -0.02294922, -0.09220377, -0.01790492, -0.0111084 , -0.03776042,\n",
       "        0.03540039, -0.03483073,  0.0764974 ,  0.07096354, -0.13916016,\n",
       "       -0.01989746,  0.06176758, -0.11336263, -0.03279241,  0.08687337,\n",
       "        0.15901692, -0.07185873,  0.02547201, -0.03220622, -0.125     ,\n",
       "       -0.12727864,  0.02563477, -0.06311035, -0.16959636, -0.10058594,\n",
       "       -0.05464681, -0.09391276,  0.06502279, -0.06184896,  0.14835612,\n",
       "       -0.1031901 ,  0.07779948, -0.06420898, -0.0892334 , -0.20214844,\n",
       "        0.13671875,  0.11507162, -0.00145467, -0.23079427, -0.04801432,\n",
       "       -0.06262207,  0.07454427,  0.0298055 , -0.01489258,  0.08854166,\n",
       "       -0.1608073 , -0.00372314, -0.056722  , -0.06841787, -0.16031902,\n",
       "        0.1538086 , -0.03597005, -0.09985352, -0.03483073,  0.07324219,\n",
       "        0.03672282,  0.03737386,  0.06705729,  0.10375977,  0.04850261,\n",
       "        0.20996094,  0.06673177,  0.03833008,  0.06363932, -0.18758138,\n",
       "       -0.10904948, -0.02693685,  0.02254232, -0.08405808,  0.02848307,\n",
       "        0.17675781,  0.01188151,  0.08610026,  0.18359375,  0.0764974 ,\n",
       "        0.03463237,  0.08015951,  0.00455729, -0.15309651,  0.00195312,\n",
       "        0.0965983 , -0.18180339, -0.02457682, -0.01757812, -0.08410645,\n",
       "        0.20092773, -0.12624104, -0.09566244, -0.03291829, -0.04532878,\n",
       "        0.04199219, -0.01635742,  0.04329427,  0.06469727,  0.04390462,\n",
       "        0.03625488, -0.04744466, -0.14420573, -0.17626953,  0.18603516,\n",
       "        0.01155599,  0.06009929, -0.02880859,  0.06738281,  0.0949707 ,\n",
       "        0.00325521, -0.07470703, -0.18782552, -0.00447591,  0.06038411,\n",
       "        0.0456543 ,  0.10611979, -0.11393229, -0.05623372, -0.03450521,\n",
       "        0.02193197, -0.12263998, -0.08158366, -0.0332845 ,  0.09596761],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the functions used in a sentence\n",
    "mysentence = 'I am handsome'\n",
    "sentence_to_avg(mysentence, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Sentence into Word2Vec Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_sentences(sentences):\n",
    "\n",
    "    encoded_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        encoded_sentence = sentence_to_avg(sentence, word2vec)\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "\n",
    "    encoded_sentences = np.array(encoded_sentences)\n",
    "    return encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10606, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.18066406,  0.13476562, -0.13085938, ...,  0.05419922,\n",
       "         0.17871094,  0.14355469],\n",
       "       [ 0.06982422,  0.00537109,  0.10314941, ...,  0.1496582 ,\n",
       "        -0.00378418,  0.01538086],\n",
       "       [ 0.03710938,  0.13769531, -0.01550293, ...,  0.06748962,\n",
       "         0.06011963, -0.05154419],\n",
       "       ...,\n",
       "       [ 0.01611328,  0.14550781,  0.22265625, ..., -0.08984375,\n",
       "         0.10986328, -0.0534668 ],\n",
       "       [-0.21154785, -0.04882812,  0.23828125, ..., -0.02050781,\n",
       "        -0.07974243, -0.16088867],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = encoded_sentences(clean_sentences)\n",
    "print(embedded_sentences.shape)\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,101\n",
      "Trainable params: 15,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model(300)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "'''\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "291/299 [============================>.] - ETA: 0s - loss: 0.4127 - accuracy: 0.8187WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4113 - accuracy: 0.8195 - val_loss: 0.3367 - val_accuracy: 0.8633\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8760 - val_loss: 0.3265 - val_accuracy: 0.8662\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 0s 931us/step - loss: 0.2999 - accuracy: 0.8831 - val_loss: 0.3224 - val_accuracy: 0.8652\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.8894 - val_loss: 0.3198 - val_accuracy: 0.8690\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 0s 996us/step - loss: 0.2827 - accuracy: 0.8915 - val_loss: 0.3185 - val_accuracy: 0.8680\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.8939 - val_loss: 0.3196 - val_accuracy: 0.8671\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 0s 906us/step - loss: 0.2724 - accuracy: 0.8939 - val_loss: 0.3139 - val_accuracy: 0.8718\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 0s 832us/step - loss: 0.2665 - accuracy: 0.9002 - val_loss: 0.3177 - val_accuracy: 0.8662\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 0s 878us/step - loss: 0.2618 - accuracy: 0.8961 - val_loss: 0.3118 - val_accuracy: 0.8784\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 0s 865us/step - loss: 0.2600 - accuracy: 0.9019 - val_loss: 0.3119 - val_accuracy: 0.8775\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 0s 819us/step - loss: 0.2562 - accuracy: 0.9021 - val_loss: 0.3112 - val_accuracy: 0.8794\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 0s 805us/step - loss: 0.2500 - accuracy: 0.9049 - val_loss: 0.3108 - val_accuracy: 0.8784\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 0s 842us/step - loss: 0.2492 - accuracy: 0.9056 - val_loss: 0.3101 - val_accuracy: 0.8784\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 0s 873us/step - loss: 0.2459 - accuracy: 0.9082 - val_loss: 0.3093 - val_accuracy: 0.8784\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 0s 877us/step - loss: 0.2437 - accuracy: 0.9062 - val_loss: 0.3138 - val_accuracy: 0.8746\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 0s 861us/step - loss: 0.2390 - accuracy: 0.9087 - val_loss: 0.3109 - val_accuracy: 0.8775\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 0s 790us/step - loss: 0.2347 - accuracy: 0.9123 - val_loss: 0.3109 - val_accuracy: 0.8775\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 0s 931us/step - loss: 0.2341 - accuracy: 0.9103 - val_loss: 0.3137 - val_accuracy: 0.8756\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 0s 941us/step - loss: 0.2314 - accuracy: 0.9115 - val_loss: 0.3101 - val_accuracy: 0.8765\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9166 - val_loss: 0.3129 - val_accuracy: 0.8718\n",
      "Epoch 21/40\n",
      "256/299 [========================>.....] - ETA: 0s - loss: 0.2239 - accuracy: 0.9135Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9126 - val_loss: 0.3110 - val_accuracy: 0.8784\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 87.93590664863586\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8131 - val_loss: 0.3390 - val_accuracy: 0.8605\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 0s 830us/step - loss: 0.3152 - accuracy: 0.8752 - val_loss: 0.3217 - val_accuracy: 0.8699\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 0s 992us/step - loss: 0.3019 - accuracy: 0.8833 - val_loss: 0.3185 - val_accuracy: 0.8690\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 0s 825us/step - loss: 0.2867 - accuracy: 0.8892 - val_loss: 0.3161 - val_accuracy: 0.8746\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 0s 870us/step - loss: 0.2826 - accuracy: 0.8881 - val_loss: 0.3140 - val_accuracy: 0.8756\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 0s 917us/step - loss: 0.2786 - accuracy: 0.8914 - val_loss: 0.3116 - val_accuracy: 0.8746\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 0s 853us/step - loss: 0.2733 - accuracy: 0.8936 - val_loss: 0.3187 - val_accuracy: 0.8690\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 0s 927us/step - loss: 0.2696 - accuracy: 0.8971 - val_loss: 0.3097 - val_accuracy: 0.8746\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 0s 927us/step - loss: 0.2659 - accuracy: 0.8980 - val_loss: 0.3118 - val_accuracy: 0.8775\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8999 - val_loss: 0.3088 - val_accuracy: 0.8728\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9024 - val_loss: 0.3076 - val_accuracy: 0.8737\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.9029 - val_loss: 0.3101 - val_accuracy: 0.8756\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.9042 - val_loss: 0.3058 - val_accuracy: 0.8756\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.9059 - val_loss: 0.3038 - val_accuracy: 0.8784\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.9074 - val_loss: 0.3063 - val_accuracy: 0.8784\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.9099 - val_loss: 0.3061 - val_accuracy: 0.8784\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2399 - accuracy: 0.9098 - val_loss: 0.3052 - val_accuracy: 0.8775\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2343 - accuracy: 0.9138 - val_loss: 0.3121 - val_accuracy: 0.8737\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2356 - accuracy: 0.9118 - val_loss: 0.3105 - val_accuracy: 0.8728\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2311 - accuracy: 0.9153 - val_loss: 0.3028 - val_accuracy: 0.8822\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2275 - accuracy: 0.9157 - val_loss: 0.3043 - val_accuracy: 0.8831\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2254 - accuracy: 0.9148 - val_loss: 0.3143 - val_accuracy: 0.8728\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2238 - accuracy: 0.9170 - val_loss: 0.3047 - val_accuracy: 0.8812\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2231 - accuracy: 0.9158 - val_loss: 0.3096 - val_accuracy: 0.8775\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9199 - val_loss: 0.3034 - val_accuracy: 0.8822\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9174 - val_loss: 0.3157 - val_accuracy: 0.8709\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.9181 - val_loss: 0.3095 - val_accuracy: 0.8803\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9206 - val_loss: 0.3070 - val_accuracy: 0.8822\n",
      "Epoch 29/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2090 - accuracy: 0.9207 - val_loss: 0.3096 - val_accuracy: 0.8831\n",
      "Epoch 30/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9205 - val_loss: 0.3148 - val_accuracy: 0.8803\n",
      "Epoch 31/40\n",
      "273/299 [==========================>...] - ETA: 0s - loss: 0.2077 - accuracy: 0.9219Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9228 - val_loss: 0.3125 - val_accuracy: 0.8831\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 88.31291198730469\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4153 - accuracy: 0.8155 - val_loss: 0.3443 - val_accuracy: 0.8765\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.8718 - val_loss: 0.3334 - val_accuracy: 0.8746\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.3009 - accuracy: 0.8837 - val_loss: 0.3229 - val_accuracy: 0.8869\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.8867 - val_loss: 0.3202 - val_accuracy: 0.8860\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.8893 - val_loss: 0.3193 - val_accuracy: 0.8860\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.8924 - val_loss: 0.3150 - val_accuracy: 0.8850\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.8941 - val_loss: 0.3157 - val_accuracy: 0.8860\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.8957 - val_loss: 0.3152 - val_accuracy: 0.8812\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2632 - accuracy: 0.8967 - val_loss: 0.3154 - val_accuracy: 0.8803\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.8997 - val_loss: 0.3150 - val_accuracy: 0.8831\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.8992 - val_loss: 0.3171 - val_accuracy: 0.8841\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.9031 - val_loss: 0.3155 - val_accuracy: 0.8841\n",
      "Epoch 13/40\n",
      "273/299 [==========================>...] - ETA: 0s - loss: 0.2458 - accuracy: 0.9042Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9034 - val_loss: 0.3145 - val_accuracy: 0.8850\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 88.68991732597351\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4162 - accuracy: 0.8163 - val_loss: 0.3761 - val_accuracy: 0.8445\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.3155 - accuracy: 0.8727 - val_loss: 0.3649 - val_accuracy: 0.8492\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2942 - accuracy: 0.8847 - val_loss: 0.3654 - val_accuracy: 0.8464\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.8905 - val_loss: 0.3610 - val_accuracy: 0.8530\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8920 - val_loss: 0.3646 - val_accuracy: 0.8520\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.8960 - val_loss: 0.3645 - val_accuracy: 0.8558\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.8974 - val_loss: 0.3645 - val_accuracy: 0.8558\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8992 - val_loss: 0.3695 - val_accuracy: 0.8567\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.8987 - val_loss: 0.3662 - val_accuracy: 0.8558\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2545 - accuracy: 0.9031 - val_loss: 0.3649 - val_accuracy: 0.8586\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.9039 - val_loss: 0.3714 - val_accuracy: 0.8539\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2503 - accuracy: 0.9062 - val_loss: 0.3648 - val_accuracy: 0.8586\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.9079 - val_loss: 0.3622 - val_accuracy: 0.8596\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2384 - accuracy: 0.9093 - val_loss: 0.3749 - val_accuracy: 0.8586\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2374 - accuracy: 0.9108 - val_loss: 0.3802 - val_accuracy: 0.8558\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2353 - accuracy: 0.9114 - val_loss: 0.3861 - val_accuracy: 0.8492\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2301 - accuracy: 0.9131 - val_loss: 0.3827 - val_accuracy: 0.8539\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.9131 - val_loss: 0.3825 - val_accuracy: 0.8567\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2263 - accuracy: 0.9164 - val_loss: 0.3757 - val_accuracy: 0.8605\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2231 - accuracy: 0.9172 - val_loss: 0.3752 - val_accuracy: 0.8615\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2213 - accuracy: 0.9143 - val_loss: 0.4060 - val_accuracy: 0.8473\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2176 - accuracy: 0.9177 - val_loss: 0.3792 - val_accuracy: 0.8549\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2124 - accuracy: 0.9206 - val_loss: 0.3966 - val_accuracy: 0.8454\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9193 - val_loss: 0.3862 - val_accuracy: 0.8549\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9202 - val_loss: 0.3860 - val_accuracy: 0.8539\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2104 - accuracy: 0.9202 - val_loss: 0.3829 - val_accuracy: 0.8558\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9207 - val_loss: 0.3947 - val_accuracy: 0.8549\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9219 - val_loss: 0.3965 - val_accuracy: 0.8586\n",
      "Epoch 29/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2021 - accuracy: 0.9215 - val_loss: 0.3943 - val_accuracy: 0.8549\n",
      "Epoch 30/40\n",
      "285/299 [===========================>..] - ETA: 0s - loss: 0.2030 - accuracy: 0.9238Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2029 - accuracy: 0.9236 - val_loss: 0.4048 - val_accuracy: 0.8567\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 86.14514470100403\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8175 - val_loss: 0.3593 - val_accuracy: 0.8596\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3113 - accuracy: 0.8767 - val_loss: 0.3457 - val_accuracy: 0.8633\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.8821 - val_loss: 0.3380 - val_accuracy: 0.8737\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.8850 - val_loss: 0.3356 - val_accuracy: 0.8709\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.8915 - val_loss: 0.3348 - val_accuracy: 0.8728\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8941 - val_loss: 0.3341 - val_accuracy: 0.8737\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2704 - accuracy: 0.8954 - val_loss: 0.3315 - val_accuracy: 0.8737\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.8954 - val_loss: 0.3349 - val_accuracy: 0.8746\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8998 - val_loss: 0.3301 - val_accuracy: 0.8765\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2554 - accuracy: 0.9024 - val_loss: 0.3295 - val_accuracy: 0.8756\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2523 - accuracy: 0.9033 - val_loss: 0.3312 - val_accuracy: 0.8765\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2516 - accuracy: 0.9021 - val_loss: 0.3278 - val_accuracy: 0.8775\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2462 - accuracy: 0.9059 - val_loss: 0.3313 - val_accuracy: 0.8812\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2468 - accuracy: 0.9058 - val_loss: 0.3296 - val_accuracy: 0.8775\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.9083 - val_loss: 0.3288 - val_accuracy: 0.8803\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.9080 - val_loss: 0.3296 - val_accuracy: 0.8831\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2357 - accuracy: 0.9093 - val_loss: 0.3286 - val_accuracy: 0.8822\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2334 - accuracy: 0.9119 - val_loss: 0.3256 - val_accuracy: 0.8850\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2317 - accuracy: 0.9118 - val_loss: 0.3325 - val_accuracy: 0.8803\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.9127 - val_loss: 0.3286 - val_accuracy: 0.8803\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2276 - accuracy: 0.9155 - val_loss: 0.3297 - val_accuracy: 0.8841\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2242 - accuracy: 0.9148 - val_loss: 0.3346 - val_accuracy: 0.8803\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2205 - accuracy: 0.9163 - val_loss: 0.3310 - val_accuracy: 0.8841\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2185 - accuracy: 0.9174 - val_loss: 0.3307 - val_accuracy: 0.8831\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9160 - val_loss: 0.3380 - val_accuracy: 0.8728\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2173 - accuracy: 0.9186 - val_loss: 0.3339 - val_accuracy: 0.8841\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2094 - accuracy: 0.9216 - val_loss: 0.3363 - val_accuracy: 0.8822\n",
      "Epoch 28/40\n",
      "291/299 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9190Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2092 - accuracy: 0.9179 - val_loss: 0.3339 - val_accuracy: 0.8831\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 88.50141167640686\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.4125 - accuracy: 0.8167 - val_loss: 0.3600 - val_accuracy: 0.8567\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8784 - val_loss: 0.3490 - val_accuracy: 0.8633\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.8817 - val_loss: 0.3495 - val_accuracy: 0.8671\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.8887 - val_loss: 0.3426 - val_accuracy: 0.8633\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8917 - val_loss: 0.3432 - val_accuracy: 0.8643\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8942 - val_loss: 0.3409 - val_accuracy: 0.8652\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8955 - val_loss: 0.3425 - val_accuracy: 0.8605\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8972 - val_loss: 0.3427 - val_accuracy: 0.8662\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2622 - accuracy: 0.9010 - val_loss: 0.3436 - val_accuracy: 0.8605\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2586 - accuracy: 0.8996 - val_loss: 0.3431 - val_accuracy: 0.8633\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2547 - accuracy: 0.9017 - val_loss: 0.3443 - val_accuracy: 0.8596\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2536 - accuracy: 0.9048 - val_loss: 0.3440 - val_accuracy: 0.8605\n",
      "Epoch 13/40\n",
      "287/299 [===========================>..] - ETA: 0s - loss: 0.2457 - accuracy: 0.9072Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2470 - accuracy: 0.9065 - val_loss: 0.3455 - val_accuracy: 0.8596\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.71064972877502\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 4s 13ms/step - loss: 0.4074 - accuracy: 0.8207 - val_loss: 0.3426 - val_accuracy: 0.8472\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.8743 - val_loss: 0.3297 - val_accuracy: 0.8594\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3033 - accuracy: 0.8836 - val_loss: 0.3247 - val_accuracy: 0.8632\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.8876 - val_loss: 0.3223 - val_accuracy: 0.8642\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.8917 - val_loss: 0.3191 - val_accuracy: 0.8698\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.8948 - val_loss: 0.3182 - val_accuracy: 0.8689\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8952 - val_loss: 0.3190 - val_accuracy: 0.8689\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2674 - accuracy: 0.8955 - val_loss: 0.3163 - val_accuracy: 0.8717\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2604 - accuracy: 0.8984 - val_loss: 0.3181 - val_accuracy: 0.8651\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2612 - accuracy: 0.8996 - val_loss: 0.3192 - val_accuracy: 0.8717\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2555 - accuracy: 0.9015 - val_loss: 0.3156 - val_accuracy: 0.8717\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.9024 - val_loss: 0.3174 - val_accuracy: 0.8670\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2480 - accuracy: 0.9049 - val_loss: 0.3143 - val_accuracy: 0.8736\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9046 - val_loss: 0.3190 - val_accuracy: 0.8717\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2442 - accuracy: 0.9027 - val_loss: 0.3175 - val_accuracy: 0.8755\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2369 - accuracy: 0.9099 - val_loss: 0.3193 - val_accuracy: 0.8745\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2354 - accuracy: 0.9113 - val_loss: 0.3212 - val_accuracy: 0.8755\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2316 - accuracy: 0.9113 - val_loss: 0.3223 - val_accuracy: 0.8726\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2300 - accuracy: 0.9128 - val_loss: 0.3238 - val_accuracy: 0.8708\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2278 - accuracy: 0.9120 - val_loss: 0.3261 - val_accuracy: 0.8679\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2246 - accuracy: 0.9134 - val_loss: 0.3220 - val_accuracy: 0.8774\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2216 - accuracy: 0.9178 - val_loss: 0.3263 - val_accuracy: 0.8745\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2230 - accuracy: 0.9153 - val_loss: 0.3263 - val_accuracy: 0.8708\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2208 - accuracy: 0.9159 - val_loss: 0.3266 - val_accuracy: 0.8755\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2184 - accuracy: 0.9189 - val_loss: 0.3285 - val_accuracy: 0.8745\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2156 - accuracy: 0.9161 - val_loss: 0.3298 - val_accuracy: 0.8717\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2133 - accuracy: 0.9172 - val_loss: 0.3315 - val_accuracy: 0.8708\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2138 - accuracy: 0.9190 - val_loss: 0.3344 - val_accuracy: 0.8736\n",
      "Epoch 29/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2056 - accuracy: 0.9221 - val_loss: 0.3387 - val_accuracy: 0.8726\n",
      "Epoch 30/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9208 - val_loss: 0.3354 - val_accuracy: 0.8717\n",
      "Epoch 31/40\n",
      "282/299 [===========================>..] - ETA: 0s - loss: 0.2065 - accuracy: 0.9228Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2052 - accuracy: 0.9228 - val_loss: 0.3355 - val_accuracy: 0.8708\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 87.73584961891174\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.3968 - accuracy: 0.8273 - val_loss: 0.3337 - val_accuracy: 0.8698\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3113 - accuracy: 0.8758 - val_loss: 0.3212 - val_accuracy: 0.8642\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.8816 - val_loss: 0.3176 - val_accuracy: 0.8698\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.8853 - val_loss: 0.3121 - val_accuracy: 0.8774\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.8878 - val_loss: 0.3104 - val_accuracy: 0.8783\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2745 - accuracy: 0.8944 - val_loss: 0.3114 - val_accuracy: 0.8764\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2728 - accuracy: 0.8941 - val_loss: 0.3118 - val_accuracy: 0.8736\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8989 - val_loss: 0.3081 - val_accuracy: 0.8783\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2642 - accuracy: 0.8980 - val_loss: 0.3129 - val_accuracy: 0.8726\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2591 - accuracy: 0.8977 - val_loss: 0.3111 - val_accuracy: 0.8736\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2548 - accuracy: 0.9010 - val_loss: 0.3113 - val_accuracy: 0.8708\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2517 - accuracy: 0.9046 - val_loss: 0.3093 - val_accuracy: 0.8774\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2464 - accuracy: 0.9083 - val_loss: 0.3113 - val_accuracy: 0.8736\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2483 - accuracy: 0.9052 - val_loss: 0.3091 - val_accuracy: 0.8755\n",
      "Epoch 15/40\n",
      "294/299 [============================>.] - ETA: 0s - loss: 0.2418 - accuracy: 0.9087Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.9083 - val_loss: 0.3120 - val_accuracy: 0.8736\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 87.83018589019775\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8160 - val_loss: 0.3714 - val_accuracy: 0.8453\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3131 - accuracy: 0.8758 - val_loss: 0.3594 - val_accuracy: 0.8462\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.8867 - val_loss: 0.3564 - val_accuracy: 0.8509\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.8913 - val_loss: 0.3542 - val_accuracy: 0.8538\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.8924 - val_loss: 0.3547 - val_accuracy: 0.8491\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.8940 - val_loss: 0.3537 - val_accuracy: 0.8491\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.8929 - val_loss: 0.3528 - val_accuracy: 0.8557\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.9002 - val_loss: 0.3527 - val_accuracy: 0.8528\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.9010 - val_loss: 0.3545 - val_accuracy: 0.8566\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2599 - accuracy: 0.9004 - val_loss: 0.3529 - val_accuracy: 0.8585\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2548 - accuracy: 0.9045 - val_loss: 0.3530 - val_accuracy: 0.8566\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9030 - val_loss: 0.3582 - val_accuracy: 0.8538\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2488 - accuracy: 0.9045 - val_loss: 0.3567 - val_accuracy: 0.8566\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2433 - accuracy: 0.9088 - val_loss: 0.3557 - val_accuracy: 0.8547\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9080 - val_loss: 0.3546 - val_accuracy: 0.8528\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2371 - accuracy: 0.9110 - val_loss: 0.3581 - val_accuracy: 0.8509\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2346 - accuracy: 0.9124 - val_loss: 0.3608 - val_accuracy: 0.8547\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2346 - accuracy: 0.9103 - val_loss: 0.3638 - val_accuracy: 0.8547\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.9140 - val_loss: 0.3648 - val_accuracy: 0.8557\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.9159Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2256 - accuracy: 0.9159 - val_loss: 0.3667 - val_accuracy: 0.8575\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 85.84905862808228\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.8128 - val_loss: 0.3511 - val_accuracy: 0.8500\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.8759 - val_loss: 0.3445 - val_accuracy: 0.8632\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.8831 - val_loss: 0.3430 - val_accuracy: 0.8698\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.8879 - val_loss: 0.3391 - val_accuracy: 0.8679\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.8882 - val_loss: 0.3357 - val_accuracy: 0.8689\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.8930 - val_loss: 0.3419 - val_accuracy: 0.8726\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.8955 - val_loss: 0.3386 - val_accuracy: 0.8745\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.8966 - val_loss: 0.3367 - val_accuracy: 0.8717\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.8997 - val_loss: 0.3385 - val_accuracy: 0.8745\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2598 - accuracy: 0.8987 - val_loss: 0.3398 - val_accuracy: 0.8745\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2579 - accuracy: 0.9008 - val_loss: 0.3428 - val_accuracy: 0.8736\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.9009 - val_loss: 0.3472 - val_accuracy: 0.8764\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9038 - val_loss: 0.3435 - val_accuracy: 0.8736\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9070 - val_loss: 0.3453 - val_accuracy: 0.8755\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.9094 - val_loss: 0.3430 - val_accuracy: 0.8708\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.9088 - val_loss: 0.3466 - val_accuracy: 0.8745\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.9073 - val_loss: 0.3498 - val_accuracy: 0.8717\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2345 - accuracy: 0.9098 - val_loss: 0.3466 - val_accuracy: 0.8726\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2342 - accuracy: 0.9101 - val_loss: 0.3583 - val_accuracy: 0.8755\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.9125 - val_loss: 0.3501 - val_accuracy: 0.8736\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2290 - accuracy: 0.9153 - val_loss: 0.3525 - val_accuracy: 0.8764\n",
      "Epoch 22/40\n",
      "297/299 [============================>.] - ETA: 0s - loss: 0.2217 - accuracy: 0.9159Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2222 - accuracy: 0.9156 - val_loss: 0.3488 - val_accuracy: 0.8736\n",
      "Epoch 00022: early stopping\n",
      "Test Accuracy: 87.64150738716125\n",
      "\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5      acc6      acc7  \\\n",
      "0  87.935907  88.312912  88.689917  86.145145  88.501412  86.71065  87.73585   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  87.830186  85.849059  87.641507  87.535254  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.935907</td>\n",
       "      <td>88.312912</td>\n",
       "      <td>88.689917</td>\n",
       "      <td>86.145145</td>\n",
       "      <td>88.501412</td>\n",
       "      <td>86.71065</td>\n",
       "      <td>87.73585</td>\n",
       "      <td>87.830186</td>\n",
       "      <td>85.849059</td>\n",
       "      <td>87.641507</td>\n",
       "      <td>87.535254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5      acc6      acc7  \\\n",
       "0  87.935907  88.312912  88.689917  86.145145  88.501412  86.71065  87.73585   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  87.830186  85.849059  87.641507  87.535254  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('Emb_MLP_MPQA.xlsx', sheet_name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,201\n",
      "Trainable params: 30,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = define_model_2(300)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3894 - accuracy: 0.8276 - val_loss: 0.3543 - val_accuracy: 0.8596\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.3024 - accuracy: 0.8800 - val_loss: 0.3517 - val_accuracy: 0.8577\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.8902 - val_loss: 0.3416 - val_accuracy: 0.8662\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2778 - accuracy: 0.8939 - val_loss: 0.3426 - val_accuracy: 0.8615\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2664 - accuracy: 0.8966 - val_loss: 0.3396 - val_accuracy: 0.8615\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.8983 - val_loss: 0.3477 - val_accuracy: 0.8615\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.9029 - val_loss: 0.3445 - val_accuracy: 0.8596\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9050 - val_loss: 0.3413 - val_accuracy: 0.8586\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.9060 - val_loss: 0.3392 - val_accuracy: 0.8643\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9086 - val_loss: 0.3499 - val_accuracy: 0.8662\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2303 - accuracy: 0.9123 - val_loss: 0.3499 - val_accuracy: 0.8662\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.9124 - val_loss: 0.3509 - val_accuracy: 0.8624\n",
      "Epoch 13/40\n",
      "283/299 [===========================>..] - ETA: 0s - loss: 0.2237 - accuracy: 0.9174Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2233 - accuracy: 0.9170 - val_loss: 0.3443 - val_accuracy: 0.8624\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.6163969039917\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 0.8303 - val_loss: 0.3542 - val_accuracy: 0.8652\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3021 - accuracy: 0.8783 - val_loss: 0.3433 - val_accuracy: 0.8728\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2902 - accuracy: 0.8881 - val_loss: 0.3353 - val_accuracy: 0.8746\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.8901 - val_loss: 0.3303 - val_accuracy: 0.8765\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2707 - accuracy: 0.8948 - val_loss: 0.3301 - val_accuracy: 0.8737\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.8989 - val_loss: 0.3280 - val_accuracy: 0.8718\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.8997 - val_loss: 0.3258 - val_accuracy: 0.8756\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9020 - val_loss: 0.3269 - val_accuracy: 0.8728\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.9027 - val_loss: 0.3283 - val_accuracy: 0.8718\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.9057 - val_loss: 0.3259 - val_accuracy: 0.8746\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.9086 - val_loss: 0.3232 - val_accuracy: 0.8699\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2306 - accuracy: 0.9091 - val_loss: 0.3219 - val_accuracy: 0.8765\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2278 - accuracy: 0.9121 - val_loss: 0.3221 - val_accuracy: 0.8775\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2239 - accuracy: 0.9149 - val_loss: 0.3278 - val_accuracy: 0.8728\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2185 - accuracy: 0.9180 - val_loss: 0.3312 - val_accuracy: 0.8699\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2167 - accuracy: 0.9181 - val_loss: 0.3214 - val_accuracy: 0.8775\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2087 - accuracy: 0.9203 - val_loss: 0.3281 - val_accuracy: 0.8709\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9217 - val_loss: 0.3253 - val_accuracy: 0.8775\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2016 - accuracy: 0.9245 - val_loss: 0.3337 - val_accuracy: 0.8737\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9239 - val_loss: 0.3270 - val_accuracy: 0.8728\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9276 - val_loss: 0.3287 - val_accuracy: 0.8737\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1936 - accuracy: 0.9274 - val_loss: 0.3337 - val_accuracy: 0.8765\n",
      "Epoch 23/40\n",
      "287/299 [===========================>..] - ETA: 0s - loss: 0.1903 - accuracy: 0.9284Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1902 - accuracy: 0.9277 - val_loss: 0.3337 - val_accuracy: 0.8718\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 87.74740695953369\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3835 - accuracy: 0.8342 - val_loss: 0.3360 - val_accuracy: 0.8633\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.8786 - val_loss: 0.3273 - val_accuracy: 0.8699\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8862 - val_loss: 0.3241 - val_accuracy: 0.8680\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.8905 - val_loss: 0.3211 - val_accuracy: 0.8699\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.8920 - val_loss: 0.3198 - val_accuracy: 0.8728\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2671 - accuracy: 0.8952 - val_loss: 0.3176 - val_accuracy: 0.8728\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2607 - accuracy: 0.9001 - val_loss: 0.3199 - val_accuracy: 0.8671\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2552 - accuracy: 0.9021 - val_loss: 0.3193 - val_accuracy: 0.8699\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9040 - val_loss: 0.3216 - val_accuracy: 0.8690\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9071 - val_loss: 0.3190 - val_accuracy: 0.8718\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2376 - accuracy: 0.9091 - val_loss: 0.3209 - val_accuracy: 0.8765\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9117 - val_loss: 0.3207 - val_accuracy: 0.8671\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2308 - accuracy: 0.9152 - val_loss: 0.3223 - val_accuracy: 0.8728\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2243 - accuracy: 0.9172 - val_loss: 0.3194 - val_accuracy: 0.8737\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2233 - accuracy: 0.9139 - val_loss: 0.3216 - val_accuracy: 0.8746\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2192 - accuracy: 0.9144 - val_loss: 0.3261 - val_accuracy: 0.8690\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.9160 - val_loss: 0.3191 - val_accuracy: 0.8756\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2125 - accuracy: 0.9174 - val_loss: 0.3140 - val_accuracy: 0.8822\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9233 - val_loss: 0.3236 - val_accuracy: 0.8746\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.9251 - val_loss: 0.3235 - val_accuracy: 0.8737\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2009 - accuracy: 0.9239 - val_loss: 0.3351 - val_accuracy: 0.8728\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1973 - accuracy: 0.9257 - val_loss: 0.3240 - val_accuracy: 0.8737\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1939 - accuracy: 0.9284 - val_loss: 0.3313 - val_accuracy: 0.8690\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9278 - val_loss: 0.3296 - val_accuracy: 0.8756\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1858 - accuracy: 0.9315 - val_loss: 0.3278 - val_accuracy: 0.8812\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1810 - accuracy: 0.9322 - val_loss: 0.3338 - val_accuracy: 0.8765\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1787 - accuracy: 0.9348 - val_loss: 0.3374 - val_accuracy: 0.8737\n",
      "Epoch 28/40\n",
      "282/299 [===========================>..] - ETA: 0s - loss: 0.1767 - accuracy: 0.9343Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9340 - val_loss: 0.3398 - val_accuracy: 0.8728\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 88.21865916252136\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8301 - val_loss: 0.3468 - val_accuracy: 0.8671\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.8789 - val_loss: 0.3303 - val_accuracy: 0.8624\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2924 - accuracy: 0.8861 - val_loss: 0.3233 - val_accuracy: 0.8671\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.8891 - val_loss: 0.3218 - val_accuracy: 0.8680\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.8923 - val_loss: 0.3232 - val_accuracy: 0.8699\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.8941 - val_loss: 0.3186 - val_accuracy: 0.8680\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.8982 - val_loss: 0.3203 - val_accuracy: 0.8728\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.8987 - val_loss: 0.3192 - val_accuracy: 0.8784\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.9042 - val_loss: 0.3181 - val_accuracy: 0.8784\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.9042 - val_loss: 0.3230 - val_accuracy: 0.8765\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.9090 - val_loss: 0.3170 - val_accuracy: 0.8746\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.9083 - val_loss: 0.3198 - val_accuracy: 0.8737\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2278 - accuracy: 0.9144 - val_loss: 0.3189 - val_accuracy: 0.8728\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2253 - accuracy: 0.9135 - val_loss: 0.3211 - val_accuracy: 0.8794\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9157 - val_loss: 0.3228 - val_accuracy: 0.8765\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2211 - accuracy: 0.9158 - val_loss: 0.3254 - val_accuracy: 0.8794\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9188 - val_loss: 0.3254 - val_accuracy: 0.8765\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2118 - accuracy: 0.9215 - val_loss: 0.3274 - val_accuracy: 0.8822\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2049 - accuracy: 0.9215 - val_loss: 0.3272 - val_accuracy: 0.8765\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2001 - accuracy: 0.9232 - val_loss: 0.3390 - val_accuracy: 0.8784\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9252 - val_loss: 0.3404 - val_accuracy: 0.8812\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1920 - accuracy: 0.9294 - val_loss: 0.3449 - val_accuracy: 0.8765\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1902 - accuracy: 0.9266 - val_loss: 0.3382 - val_accuracy: 0.8756\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9287 - val_loss: 0.3376 - val_accuracy: 0.8784\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9315 - val_loss: 0.3417 - val_accuracy: 0.8775\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.9307 - val_loss: 0.3443 - val_accuracy: 0.8728\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1777 - accuracy: 0.9331 - val_loss: 0.3424 - val_accuracy: 0.8765\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.9328Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.9328 - val_loss: 0.3456 - val_accuracy: 0.8822\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 88.21865916252136\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3880 - accuracy: 0.8282 - val_loss: 0.3560 - val_accuracy: 0.8464\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8821 - val_loss: 0.3504 - val_accuracy: 0.8454\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.8880 - val_loss: 0.3460 - val_accuracy: 0.8511\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2800 - accuracy: 0.8940 - val_loss: 0.3406 - val_accuracy: 0.8549\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8943 - val_loss: 0.3457 - val_accuracy: 0.8586\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2656 - accuracy: 0.8980 - val_loss: 0.3436 - val_accuracy: 0.8577\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9001 - val_loss: 0.3403 - val_accuracy: 0.8624\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.9035 - val_loss: 0.3418 - val_accuracy: 0.8652\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.9039 - val_loss: 0.3425 - val_accuracy: 0.8624\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2445 - accuracy: 0.9057 - val_loss: 0.3434 - val_accuracy: 0.8577\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2379 - accuracy: 0.9074 - val_loss: 0.3466 - val_accuracy: 0.8586\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2322 - accuracy: 0.9130 - val_loss: 0.3457 - val_accuracy: 0.8605\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2282 - accuracy: 0.9128 - val_loss: 0.3421 - val_accuracy: 0.8624\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2266 - accuracy: 0.9134 - val_loss: 0.3440 - val_accuracy: 0.8586\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2201 - accuracy: 0.9163 - val_loss: 0.3516 - val_accuracy: 0.8615\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2183 - accuracy: 0.9192 - val_loss: 0.3541 - val_accuracy: 0.8596\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2129 - accuracy: 0.9195 - val_loss: 0.3580 - val_accuracy: 0.8596\n",
      "Epoch 18/40\n",
      "296/299 [============================>.] - ETA: 0s - loss: 0.2092 - accuracy: 0.9198Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2094 - accuracy: 0.9199 - val_loss: 0.3558 - val_accuracy: 0.8605\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 86.52215003967285\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 2s 7ms/step - loss: 0.3850 - accuracy: 0.8334 - val_loss: 0.3388 - val_accuracy: 0.8615\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.8786 - val_loss: 0.3217 - val_accuracy: 0.8728\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2907 - accuracy: 0.8873 - val_loss: 0.3184 - val_accuracy: 0.8680\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.8914 - val_loss: 0.3147 - val_accuracy: 0.8784\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2728 - accuracy: 0.8913 - val_loss: 0.3172 - val_accuracy: 0.8737\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8977 - val_loss: 0.3203 - val_accuracy: 0.8718\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2614 - accuracy: 0.8997 - val_loss: 0.3138 - val_accuracy: 0.8775\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2540 - accuracy: 0.9016 - val_loss: 0.3130 - val_accuracy: 0.8784\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2498 - accuracy: 0.9043 - val_loss: 0.3226 - val_accuracy: 0.8737\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9060 - val_loss: 0.3148 - val_accuracy: 0.8822\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2395 - accuracy: 0.9074 - val_loss: 0.3092 - val_accuracy: 0.8803\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2355 - accuracy: 0.9123 - val_loss: 0.3223 - val_accuracy: 0.8803\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2322 - accuracy: 0.9104 - val_loss: 0.3129 - val_accuracy: 0.8803\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2250 - accuracy: 0.9142 - val_loss: 0.3172 - val_accuracy: 0.8803\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2215 - accuracy: 0.9153 - val_loss: 0.3227 - val_accuracy: 0.8794\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2184 - accuracy: 0.9155 - val_loss: 0.3212 - val_accuracy: 0.8812\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2145 - accuracy: 0.9173 - val_loss: 0.3166 - val_accuracy: 0.8850\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9227 - val_loss: 0.3160 - val_accuracy: 0.8822\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2057 - accuracy: 0.9244 - val_loss: 0.3138 - val_accuracy: 0.8794\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9233 - val_loss: 0.3207 - val_accuracy: 0.8841\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1973 - accuracy: 0.9251 - val_loss: 0.3192 - val_accuracy: 0.8812\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1982 - accuracy: 0.9241 - val_loss: 0.3234 - val_accuracy: 0.8822\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1937 - accuracy: 0.9273 - val_loss: 0.3234 - val_accuracy: 0.8812\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1919 - accuracy: 0.9303 - val_loss: 0.3333 - val_accuracy: 0.8784\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9299 - val_loss: 0.3237 - val_accuracy: 0.8803\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1837 - accuracy: 0.9305 - val_loss: 0.3301 - val_accuracy: 0.8794\n",
      "Epoch 27/40\n",
      "297/299 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9295Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9289 - val_loss: 0.3395 - val_accuracy: 0.8784\n",
      "Epoch 00027: early stopping\n",
      "Test Accuracy: 88.50141167640686\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 0.3852 - accuracy: 0.8281 - val_loss: 0.3555 - val_accuracy: 0.8462\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.8785 - val_loss: 0.3453 - val_accuracy: 0.8575\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.8868 - val_loss: 0.3432 - val_accuracy: 0.8604\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8903 - val_loss: 0.3407 - val_accuracy: 0.8660\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2703 - accuracy: 0.8939 - val_loss: 0.3379 - val_accuracy: 0.8717\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2618 - accuracy: 0.9001 - val_loss: 0.3378 - val_accuracy: 0.8698\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2572 - accuracy: 0.9007 - val_loss: 0.3370 - val_accuracy: 0.8717\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.9028 - val_loss: 0.3410 - val_accuracy: 0.8642\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2432 - accuracy: 0.9049 - val_loss: 0.3396 - val_accuracy: 0.8717\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2396 - accuracy: 0.9084 - val_loss: 0.3396 - val_accuracy: 0.8764\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2365 - accuracy: 0.9103 - val_loss: 0.3398 - val_accuracy: 0.8726\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2312 - accuracy: 0.9106 - val_loss: 0.3412 - val_accuracy: 0.8689\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2256 - accuracy: 0.9144 - val_loss: 0.3434 - val_accuracy: 0.8736\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2232 - accuracy: 0.9158 - val_loss: 0.3442 - val_accuracy: 0.8670\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2184 - accuracy: 0.9167 - val_loss: 0.3452 - val_accuracy: 0.8717\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9197 - val_loss: 0.3450 - val_accuracy: 0.8689\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9209 - val_loss: 0.3437 - val_accuracy: 0.8717\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9222 - val_loss: 0.3458 - val_accuracy: 0.8689\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9232 - val_loss: 0.3509 - val_accuracy: 0.8698\n",
      "Epoch 20/40\n",
      "295/299 [============================>.] - ETA: 0s - loss: 0.2002 - accuracy: 0.9232Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9231 - val_loss: 0.3512 - val_accuracy: 0.8660\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 87.64150738716125\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 0.3904 - accuracy: 0.8274 - val_loss: 0.3502 - val_accuracy: 0.8585\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3022 - accuracy: 0.8807 - val_loss: 0.3464 - val_accuracy: 0.8670\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2870 - accuracy: 0.8856 - val_loss: 0.3421 - val_accuracy: 0.8679\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.8902 - val_loss: 0.3417 - val_accuracy: 0.8698\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2695 - accuracy: 0.8941 - val_loss: 0.3417 - val_accuracy: 0.8717\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2644 - accuracy: 0.8971 - val_loss: 0.3389 - val_accuracy: 0.8679\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2543 - accuracy: 0.9023 - val_loss: 0.3388 - val_accuracy: 0.8698\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.9049 - val_loss: 0.3370 - val_accuracy: 0.8670\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2431 - accuracy: 0.9073 - val_loss: 0.3471 - val_accuracy: 0.8660\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2391 - accuracy: 0.9085 - val_loss: 0.3424 - val_accuracy: 0.8698\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2373 - accuracy: 0.9099 - val_loss: 0.3404 - val_accuracy: 0.8698\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2288 - accuracy: 0.9151 - val_loss: 0.3418 - val_accuracy: 0.8717\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2237 - accuracy: 0.9161 - val_loss: 0.3427 - val_accuracy: 0.8745\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2207 - accuracy: 0.9171 - val_loss: 0.3472 - val_accuracy: 0.8679\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9160 - val_loss: 0.3502 - val_accuracy: 0.8660\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9203 - val_loss: 0.3487 - val_accuracy: 0.8774\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9223 - val_loss: 0.3525 - val_accuracy: 0.8736\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9224 - val_loss: 0.3469 - val_accuracy: 0.8708\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2022 - accuracy: 0.9236 - val_loss: 0.3542 - val_accuracy: 0.8689\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9242 - val_loss: 0.3500 - val_accuracy: 0.8736\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9266 - val_loss: 0.3531 - val_accuracy: 0.8726\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.1922 - accuracy: 0.9282 - val_loss: 0.3569 - val_accuracy: 0.8698\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1896 - accuracy: 0.9275 - val_loss: 0.3614 - val_accuracy: 0.8764\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1873 - accuracy: 0.9305 - val_loss: 0.3673 - val_accuracy: 0.8745\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1826 - accuracy: 0.9314 - val_loss: 0.3635 - val_accuracy: 0.8679\n",
      "Epoch 26/40\n",
      "288/299 [===========================>..] - ETA: 0s - loss: 0.1838 - accuracy: 0.9324Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1841 - accuracy: 0.9324 - val_loss: 0.3648 - val_accuracy: 0.8736\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 87.73584961891174\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 5s 17ms/step - loss: 0.3851 - accuracy: 0.8319 - val_loss: 0.3542 - val_accuracy: 0.8528\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 0.3021 - accuracy: 0.8821 - val_loss: 0.3494 - val_accuracy: 0.8566\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2897 - accuracy: 0.8886 - val_loss: 0.3478 - val_accuracy: 0.8557\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2751 - accuracy: 0.8960 - val_loss: 0.3504 - val_accuracy: 0.8557\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2697 - accuracy: 0.8955 - val_loss: 0.3514 - val_accuracy: 0.8604\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2620 - accuracy: 0.9000 - val_loss: 0.3458 - val_accuracy: 0.8585\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2557 - accuracy: 0.9009 - val_loss: 0.3497 - val_accuracy: 0.8632\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2457 - accuracy: 0.9076 - val_loss: 0.3579 - val_accuracy: 0.8547\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2415 - accuracy: 0.9087 - val_loss: 0.3557 - val_accuracy: 0.8594\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2373 - accuracy: 0.9095 - val_loss: 0.3493 - val_accuracy: 0.8660\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2331 - accuracy: 0.9099 - val_loss: 0.3533 - val_accuracy: 0.8623\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 0.2267 - accuracy: 0.9154 - val_loss: 0.3591 - val_accuracy: 0.8604\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2228 - accuracy: 0.9142 - val_loss: 0.3579 - val_accuracy: 0.8698\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 0.2195 - accuracy: 0.9177 - val_loss: 0.3602 - val_accuracy: 0.8613\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 0.2157 - accuracy: 0.9163 - val_loss: 0.3637 - val_accuracy: 0.8566\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9215 - val_loss: 0.3604 - val_accuracy: 0.8604\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9221 - val_loss: 0.3666 - val_accuracy: 0.8623\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9231 - val_loss: 0.3787 - val_accuracy: 0.8585\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9225 - val_loss: 0.3694 - val_accuracy: 0.8642\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9255 - val_loss: 0.3841 - val_accuracy: 0.8585\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1926 - accuracy: 0.9252 - val_loss: 0.3897 - val_accuracy: 0.8528\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9291 - val_loss: 0.3820 - val_accuracy: 0.8670\n",
      "Epoch 23/40\n",
      "287/299 [===========================>..] - ETA: 0s - loss: 0.1886 - accuracy: 0.9313Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1884 - accuracy: 0.9314 - val_loss: 0.3950 - val_accuracy: 0.8500\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 86.98112964630127\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 0.3847 - accuracy: 0.8329 - val_loss: 0.3449 - val_accuracy: 0.8698\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.3045 - accuracy: 0.8803 - val_loss: 0.3388 - val_accuracy: 0.8679\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2907 - accuracy: 0.8862 - val_loss: 0.3351 - val_accuracy: 0.8670\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2823 - accuracy: 0.8889 - val_loss: 0.3355 - val_accuracy: 0.8698\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.8968 - val_loss: 0.3293 - val_accuracy: 0.8689\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8964 - val_loss: 0.3329 - val_accuracy: 0.8613\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2598 - accuracy: 0.8991 - val_loss: 0.3317 - val_accuracy: 0.8642\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2554 - accuracy: 0.9029 - val_loss: 0.3321 - val_accuracy: 0.8651\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2487 - accuracy: 0.9045 - val_loss: 0.3285 - val_accuracy: 0.8670\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.9063 - val_loss: 0.3315 - val_accuracy: 0.8632\n",
      "Epoch 11/40\n",
      "289/299 [===========================>..] - ETA: 0s - loss: 0.2386 - accuracy: 0.9096Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2391 - accuracy: 0.9097 - val_loss: 0.3296 - val_accuracy: 0.8651\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 86.98112964630127\n",
      "\n",
      "\n",
      "        acc1       acc2       acc3       acc4      acc5       acc6       acc7  \\\n",
      "0  86.616397  87.747407  88.218659  88.218659  86.52215  88.501412  87.641507   \n",
      "\n",
      "       acc8      acc9     acc10       AVG  \n",
      "0  87.73585  86.98113  86.98113  87.51643  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_2(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.616397</td>\n",
       "      <td>87.747407</td>\n",
       "      <td>88.218659</td>\n",
       "      <td>88.218659</td>\n",
       "      <td>86.52215</td>\n",
       "      <td>88.501412</td>\n",
       "      <td>87.641507</td>\n",
       "      <td>87.73585</td>\n",
       "      <td>86.98113</td>\n",
       "      <td>86.98113</td>\n",
       "      <td>87.51643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4      acc5       acc6       acc7  \\\n",
       "0  86.616397  87.747407  88.218659  88.218659  86.52215  88.501412  87.641507   \n",
       "\n",
       "       acc8      acc9     acc10       AVG  \n",
       "0  87.73585  86.98113  86.98113  87.51643  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('Emb_MLP_MPQA_2.xlsx', sheet_name='model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_3(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 35,201\n",
      "Trainable params: 35,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = define_model_3(300)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "299/299 [==============================] - 2s 7ms/step - loss: 0.4129 - accuracy: 0.8118 - val_loss: 0.3339 - val_accuracy: 0.8690\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.8787 - val_loss: 0.3365 - val_accuracy: 0.8652\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2969 - accuracy: 0.8866 - val_loss: 0.3269 - val_accuracy: 0.8699\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.8937 - val_loss: 0.3227 - val_accuracy: 0.8709\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.8954 - val_loss: 0.3233 - val_accuracy: 0.8662\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2629 - accuracy: 0.8993 - val_loss: 0.3240 - val_accuracy: 0.8709\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2546 - accuracy: 0.9043 - val_loss: 0.3204 - val_accuracy: 0.8699\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 2s 7ms/step - loss: 0.2435 - accuracy: 0.9103 - val_loss: 0.3317 - val_accuracy: 0.8699\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 2s 7ms/step - loss: 0.2336 - accuracy: 0.9116 - val_loss: 0.3281 - val_accuracy: 0.8680\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2219 - accuracy: 0.9175 - val_loss: 0.3270 - val_accuracy: 0.8709\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2206 - accuracy: 0.9175 - val_loss: 0.3317 - val_accuracy: 0.8643\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9233 - val_loss: 0.3488 - val_accuracy: 0.8643\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9249 - val_loss: 0.3443 - val_accuracy: 0.8633\n",
      "Epoch 14/40\n",
      "287/299 [===========================>..] - ETA: 0s - loss: 0.2026 - accuracy: 0.9235Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9230 - val_loss: 0.3347 - val_accuracy: 0.8709\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 87.08765506744385\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 0.4204 - accuracy: 0.8083 - val_loss: 0.3399 - val_accuracy: 0.8690\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.3166 - accuracy: 0.8746 - val_loss: 0.3384 - val_accuracy: 0.8671\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2983 - accuracy: 0.8842 - val_loss: 0.3374 - val_accuracy: 0.8728\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2812 - accuracy: 0.8911 - val_loss: 0.3359 - val_accuracy: 0.8728\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.2738 - accuracy: 0.8936 - val_loss: 0.3361 - val_accuracy: 0.8718\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2595 - accuracy: 0.8998 - val_loss: 0.3424 - val_accuracy: 0.8718\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9075 - val_loss: 0.3373 - val_accuracy: 0.8662\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2370 - accuracy: 0.9106 - val_loss: 0.3526 - val_accuracy: 0.8671\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2310 - accuracy: 0.9131 - val_loss: 0.3377 - val_accuracy: 0.8756\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9180 - val_loss: 0.3605 - val_accuracy: 0.8680\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.2184 - accuracy: 0.9203 - val_loss: 0.3514 - val_accuracy: 0.8718\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2116 - accuracy: 0.9195 - val_loss: 0.3571 - val_accuracy: 0.8709\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2000 - accuracy: 0.9235 - val_loss: 0.3623 - val_accuracy: 0.8709\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1926 - accuracy: 0.9254 - val_loss: 0.3796 - val_accuracy: 0.8615\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1909 - accuracy: 0.9278 - val_loss: 0.3697 - val_accuracy: 0.8728\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1881 - accuracy: 0.9304 - val_loss: 0.3679 - val_accuracy: 0.8680\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1831 - accuracy: 0.9300 - val_loss: 0.3701 - val_accuracy: 0.8728\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1716 - accuracy: 0.9356 - val_loss: 0.3903 - val_accuracy: 0.8718\n",
      "Epoch 19/40\n",
      "288/299 [===========================>..] - ETA: 0s - loss: 0.1715 - accuracy: 0.9363Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1714 - accuracy: 0.9360 - val_loss: 0.3908 - val_accuracy: 0.8709\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 87.55890727043152\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4133 - accuracy: 0.8149 - val_loss: 0.3667 - val_accuracy: 0.8492\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3145 - accuracy: 0.8776 - val_loss: 0.3601 - val_accuracy: 0.8464\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.8874 - val_loss: 0.3505 - val_accuracy: 0.8530\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2830 - accuracy: 0.8914 - val_loss: 0.3532 - val_accuracy: 0.8586\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2709 - accuracy: 0.8973 - val_loss: 0.3544 - val_accuracy: 0.8615\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2584 - accuracy: 0.8993 - val_loss: 0.3523 - val_accuracy: 0.8643\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2542 - accuracy: 0.9065 - val_loss: 0.3548 - val_accuracy: 0.8615\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.9107 - val_loss: 0.3584 - val_accuracy: 0.8652\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2321 - accuracy: 0.9135 - val_loss: 0.3622 - val_accuracy: 0.8624\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2251 - accuracy: 0.9202 - val_loss: 0.3548 - val_accuracy: 0.8671\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2179 - accuracy: 0.9203 - val_loss: 0.3614 - val_accuracy: 0.8633\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2123 - accuracy: 0.9217 - val_loss: 0.3621 - val_accuracy: 0.8671\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2036 - accuracy: 0.9249 - val_loss: 0.3777 - val_accuracy: 0.8652\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1950 - accuracy: 0.9291 - val_loss: 0.3764 - val_accuracy: 0.8699\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1883 - accuracy: 0.9311 - val_loss: 0.3797 - val_accuracy: 0.8728\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1882 - accuracy: 0.9338 - val_loss: 0.3839 - val_accuracy: 0.8699\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1852 - accuracy: 0.9339 - val_loss: 0.3913 - val_accuracy: 0.8690\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1787 - accuracy: 0.9335 - val_loss: 0.4016 - val_accuracy: 0.8718\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9366 - val_loss: 0.3931 - val_accuracy: 0.8718\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9370 - val_loss: 0.4178 - val_accuracy: 0.8746\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9425 - val_loss: 0.4141 - val_accuracy: 0.8728\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1574 - accuracy: 0.9420 - val_loss: 0.4287 - val_accuracy: 0.8652\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9391 - val_loss: 0.4254 - val_accuracy: 0.8680\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1556 - accuracy: 0.9412 - val_loss: 0.4430 - val_accuracy: 0.8718\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1476 - accuracy: 0.9445 - val_loss: 0.4383 - val_accuracy: 0.8718\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9460 - val_loss: 0.4558 - val_accuracy: 0.8690\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9467 - val_loss: 0.4527 - val_accuracy: 0.8671\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1378 - accuracy: 0.9452 - val_loss: 0.4672 - val_accuracy: 0.8699\n",
      "Epoch 29/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1391 - accuracy: 0.9464 - val_loss: 0.4629 - val_accuracy: 0.8671\n",
      "Epoch 30/40\n",
      "294/299 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9489Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1404 - accuracy: 0.9492 - val_loss: 0.4420 - val_accuracy: 0.8671\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 87.4646544456482\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4152 - accuracy: 0.8135 - val_loss: 0.3376 - val_accuracy: 0.8633\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8725 - val_loss: 0.3220 - val_accuracy: 0.8728\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2993 - accuracy: 0.8864 - val_loss: 0.3169 - val_accuracy: 0.8709\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.8903 - val_loss: 0.3083 - val_accuracy: 0.8737\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8975 - val_loss: 0.3327 - val_accuracy: 0.8699\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2562 - accuracy: 0.9047 - val_loss: 0.3165 - val_accuracy: 0.8746\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.9046 - val_loss: 0.3157 - val_accuracy: 0.8765\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2369 - accuracy: 0.9095 - val_loss: 0.3204 - val_accuracy: 0.8737\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2294 - accuracy: 0.9146 - val_loss: 0.3304 - val_accuracy: 0.8737\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2173 - accuracy: 0.9179 - val_loss: 0.3348 - val_accuracy: 0.8709\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2190 - accuracy: 0.9230 - val_loss: 0.3423 - val_accuracy: 0.8709\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2071 - accuracy: 0.9228 - val_loss: 0.3413 - val_accuracy: 0.8765\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2026 - accuracy: 0.9245 - val_loss: 0.3487 - val_accuracy: 0.8728\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9284 - val_loss: 0.3603 - val_accuracy: 0.8662\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1898 - accuracy: 0.9299 - val_loss: 0.3619 - val_accuracy: 0.8652\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1819 - accuracy: 0.9339 - val_loss: 0.3734 - val_accuracy: 0.8596\n",
      "Epoch 17/40\n",
      "284/299 [===========================>..] - ETA: 0s - loss: 0.1782 - accuracy: 0.9317Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1777 - accuracy: 0.9317 - val_loss: 0.3724 - val_accuracy: 0.8680\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 87.65316009521484\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.8147 - val_loss: 0.3402 - val_accuracy: 0.8765\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3153 - accuracy: 0.8766 - val_loss: 0.3234 - val_accuracy: 0.8831\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.8841 - val_loss: 0.3154 - val_accuracy: 0.8869\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.8885 - val_loss: 0.3187 - val_accuracy: 0.8888\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8995 - val_loss: 0.3148 - val_accuracy: 0.8878\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.9008 - val_loss: 0.3207 - val_accuracy: 0.8841\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2516 - accuracy: 0.9076 - val_loss: 0.3150 - val_accuracy: 0.8878\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2429 - accuracy: 0.9089 - val_loss: 0.3126 - val_accuracy: 0.8850\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2359 - accuracy: 0.9100 - val_loss: 0.3235 - val_accuracy: 0.8784\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2265 - accuracy: 0.9153 - val_loss: 0.3285 - val_accuracy: 0.8822\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2226 - accuracy: 0.9175 - val_loss: 0.3275 - val_accuracy: 0.8841\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2115 - accuracy: 0.9226 - val_loss: 0.3242 - val_accuracy: 0.8812\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2087 - accuracy: 0.9254 - val_loss: 0.3272 - val_accuracy: 0.8850\n",
      "Epoch 14/40\n",
      "292/299 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9242Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2034 - accuracy: 0.9243 - val_loss: 0.3353 - val_accuracy: 0.8841\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 88.87841701507568\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8170 - val_loss: 0.3645 - val_accuracy: 0.8473\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3133 - accuracy: 0.8811 - val_loss: 0.3610 - val_accuracy: 0.8417\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.8892 - val_loss: 0.3580 - val_accuracy: 0.8483\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8946 - val_loss: 0.3522 - val_accuracy: 0.8530\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.9013 - val_loss: 0.3530 - val_accuracy: 0.8501\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2528 - accuracy: 0.9047 - val_loss: 0.3638 - val_accuracy: 0.8520\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2445 - accuracy: 0.9100 - val_loss: 0.3766 - val_accuracy: 0.8426\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2349 - accuracy: 0.9121 - val_loss: 0.3707 - val_accuracy: 0.8492\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2265 - accuracy: 0.9170 - val_loss: 0.3741 - val_accuracy: 0.8473\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2196 - accuracy: 0.9167 - val_loss: 0.3750 - val_accuracy: 0.8445\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2133 - accuracy: 0.9199 - val_loss: 0.3752 - val_accuracy: 0.8501\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2064 - accuracy: 0.9228 - val_loss: 0.3919 - val_accuracy: 0.8549\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9262 - val_loss: 0.3846 - val_accuracy: 0.8511\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1920 - accuracy: 0.9261 - val_loss: 0.4109 - val_accuracy: 0.8511\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1908 - accuracy: 0.9296 - val_loss: 0.4078 - val_accuracy: 0.8454\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1748 - accuracy: 0.9361 - val_loss: 0.4094 - val_accuracy: 0.8530\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1760 - accuracy: 0.9353 - val_loss: 0.4017 - val_accuracy: 0.8567\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9366 - val_loss: 0.4094 - val_accuracy: 0.8492\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1659 - accuracy: 0.9382 - val_loss: 0.4218 - val_accuracy: 0.8539\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9405 - val_loss: 0.4486 - val_accuracy: 0.8492\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1534 - accuracy: 0.9428 - val_loss: 0.4593 - val_accuracy: 0.8567\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1525 - accuracy: 0.9425 - val_loss: 0.4764 - val_accuracy: 0.8464\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9413 - val_loss: 0.4616 - val_accuracy: 0.8473\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1461 - accuracy: 0.9439 - val_loss: 0.4807 - val_accuracy: 0.8530\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9442 - val_loss: 0.4910 - val_accuracy: 0.8567\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1405 - accuracy: 0.9476 - val_loss: 0.4741 - val_accuracy: 0.8520\n",
      "Epoch 27/40\n",
      "286/299 [===========================>..] - ETA: 0s - loss: 0.1403 - accuracy: 0.9480Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1420 - accuracy: 0.9475 - val_loss: 0.4666 - val_accuracy: 0.8483\n",
      "Epoch 00027: early stopping\n",
      "Test Accuracy: 85.67389249801636\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.8113 - val_loss: 0.3295 - val_accuracy: 0.8632\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8749 - val_loss: 0.3143 - val_accuracy: 0.8783\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2990 - accuracy: 0.8870 - val_loss: 0.3072 - val_accuracy: 0.8792\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2830 - accuracy: 0.8940 - val_loss: 0.3007 - val_accuracy: 0.8840\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2735 - accuracy: 0.8943 - val_loss: 0.2975 - val_accuracy: 0.8811\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2597 - accuracy: 0.9019 - val_loss: 0.2959 - val_accuracy: 0.8887\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2514 - accuracy: 0.9028 - val_loss: 0.2943 - val_accuracy: 0.8802\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2452 - accuracy: 0.9080 - val_loss: 0.3014 - val_accuracy: 0.8811\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2344 - accuracy: 0.9087 - val_loss: 0.3003 - val_accuracy: 0.8868\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2268 - accuracy: 0.9147 - val_loss: 0.2975 - val_accuracy: 0.8868\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2211 - accuracy: 0.9149 - val_loss: 0.2953 - val_accuracy: 0.8792\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2123 - accuracy: 0.9186 - val_loss: 0.3026 - val_accuracy: 0.8764\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2036 - accuracy: 0.9235 - val_loss: 0.3061 - val_accuracy: 0.8849\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1978 - accuracy: 0.9249 - val_loss: 0.3139 - val_accuracy: 0.8858\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1831 - accuracy: 0.9298 - val_loss: 0.3255 - val_accuracy: 0.8830\n",
      "Epoch 16/40\n",
      "296/299 [============================>.] - ETA: 0s - loss: 0.1857 - accuracy: 0.9306Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1854 - accuracy: 0.9308 - val_loss: 0.3244 - val_accuracy: 0.8774\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 88.86792659759521\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4152 - accuracy: 0.8123 - val_loss: 0.3392 - val_accuracy: 0.8519\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.3177 - accuracy: 0.8781 - val_loss: 0.3358 - val_accuracy: 0.8557\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2972 - accuracy: 0.8834 - val_loss: 0.3271 - val_accuracy: 0.8623\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.8906 - val_loss: 0.3279 - val_accuracy: 0.8575\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.8967 - val_loss: 0.3230 - val_accuracy: 0.8623\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.9004 - val_loss: 0.3254 - val_accuracy: 0.8623\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2512 - accuracy: 0.9049 - val_loss: 0.3229 - val_accuracy: 0.8679\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.9098 - val_loss: 0.3210 - val_accuracy: 0.8670\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2342 - accuracy: 0.9146 - val_loss: 0.3342 - val_accuracy: 0.8623\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2276 - accuracy: 0.9160 - val_loss: 0.3330 - val_accuracy: 0.8651\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2136 - accuracy: 0.9215 - val_loss: 0.3360 - val_accuracy: 0.8660\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2083 - accuracy: 0.9259 - val_loss: 0.3396 - val_accuracy: 0.8604\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9258 - val_loss: 0.3415 - val_accuracy: 0.8660\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1992 - accuracy: 0.9263 - val_loss: 0.3459 - val_accuracy: 0.8623\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1888 - accuracy: 0.9313 - val_loss: 0.3477 - val_accuracy: 0.8651\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1872 - accuracy: 0.9304 - val_loss: 0.3529 - val_accuracy: 0.8679\n",
      "Epoch 17/40\n",
      "295/299 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9349Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.1755 - accuracy: 0.9346 - val_loss: 0.3628 - val_accuracy: 0.8623\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 86.79245114326477\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8065 - val_loss: 0.3483 - val_accuracy: 0.8689\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8773 - val_loss: 0.3403 - val_accuracy: 0.8670\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.8867 - val_loss: 0.3487 - val_accuracy: 0.8642\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.8923 - val_loss: 0.3415 - val_accuracy: 0.8679\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8959 - val_loss: 0.3319 - val_accuracy: 0.8755\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2562 - accuracy: 0.9003 - val_loss: 0.3424 - val_accuracy: 0.8736\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2480 - accuracy: 0.9063 - val_loss: 0.3362 - val_accuracy: 0.8811\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2390 - accuracy: 0.9105 - val_loss: 0.3280 - val_accuracy: 0.8868\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2313 - accuracy: 0.9127 - val_loss: 0.3368 - val_accuracy: 0.8792\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2249 - accuracy: 0.9147 - val_loss: 0.3389 - val_accuracy: 0.8783\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2169 - accuracy: 0.9177 - val_loss: 0.3418 - val_accuracy: 0.8821\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9216 - val_loss: 0.3491 - val_accuracy: 0.8811\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1981 - accuracy: 0.9246 - val_loss: 0.3558 - val_accuracy: 0.8774\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9282 - val_loss: 0.3616 - val_accuracy: 0.8830\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.9253 - val_loss: 0.3706 - val_accuracy: 0.8736\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.9282 - val_loss: 0.3771 - val_accuracy: 0.8802\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.9334 - val_loss: 0.3679 - val_accuracy: 0.8821\n",
      "Epoch 18/40\n",
      "289/299 [===========================>..] - ETA: 0s - loss: 0.1716 - accuracy: 0.9372Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9368 - val_loss: 0.3931 - val_accuracy: 0.8811\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 88.67924809455872\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.4164 - accuracy: 0.8123 - val_loss: 0.3559 - val_accuracy: 0.8594\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3095 - accuracy: 0.8790 - val_loss: 0.3474 - val_accuracy: 0.8604\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.8881 - val_loss: 0.3431 - val_accuracy: 0.8651\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8940 - val_loss: 0.3372 - val_accuracy: 0.8632\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.8997 - val_loss: 0.3428 - val_accuracy: 0.8670\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2574 - accuracy: 0.9039 - val_loss: 0.3430 - val_accuracy: 0.8651\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2467 - accuracy: 0.9066 - val_loss: 0.3426 - val_accuracy: 0.8708\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2389 - accuracy: 0.9093 - val_loss: 0.3402 - val_accuracy: 0.8698\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2291 - accuracy: 0.9163 - val_loss: 0.3386 - val_accuracy: 0.8708\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9182 - val_loss: 0.3472 - val_accuracy: 0.8670\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2162 - accuracy: 0.9193 - val_loss: 0.3515 - val_accuracy: 0.8585\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2074 - accuracy: 0.9230 - val_loss: 0.3391 - val_accuracy: 0.8698\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9292 - val_loss: 0.3587 - val_accuracy: 0.8698\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1968 - accuracy: 0.9289 - val_loss: 0.3437 - val_accuracy: 0.8755\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1906 - accuracy: 0.9309 - val_loss: 0.3644 - val_accuracy: 0.8708\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9330 - val_loss: 0.3681 - val_accuracy: 0.8670\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1812 - accuracy: 0.9324 - val_loss: 0.3539 - val_accuracy: 0.8642\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9347 - val_loss: 0.3683 - val_accuracy: 0.8651\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1669 - accuracy: 0.9395 - val_loss: 0.3702 - val_accuracy: 0.8651\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9384 - val_loss: 0.3741 - val_accuracy: 0.8774\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1666 - accuracy: 0.9368 - val_loss: 0.3735 - val_accuracy: 0.8670\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1564 - accuracy: 0.9424 - val_loss: 0.3795 - val_accuracy: 0.8670\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9421 - val_loss: 0.4065 - val_accuracy: 0.8623\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1517 - accuracy: 0.9429 - val_loss: 0.4090 - val_accuracy: 0.8717\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1464 - accuracy: 0.9446 - val_loss: 0.4101 - val_accuracy: 0.8679\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1442 - accuracy: 0.9432 - val_loss: 0.4051 - val_accuracy: 0.8679\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9483 - val_loss: 0.4198 - val_accuracy: 0.8660\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1403 - accuracy: 0.9448 - val_loss: 0.4281 - val_accuracy: 0.8670\n",
      "Epoch 29/40\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9481 - val_loss: 0.4157 - val_accuracy: 0.8698\n",
      "Epoch 30/40\n",
      "278/299 [==========================>...] - ETA: 0s - loss: 0.1361 - accuracy: 0.9491Restoring model weights from the end of the best epoch.\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9496 - val_loss: 0.4305 - val_accuracy: 0.8764\n",
      "Epoch 00030: early stopping\n",
      "Test Accuracy: 87.73584961891174\n",
      "\n",
      "\n",
      "        acc1       acc2       acc3      acc4       acc5       acc6       acc7  \\\n",
      "0  87.087655  87.558907  87.464654  87.65316  88.878417  85.673892  88.867927   \n",
      "\n",
      "        acc8       acc9     acc10        AVG  \n",
      "0  86.792451  88.679248  87.73585  87.639216  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Define the word_index\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_3(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.087655</td>\n",
       "      <td>87.558907</td>\n",
       "      <td>87.464654</td>\n",
       "      <td>87.65316</td>\n",
       "      <td>88.878417</td>\n",
       "      <td>85.673892</td>\n",
       "      <td>88.867927</td>\n",
       "      <td>86.792451</td>\n",
       "      <td>88.679248</td>\n",
       "      <td>87.73585</td>\n",
       "      <td>87.639216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3      acc4       acc5       acc6       acc7  \\\n",
       "0  87.087655  87.558907  87.464654  87.65316  88.878417  85.673892  88.867927   \n",
       "\n",
       "        acc8       acc9     acc10        AVG  \n",
       "0  86.792451  88.679248  87.73585  87.639216  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('Emb_MLP_MPQA_3.xlsx', sheet_name='model_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
